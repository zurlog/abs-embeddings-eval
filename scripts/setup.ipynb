{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## **Setup**"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Python â‰¥3.5 is required\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","\n","# Common imports\n","import numpy as np\n","import os\n","import time\n","import memory_profiler\n","import pandas as pd\n","import random\n","import time\n","from IPython.display import HTML\n","\n","# scikit-learn\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold, cross_validate, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.dummy import DummyClassifier\n","\n","# NLP imports\n","import re\n","import transformers\n","from datasets import Dataset, ClassLabel, load_dataset, Features, Value\n","import torch\n","\n","# Transformers\n","from transformers import AutoTokenizer, AutoModel, AutoAdapterModel\n","\n","\n","# to make this notebook's output stable across runs\n","np.random.seed(42)\n","\n","# To plot pretty figures\n","%matplotlib inline \n","import matplotlib as mpl \n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","from plotly.offline import iplot\n","import plotly.express as px\n","\n","import seaborn as sns\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)\n","\n","# Where to save the data, results and images\n","ROOT_DIR = \"../\"\n","\n","DATA_PATH = os.path.join(ROOT_DIR, \"data\")\n","os.makedirs(DATA_PATH, exist_ok=True)\n","\n","RESULTS_PATH = os.path.join(ROOT_DIR, \"results\")\n","os.makedirs(RESULTS_PATH, exist_ok=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## **Few Functions**"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["@torch.no_grad()\n","def generate_embeddings(abstracts, tokenizer, model, device):\n","    \"\"\"\n","    Generate embeddings using BERT-based model.\n","\n","    Args:\n","    abstracts : list\n","        Abstract texts.\n","    tokenizer : transformers.models.bert.tokenization_bert_fast.BertTokenizerFast\n","        Tokenizer.\n","    model : transformers.models.bert.modeling_bert.BertModel\n","        BERT-based model.\n","    device : str, {\"cuda\", \"cpu\"}\n","        \"cuda\" if torch.cuda.is_available() else \"cpu\".\n","        \n","    Returns:\n","    embedding_cls : ndarray\n","        [CLS] tokens of the abstracts.\n","    embedding_sep : ndarray\n","        [SEP] tokens of the abstracts.\n","    embedding_av : ndarray\n","        Average of tokens of the abstracts.\n","    \"\"\"\n","    \n","    # preprocess the input\n","    inputs = tokenizer(\n","        abstracts,\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\",\n","        max_length=512,\n","    ).to(device)\n","\n","    # inference\n","    outputs = model(**inputs, output_hidden_states=True) \n","    last_hidden = outputs.hidden_states[-1].cpu().detach() \n","    second_last = outputs.hidden_states[-2].cpu().detach() \n","    \n","    embedding_av = torch.mean(second_last[:,1:-1,:],[0,1]).numpy()\n","    embedding_sep = last_hidden[:, -1, :].numpy()\n","    embedding_cls = last_hidden[:, 0, :].numpy()\n","\n","    \n","    return embedding_cls, embedding_sep, embedding_av"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def knn_accuracy(selected_embeddings, true_labels, k=10, rs=42, **kwargs):\n","    \"\"\"\n","    Calculate k-NN classification accuracy using cross-validation.\n","\n","    This function calculates the k-NN classification accuracy using cross-validation with the specified number of\n","    neighbors (k) and a random seed (rs). The k-NN model is trained and tested on the provided selected_embeddings and\n","    true_labels.\n","\n","    Parameters\n","    ----------\n","    selected_embeddings : array-like\n","        The input embeddings to be used for classification.\n","    true_labels : array-like\n","        Array of labels corresponding to the selected_embeddings records.\n","    k : int, default=10\n","        Number of folds/splits to use in k-fold cross-validation.\n","    rs : int, default=42\n","        Random seed for reproducibility.\n","    **kwargs : key=value, optional\n","        Optional keyword arguments to be passed to the kNN classifier.\n","\n","    Returns\n","    -------\n","    dict\n","    A dictionary containing the kNN CV accuracy and balanced accuracy on the provided embeddings set.\n","        The dictionary has the following keys:\n","                - 'accuracy': The average accuracy across all folds.\n","                - 'balanced_accuracy': The average balanced accuracy across all folds.\n","    \"\"\"\n","\n","    # Set the random seed\n","    random_state = np.random.seed(rs)\n","\n","    # Convert selected_embeddings to a NumPy array with proper shape\n","    feature_mat = np.array(selected_embeddings.tolist())\n","\n","    # Create StratifiedKFold object\n","    kf = StratifiedKFold(n_splits=k, random_state=rs, shuffle=True)\n","\n","    # Instantiate a k-NN model\n","    knn = KNeighborsClassifier(n_neighbors=10, algorithm='auto', weights='distance', metric='cosine', n_jobs=-1)\n","    knn = knn.set_params(**kwargs)\n","\n","    # Define the scoring metrics\n","    scoring_metrics = ('accuracy', 'balanced_accuracy')\n","\n","    # Perform cross-validation and calculate the scores\n","    scores = cross_validate(knn, X=feature_mat, y=true_labels, scoring=scoring_metrics, cv=kf, n_jobs=-1)\n","\n","    # Create a dictionary to store the accuracy scores\n","    accuracy_dict = {'accuracy': scores['test_accuracy'].mean(), 'balanced_accuracy': scores['test_balanced_accuracy'].mean(),\n","                     'accuracy_std': scores['test_accuracy'].std() * 2, 'balanced_accuracy_std': scores['test_balanced_accuracy'].std() * 2}\n","\n","    return accuracy_dict\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def compare_embeddings(embeddings_all, y, k, strategy, tables=None, save=False, **kwargs):\n","    \"\"\"\n","    Compares different sets of embeddings using kNN accuracy and balanced accuracy.\n","\n","    Parameters\n","    ----------\n","    embeddings_all : iterable\n","        Iterable containing different sets of embeddings to compare.\n","    y : pd.Series\n","        Pandas Series containing the labels.\n","    k : int\n","        Positive integer controlling the number of splits in k-fold cross-validation.\n","    strategy : str\n","        String indicating the embedding extraction strategy to use ('[CLS]' or '[SEP]' or 'AVG').\n","    tables : tuple or list of pd.DataFrame, optional\n","        Tuple or list of DataFrames containing pre-existing tables for accuracy and balanced accuracy.\n","        If None, new tables will be created.\n","    save : bool, default=False\n","        Whether to save the accuracy and balanced accuracy tables to CSV files.\n","    **kwargs : dict, optional\n","        Optional keyword arguments to be passed to the knn_accuracy function.\n","\n","    Returns\n","    -------\n","    pd.DataFrame, pd.DataFrame\n","        Two DataFrames containing the accuracy and balanced accuracy scores, respectively.\n","\n","    Note\n","    ----\n","    - embeddings_all must be an iterable.\n","    - y must be a pd.Series.\n","    - k is a positive integer controlling the number of k-fold splits.\n","    - strategy must be a string either '[CLS]' or '[SEP]' or 'AVG'.\n","    - tables must be a tuple or list of DataFrames.\n","\n","    \"\"\"\n","\n","    model_names = [model.replace('_',' ') for model in models_norm]\n","\n","    if tables is None:\n","        # Create new tables for accuracy and balanced accuracy\n","        accuracy = pd.DataFrame(index=model_names, columns=['[CLS]', '[SEP]', 'AVG'])\n","        balanced_acc = pd.DataFrame(index=model_names, columns=['[CLS]', '[SEP]', 'AVG'])\n","    else:\n","        # Use pre-existing tables for accuracy and balanced accuracy\n","        accuracy = tables[0]\n","        balanced_acc = tables[1]\n","\n","    for i, embeddings in enumerate(embeddings_all):\n","        # Calculate kNN accuracy and balanced accuracy for each set of embeddings\n","        results = knn_accuracy(embeddings, y, k=k, **kwargs)\n","        accuracy.at[model_names[i], strategy] = results['accuracy']\n","        balanced_acc.at[model_names[i], strategy] = results['balanced_accuracy']\n","\n","    label = y.name\n","    if save:\n","        # Save accuracy and balanced accuracy tables to CSV files\n","        accuracy.to_csv(os.path.join(RESULTS_PATH, f'{label}_accuracy.csv'))\n","        balanced_acc.to_csv(os.path.join(RESULTS_PATH, f'{label}_balanced_acc.csv'))\n","\n","    return accuracy, balanced_acc\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def chance_knn_accuracy(Zs, true_labels, k=10, rs=42, **kwargs):\n","    \"\"\"Chance kNN accuracy.\n","    Calculate chance scores for a given set of embeddings and true_labels, using cross-validation.\n","    Note that the dataset does not really matter since the dummy classifier does not look for neighbors but just randomly draws one of the labels as prediction.\n","    For efficiency, you could just provide one embeddings set from any of the models.\n","\n","    Parameters\n","    ----------\n","    Zs : list of array-like\n","        List with the different datasets for which to calculate the chance accuracy.\n","    true_labels : array-like\n","        Array with labels.\n","    k : int, default=10\n","        The number of splits in the stratified k-fold cross-validation.\n","    rs : int, default=42\n","        Random seed for reproducibility.\n","    **kwargs : dict, optional\n","        Optional keyword arguments to be passed to the DummyClassifier object.\n","    \n","    Returns\n","    -------\n","    chance_dict : dict\n","        A dictionary containing the chance scores for 'accuracy', 'ba' (balanced accuracy),\n","        'accuracy_std' (standard deviation of accuracy), and 'balanced_accuracy_std'\n","        (standard deviation of balanced accuracy) across all folds.\n","    \"\"\"\n","    \n","    accs=[]\n","    baccs=[]\n","    accs_sd=[]\n","    baccs_sd=[]\n","    \n","    for i, Xrp in enumerate(Zs):\n","        # Convert selected_embeddings to a NumPy array with proper shape\n","        feature_mat = np.array(Xrp.tolist())\n","\n","        # Create StratifiedKFold object\n","        np.random.seed(rs)\n","        kf = StratifiedKFold(n_splits=k, random_state=rs, shuffle=True)\n","\n","        # Instantiate a DummyClassifier object \n","        dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=rs)\n","        dummy_clf.set_params(**kwargs)\n","\n","        # Define the scoring metrics\n","        scoring_metrics = ('accuracy', 'balanced_accuracy')\n","\n","        # Perform cross-validation and calculate the scores\n","        scores = cross_validate(dummy_clf, X=feature_mat, y=true_labels, scoring=scoring_metrics, cv=kf, n_jobs=-1)\n","\n","        acc = scores['test_accuracy'].mean()\n","        bacc = scores['test_balanced_accuracy'].mean()\n","        acc_sd = scores['test_accuracy'].std() * 2\n","        bacc_sd = scores['test_balanced_accuracy'].std() *2\n","        accs.append(acc)\n","        baccs.append(bacc)\n","        accs_sd.append(acc_sd)\n","        baccs_sd.append(bacc_sd)\n","\n","    # Create a dictionary to store the chance scores\n","    chance_dict = {'accuracy': np.mean(accs), 'ba': np.mean(baccs),\n","                   'accuracy_std': np.mean(accs_sd), 'ba_std': np.mean(baccs_sd)}\n","\n","    return chance_dict"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def df_display(df, title, decimals = 3, highlight = False):\n","    \"\"\"\n","    Display a pandas DataFrame with specified formatting options and optionally highlight max and min values.\n","\n","    Parameters:\n","        df (pandas.DataFrame): The DataFrame to display.\n","        title (str): The title to be displayed as the caption for the table.\n","        decimals (int, optional): The number of decimal places to display. Default is 3.\n","        highlight (bool, optional): If True, highlight the maximum and minimum column-wise values in the DataFrame. Default is False.\n","\n","    Returns:\n","        pandas.io.formats.style.Styler: A Styler object with the specified formatting and, optionally, highlighted values.\n","    \"\"\"\n","\n","    # Create a style object with the specified formatting options\n","    style = (\n","        df.style\n","        .set_caption(title)                                                             # Set the caption for the table\n","        .set_precision(decimals)                                                        # Set the number of decimal places to display\n","        .set_properties(**{'font-size': '13pt'})                                        # Set the font size for the cells\n","        .set_table_styles([{'selector': 'caption', 'props': [('font-size', '14pt')]}])  # Set the font size for the caption\n","    )\n","    \n","    # If highlight is True, apply the highlight_max and highlight_min methods to the style object\n","    if highlight:\n","        style = style.highlight_max(axis=0, color='#90EE90').highlight_min(axis=0, color='#FFB6C1')\n","        \n","    return style"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
