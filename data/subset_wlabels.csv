System ID,DOI,Latest Version,PMCID,PMID,Pub Year,Publication Date,Publication Types,Source,Peer_Review,Title,Cleaned_Abs,Lenght_Abs,Condition,Total Citations,Journal Name,Visualization Categories,influence_score,popularity_alt_score,popularity_score,influence_alt_score,tweets_count,Data_origin,Task_(primary),Modality
10.1101/2020.03.26.20044610,10.1101/2020.03.26.20044610,Yes,,,2020,2020-03-31,Preprint,medRxiv,0,the diagnostic evaluation of convolutional neural network (cnn) for the assessment of chest x-ray of patients infected with covid-19,"The main target of COVID-19 is the lungs where it may cause pneumonia in severely ill patients. Chest X-ray is an important diagnostic test to assess the lung for the damaging effects of COVID-19. Many other microbial pathogens can also cause damage to lungs leading to pneumonia but there are certain radiological features which can favor the diagnosis of pneumonia caused by COVID-19. With the rising number of cases of COVID-19, it would be imperative to develop computer programs which may assist the health professionals in the prevailing scenario. A total of two hundred and seventy eight images of chest X-rays have been assessed by applying ResNet-50 convolutional neural network architectures in the present study. The digital images were acquired from the public repositories provided by University of Montreal and National Institutes of Health. These digital images of Chest X-rays were divided into three groups labeled as normal, pneumonia and COVID-19. The third group contains digital images of chest X-rays of patients diagnosed with COVID-19 infection while the second group contains images of lung with pneumonia caused by other pathogens. The radiological images included in the data set are 89 images of lungs with COVID-19 infection, 93 images of lungs without any radiological abnormality and 96 images of patient with pneumonia caused by other pathogens. In this data set, 80% of the images were employed for training, and 20% for testing. A pre-trained (on ImageNet data set) ResNet-50 architecture was used to diagnose the cases of COVID-19 infections on lung X-ray images. The analysis of the data revealed that computer vision based program achieved diagnostic accuracy of 98.18 %, and F1-score of 98.19. The performance of convolutional neural network regarding the differentiation of pulmonary changes caused by COVID-19 from the other type of pneumonias on digital images of the chest X-rays is excellent and it may be an extremely useful adjunct tool for the health professionals.",316,COVID-19;Infections;Pneumonia,,,Diagnostic Tests;Architecture;COVID-19 Testing,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.03.28.20046045,10.1101/2020.03.28.20046045,Yes,,,2020,2020-03-30,Preprint,medRxiv,0,deep learning-based recognizing covid-19 and other common infectious diseases of the lung by chest ct scan images,"COVID-19 has become global threaten. CT acts as an important method of diagnosis. However, human-based interpretation of CT imaging is time consuming. More than that, substantial inter-observer-variation cannot be ignored. We aim at developing a diagnostic tool for artificial intelligence (AI)-based classification of CT images for recognizing COVID-19 and other common infectious diseases of the lung. In this study, images were retrospectively collected and prospectively analyzed using machine learning. CT scan images of the lung that show or do not show COVID-19 were used to train and validate a classification framework based on convolutional neural network. Five conditions including COVID-19 pneumonia, non-COVID-19 viral pneumonia, bacterial pneumonia, pulmonary tuberculosis, and normal lung were evaluated. Training and validation set of images were collected from Wuhan Jin Yin-Tan Hospital whereas test set of images were collected from Zhongshan Hospital Xiamen University and the fifth Hospital of Wuhan. Accuracy, sensitivity, and specificity of the AI framework were reported. For test dataset, accuracies for recognizing normal lung, COVID-19 pneumonia, non-COVID-19 viral pneumonia, bacterial pneumonia, and pulmonary tuberculosis were 99.4%, 98.8%, 98.5%, 98.3%, and 98.6%, respectively. For the test dataset, accuracy, sensitivity, specificity, PPV, and NPV of recognizing COVID-19 were 98.8%, 98.2%, 98.9%, 94.5%, and 99.7%, respectively. The performance of the proposed AI framework has excellent performance of recognizing COVID-19 and other common infectious diseases of the lung, which also has balanced sensitivity and specificity.",229,"COVID-19;Communicable Diseases;Pneumonia;Pneumonia, Bacterial;Pneumonia, Viral;Tuberculosis, Pulmonary",,,Other Topics,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,CT
10.1101/2020.04.13.20063461,10.1101/2020.04.13.20063461,Yes,,,2020,2020-04-17,Preprint,medRxiv,0,accurate prediction of covid-19 using chest x-ray images through deep feature learning model with smote and machine learning classifiers,"According to the World Health Organization (WHO), the coronavirus (COVID-19) pandemic is putting even the best healthcare systems across the world under tremendous pressure. The early detection of this type of virus will help in relieving the pressure of the healthcare systems. Chest X-rays has been playing a crucial role in the diagnosis of diseases like Pneumonia. As COVID-19 is a type of influenza, it is possible to diagnose using this imaging technique. With rapid development in the area of Machine Learning (ML) and Deep learning, there had been intelligent systems to classify between Pneumonia and Normal patients. This paper proposes the machine learning-based classification of the extracted deep feature using ResNet152 with COVID-19 and Pneumonia patients on chest X-ray images. SMOTE is used for balancing the imbalanced data points of COVID-19 and Normal patients. This non-invasive and early prediction of novel coronavirus (COVID-19) by analyzing chest X-rays can further be used to predict the spread of the virus in asymptomatic patients. The model is achieving an accuracy of 0.973 on Random Forest and 0.977 using XGBoost predictive classifiers. The establishment of such an approach will be useful to predict the outbreak early, which in turn can aid to control it effectively.",202,"COVID-19;COVID-19 Pandemic;Influenza, Human;Pneumonia",,,World Health Organization;Health Care;Disease Outbreaks;Random Forest,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.04.13.20063479,10.1101/2020.04.13.20063479,Yes,,,2020,2020-04-17,Preprint,medRxiv,0,machine learning analysis of chest ct scan images as a complementary digital test of coronavirus (covid-19) patients,"This paper reports on the development and performance of machine learning schemes for the analysis of Chest CT Scan images of Coronavirus COVID-19 patients and demonstrates significant success in efficiently and automatically testing for COVID-19 infection. In particular, an innovative frequency domain algorithm, to be called FFT-Gabor scheme, will be shown to predict in almost real-time the state of the patient with an average accuracy of 95.37%, sensitivity 95.99% and specificity 94.76%. The FFT-Gabor scheme is adequately informative in that clinicians can visually examine the FFT-Gabor feature to support their final diagnostic.The proposed FFT-Gabor scheme is an automatic machine learning scheme that works in real time and achieves significantly high accuracy with very low false negative, and can provide supporting evidences of the predicted decision by visually displaying the final features upon which decision is made. This scheme will be most beneficial when used in addition to the RT-PCR swab test of non-symptomatic cases.",154,COVID-19;Infections,,,Coronavirus Infections;Polymerase Chain Reaction,,,,,,External,2. Detection/Diagnosis,CT
10.1101/2020.04.14.20065722,10.1101/2020.04.14.20065722,Yes,,,2020,2020-04-17,Preprint,medRxiv,0,coronet: a deep network architecture for semi-supervised task-based identification of covid-19 from chest x-ray images,"In late 2019, a new Coronavirus disease, referred to as Corona virus disease 2019 (COVID-19), emerged in Wuhan city, Hubei, China, and resulted in a global pandemic, claiming a large number of lives and affecting billions all around the world. The current global standard used in diagnosis of COVID-19 in suspected cases is the real-time polymerase chain reaction (RT-PCR) test. Although the RT-PCR remains the standard reference for diagnosis purposes, it is a time-consuming and expensive test, and moreover, it usually suffers from high rates of false-negatives. Several early works have reported that the sensitivity of the chest Computed Tomography (CT) and the chest X-ray imaging are noticeably greater than that of the RT-PCR test at the initial representations of the disease, making them great candidates for developing new and sophisticated methodologies for analysis and classification of COVID-19 cases. In this paper, we establish the use of a rapid, non-invasive and cost-effective X-ray-based method as a key diagnosis and screening tool for COVID-19 at early and intermediate stages of the disease. To this end, we develop a novel and sophisticated deep learning-based signal and image processing technique as well as classification methodology for analyzing X-ray images specific to COVID-19 disease. Specifically, we consider a semi-supervised learning methodology based on AutoEncoders to first extract the infected legions in chest X-ray manifestation of COVID-19 and other Pneumonia-like diseases (as well as healthy cases). Then, we utilize this highly-tailored deep architecture to extract the relevant features specific to each class (i.e., healthy, non-COVID pneumonia, and COVID-19) and train a powerful yet efficient classifier to perform the task of automatic diagnosis. Furthermore, the semi-supervised nature of the proposed framework enables us to efficiently exploit the limited available dataset on COVID-19 while exploiting the vast amount of available X-ray dataset for healthy and non-COVID classes. Moreover, such a semi-supervised approach does not require an expert-annotated lesion area for each class. Our numerical investigations demonstrate that the proposed framework outperforms the state-of-the-art methods for COVID-19 identification while employing approximately ten times fewer training parameters as compared to other existing methodologies for classification of the COVID-19 from X-ray images (facilitating efficient training in a limited data regime). We further develop explainable artificial intelligence tools that can explain the diagnosis by using attribution maps while providing an indispensable tool for the radiologist in triage state. We have made the codes of our proposed framework publicly available to the research and healthcare community1.",404,COVID-19;Pneumonia;Virus Diseases,,,Semi-supervised Learning;Art;Health Care;Architecture;Health;Polymerase Chain Reaction;Tomography;Other Topics;Real-Time Polymerase Chain Reaction;Map,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.04.21.20072637,10.1101/2020.04.21.20072637,Yes,,,2020,2020-04-25,Preprint,medRxiv,0,research on cnn-based models optimized by genetic algorithm and application in the diagnosis of pneumonia and covid-19,"In this research, an optimized deep learning method was proposed to explore the possibility and practicality of neural network applications in medical imaging. The method was used to achieve the goal of judging common pneumonia and even COVID-19 more effectively. Where, the genetic algorithm was taken advantage to optimize the Dropout module, which is essential in neural networks so as to improve the performance of typical neural network models. The experiment results demonstrate that the proposed method shows excellent performance and strong practicability in judging pneumonia, and the application of advanced artificial intelligence technology in the field of medical imaging has broad prospects.",103,COVID-19;Pneumonia,,,Neural Networks;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.04.24.20078998,10.1101/2020.04.24.20078998,Yes,,,2020,2020-05-03,Preprint,medRxiv,0,automated diagnosis of covid-19 using deep learning and data augmentation on chest ct,"Coronavirus disease 2019 (COVID-19) has surprised the world since the beginning of 2020, and the rapid growth of COVID-19 is beyond the capability of doctors and hospitals that could deal in many areas. The chest computed tomography (CT) could be served as an effective tool in detection of COVID-19. It is valuable to develop automatic detection of COVID-19. The collected dataset consisted of 1042 chest CT images (including 521 COVID-19, 397 healthy, 76 bacterial pneumonia and 48 SARS) obtained by exhaustively searching available data on the Internet. Then, these data are divided into three sets, referred to training set, validation set and testing set. Sixteen data augmentation operations are designed to enrich the training set in deep learning training phase. Multiple experiments were conducted to analyze the performance of the model in the detection of COVID-19 both in case of no noisy labels and noisy labels. The performance was assessed by the AUC, sensitivity, specificity and accuracy. The data augmentation operations on the training set are effective for improvement of the model performance. The AUC is 0.9689 with in case of no noisy labels for the classification of COVID-19 from heathy subject, while the per-exam sensitivity, specificity and accuracy for detecting COVID-19 in the independent testing set are 90.52%, 91.58% and 91.21%, respectively. In the classification of COVID-19 from other hybrid cases, the average AUC of the proposed model is 0.9222 with if there are no noisy labels. The model is also robust when part of the training samples is marked incorrectly. The average AUC is 92.23% in the case of noisy labels of 10% in the training set. A deep learning model with insufficient samples can be developed by using data augmentation in assisting medical workers in making quick and correct diagnosis of COVID-19.",295,"COVID-19;Pneumonia, Bacterial",,,Other Topics,,,,,,External,2. Detection/Diagnosis,CT
10.1101/2020.04.27.20081984,10.1101/2020.04.27.20081984,Yes,,,2020,2020-05-03,Preprint,medRxiv,0,distinguishing l and h phenotypes of covid-19 using a single x-ray image,"Recent observations have shown that there are two types of COVID-19 response: an H phenotype with high lung elastance and weight, and an L phenotype with low measures1. H-type patients have pneumonia-like thickening of the lungs and require ventilation to survive; L-type patients have clearer lungs that may be injured by mechanical assistance2,3. As treatment protocols differ between the two types, and the number of ventilators is limited, it is vital to classify patients appropriately. To date, the only way to confirm phenotypes is through high-resolution computed tomography2. Here, we identify L- and H-type patients from their frontal chest x-rays using feature-embedded machine learning. We then apply the categorization to multiple images from the same patient, extending it to detect and monitor disease progression and recovery. The results give an immediate criterion for coronavirus triage and provide a methodology for respiratory diseases beyond COVID-19.",144,COVID-19;Disease Progression;Pneumonia;Respiratory Tract Diseases,,,Other Topics,,,,,,External,4. Prognosis/Treatment,X-Ray
10.1101/2020.04.28.20082776,10.1101/2020.04.28.20082776,Yes,,,2020,2020-05-01,Preprint,medRxiv,0,curbing the ai-induced enthusiasm in diagnosing covid-19 on chest x-rays: the present and the near-future,"In the current context of COVID-19 pandemic, a rapid and accessible screening tool based on image processing of chest X-rays (CXRs) using machine learning (ML) approaches would be much needed. Initially, we intended to create and validate an ML software solution able to discriminate on the basis of the CXR between SARS-CoV-2-induced bronchopneumonia and other bronchopneumonia etiologies. A systematic search of PubMed, Scopus and arXiv databases using the following search terms, AND AND found 14 recent studies. Most of them declared to be able to confidently identify COVID-19 based on CXRs using deep neural networks. Firstly, weaknesses of artificial intelligence (AI) solutions were analyzed, tackling the issues with datasets (from both medical and technical points of view) and the vulnerability of used algorithms. Then, arguments were provided for why our study design is stronger and more realistic than the previously quoted papers, balancing the possible false expectations with facts. The authors consider that the potential of AI use in COVID-19 diagnosis on CXR is real. However, scientific community should be careful in interpreting statements, results and conclusions regarding AI use in imaging. It is therefore necessary to adopt standards for research and publication of data, because it seems that in the recent months scientific reality suffered manipulations and distortions. Also, a call for responsible approaches to the imaging methods in COVID-19 is raised. It seems mandatory to follow some rigorous approaches in order to provide with adequate results in daily routine. In addition, the authors intended to raise public awareness about the quality of AI protocols and algorithms and to encourage public sharing of as many CXR images with common quality standards.",272,Bronchopneumonia;COVID-19;COVID-19 Pandemic,,,Other Topics,,,,,,,Review,X-Ray
10.1101/2020.05.01.20086207,10.1101/2020.05.01.20086207,Yes,,,2020,2020-05-05,Preprint,medRxiv,0,tracking and predicting covid-19 radiological trajectory using deep learning on chest x-rays: initial accuracy testing,"Decision scores and ethically mindful algorithms are being established to adjudicate mechanical ventilation in the context of potential resources shortage due to the current onslaught of COVID-19 cases. There is a need for a reproducible and objective method to provide quantitative information for those scores. Towards this goal, we present a retrospective study testing the ability of a deep learning algorithm at extracting features from chest x-rays (CXR) to track and predict radiological evolution. We trained a repurposed deep learning algorithm on the CheXnet open dataset (224,316 chest X-ray images of 65,240 unique patients) to extract features that mapped to radiological labels. We collected CXRs of COVID-19-positive patients from two open-source datasets (last accessed on April 9, 2020)(Italian Society for Medical and Interventional Radiology and MILA). Data collected form 60 pairs of sequential CXRs from 40 COVID patients (mean age ± standard deviation: 56 years; 23 men, 10 women, seven not reported) and were categorized in three categories: “Worse”, “Stable”, or “Improved” on the basis of radiological evolution ascertained from images and reports. Receiver operating characteristic analyses, Mann-Whitney tests were performed. On patients from the CheXnet dataset, the AUC ranged from 0.71 to 0.93 for seven imaging features and one diagnosis. Deep learning features between “Worse” and “Improved” outcome categories were significantly different for three radiological signs and one diagnostic (“Consolidation”, “Lung Lesion”, “Pleural effusion” and “Pneumonia”; all P < 0.05). Features from the first CXR of each pair could correctly predict the outcome category between “Worse” and “Improved” cases with 82.7% accuracy. CXR deep learning features show promise for classifying the disease trajectory. Once validated in studies incorporating clinical data and with larger sample sizes, this information may be considered to inform triage decisions.",285,COVID-19;Pleural Effusion;Pneumonia,,,Algorithms;ROC Curve;Ventilation;Retrospective Studies;Lung Diseases;Receiver Operating Characteristic,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.05.01.20088211,10.1101/2020.05.01.20088211,Yes,,,2020,2020-06-18,Preprint,medRxiv,0,classification of covid-19 from chest x-ray images using deep convolutional neural networks,"The COVID-19 pandemic continues to have a devastating effect on the health and well-being of the global population. A vital step in the combat towards COVID-19 is a successful screening of contaminated patients, with one of the key screening approaches being radiological imaging using chest radiography. This study aimed to automatically detect COVID‐ 19 pneumonia patients using digital chest x‐ ray images while maximizing the accuracy in detection using deep convolutional neural networks (DCNN). The dataset consists of 864 COVID‐ 19, 1345 viral pneumonia and 1341 normal chest x‐ ray images. In this study, DCNN based model Inception V3 with transfer learning have been proposed for the detection of coronavirus pneumonia infected patients using chest X-ray radiographs and gives a classification accuracy of more than 98% (training accuracy of 97% and validation accuracy of 93%). The results demonstrate that transfer learning proved to be effective, showed robust performance and easily deployable approach for COVID-19 detection.",155,"COVID-19;COVID-19 Pandemic;Pneumonia;Pneumonia, Viral",,,Transfer Learning;Other Topics,,,,,,External,2. Detection/Diagnosis,Multimodal
10.1101/2020.05.04.20090779,10.1101/2020.05.04.20090779,Yes,,,2020,2020-05-08,Preprint,medRxiv,0,mantiscovid: rapid x-ray chest radiograph and mortality rate evaluation with artificial intelligence for covid-19,"The novel coronavirus pandemic has negative impacts over the health, economy and well-being of the global population. This negative effect is growing with the high spreading rate of the virus. The most critical step to prevent the spreading of the virus is pre-screening and early diagnosis of the individuals. This results in quaranteeing the patients not to effect the healthy population. COVID-19 is the name of the disease caused by the novel coronavirus. It has a high infection rate and it is urgent to diagnose many patients as we can to prevent the spread of the virus at the early stage. Rapid diagnostic tools development is urgent to save lives. MantisCOVID is a cloud-based pre-diagnosis tool to be accessed from the internet. This tool delivers a rapid screening test by analyzing the X-ray Chest Radiograph scans via Artificial Intelligence (AI) and it also evaluates the mortality rate of patients with the synthesis of the patient’s history with the machine learning methods. This study reveals the methods used over the platform and evaluation of the algorithms via open datasets.",178,COVID-19;Infections,,,Coronavirus Infections;Diagnostic Tests;COVID-19 Testing,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.05.05.20091561,10.1101/2020.05.05.20091561,Yes,,,2020,2020-05-08,Preprint,medRxiv,0,ai based chest x-ray (cxr) scan texture analysis algorithm for digital test of covid-19 patients,"Chest Imaging in COVID-19 patient management is becoming an essential tool for controlling the pandemic that is gripping the international community. It is already indicated in patients with COVID-19 and worsening respiratory status. The rapid spread of the pandemic to all continents, albeit with a nonuniform community transmission, necessitates chest imaging for medical triage of patients presenting moderate-severe clinical COVID-19 features. This paper reports the development of innovative machine learning schemes for the analysis of Chest X-Ray (CXR) scan images of COVID-19 patients in almost real-time, demonstrating significantly high accuracy in identifying COVID-19 infection. The performance testing was conducted on a combined dataset comprising CXRs of positive COVID-19 patients, patients with various viral and bacterial infections, as well as persons with a clear chest. The test resulted in successfully distinguishing CXR COVID-19 infection from the other cases with an average accuracy of 94.43%, sensitivity 95% and specificity 93.86%.The development of efficient automatic AI texture analysis schemes for classification of chest X-Ray of COVID-19 patients with highest accuracy with equally low false negative and positive rates. Decisions would be supported by visual evidence viewable by clinician and help speed up the initial assessment process of new suspected cases, especially in a resource-constrained environment.",202,Bacterial Infections;COVID-19;Infections,,,Health Care;Sensitivity and Specificity,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.05.06.20092874,10.1101/2020.05.06.20092874,Yes,,,2020,2020-05-08,Preprint,medRxiv,0,prognet: covid-19 prognosis using recurrent and convolutional neural networks,", Humanity is facing nowadays a dramatic pandemic episode with the Coronavirus propagation over all continents. The Covid-19 disease is still not well characterized, and many research teams all over the world are working on either therapeutic or vaccination issues. Massive testing is one of the main recommendations. In addition to laboratory tests, imagery-based tools are being widely investigated. Artificial intelligence is therefore contributing to the efforts made to face this pandemic phase. Regarding patients in hospitals, it is important to monitor the evolution of lung pathologies due to the virus. A prognosis is therefore of great interest for doctors to adapt their care strategy. In this paper, we propose a method for Covid-19 prognosis based on deep learning architectures. The proposed method is based on the combination of a convolutional and recurrent neural networks to classify multi-temporal chest X-ray images and predict the evolution of the observed lung pathology. When applied to radiological time-series, promising results are obtained with an accuracy rates higher than 92%.",166,COVID-19,,,Other Topics,,,,,,External,4. Prognosis/Treatment,X-Ray
10.1101/2020.05.10.20097063,10.1101/2020.05.10.20097063,Yes,,,2020,2020-05-14,Preprint,medRxiv,0,automatic detection of covid-19 infection from chest x-ray using deep learning,"COVID-19 infection has created a panic across the globe in recent times. Early detection of COVID-19 infection can save many lives in the prevailing situation. This virus affects the respiratory system of a person and creates white patchy shadows in the lungs. Deep learning is one of the most effective Artificial Intelligence techniques to analyse chest X-ray images for efficient and reliable COVID-19 screening. In this paper, we have proposed a Deep Convolutional Neural Network method for fast and dependable identification of COVID-19 infection cases from the patient chest X-ray images. To validate the performance of the proposed system, chest X-ray images of more than 150 confirmed COVID-19 patients from the Kaggle data repository are used in the experimentation. The results show that the proposed system identifies the cases with an accuracy of 93%.",134,COVID-19;Infections,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.05.11.20097907,10.1101/2020.05.11.20097907,Yes,,,2020,2020-05-29,Preprint,medRxiv,0,online covid-19 diagnosis with chest ct images: lesion-attention deep neural networks,"Chest computed tomography (CT) scanning is one of the most important technologies for COVID-19 diagnosis and disease monitoring, particularly for early detection of coronavirus. Recent advancements in computer vision motivate more concerted efforts in developing AI-driven diagnostic tools to accommodate the enormous demands for the COVID-19 diagnostic tests globally. To help alleviate burdens on medical systems, we develop a lesion-attention deep neural network (LA-DNN) to predict COVID-19 positive or negative with a richly annotated chest CT image dataset. Based on the textual radiological report accompanied with each CT image, we extract two types of important information for the annotations: One is the indicator of a positive or negative case of COVID-19, and the other is the description of five lesions on the CT images associated with the positive cases. The proposed data-efficient LA-DNN model focuses on the primary task of binary classification for COVID-19 diagnosis, while an auxiliary multi-label learning task is implemented simultaneously to draw the model’s attention to the five lesions associated with COVID-19. The joint task learning process makes it a highly sample-efficient deep neural network that can learn COVID-19 radiology features more effectively with limited but high-quality, rich-information samples. The experimental results show that the AUC and sensitivity (recall), precision, and accuracy for COVID-19 diagnosis are 94.0%, 88.8%, 87.9%, and 88.6% respectively, which reach the clinical standards for practical use. A free online system is currently alive for fast diagnosis using CT images at the website /, and all codes and datasets are freely accessible at our github address.",253,COVID-19,,,Diagnostic Tests;COVID-19 Testing,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,CT
10.1101/2020.05.12.20098954,10.1101/2020.05.12.20098954,Yes,,,2020,2020-05-19,Preprint,medRxiv,0,covid-19 detection using cnn transfer learning from x-ray images,"The Covid-19 first occurs in Wuhan, China in December 2019. After that the virus spread all around the world and at the time of writing this paper the total number of confirmed cases are above 4.7 million with over 315000 deaths. Machine learning algorithms built on radiography images can be used as decision support mechanism to aid radiologists to speed up the diagnostic process. The aim of this work is twofold. First, a quantitative analysis to evaluate 12 off-the-shelf convolutional neural networks (CNNs) for the purpose of COVID-19 X-ray image analysis. Specifically, CNN transfer learning procedure was adopted due to the small number of images available for investigation. We also proposed a simple CNN architecture with a small number of parameters that perform well on distinguishing COVID-19 from normal X-rays. Secondly, a qualitative investigation performed to inspect the decisions made by CNNs using a technique known as class activation maps (CAM). Using CAMs, one can map the activations contributed most to the decision of CNNs back to the original image to visualize the most discriminating regions on the input image. Chest X-ray images used in this work are coming from 3 publicly available sources. Two COVID-19 X-ray image datasets and a large dataset of other non-COVID-19 viral infections, bacterial infections and normal X-rays utilised. We conclude that CNN decisions should not be taken into consideration, despite their high classification accuracy, until clinicians can visually inspect the regions of the input image used by CNNs that lead to its prediction.",249,Bacterial Infections;COVID-19;Death;Virus Diseases,,,Algorithms;Transfer Learning;Architecture;Map,,,,,,External,Segmentation-only,X-Ray
10.1101/2020.05.12.20099937,10.1101/2020.05.12.20099937,Yes,,,2020,2020-05-14,Preprint,medRxiv,0,deep transfer learning-based covid-19 prediction using chest x-rays,"The novel coronavirus disease (COVID-19) is spreading very rapidly across the globe because of its highly contagious nature, and is declared as a pandemic by world health organization (WHO). Scientists are endeavoring to ascertain the drugs for its efficacious treatment. Because, till now, no full-proof drug is available to cure this deadly disease. Therefore, identifying COVID-19 positive people and to quarantine them, can be an effective solution to control its spread. Many machine learning and deep learning techniques are being used quite effectively to classify positive and negative cases. In this work, a deep transfer learning-based model is proposed to classify the COVID-19 cases using chest X-rays or CT scan images of infected persons. The proposed model is based on the ensembling of DenseNet121 and SqueezeNet1.0, which is named as DeQueezeNet. The model can extract the importance of various influential features from the X-ray images, which are effectively used to classify the COVID-19 cases. The performance study of the proposed model depicts its effectiveness in terms of accuracy and precision. A comparative study has also been done with the recently published works and it is observed the performance of the proposed model is significantly better.",195,COVID-19,,,World Health Organization;Transfer Learning;Other Topics;Pharmaceutical Preparations,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.05.14.20101972,10.1101/2020.05.14.20101972,Yes,,,2020,2020-10-06,Preprint,medRxiv,0,integration of clinical characteristics lab tests and a deep learning ct scan analysis to predict severity of hospitalized covid-19 patients,"The SARS-COV-2 pandemic has put pressure on Intensive Care Units, so that identifying predictors of disease severity is a priority. We collected 58 clinical and biological variables, chest CT scan data (506,341 images), and radiology reports from 1,003 coronavirus-infected patients from two French hospitals. We trained a deep learning model based on CT scans to predict severity; this model was more discriminative than a radiologist quantification of disease extent. We showed that neural network analysis of CT-scan brings unique prognosis information, although it is correlated with other markers of severity (oxygenation, LDH, and CRP). To provide a multimodal severity score, we developed AI-severity that includes 5 clinical and biological variables (age, sex, oxygenation, urea, platelet) as well as the CT deep learning model. When comparing AI-severity with 11 existing scores for severity, we find significantly improved prognosis performance; AI-severity can therefore rapidly become a reference scoring approach.",147,COVID-19,,,Other Topics,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
10.1101/2020.05.24.20111922,10.1101/2020.05.24.20111922,Yes,,,2020,2020-05-25,Preprint,medRxiv,0,aidcov: an interpretable artificial intelligence model for detection of covid-19 from chest radiography images,"As the Coronavirus Disease 2019 (COVID-19) pandemic continues to grow globally, testing to detect COVID-19 and isolating individuals who test positive remains to be the primary strategy for preventing community spread of the disease. The current gold standard method of testing for COVID-19 is the reverse transcription polymerase chain reaction (RT-PCR) test. The RT-PCR test, however, has an imperfect sensitivity (around 70%), is time-consuming and labor-intensive, and is in short supply, particularly in resource-limited countries. Therefore, automatic and accurate detection of COVID-19 using medical imaging modalities such as chest X-ray and Computed Tomography, which are more widely available and accessible, can be beneficial. We develop a novel hierarchical attention neural network model to classify chest radiography images as belonging to a person with either COVID-19, other infections, or no pneumonia (i.e., normal). We refer to this model as Artificial Intelligence for Detection of COVID-19 (AIDCOV). The hierarchical structure in AIDCOV captures the dependency of features and improves model performance while the attention mechanism makes the model interpretable and transparent. Using a publicly available dataset of 5801 chest images, we demonstrate that our model achieves a mean cross-validation accuracy of 97.8%. AIDCOV has a sensitivity of 99.3%, a specificity of 99.98%, and a positive predictive value of 99.6% in detecting COVID-19 from chest radiography images. AIDCOV can be used in conjunction with or instead of RT-PCR testing (where RT-PCR testing is unavailable) to detect and isolate individuals with COVID-19 and prevent onward transmission to the general population and healthcare workers.",249,COVID-19;COVID-19 Pandemic;Infections;Pneumonia,,,Predictive Value;Sensitivity and Specificity;Polymerase Chain Reaction;Neural Networks;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.05.25.20113084,10.1101/2020.05.25.20113084,Yes,,,2020,2020-05-27,Preprint,medRxiv,0,a chest radiography-based artificial intelligence deep-learning model to predict severe covid-19 patient outcomes: the cape (covid-19 ai predictive engine) model,"Chest radiography may be used together with deep-learning models to prognosticate COVID-19 patient outcomesT o evaluate the performance of a deep-learning model for the prediction of severe patient outcomes from COVID-19 pneumonia on chest radiographs.A deep-learning model (CAPE: Covid-19 AI Predictive Engine) was trained on 2337 CXR images including 2103 used only for validation while training. The prospective test set consisted of CXR images (n=70) obtained from RT-PCR confirmed COVID-19 pneumonia patients between 1 January and 30 April 2020 in a single center. The radiographs were analyzed by the AI model. Model performance was obtained by receiver operating characteristic curve analysis.In the prospective test set, the mean age of the patients was 46 years (84.2% male). The deep-learning model accurately predicted outcomes of ICU admission/mortality from COVID-19 pneumonia with an AUC of 0.79. Compared to traditional risk scoring systems for pneumonia based upon laboratory and clinical parameters, the model matched the EWS and MulBTSA risk scoring systems and outperformed CURB-65.A deep-learning model was able to predict severe patient outcomes (ICU admission and mortality) from COVID-19 on chest radiographs.A deep-learning model was able to predict severe patient outcomes (ICU admission and mortality) from COVID-19 from chest radiographs with an AUC of 0.79, which is comparable to traditional risk scoring systems for pneumonia.This is a chest radiography-based AI model to prognosticate the risk of severe COVID-19 pneumonia outcomes.",226,COVID-19;Pneumonia,,,Polymerase Chain Reaction;Area under Curve,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.05.26.20113761,10.1101/2020.05.26.20113761,Yes,,,2020,2020-05-27,Preprint,medRxiv,0,differentiating covid-19 from other types of pneumonia with convolutional neural networks,"A widely-used method for diagnosing COVID-19 is the nucleic acid test based on real-time reverse transcriptase-polymerase chain reaction (RT-PCR). However, the sensitivity of real time RT-PCR tests is low and it can take up to 8 hours to receive the test results. Radiologic methods can provide higher sensitivity. The aim of this study is to investigate the use of X-ray and convolutional neural networks for the diagnosis of COVID-19 and to differentiate it from viral and/or bacterial pneumonia, as 2-class (bacterial pneumonia vs COVID-19 and viral pneumonia vs COVID-19) and 3- class (bacterial pneumonia, COVID-19, and healthy group (BCH), and among viral pneumonia, COVID- 19, and healthy group (VCH)) experiments. 225 COVID-19, 1,583 healthy control, 2,780 bacterial pneumonia, and 1,493 viral pneumonia chest X-ray images were used. 2-class- and 3-class-experiments were performed with different convolutional neural network (ConvNet) architectures, with different variations of convolutional layers and fully-connected layers. The results showed that bacterial pneumonia vs COVID-19 and viral pneumonia vs COVID- 19 reached a mean ROC AUC of 97.32% and 96.80%, respectively. In the 3-class-experiments, macro-average F1 scores of 95.79% and 94.59% were obtained in terms of detecting COVID-19 among BCH and VCH, respectively. The ConvNet was able to distinguish the COVID-19 images among non-COVID-19 images, namely bacterial and viral pneumonia as well as normal X-ray images.",217,"COVID-19;Pneumonia;Pneumonia, Bacterial;Pneumonia, Viral",,,Polymerase Chain Reaction;Area under Curve;Nucleic Acids,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.06.07.20124594,10.1101/2020.06.07.20124594,Yes,,,2020,2020-06-08,Preprint,medRxiv,0,early detection of coronavirus cases using chest x-ray images employing machine learning and deep learning approaches,"This study aims to investigate if applying machine learning and deep learning approaches on chest X-ray images can detect cases of coronavirus. The chest X-ray datasets were obtained from Kaggle and Github and pre-processed into a single dataset using random sampling. We applied several machine learning and deep learning methods including Convolutional Neural Networks (CNN) along with classical machine learners. In deep learning procedure, several pre-trained models were also employed transfer learning in this dataset. Our proposed CNN model showed the highest accuracy, AUC, f-measure, sensitivity and specificity as well as the lowest fall out and miss rate respectively. We also evaluated specificity and fall out rate along with accuracy to identify non-COVID-19 individuals more accurately. As a result, our new models might help to early detect COVID-19 patients and prevent community transmission compared to traditional methods.",137,COVID-19,,,Transfer Learning;Area under Curve,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.06.08.20125963,10.1101/2020.06.08.20125963,Yes,,,2021,2021-11-04,Preprint,medRxiv,0,benchmarking deep learning models and automated model design for covid-19 detection with chest ct scans,"COVID-19 pandemic has spread all over the world for months. As its transmissibility and high pathogenicity seriously threaten people’s lives, the accurate and fast detection of the COVID-19 infection is crucial. Although many recent studies have shown that deep learning based solutions can help detect COVID-19 based on chest CT scans, there lacks a consistent and systematic comparison and evaluation on these techniques. In this paper, we first build a clean and segmented CT dataset called Clean-CC-CCII by fixing the errors and removing some noises in a large CT scan dataset CC-CCII with three classes: novel coronavirus pneumonia (NCP), common pneumonia (CP), and normal controls (Normal). After cleaning, our dataset consists of a total of 340,190 slices of 3,993 scans from 2,698 patients. Then we benchmark and compare the performance of a series of state-of-the-art (SOTA) 3D and 2D convolutional neural networks (CNNs). The results show that 3D CNNs outperform 2D CNNs in general. With extensive effort of hyperparameter tuning, we find that the 3D CNN model DenseNet3D121 achieves the highest accuracy of 88.63% (F1-score is 88.14% and AUC is 0.940), and another 3D CNN model ResNet3D34 achieves the best AUC of 0.959 (accuracy is 87.83% and F1-score is 86.04%). We further demonstrate that the mixup data augmentation technique can largely improve the model performance. At last, we design an automated deep learning methodology to generate a lightweight deep learning model MNas3DNet41 that achieves an accuracy of 87.14%, F1-score of 87.25%, and AUC of 0.957, which are on par with the best models made by AI experts. The automated deep learning design is a promising methodology that can help health-care professionals develop effective deep learning models using their private data sets. Our Clean-CC-CCII dataset and source code are available at: GitHub",291,COVID-19;COVID-19 Pandemic;Infections;Pneumonia,,,Coronavirus Infections;Art;Health Care;Noise;Area under Curve,,,,,,External,2. Detection/Diagnosis,CT
10.1101/2020.07.02.20136721,10.1101/2020.07.02.20136721,Yes,,,2020,2020-07-05,Preprint,medRxiv,0,an automatic computer-based method for fast and accurate covid-19 diagnosis,"At present, the whole world is witnessing a horrifying outbreak caused by the Coronavirus Disease 2019 (COVID-19). The virus responsible for this disease is called SARS-CoV-2. It affects its victims’ respiratory system and causes severe lung inflammation, making it harder for them to breathe. The virus is airborne, and so has a high infection rate. Originated in China last December, the virus has spread across seven continents, affecting the population of over 210 countries, making it one of the fiercest pandemics ever recorded. Despite multiple independent and collaborative attempts to develop a vaccine or a cure, an effective solution is yet to come out. While the disease has put the world in a standstill, detecting the positive subjects and isolating them from the others as soon as possible is the only way to minimize its spread. However, many countries are currently experiencing a massive shortage of diagnostic equipment and medical personals. This insufficiency inspired us to work on a computer-based automatic method for the diagnosis of COVID-19. In this paper, we proposed a sequential Convolutional Neural Network (CNN)-based model to detect COVID-19 through analyzing Computed Tomography (CT) scan images. The model is capable of identifying the disease with almost 92.5% accuracy. We believe the implementation of this model will help the physicians and pathologists all over the world to single out the victims quickly and thus reduce the prevalence of COVID-19.",231,COVID-19;Infections;Pneumonitis,,,Disease Outbreaks;Other Topics,,,,,,External,2. Detection/Diagnosis,CT
10.1101/2020.07.08.20149161,10.1101/2020.07.08.20149161,Yes,,,2020,2020-07-10,Preprint,medRxiv,0,covidpen: a novel covid-19 detection model using chest x-rays and ct scans,"The trending global pandemic of COVID-19 is the fastest ever impact which caused people worldwide by severe acute respiratory syndrome (SARS)-driven coronavirus. However, several countries suffer from the shortage of test kits and high false negative rate in PCR test. Enhancing the chest X-ray or CT detection rate becomes critical. The patient triage is of utmost importance and the use of machine learning can drive the diagnosis of chest X-ray or CT image by identifying COVID-19 cases. To tackle this problem, we propose COVIDPEN - a transfer learning approach on Pruned EfficientNet-based model for the detection of COVID-19 cases. The proposed model is further interpolated by post-hoc analysis for the explainability of the predictions. The effectiveness of our proposed model is demonstrated on two systematic datasets of chest radiographs and computed tomography scans. Experimental results with several baseline comparisons show that our method is on par and confers clinically explicable instances, which are meant for healthcare providers.",157,COVID-19;Severe Acute Respiratory Syndrome,,,Transfer Learning;Polymerase Chain Reaction;Tomography;Other Topics,,,,,,External,2. Detection/Diagnosis,Multimodal
10.1101/2020.07.11.20149112,10.1101/2020.07.11.20149112,Yes,,,2020,2020-07-11,Preprint,medRxiv,0,reconet: multi-level preprocessing of chest x-rays for covid-19 detection using convolutional neural networks,"Life-threatening COVID-19 detection from radiomic features has become a dire need of the present time for infection control and socio-economic crisis management around the world. In this paper, a novel convolutional neural network (CNN) architecture, ReCoNet (residual image-based COVID-19 detection network), is proposed for COVID-19 detection. This is achieved from chest X-ray (CXR) images shedding light on the preprocessing task considered to be very useful for enhancing the COVID-19 fingerprints. The proposed modular architecture consists of a CNN-based multi-level preprocessing filter block in cascade with a multi-layer CNN-based feature extractor and a classification block. A multi-task learning loss function is adopted for optimization of the preprocessing block trained end-to-end with the rest of the proposed network. Additionally, a data augmentation technique is applied for boosting the network performance. The whole network when pre-trained end-to-end on the CheXpert open source dataset, and trained and tested with the COVIDx dataset of 15,134 original CXR images yielded an overall benchmark accuracy, sensitivity, and specificity of 97.48%, 96.39%, and 97.53%, respectively. The immense potential of ReCoNet may be exploited in clinics for rapid and safe detection of COVID-19 globally, in particular in the low and middle income countries where RT-PCR labs and/or kits are in a serious crisis.",204,COVID-19;Infections,,,Polymerase Chain Reaction;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.07.13.20152231,10.1101/2020.07.13.20152231,Yes,,,2020,2020-10-16,Preprint,medRxiv,0,a quantitative lung computed tomography image feature for multi-center severity assessment of covid-19,"The COVID-19 pandemic has affected millions and congested healthcare systems globally. Hence an objective severity assessment is crucial in making therapeutic decisions judiciously. Computed Tomography (CT)-scans can provide demarcating features to identify severity of pneumonia, commonly associated with COVID-19, in the affected lungs. Here, a quantitative severity assessing chest CT image feature is demonstrated for COVID-19 patients. We incorporated 509 CT images from 101 diagnosed and expert-annotated cases (age 20-90, 60% males) in the study collected from a multi-center Italian database1 sourced from 41 radio-diagnostic centers. Lesions in the form of opacifications, crazy-paving patterns, and consolidations were segmented. The severity determining feature, Lnorm was quantified and established to be statistically distinct for the three, mild, moderate, and severe classes (p-value<0.0001). The thresholds of Lnorm for a 3-class classification were determined based on the optimum sensitivity/specificity combination from Receiver Operating Characteristic (ROC) analyses. The feature Lnorm classified the cases in the three severity categories with 86.88% accuracy. ‘Substantial’ to ‘almost-perfect’ intra-rater and inter-rater agreements were achieved involving expert (manual segmentation) and non-expert (graph-cut and deep-learning based segmentation) labels (κ-score 0.79-0.97). We trained several machine learning classification models and showed Lnorm alone has a superior diagnostic accuracy over standard image intensity and texture features. Classification accuracy was further increased when Lnorm was used for 2-class classification i.e. to delineate the severe cases from non-severe ones with a high sensitivity, and specificity. Therefore, key highlights of the COVID-19 severity assessment feature are high accuracy, low dependency on expert availability, and wide utility across different CT-imaging centers.",253,COVID-19;COVID-19 Pandemic;Pneumonia,,,Health Care;Sensitivity and Specificity;Other Topics;ROC Curve,,,,,,External,3. Monitoring/Severity assessment,CT
10.1101/2020.07.15.20154385,10.1101/2020.07.15.20154385,Yes,,,2020,2020-07-16,Preprint,medRxiv,0,interpreting deep ensemble learning through radiologist annotations for covid-19 detection in chest radiographs,"Data-driven deep learning (DL) methods using convolutional neural networks (CNNs) demonstrate promising performance in natural image computer vision tasks. However, using these models in medical computer vision tasks suffers from several limitations, viz., adapting to visual characteristics that are unlike natural images; modeling random noise during training due to stochastic optimization and backpropagation-based learning strategy; challenges in explaining DL black-box behavior to support clinical decision-making; and inter-reader variability in the ground truth (GT) annotations affecting learning and evaluation. This study proposes a systematic approach to address these limitations for COVID-19 detection using chest X-rays (CXRs). Specifically, our contribution benefits from pretraining specific to CXRs in transferring and fine-tuning the learned knowledge toward improving COVID-19 detection performance; using ensembles of the fine-tuned models to further improve performance compared to individual constituent models; performing statistical analyses at various learning stages to validate our claims; interpreting learned individual and ensemble model behavior through class-selective relevance mapping (CRM)-based region of interest (ROI) localization; analyzing inter-reader variability and ensemble localization performance using Simultaneous Truth and Performance Level Estimation (STAPLE) methods. We observe that: ensemble approaches improved classification and localization performance; and, inter-reader variability and performance level assessment helped guide algorithm design and parameter optimization. To the best of our knowledge, this is the first study to construct ensembles, perform ensemble-based disease ROI localization, and analyze inter-reader variability and algorithm performance for COVID-19 detection in CXRs.",230,COVID-19,,,Black Americans;Noise;X-Rays;Radiologists;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.07.15.205567,10.1101/2020.07.15.205567,Yes,,,2020,2020-07-17,Preprint,bioRxiv,0,covid-19 detection on chest x-ray and ct scan images using multi-image augmented deep learning model,"COVID-19 is posed as very infectious and deadly pneumonia type disease until recent time. Novel coronavirus or SARS-COV-2 strain is responsible for COVID-19 and it has already shown the deadly nature of respiratory disease by threatening the health of millions of lives across the globe. Clinical study reveals that a COVID-19 infected person may experience dry cough, muscle pain, headache, fever, sore throat and mild to moderate respiratory illness. At the same time, it affects the lungs badly with virus infection. So, the lung can be a prominent internal organ to diagnose the gravity of COVID-19 infection using X-Ray and CT scan images of chest. Despite having lengthy testing time, RT-PCR is a proven testing methodology to detect coronavirus infection. Sometimes, it might give more false positive and false negative results than the desired rates. Therefore, to assist the traditional RT-PCR methodology for accurate clinical diagnosis, COVID-19 screening can be adopted with X-Ray and CT scan images of lung of an individual. This image based diagnosis will bring radical change in detecting coronavirus infection in human body with ease and having zero or near to zero false positives and false negatives rates. This paper reports a convolutional neural network (CNN) based multi-image augmentation technique for detecting COVID-19 in chest X-Ray and chest CT scan images of coronavirus suspected individuals. Multi-image augmentation makes use of discontinuity information obtained in the filtered images for increasing the number of effective examples for training the CNN model. With this approach, the proposed model exhibits higher classification accuracy around 95.38% and 98.97% for CT scan and X-Ray images respectively. CT scan images with multi-image augmentation achieves sensitivity of 94.78% and specificity of 95.98%, whereas X-Ray images with multi-image augmentation achieves sensitivity of 99.07% and specificity of 98.88%. Evaluation has been done on publicly available databases containing both chest X-Ray and CT scan images and the experimental results are also compared with ResNet-50 and VGG-16 models.",320,COVID-19;Coronavirus Infections;Cough;Fever;Headache;Infections;Myalgia;Pneumonia;Respiratory Tract Diseases;Sore Throat;Strains;Virus Diseases,,,Coronavirus Infections;Polymerase Chain Reaction,,,,,,External,2. Detection/Diagnosis,Multimodal
10.1101/2020.07.16.20155093,10.1101/2020.07.16.20155093,Yes,,,2020,2020-11-06,Preprint,medRxiv,0,automated covid-19 detection from frontal chest x-ray images using deep learning: an online feasibility study,"to evaluate the performance of Deep Learning methods to detect covid-19 from X-Ray chest images Chest X-Ray (CXR) images collected from confirmed covid-19 cases in several different centers and institutions and available online were downloaded and combined together with images of healthy patients and patients suffering from bacterial pneumonia found in other online sources. An AI image-based covid-19 classifier was developed and evaluated on the CXR images downloaded. Seven different online data sources were combined for a total of N=16,665 patients (3,156 with covid-19, 2,311 with bacterial pneumonia and 11,198 healthy patients). When half of the patients (N=8,331) where used to train the classifier leaving the other half (N=8,334) for validation, the classifier reached an AUC for covid-19 detection of 98.6% (detection rate of 91.8% at 1.1% false positive rate). Results were similar for other training/validation splits. AUC was close to 90% even when tested on patients from a source not used to train the classifier. Computer aided automatic covid-19 detection from CXR images showed promising results on a large cohort of patients. The classifier will be made available online for its evaluation. These results merit further evaluation through a prospective clinical study.",193,"COVID-19;Pneumonia, Bacterial",,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.08.03.20167007,10.1101/2020.08.03.20167007,Yes,,,2020,2020-08-04,Preprint,medRxiv,0,severity assessment and progression prediction of covid-19 patients based on the lesionencoder framework and chest ct,"Automatic severity assessment and progression prediction can facilitate admission, triage, and referral of COVID-19 patients. This study aims to explore the potential use of lung lesion features in the management of COVID-19, based on the assumption that lesion features may carry important diagnostic and prognostic information for quantifying infection severity and forecasting disease progression.A novel LesionEncoder framework is proposed to detect lesions in chest CT scans and to encode lesion features for automatic severity assessment and progression prediction. The LesionEncoder framework consists of a U-Net module for detecting lesions and extracting features from individual CT slices, and a recurrent neural network (RNN) module for learning the relationship between feature vectors and collectively classifying the sequence of feature vectors.Chest CT scans of two cohorts of COVID-19 patients from two hospitals in China were used for training and testing the proposed framework. When applied to assessing severity, this framework outperformed baseline methods achieving a sensitivity of 0.818, specificity of 0.952, accuracy of 0.940, and AUC of 0.903. It also outperformed the other tested methods in disease progression prediction with a sensitivity of 0.667, specificity of 0.838, accuracy of 0.829, and AUC of 0.736. The LesionEncoder framework demonstrates a strong potential for clinical application in current COVID-19 management, particularly in automatic severity assessment of COVID-19 patients. This framework also has a potential for other lesion-focused medical image analyses.",225,COVID-19;Disease Progression;Infections,,,Other Topics,,,,,,Self-recorded/clinical,4. Prognosis/Treatment,CT
10.1101/2020.08.12.20173872,10.1101/2020.08.12.20173872,Yes,,,2020,2020-08-14,Preprint,medRxiv,0,severity assessment of covid-19 based on clinical and imaging data,"This study aims to develop a machine learning approach for automated severity assessment of COVID-19 patients based on clinical and imaging data. Clinical data, demographics, signs, symptoms, comorbidities and blood test results, and chest CT scans of 346 patients from two hospitals in the Hubei province, China, were used to develop machine learning models for automated severity assessment of diagnosed COVID-19 cases. We compared the predictive power of clinical and imaging data by testing multiple machine learning models, and further explored the use of four oversampling methods to address the imbalance distribution issue. Features with the highest predictive power were identified using the SHAP framework. Targeting differentiation between mild and severe cases, logistic regression models achieved the best performance on clinical features (AUC:0.848, sensitivity:0.455, specificity:0.906), imaging features (AUC:0.926, sensitivity:0.818, specificity:0.901) and the combined features (AUC:0.950, sensitivity:0.764, specificity:0.919). The SMOTE oversampling method further improved the performance of the combined features to AUC of 0.960 (sensitivity:0.845, specificity:0.929). Imaging features had the strongest impact on the model output, while a combination of clinical and imaging features yielded the best performance overall. The identified predictive features were consistent with findings from previous studies. Oversampling yielded mixed results, although it achieved the best performance in our study. This study indicates that clinical and imaging features can be used for automated severity assessment of COVID-19 patients and have the potential to assist with triaging COVID-19 patients and prioritizing care for patients at higher risk of severe cases.",241,COVID-19,,,COVID-19 Testing;Hematologic Tests,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
10.1101/2020.08.13.20173997,10.1101/2020.08.13.20173997,Yes,,,2020,2020-08-14,Preprint,medRxiv,0,deep learning for automated recognition of covid-19 from chest x-ray images,"The pandemic caused by coronavirus in recent months is having a devastating global effect, which puts the world under the most ever unprecedented emergency. Currently, since there are not effective antiviral treatments for Covid-19 yet, it is crucial to early detect and monitor the progression of the disease, thus helping to reduce mortality. While a corresponding vaccine is being developed, and different measures are being used to combat the virus, medical imaging techniques have also been investigated to assist doctors in diagnosing this disease.This paper presents a practical solution for the detection of Covid-19 from chest X-ray (CXR) images, exploiting cutting-edge Machine Learning techniques.We employ EfficientNet and MixNet, two recently developed families of deep neural networks, as the main classification engine. Furthermore, we also apply different transfer learning strategies, aiming at making the training process more accurate and efficient. The proposed approach has been validated by means of two real datasets, the former consists of 13,511 training images and 1,489 testing images, the latter has 14,324 and 3,581 images for training and testing, respectively.The results are promising: by all the experimental configurations considered in the evaluation, our approach always yields an accuracy larger than 95.0%, with the maximum accuracy obtained being 96.64%.As a comparison with various existing studies, we can thus conclude that our performance improvement is significant.",218,COVID-19,,,Transfer Learning;Antiviral Agents;Pharmaceutical Preparations,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.08.13.20174144,10.1101/2020.08.13.20174144,Yes,,,2020,2020-08-14,Preprint,medRxiv,0,precise prediction of covid-19 in chest x-ray images using ke sieve algorithm,"The novel coronavirus (COVID-19) pandemic is pressurizing the healthcare systems across the globe and few of them are on the verge of failing. The detection of this virus as early as possible will help in contaminating the spread of it as the virus is mutating itself as fast as possible and currently there are about 4,300 strains of the virus according to the reports. Clinical studies have shown that most of the COVID-19 patients suffer from a lung infection similar to influenza. So, it is possible to diagnose lung infection using imaging techniques. Although a chest computed tomography (CT) scan has been shown to be an effective imaging technique for lung-related disease diagnosis, chest X-ray is more widely available across the hospitals due to its considerably lower cost and faster imaging time than CT scan. The advancements in the area of machine learning and pattern recognition has resulted in intelligent systems that analyze CT Scans or X-ray images and classify between pneumonia and normal patients. This paper proposes KE Sieve Neural Network architecture, which helps in the rapid diagnosis of COVID-19 using chest X-ray images. This architecture is achieving an accuracy of 98.49%. This noninvasive prediction method can assist the doctors in this pandemic and reduce the stress on health care systems.",212,"COVID-19;COVID-19 Pandemic;Infections;Influenza, Human;Pneumonia;Strains",,,Coronavirus Infections;Health Care,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.08.18.20175521,10.1101/2020.08.18.20175521,Yes,,,2020,2020-08-21,Preprint,medRxiv,0,machine learning and ai aided tool to differentiate covid-19 and non-covid-19 lung cxr,"One of the main challenges in dealing with the current COVID 19 pandemic is how to detect and distinguish between the COVID 19 and non COVID 19 cases. This problem arises since COVID 19 symptoms resemble with other cases. One of the golden standards is by examining the lung using the chest X ray radiograph (CXR). Currently there is growing COVID 19 cases followed by the CXR images waiting to be analyzed and this may outnumber the health capacity. Learning from that current situation and to fulfill the demand for CXRs analysis, a novel solution is required. The tool is expected can detect and distinguish the COVID 19 case lung rely on CXR. Respectively, this study aims to propose the use of AI and machine learning aided tool to distinguish the COVID 19 and non COVID 19 cases based on the CXR lung image. The compared non COVID 19 CXR cases in this study include normal (healthy), influenza A, tuberculosis, and active smoker. The results confirm that the machine learning tool is able to distinguish the COVID 19 CXR lungs based on lung consolidation. Moreover, the tool is also able to recognize an abnormality of COVID 19 lung in the form of patchy ground glass opacity. To conclude, AI and machine learning may be considered as a detection tool to identify and distinguish between COVID 19 and non COVID 19 cases in particular epidemic areas.",235,"COVID-19;COVID-19 Pandemic;Influenza, Human;Tuberculosis",,,Health;Eyeglasses,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.08.20.20178723,10.1101/2020.08.20.20178723,Yes,,,2020,2020-08-23,Preprint,medRxiv,0,automatic analysis system of covid-19 radiographic lung images (xraycovidetector),"COVID-19 is a pandemic infectious disease caused by the SARS-CoV-2 virus, having reached more than 210 countries and territories. It produces symptoms such as fever, dry cough, dyspnea, fatigue, pneumonia, and radiological manifestations. The most common reported RX and CT findings include lung consolidation and ground-glass opacities. In this paper, we describe a machine learning-based system (XrayCoviDetector; until the image has a size ), that detects automatically, the probability that a thorax radiological image includes COVID-19 lung patterns. XrayCoviDetector has an accuracy of 0.93, a sensitivity of 0.96, and a specificity of 0.90.",93,COVID-19;Communicable Diseases;Cough;Dyspnea;Fatigue;Fever;Pneumonia,,,Specificity;Communicable Diseases;Eyeglasses,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
10.1101/2020.08.24.20181339,10.1101/2020.08.24.20181339,Yes,,,2021,2021-08-09,Preprint,medRxiv,0,diagnosis of covid-19 from x-rays using combined cnn-rnn architecture with transfer learning,"The confrontation of COVID-19 pandemic has become one of the promising challenges of the world healthcare. Accurate and fast diagnosis of COVID-19 cases is essential for correct medical treatment to control this pandemic. Compared with the reverse-transcription polymerase chain reaction (RT-PCR) method, chest radiography imaging techniques are shown to be more effective to detect coronavirus. For the limitation of available medical images, transfer learning is better suited to classify patterns in medical images. This paper presents a combined architecture of convolutional neural network (CNN) and recurrent neural network (RNN) to diagnose COVID-19 from chest X-rays. The deep transfer techniques used in this experiment are VGG19, DenseNet121, InceptionV3, and Inception-ResNetV2. CNN is used to extract complex features from samples and classified them using RNN. The VGG19-RNN architecture achieved the best performance among all the networks in terms of accuracy in our experiments. Finally, Gradient-weighted Class Activation Mapping (Grad-CAM) was used to visualize class-specific regions of images that are responsible to make decision. The system achieved promising results compared to other existing systems and might be validated in the future when more samples would be available. The experiment demonstrated a good alternative method to diagnose COVID-19 for medical staff.",197,COVID-19;COVID-19 Pandemic,,,Health Care;Transfer Learning;Architecture;Polymerase Chain Reaction;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.08.31.20175828,10.1101/2020.08.31.20175828,Yes,,,2020,2020-09-02,Preprint,medRxiv,0,covid-19 detection from chest x-ray images using deep learning and convolutional neural networks,"Accurate and efficient diagnosis of potential COVID-19 patients is vital in the fight against the current pandemic. However, even the gold-standard COVID-19 test, reverse transcription polymerase chain reaction, suffers from a high false negative rate and a turnaround time of up to one week, preventing the infected from accessing the timely care they require, and impeding efforts to isolate positive cases. To address these shortcomings, this study develops a machine learning model based on the DenseNet-201 deep convolutional neural network, that can classify COVID-19 from chest radiographs in less than one minute and far more accurately than conventional tests (F1-score: 0.96; precision: 0.95; recall: 0.98). It uses a significantly larger dataset and more control classes than previously published models, demonstrating the promise of a machine learning approach for accurate and efficient COVID-19 screening. A live web application of the trained model can be accessed at /.",146,COVID-19,,,Polymerase Chain Reaction;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.09.07.20189852,10.1101/2020.09.07.20189852,Yes,,,2020,2020-09-09,Preprint,medRxiv,0,network for subclinical prognostication of covid-19 patients from data of thoracic roentgenogram: a feasible alternative screening technology,"COVID 19 is the terminology driving people’s life in the year 2020 without a supportive globally high mortality rate. Coronavirus lead pandemic is a new found disease with no gold standard diagnostic and therapeutic guideline across the globe. Amidst this scenario our aim is to develop a prediction model that makes mass screening easy on par with reducing strain on hospitals diagnostic facility and doctors alike. For this prediction model, a neural network based on Chest X-ray images has been developed. Alongside the aim is also to generate a case record form that would include prediction model result along with few other subclinical factors for generating disease identification. Once found positive then only it will proceed to RT-PCR for final validation. The objective was to provide a cheap alternative to RT-PCR for mass screening and to reduced burden on diagnostic facility by keeping RT-PCR only for final confirmation. Datasets of chest X-ray images gathered from across the globe has been used to test and train the network after proper dataset curing and augmentation. The final neural network-based prediction model showed an accuracy of 81% with sensitivity of 82% and specificity of 90%. The AUC score obtained is 93.7%. The above results based on the existing datasets showcase our model capability to successfully distinguish patients based on Chest X-ray (a non-invasive tool) and along with the designed case record form it can significantly contribute in increasing hospitals monitoring and health care capability.",241,COVID-19;Strains,,,Health Care;Sensitivity and Specificity;Polymerase Chain Reaction;Area under Curve,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.10.13.20178483,10.1101/2020.10.13.20178483,Yes,,,2020,2020-10-14,Preprint,medRxiv,0,automated chest radiograph diagnosis: a twofer for tuberculosis and covid-19,"Coronavirus disease (Covid 19) and Tuberculosis (TB) are two challenges the world is facing. TB is a pandemic which has challenged mankind for ages and Covid 19 is a recent onset fast spreading pandemic. We study these two conditions with focus on Artificial Intelligence (AI) based imaging, the role of digital chest x-ray and utility of end to end platform to improve turnaround times. Using artificial intelligence assisted technology for triage and creation of structured radiology reports using an end to end platform can ensure quick diagnosis. Changing dynamics of TB screening in the times of Covid 19 pandemic have resulted in bottlenecks for TB diagnosis. The paper tries to outline two types of use cases, one is COVID-19 screening in a hospital-based scenario and the other is TB screening project in mobile van setting and discusses the learning of these models which have both used AI for prescreening and generating structured radiology reports.",154,COVID-19;COVID-19 Pandemic;Tuberculosis,,,Other Topics,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
10.1101/2020.10.13.20212258,10.1101/2020.10.13.20212258,Yes,,,2020,2020-10-22,Preprint,medRxiv,0,development of a deep learning classifier to accurately distinguish covid-19 from look-a-like pathology on lung ultrasound,"Lung ultrasound (LUS) is a portable, low cost respiratory imaging tool but is challenged by user dependence and lack of diagnostic specificity. It is unknown whether the advantages of LUS implementation could be paired with deep learning techniques to match or exceed human-level, diagnostic specificity among similar appearing, pathological LUS images. A convolutional neural network was trained on LUS images with B lines of different etiologies. CNN diagnostic performance, as validated using a 10% data holdback set was compared to surveyed LUS-competent physicians. Two tertiary Canadian hospitals. 600 LUS videos (121,381 frames) of B lines from 243 distinct patients with either 1) COVID-19, Non-COVID acute respiratory distress syndrome (NCOVID) and 3) Hydrostatic pulmonary edema (HPE). The trained CNN performance on the independent dataset showed an ability to discriminate between COVID (AUC 1.0), NCOVID (AUC 0.934) and HPE (AUC 1.0) pathologies. This was significantly better than physician ability (AUCs of 0.697, 0.704, 0.967 for the COVID, NCOVID and HPE classes, respectively), p < 0.01. A deep learning model can distinguish similar appearing LUS pathology, including COVID-19, that cannot be distinguished by humans. The performance gap between humans and the model suggests that subvisible biomarkers within ultrasound images could exist and multi-center research is merited.",203,"COVID-19;Pulmonary Edema;Respiratory Distress Syndrome, Acute",,,Other Topics,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
10.1101/2020.10.19.20215483,10.1101/2020.10.19.20215483,Yes,,,2022,2022-02-22,Preprint,medRxiv,0,deep learning segmentation model for automated detection of the opacity regions in the chest x-rays of the covid-19 positive patients and the application for disease severity,"The pandemic of Covid-19 has caused tremendous losses to lives and economy in the entire world. The machine learning models have been applied to the radiological images of the Covid-19 positive patients for disease prediction and severity assessment. However, a segmentation model for detecting the opacity regions like haziness, ground-glass opacity and lung consolidation from the Covid-19 positive chest X-rays is still lacking. The recently published collection of the radiological images for a rural population in United States had made the development of such a model a possibility, for the high quality images and consistent clinical measurements. We manually annotated 221 chest X-ray images with the lung fields and the opacity regions and trained a segmentation model for the opacity region using the Unet framework and the Resnet18 backbone. In addition, we applied the percentage of the opacity region over the area of the total lung fields for predicting the severity of patients. The model has a good performance regarding the overlap between the predicted and the manually labelled opacity regions. The performance is comparable for both the testing data set and the validation data set which comes from very diverse sources. However, careful manual examinations by experienced radiologists show mistakes in the predictions, which could be caused by the anatomical complexities. Nevertheless, the percentage of the opacity region can predict the severity of the patients well in regards to the ICU admissions and mortality. In view of the above, our model is a successful first try in the development of a segmentation model for the opacity regions for the Covid-19 positive chest X-rays. However, additional work is needed before a robust model can be developed for the ultimate goal of the implementations in the clinical setting. Model and supporting materials can be found in GitHub",296,COVID-19,,,Dataset;Radiologists;Eyeglasses,,,,,,External,Segmentation-only,CT
10.1101/2020.10.30.20222786,10.1101/2020.10.30.20222786,Yes,,,2020,2020-11-03,Preprint,medRxiv,0,deep learning model for improving the characterization of coronavirus on chest x-ray images using cnn,"The novel Coronavirus, also known as Covid19, is a pandemic that has weighed heavily on the socio-economic affairs of the world. Although researches into the production of relevant vaccine are being advanced, there is, however, a need for a computational solution to mediate the process of aiding quick detection of the disease. Different computational solutions comprised of natural language processing, knowledge engineering and deep learning have been adopted for this task. However, deep learning solutions have shown interesting performance compared to other methods. This paper therefore aims to advance the application deep learning technique to the problem of characterization and detection of novel coronavirus. The approach adopted in this study proposes a convolutional neural network (CNN) model which is further enhanced using the technique of data augmentation. The motive for the enhancement of the CNN model through the latter technique is to investigate the possibility of further improving the performances of deep learning models in detection of coronavirus. The proposed model is then applied to the COVID-19 X-ray dataset in this study which is the National Institutes of Health (NIH) Chest X-Ray dataset obtained from Kaggle for the purpose of promoting early detection and screening of coronavirus disease. Results obtained showed that our approach achieved a performance of 100% accuracy, recall/precision of 0.85, F-measure of 0.9, and specificity of 1.0. The proposed CNN model and data augmentation solution may be adopted in pre-screening suspected cases of Covid19 to provide support to the use of the well-known RT-PCR testing.",248,COVID-19,,,Polymerase Chain Reaction;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.11.08.20227819,10.1101/2020.11.08.20227819,Yes,,,2020,2020-11-12,Preprint,medRxiv,0,detection of covid-19 disease from chest x-ray images: a deep transfer learning framework,"World economy as well as public health have been facing a devastating effect caused by the disease termed as Coronavirus (COVID-19). A significant step of COVID-19 affected patient’s treatment is the faster and accurate detection of the disease which is the motivation of this study. In this paper, implementation of a deep transfer learning-based framework using a pre-trained network (ResNet-50) for detecting COVID-19 from the chest X-rays was done. Our dataset consists of 2905 chest X-ray images of three categories: COVID-19 affected (219 cases), Viral Pneumonia affected (1345 cases), and Normal Chest X-rays (1341 cases). The implemented neural network demonstrates significant performance in classifying the cases with an overall accuracy of 96%. Most importantly, the model has shown a significantly good performance over the current research-based methods in detecting the COVID-19 cases in the test dataset (Precision = 1.00, Recall = 1.00, F1-score = 1.00 and Specificity = 1.00). Therefore, our proposed approach can be adapted as a reliable method for faster and accurate COVID-19 affected case detection.",168,"COVID-19;Pneumonia, Viral",,,Public Health;Transfer Learning,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.11.08.20228080,10.1101/2020.11.08.20228080,Yes,,,2020,2020-11-12,Preprint,medRxiv,0,automatic covid-19 detection from chest radiographic images using convolutional neural network,"The global pandemic of the novel coronavirus that started in Wuhan, China has affected more than 2 million people worldwide and caused more than 130,000 tragic deaths. To date, the COVID-19 virus is still spreading and affecting thousands of people. The main problem with testing for COVID-19 is that there are very few test kits available for a large number of affected or suspicious individuals. This leads to the need for automatic detection systems that use artificial intelligence. Deep learning is one of the most powerful AI tools available, so we recommend creating a convolutional neural network to detect COVID-19 positive patients from chest radiographs. According to previous studies, lung X-rays of COVID-19-positive patients show obvious characteristics, so this is a reliable method for testing patients, because X-ray examination of suspicious patients is easier than rt-PCR. Our model has been trained with 820 chest radiographic images (excluding data augmentation) collected from 3 databases, with a classification accuracy of 99.61% (training accuracy of 99.59%), sensitivity of 99.21% and specificity of 99.29 %, proved that our model has become a reliable COVID-19 detector.",181,COVID-19;Death,,,Polymerase Chain Reaction;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.12.14.20248158,10.1101/2020.12.14.20248158,Yes,,,2020,2020-12-16,Preprint,medRxiv,0,transfer learning for covid-19 pneumonia detection and classification in chest x-ray images,"We introduce a deep learning framework that can detect COVID-19 pneumonia in thoracic radiographs, as well as differentiate it from bacterial pneumonia infection. Deep classification models, such as convolutional neural networks (CNNs), require large-scale datasets in order to be trained and perform properly. Since the number of X-ray samples related to COVID-19 is limited, transfer learning (TL) appears as the go-to method to alleviate the demand for training data and develop accurate automated diagnosis models. In this context, networks are able to gain knowledge from pretrained networks on large-scale image datasets or alternative data-rich sources (i.e. bacterial and viral pneumonia radiographs). The experimental results indicate that the TL approach outperforms the performance obtained without TL, for the COVID-19 classification task in chest X-ray images.",124,"COVID-19;Infections;Pneumonia;Pneumonia, Bacterial;Pneumonia, Viral",,,Transfer Learning;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.12.19.20248530,10.1101/2020.12.19.20248530,Yes,,,2020,2020-12-23,Preprint,medRxiv,0,lungai: a deep learning convolutional neural network for automated detection of covid-19 from posteroanterior chest x-rays,"COVID-19 is an infectious disease caused by the Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2). As of December 2020, more than 72 million cases have been reported worldwide. The standard method of diagnosis is by Real-Time Reverse Transcription Polymerase Chain Reaction (rRT-PCR) from a Nasopharyngeal Swab. Currently, there is no vaccine or specific antiviral treatment for COVID-19. Due to rate of spreading of the disease manual detection among people is becoming more difficult because of a clear lack of testing capability. Thus there was need of a quick and reliable yet non-labour intensive detection technique. Considering that the virus predominantly appears in the form of a lung based abnormality I made use of Chest X-Rays as our primary mode of detection. For this detection system we made use of Posteroanterior (PA) Chest X-rays of people infected with Bacterial Pneumonia (2780 Images), Viral Pneumonia (1493 Images), Covid-19 (729 Images) as well as those of perfectly Healthy Individuals (1583 Images) procured from various Publicly Available Datasets and Radiological Societies. LungAI is a novel Convolutional Neural Network based on a Hybrid of the DarkNet and AlexNet architecture. The network was trained on 80% of the dataset with 20% kept for validation. The proposed Coronavirus Detection Model performed exceedingly well with an accuracy of 99.16%, along with a Sensitivity value of 99.31% and Specificity value of 99.14%. Thus LungAI has the potential to prove useful in managing the current Pandemic Situation by providing a reliable and fast alternative to Coronavirus Detection given strong results.",250,"COVID-19;Communicable Diseases;Pneumonia, Bacterial;Pneumonia, Viral;Severe Acute Respiratory Syndrome",,,Polymerase Chain Reaction;Antiviral Agents;Pharmaceutical Preparations;Communicable Diseases;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,X-Ray
10.1101/2020.12.20.20248582,10.1101/2020.12.20.20248582,Yes,,,2020,2020-12-23,Preprint,medRxiv,0,rapid covid-19 diagnosis using deep learning of the computerized tomography scans,"Several studies suggest that COVID-19 may be accompanied by symptoms such as a dry cough, muscle aches, sore throat, and mild to moderate respiratory illness. The symptoms of this disease indicate the fact that COVID-19 causes noticeable negative effects on the lungs. Therefore, considering the health status of the lungs using X-rays and CT scans of the chest can significantly help diagnose COVID-19 infection. Due to the fact that most of the methods that have been proposed to COVID-19 diagnose deal with the lengthy testing time and also might give more false positive and false negative results, this paper aims to review and implement artificial intelligence (AI) image-based diagnosis methods in order to detect coronavirus infection with zero or near to zero false positives and false negatives rates. Besides the already existing AI image-based medical diagnosis method for the other well-known disease, this study aims on finding the most accurate COVID-19 detection method among AI methods such as machine learning (ML) and artificial neural network (ANN), ensemble learning (EL) methods.",170,Ache;COVID-19;Coronavirus Infections;Cough;Infections;Sore Throat,,,Other Topics,,,,,,External,2. Detection/Diagnosis,CT
10.1101/2021.03.02.21252269,10.1101/2021.03.02.21252269,Yes,,,2021,2021-03-05,Preprint,medRxiv,0,an explainable artificial intelligence based prospective framework for covid-19 risk prediction,"Given the spread of COVID-19 to vast geographical regions and populations, it is not feasible to undergo or recommend the RT-PCR based tests to all individuals with flu-like symptoms. The reach of RT-PCR based testing is still limited due to the high cost of the test and huge population in few countries. Thus, alternative methods for COVID-19 infection risk prediction can be useful. We built an explainable artificial intelligence (AI) based integrated web-based prospective framework for COVID-19 risk prediction. We employed a two-step procedure for the non-clinical prediction of COVID19 infection risk. In the first step we assess the initial risk of COVID19 infection based on carefully selected parameters associated with COVID-19 positive symptoms from recent research. Generally, X-ray scans are cheaper and easily available in most government and private health centres. Therefore, based on the outcome of the computed initial risk in first step, we further provide an optional prediction using the chest X-ray scans in the second step of our proposed AI based prospective framework. Since there is a bottleneck to undergo an expensive RT-PCR based confirmatory test in economically backward nations, this is a crucial part of our explainable AI based prospective framework. The initial risk assessment outcome is analysed in combination with the advanced deep learning-based analysis of chest X-ray scans to provide an accurate prediction of COVID-19 infection risk. This prospective web-based AI framework can be employed in limited resource settings after clinical validation in future. The cost and time associated with the adoption of this prospective AI based prospective framework will be minimal and hence it will be beneficial to majority of the population living in low-income settings such as small towns and rural areas that have limited access to advanced healthcare facilities.",289,COVID-19;Infections,,,Health Care;Polymerase Chain Reaction;Other Topics,,,,,,,1. Risk identification,X-Ray
10.1101/2021.04.19.21254974,10.1101/2021.04.19.21254974,Yes,,,2021,2021-04-20,Preprint,medRxiv,0,a simplified point-of-care lung ultrasound protocol to detect coronavirus disease 2019 in patients: a prospective observational study,"To assess the diagnostic performance of lung point-of-care ultrasound (POCUS) compared to either a positive nucleic acid test (NAT) or a COVID-19-typical pattern on computed tomography (CT) and to evaluate opportunities to simplify a POCUS algorithm. Hospital-admitted adult inpatients with either confirmed or suspected COVID-19 and a completed or ordered CT within the preceding 24 hours were recruited. Twelve lung zones were scanned with a handheld POCUS machine. POCUS, CT, and X-ray (CXR) images were reviewed independently by blinded experts. A simplified POCUS algorithm was developed via machine learning. Of 79 enrolled subjects, 26.6% had a positive NAT and 31.6% had a CT typical for COVID-19. The receiver operator curve (ROC) for a 12-zone POCUS protocol had an AUC of 0.787 for positive NAT and 0.820 for typical CT. A simplified four-zone protocol had an AUC of 0.862 for typical CT and 0.862 for positive NAT. CT had an AUC of 0.815 for positive NAT; CXR had AUCs of 0.793 for positive NAT and 0.733 for typical CT. Performance of the four-zone protocol was superior to CXR for positive NAT (p=0.0471). Using a two-point cutoff system, the four-zone POCUS protocol had a sensitivity of 0.920 and 0.904 compared to CT and NAT, respectively, at the lower cutoff; it had a specificity of 0.926 and 0.948 at the higher cutoff, respectively. POCUS outperformed CXR to predict positive NAT. POCUS could potentially replace other chest imaging for persons under investigation for COVID-19.",240,COVID-19,,,Algorithms;ROC Curve,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
2003.05037,,Yes,,,2020,2020-03-24,Preprint,arXiv,0,rapid ai development cycle for the coronavirus (covid-19) pandemic: initial results for automated detection and patient monitoring using deep learning ct image analysis,"Develop AI-based automated CT image analysis tools for detection, quantification, and tracking of Coronavirus; demonstrate they can differentiate coronavirus patients from non-patients. Multiple international datasets, including from Chinese disease-infected areas were included. We present a system that utilizes robust 2D and 3D deep learning models, modifying and adapting existing AI models and combining them with clinical understanding. We conducted multiple retrospective experiments to analyze the performance of the system in the detection of suspected COVID-19 thoracic CT features and to evaluate evolution of the disease in each patient over time using a 3D volume review, generating a Corona score. The study includes a testing set of 157 international patients (China and U.S). Classification results for Coronavirus vs Non-coronavirus cases per thoracic CT studies were 0.996 AUC ; on datasets of Chinese control and infected patients. 98.2% sensitivity, 92.2% specificity. For time analysis of Coronavirus patients, the system output enables quantitative measurements for smaller opacities (volume, diameter) and visualization of the larger opacities in a slice-based heat map or a 3D volume display. Our suggested Corona score measures the progression of disease over time. This initial study, which is currently being expanded to a larger population, demonstrated that rapidly developed AI-based image analysis can achieve high accuracy in detection of Coronavirus as well as quantification and tracking of disease burden.",219,COVID-19;COVID-19 Pandemic,,,Specificity;Area under Curve;Map,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
2003.09439,,Yes,,,2020,2020-09-22,Preprint,arXiv,0,roam: random layer mixup for semi-supervised learning in medical imaging,"Medical image segmentation is one of the major challenges addressed by machine learning methods. Yet, deep learning methods profoundly depend on a large amount of annotated data, which is time-consuming and costly. Though, semi-supervised learning methods approach this problem by leveraging an abundant amount of unlabeled data along with a small amount of labeled data in the training process. Recently, MixUp regularizer has been successfully introduced to semi-supervised learning methods showing superior performance. MixUp augments the model with new data points through linear interpolation of the data at the input space. We argue that this option is limited. Instead, we propose ROAM, a \random layer mixup, which encourages the network to be less confident for interpolated data points at randomly selected space. ROAM generates more data points that have never seen before, and hence it avoids over-fitting and enhances the generalization ability. We conduct extensive experiments to validate our method on publicly available datasets on whole-brain image segmentation (MALC) and Lung and Infection segmentation in COVID-19. ROAM achieves state-of-the-art (SOTA) results in fully supervised and semi-supervised settings with a relative improvement of up to 2.40\% and 16.50\%, respectively for the whole-brain segmentation. Similarly, ROAM achieves superior performance for COVID-19 segmentation beating SOTA SSL settings.",204,COVID-19;Infections,,,Art;Other Topics,,,,,,External,Segmentation-only,Multimodal
2003.10304,,Yes,,,2020,2020-03-23,Preprint,arXiv,0,attention u-net based adversarial architectures for chest x-ray lung segmentation,"Chest X-ray is the most common test among medical imaging modalities. It is applied for detection and differentiation of, among others, lung cancer, tuberculosis, and pneumonia, the last with importance due to the COVID-19 disease. Integrating computer-aided detection methods into the radiologist diagnostic pipeline, greatly reduces the doctors' workload, increasing reliability and quantitative analysis. Here we present a novel deep learning approach for lung segmentation, a basic, but arduous task in the diagnostic pipeline. Our method uses state-of-the-art fully convolutional neural networks in conjunction with an adversarial critic model. It generalized well to CXR images of unseen datasets with different patient profiles, achieving a final DSC of 97.5% on the JSRT dataset.",112,COVID-19;Lung Cancer;Pneumonia;Tuberculosis,,,Art;Architecture;Lung Diseases,,,,,,External,Segmentation-only,X-Ray
2003.10769,,Yes,,,2020,2020-03-27,Preprint,arXiv,0,estimating uncertainty and interpretability in deep learning for coronavirus (covid-19) detection,"Deep Learning has achieved state of the art performance in medical imaging. However, these methods for disease detection focus exclusively on improving the accuracy of classification or predictions without quantifying uncertainty in a decision. Knowing how much confidence there is in a computer-based medical diagnosis is essential for gaining clinicians trust in the technology and therefore improve treatment. Today, the 2019 Coronavirus (SARS-CoV-2) infections are a major healthcare challenge around the world. Detecting COVID-19 in X-ray images is crucial for diagnosis, assessment and treatment. However, diagnostic uncertainty in the report is a challenging and yet inevitable task for radiologist. In this paper, we investigate how drop-weights based Bayesian Convolutional Neural Networks (BCNN) can estimate uncertainty in Deep Learning solution to improve the diagnostic performance of the human-machine team using publicly available COVID-19 chest X-ray dataset and show that the uncertainty in prediction is highly correlates with accuracy of prediction. We believe that the availability of uncertainty-aware deep learning solution will enable a wider adoption of Artificial Intelligence (AI) in a clinical setting.",172,COVID-19,,,Coronavirus Infections;Art;Health Care,,,,,,External,Segmentation-only,X-Ray
2003.11055,,Yes,,,2020,2020-03-24,Preprint,arXiv,0,covidx-net: a framework of deep learning classifiers to diagnose covid-19 in x-ray images,"Coronaviruses (CoV) are perilous viruses that may cause Severe Acute Respiratory Syndrome (SARS-CoV), Middle East Respiratory Syndrome (MERS-CoV). The novel 2019 Coronavirus disease (COVID-19) was discovered as a novel disease pneumonia in the city of Wuhan, China at the end of 2019. Now, it becomes a Coronavirus outbreak around the world, the number of infected people and deaths are increasing rapidly every day according to the updated reports of the World Health Organization (WHO). Therefore, the aim of this article is to introduce a new deep learning framework; namely COVIDX-Net to assist radiologists to automatically diagnose COVID-19 in X-ray images. Due to the lack of public COVID-19 datasets, the study is validated on 50 Chest X-ray images with 25 confirmed positive COVID-19 cases. The COVIDX-Net includes seven different architectures of deep convolutional neural network models, such as modified Visual Geometry Group Network (VGG19) and the second version of Google MobileNet. Each deep neural network model is able to analyze the normalized intensities of the X-ray image to classify the patient status either negative or positive COVID-19 case. Experiments and evaluation of the COVIDX-Net have been successfully done based on 80-20% of X-ray images for the model training and testing phases, respectively. The VGG19 and Dense Convolutional Network (DenseNet) models showed a good and similar performance of automated COVID-19 classification with f1-scores of 0.89 and 0.91 for normal and COVID-19, respectively. This study demonstrated the useful application of deep learning models to classify COVID-19 in X-ray images based on the proposed COVIDX-Net framework. Clinical studies are the next milestone of this research work.",262,COVID-19;Death;Middle East Respiratory Syndrome;Pneumonia;Severe Acute Respiratory Syndrome,,,World Health Organization;Architecture;Disease Outbreaks;Radiologists;Neural Networks,,,,,,External,2. Detection/Diagnosis,X-Ray
2003.11988,,Yes,,,2020,2020-03-26,Preprint,arXiv,0,severity assessment of coronavirus disease 2019 (covid-19) using quantitative features from chest ct images,"Chest computed tomography (CT) is recognized as an important tool for COVID-19 severity assessment. As the number of affected patients increase rapidly, manual severity assessment becomes a labor-intensive task, and may lead to delayed treatment. Using machine learning method to realize automatic severity assessment (non-severe or severe) of COVID-19 based on chest CT images, and to explore the severity-related features from the resulting assessment model. Chest CT images of 176 patients (age 45.3 years, 96 male and 80 female) with confirmed COVID-19 are used, from which 63 quantitative features, e.g., the infection volume/ratio of the whole lung and the volume of ground-glass opacity (GGO) regions, are calculated. A random forest (RF) model is trained to assess the severity (non-severe or severe) based on quantitative features. Importance of each quantitative feature, which reflects the correlation to the severity of COVID-19, is calculated from the RF model. Using three-fold cross validation, the RF model shows promising results, i.e., 0.933 of true positive rate, 0.745 of true negative rate, 0.875 of accuracy, and 0.91 of AUC. The resulting importance of quantitative features shows that the volume and its ratio (with respect to the whole lung volume) of ground glass opacity (GGO) regions are highly related to the severity of COVID-19, and the quantitative features calculated from the right lung are more related to the severity assessment than those of the left lung. The RF based model can achieve automatic severity assessment (non-severe or severe) of COVID-19 infection, and the performance is promising. Several quantitative features, which have the potential to reflect the severity of COVID-19, were revealed.",264,COVID-19;Infections,,,Other Topics,,,,,,External,2. Detection/Diagnosis,CT
2003.13145,10.1109/ACCESS.2020.3010287,Yes,,,2020,2020-06-15,Preprint,arXiv,0,can ai help in screening viral and covid-19 pneumonia?,"Coronavirus disease (COVID-19) is a pandemic disease, which has already caused thousands of causalities and infected several millions of people worldwide. Any technological tool enabling rapid screening of the COVID-19 infection with high accuracy can be crucially helpful to healthcare professionals. The main clinical tool currently in use for the diagnosis of COVID-19 is the Reverse transcription polymerase chain reaction (RT-PCR), which is expensive, less-sensitive and requires specialized medical personnel. X-ray imaging is an easily accessible tool that can be an excellent alternative in the COVID-19 diagnosis. This research was taken to investigate the utility of artificial intelligence (AI) in the rapid and accurate detection of COVID-19 from chest X-ray images. The aim of this paper is to propose a robust technique for automatic detection of COVID-19 pneumonia from digital chest X-ray images applying pre-trained deep-learning algorithms while maximizing the detection accuracy. A public database was created by the authors combining several public databases and also by collecting images from recently published articles. The database contains a mixture of 423 COVID-19, 1485 viral pneumonia, and 1579 normal chest X-ray images. Transfer learning technique was used with the help of image augmentation to train and validate several pre-trained deep Convolutional Neural Networks (CNNs). The networks were trained to classify two different schemes: i) normal and COVID-19 pneumonia; ii) normal, viral and COVID-19 pneumonia with and without image augmentation. The classification accuracy, precision, sensitivity, and specificity for both the schemes were 99.7%, 99.7%, 99.7% and 99.55% and 97.9%, 97.95%, 97.9%, and 98.8%, respectively.",251,"COVID-19;Infections;Pneumonia;Pneumonia, Viral",,,Coronavirus Infections;Occupational Groups;Health Care;Algorithms;Transfer Learning;Sensitivity and Specificity;Polymerase Chain Reaction;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,X-Ray
2003.14363,,Yes,,,2020,2020-03-31,Preprint,arXiv,0,automated methods for detection and classification pneumonia based on x-ray images using deep learning,"Recently, researchers, specialists, and companies around the world are rolling out deep learning and image processing-based systems that can fastly process hundreds of X-Ray and computed tomography (CT) images to accelerate the diagnosis of pneumonia such as SARS, COVID-19, and aid in its containment. Medical images analysis is one of the most promising research areas, it provides facilities for diagnosis and making decisions of a number of diseases such as MERS, COVID-19. In this paper, we present a comparison of recent Deep Convolutional Neural Network (DCNN) architectures for automatic binary classification of pneumonia images based fined tuned versions of (VGG16, VGG19, DenseNet201, Inception_ResNet_V2, Inception_V3, Resnet50, MobileNet_V2 and Xception). The proposed work has been tested using chest X-Ray and CT dataset which contains 5856 images (4273 pneumonia and 1583 normal). As result we can conclude that fine-tuned version of Resnet50, MobileNet_V2 and Inception_Resnet_V2 show highly satisfactory performance with rate of increase in training and validation accuracy (more than 96% of accuracy). Unlike CNN, Xception, VGG16, VGG19, Inception_V3 and DenseNet201 display low performance (more than 84% accuracy).",175,COVID-19;Pneumonia,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2003.14395,,Yes,,,2020,2020-03-31,Preprint,arXiv,0,covid-resnet: a deep learning framework for screening of covid-19 from radiographs,"In the last few months, the novel COVID19 pandemic has spread all over the world. Due to its easy transmission, developing techniques to accurately and easily identify the presence of COVID19 and distinguish it from other forms of flu and pneumonia is crucial. Recent research has shown that the chest Xrays of patients suffering from COVID19 depicts certain abnormalities in the radiography. However, those approaches are closed source and not made available to the research community for re-producibility and gaining deeper insight. The goal of this work is to build open source and open access datasets and present an accurate Convolutional Neural Network framework for differentiating COVID19 cases from other pneumonia cases. Our work utilizes state of the art training techniques including progressive resizing, cyclical learning rate finding and discriminative learning rates to training fast and accurate residual neural networks. Using these techniques, we showed the state of the art results on the open-access COVID-19 dataset. This work presents a 3-step technique to fine-tune a pre-trained ResNet-50 architecture to improve model performance and reduce training time. We call it COVIDResNet. This is achieved through progressively re-sizing of input images to 128x128x3, 224x224x3, and 229x229x3 pixels and fine-tuning the network at each stage. This approach along with the automatic learning rate selection enabled us to achieve the state of the art accuracy of 96.23% (on all the classes) on the COVIDx dataset with only 41 epochs. This work presented a computationally efficient and highly accurate model for multi-class classification of three different infection types from along with Normal individuals. This model can help in the early screening of COVID19 cases and help reduce the burden on healthcare systems.",277,COVID-19;COVID-19 Pandemic;Infections;Pneumonia,,,Art;Health Care;Architecture;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2004.00038,,Yes,,,2020,2020-03-31,Preprint,arXiv,0,diagnosing covid-19 pneumonia from x-ray and ct images using deep learning and transfer learning algorithms,"COVID-19 (also known as 2019 Novel Coronavirus) first emerged in Wuhan, China and spread across the globe with unprecedented effect and has now become the greatest crisis of the modern era. The COVID-19 has proved much more pervasive demands for diagnosis that has driven researchers to develop more intelligent, highly responsive and efficient detection methods. In this work, we focus on proposing AI tools that can be used by radiologists or healthcare professionals to diagnose COVID-19 cases in a quick and accurate manner. However, the lack of a publicly available dataset of X-ray and CT images makes the design of such AI tools a challenging task. To this end, this study aims to build a comprehensive dataset of X-rays and CT scan images from multiple sources as well as provides a simple but an effective COVID-19 detection technique using deep learning and transfer learning algorithms. In this vein, a simple convolution neural network (CNN) and modified pre-trained AlexNet model are applied on the prepared X-rays and CT scan images dataset. The result of the experiments shows that the utilized models can provide accuracy up to 98 % via pre-trained network and 94.1 % accuracy by using the modified CNN.",199,COVID-19;Pneumonia,,,Health Care;Algorithms;Transfer Learning;Research Personnel,,,,,,External,2. Detection/Diagnosis,Multimodal
2004.02060,,Yes,,,2020,2020-05-20,Preprint,arXiv,0,finding covid-19 from chest x-rays using deep learning on a small dataset,"Testing for COVID-19 has been unable to keep up with the demand. Further, the false negative rate is projected to be as high as 30% and test results can take some time to obtain. X-ray machines are widely available and provide images for diagnosis quickly. This paper explores how useful chest X-ray images can be in diagnosing COVID-19 disease. We have obtained 122 chest X-rays of COVID-19 and over 4,000 chest X-rays of viral and bacterial pneumonia. A pretrained deep convolutional neural network has been tuned on 102 COVID-19 cases and 102 other pneumonia cases in a 10-fold cross validation. The results were all 102 COVID-19 cases were correctly classified and there were 8 false positives resulting in an AUC of 0.997. On a test set of 20 unseen COVID-19 cases all were correctly classified and more than 95% of 4171 other pneumonia examples were correctly classified. This study has flaws, most critically a lack of information about where in the disease process the COVID-19 cases were and the small data set size. More COVID-19 case images will enable a better answer to the question of how useful chest X-rays can be for diagnosing COVID-19 (so please send them).",199,"COVID-19;Pneumonia;Pneumonia, Bacterial",,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2004.02640,,Yes,,,2020,2020-04-06,Preprint,arXiv,0,coronavirus detection and analysis on chest ct with deep learning,"The outbreak of the novel coronavirus, officially declared a global pandemic, has a severe impact on our daily lives. As of this writing there are approximately 197,188 confirmed cases of which 80,881 are in ""Mainland China"" with 7,949 deaths, a mortality rate of 3.4%. In order to support radiologists in this overwhelming challenge, we develop a deep learning based algorithm that can detect, localize and quantify severity of COVID-19 manifestation from chest CT scans. The algorithm is comprised of a pipeline of image processing algorithms which includes lung segmentation, 2D slice classification and fine grain localization. In order to further understand the manifestations of the disease, we perform unsupervised clustering of abnormal slices. We present our results on a dataset comprised of 110 confirmed COVID-19 patients from Zhejiang province, China.",130,COVID-19;Death,,,Disease Outbreaks;Radiologists;Other Topics;Cluster Analysis,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,CT
2004.03042,,Yes,,,2020,2020-09-07,Preprint,arXiv,0,covid-mobilexpert: on-device covid-19 patient triage and follow-up using chest x-rays,"During the COVID-19 pandemic, there has been an emerging need for rapid, dedicated, and point-of-care COVID-19 patient disposition techniques to optimize resource utilization and clinical workflow. In view of this need, we present COVID-MobileXpert: a lightweight deep neural network (DNN) based mobile app that can use chest X-ray (CXR) for COVID-19 case screening and radiological trajectory prediction. We design and implement a novel three-player knowledge transfer and distillation (KTD) framework including a pre-trained attending physician (AP) network that extracts CXR imaging features from a large scale of lung disease CXR images, a fine-tuned resident fellow (RF) network that learns the essential CXR imaging features to discriminate COVID-19 from pneumonia and/or normal cases with a small amount of COVID-19 cases, and a trained lightweight medical student (MS) network to perform on-device COVID-19 patient triage and follow-up. To tackle the challenge of vastly similar and dominant fore- and background in medical images, we employ novel loss functions and training schemes for the MS network to learn the robust features. We demonstrate the significant potential of COVID-MobileXpert for rapid deployment via extensive experiments with diverse MS architecture and tuning parameter settings. The source codes for cloud and mobile based models are available from the following url: GitHub",204,COVID-19;COVID-19 Pandemic;Lung Diseases;Pneumonia,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2004.03698,,Yes,,,2020,2020-04-07,Preprint,arXiv,0,coronavirus (covid-19) classification using deep features fusion and ranking technique,"Coronavirus (COVID-19) emerged towards the end of 2019. World Health Organization (WHO) was identified it as a global epidemic. Consensus occurred in the opinion that using Computerized Tomography (CT) techniques for early diagnosis of pandemic disease gives both fast and accurate results. It was stated by expert radiologists that COVID-19 displays different behaviours in CT images. In this study, a novel method was proposed as fusing and ranking deep features to detect COVID-19 in early phase. 16x16 (Subset-1) and 32x32 (Subset-2) patches were obtained from 150 CT images to generate sub-datasets. Within the scope of the proposed method, 3000 patch images have been labelled as CoVID-19 and No finding for using in training and testing phase. Feature fusion and ranking method have been applied in order to increase the performance of the proposed method. Then, the processed data was classified with a Support Vector Machine (SVM). According to other pre-trained Convolutional Neural Network (CNN) models used in transfer learning, the proposed method shows high performance on Subset-2 with 98.27% accuracy, 98.93% sensitivity, 97.60% specificity, 97.63% precision, 98.28% F1-score and 96.54% Matthews Correlation Coefficient (MCC) metrics.",185,COVID-19,,,Transfer Learning;World Health Organization;Tomography,,,,,,External,2. Detection/Diagnosis,CT
2004.03747,,Yes,,,2020,2020-04-18,Preprint,arXiv,0,covid_mtnet: covid-19 detection with multi-task deep learning approaches,"COVID-19 is currently one the most life-threatening problems around the world. The fast and accurate detection of the COVID-19 infection is essential to identify, take better decisions and ensure treatment for the patients which will help save their lives. In this paper, we propose a fast and efficient way to identify COVID-19 patients with multi-task deep learning (DL) methods. Both X-ray and CT scan images are considered to evaluate the proposed technique. We employ our Inception Residual Recurrent Convolutional Neural Network with Transfer Learning (TL) approach for COVID-19 detection and our NABLA-N network model for segmenting the regions infected by COVID-19. The detection model shows around 84.67% testing accuracy from X-ray images and 98.78% accuracy in CT-images. A novel quantitative analysis strategy is also proposed in this paper to determine the percentage of infected regions in X-ray and CT images. The qualitative and quantitative results demonstrate promising results for COVID-19 detection and infected region localization.",155,COVID-19;Infections,,,Transfer Learning;Other Topics,,,,,,External,2. Detection/Diagnosis,Multimodal
2004.04582,,Yes,,,2020,2020-06-06,Preprint,arXiv,0,deepcovidexplainer: explainable covid-19 diagnosis based on chest x-ray images,"Amid the coronavirus disease (COVID-19) pandemic, humanity experiences a rapid increase in infection numbers across the world. Challenge hospitals are faced with, in the fight against the virus, is the effective screening of incoming patients. One methodology is the assessment of chest radiography (CXR) images, which usually requires expert radiologist's knowledge. In this paper, we propose an explainable deep neural networks (DNN)-based method for automatic detection of COVID-19 symptoms from CXR images, which we call DeepCOVIDExplainer. We used 15,959 CXR images of 15,854 patients, covering normal, pneumonia, and COVID-19 cases. CXR images are first comprehensively preprocessed, before being augmented and classified with a neural ensemble method, followed by highlighting class-discriminating regions using gradient-guided class activation maps (Grad-CAM++) and layer-wise relevance propagation (LRP). Further, we provide human-interpretable explanations of the predictions. Evaluation results based on hold-out data show that our approach can identify COVID-19 confidently with a positive predictive value (PPV) of 91.6%, 92.45%, and 96.12%; precision, recall, and F1 score of 94.6%, 94.3%, and 94.6%, respectively for normal, pneumonia, and COVID-19 cases, respectively, making it comparable or improved results over recent approaches. We hope that our findings will be a useful contribution to the fight against COVID-19 and, in more general, towards an increasing acceptance and adoption of AI-assisted applications in the clinical practice.",214,COVID-19;COVID-19 Pandemic;Infections;Pneumonia,,,Coronavirus Infections;Map,,,,,,External,2. Detection/Diagnosis,X-Ray
2004.05436,,Yes,,,2020,2020-04-11,Preprint,arXiv,0,detection of covid-19 from chest x-ray images using artificial intelligence: an early review,"In 2019, the entire world is facing a situation of health emergency due to a newly emerged coronavirus (COVID-19). Almost 196 countries are affected by covid-19, while USA, Italy, China, Spain, Iran, and France have the maximum active cases of COVID-19. The issues, medical and healthcare departments are facing in delay of detecting the COVID-19. Several artificial intelligence based system are designed for the automatic detection of COVID-19 using chest x-rays. In this article we will discuss the different approaches used for the detection of COVID-19 and the challenges we are facing. It is mandatory to develop an automatic detection system to prevent the transfer of the virus through contact. Several deep learning architecture are deployed for the detection of COVID-19 such as ResNet, Inception, Googlenet etc. All these approaches are detecting the subjects suffering with pneumonia while its hard to decide whether the pneumonia is caused by COVID-19 or due to any other bacterial or fungal attack.",158,COVID-19;Pneumonia,,,Health Care;Other Topics,,,,,,External,Review,X-Ray
2004.05645,,Yes,,,2020,2020-04-12,Preprint,arXiv,0,residual attention u-net for automated multi-class segmentation of covid-19 chest ct images,"The novel coronavirus disease 2019 (COVID-19) has been spreading rapidly around the world and caused significant impact on the public health and economy. However, there is still lack of studies on effectively quantifying the lung infection caused by COVID-19. As a basic but challenging task of the diagnostic framework, segmentation plays a crucial role in accurate quantification of COVID-19 infection measured by computed tomography (CT) images. To this end, we proposed a novel deep learning algorithm for automated segmentation of multiple COVID-19 infection regions. Specifically, we use the Aggregated Residual Transformations to learn a robust and expressive feature representation and apply the soft attention mechanism to improve the capability of the model to distinguish a variety of symptoms of the COVID-19. With a public CT image dataset, we validate the efficacy of the proposed algorithm in comparison with other competing methods. Experimental results demonstrate the outstanding performance of our algorithm for automated segmentation of COVID-19 Chest CT images. Our study provides a promising deep leaning-based segmentation tool to lay a foundation to quantitative diagnosis of COVID-19 lung infection in CT images.",181,COVID-19;Infections,,,Other Topics,,,,,,External,Segmentation-only,CT
2004.05717,10.1007/s42600-021-00151-6,Yes,,,2021,2021-04-24,Preprint,arXiv,0,towards an effective and efficient deep learning model for covid-19 patterns detection in x-ray images,"Confronting the pandemic of COVID-19, is nowadays one of the most prominent challenges of the human species. A key factor in slowing down the virus propagation is the rapid diagnosis and isolation of infected patients. The standard method for COVID-19 identification, the Reverse transcription polymerase chain reaction method, is time-consuming and in short supply due to the pandemic. Thus, researchers have been looking for alternative screening methods and deep learning applied to chest X-rays of patients has been showing promising results. Despite their success, the computational cost of these methods remains high, which imposes difficulties to their accessibility and availability. Thus, the main goal of this work is to propose an accurate yet efficient method in terms of memory and processing time for the problem of COVID-19 screening in chest X-rays. To achieve the defined objective we exploit and extend the EfficientNet family of deep artificial neural networks which are known for their high accuracy and low footprints in other applications. We also exploit the underlying taxonomy of the problem with a hierarchical classifier. A dataset of 13,569 X-ray images divided into healthy, non-COVID-19 pneumonia, and COVID-19 patients is used to train the proposed approaches and other 5 competing architectures. Finally, 231 images of the three classes were used to assess the quality of the methods. The results show that the proposed approach was able to produce a high-quality model, with an overall accuracy of 93.9%, COVID-19, sensitivity of 96.8% and positive prediction of 100%, while having from 5 to 30 times fewer parameters than other than the other tested architectures. Larger and more heterogeneous databases are still needed for validation before claiming that deep learning can assist physicians in the task of detecting COVID-19 in X-ray images.",288,COVID-19;Pneumonia,,,Research Personnel;Polymerase Chain Reaction;Reverse Transcription,8.639495113515313e-07,0.0,5.502367381973795e-07,0.0,0.0,External,2. Detection/Diagnosis,X-Ray
2004.06689,,Yes,,,2020,2020-04-14,Preprint,arXiv,0,weakly supervised deep learning for covid-19 infection detection and classification from ct images,"An outbreak of a novel coronavirus disease (i.e., COVID-19) has been recorded in Wuhan, China since late December 2019, which subsequently became pandemic around the world. Although COVID-19 is an acutely treated disease, it can also be fatal with a risk of fatality of 4.03% in China and the highest of 13.04% in Algeria and 12.67% Italy (as of 8th April 2020). The onset of serious illness may result in death as a consequence of substantial alveolar damage and progressive respiratory failure. Although laboratory testing, e.g., using reverse transcription polymerase chain reaction (RT-PCR), is the golden standard for clinical diagnosis, the tests may produce false negatives. Moreover, under the pandemic situation, shortage of RT-PCR testing resources may also delay the following clinical decision and treatment. Under such circumstances, chest CT imaging has become a valuable tool for both diagnosis and prognosis of COVID-19 patients. In this study, we propose a weakly supervised deep learning strategy for detecting and classifying COVID-19 infection from CT images. The proposed method can minimise the requirements of manual labelling of CT images but still be able to obtain accurate infection detection and distinguish COVID-19 from non-COVID-19 cases. Based on the promising results obtained qualitatively and quantitatively, we can envisage a wide deployment of our developed technique in large-scale clinical studies.",215,COVID-19;Death;Infections;Respiratory Failure,,,Coronavirus Infections;Disease Outbreaks;Polymerase Chain Reaction;Reverse Transcription,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,CT
2004.08379,,Yes,,,2021,2021-03-05,Preprint,arXiv,0,iteratively pruned deep learning ensembles for covid-19 detection in chest x-rays,"We demonstrate use of iteratively pruned deep learning model ensembles for detecting pulmonary manifestation of COVID-19 with chest X-rays. This disease is caused by the novel Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) virus, also known as the novel Coronavirus (2019-nCoV). A custom convolutional neural network and a selection of ImageNet pretrained models are trained and evaluated at patient-level on publicly available CXR collections to learn modality-specific feature representations. The learned knowledge is transferred and fine-tuned to improve performance and generalization in the related task of classifying CXRs as normal, showing bacterial pneumonia, or COVID-19-viral abnormalities. The best performing models are iteratively pruned to reduce complexity and improve memory efficiency. The predictions of the best-performing pruned models are combined through different ensemble strategies to improve classification performance. Empirical evaluations demonstrate that the weighted average of the best-performing pruned models significantly improves performance resulting in an accuracy of 99.01% and AUC of 0.9972 in detecting COVID-19 findings on CXRs. The combined use of modality-specific knowledge transfer, iterative model pruning, and ensemble learning resulted in improved predictions. We expect that this model can be quickly adopted for COVID-19 screening using chest radiographs.",190,"COVID-19;Pneumonia, Bacterial;Severe Acute Respiratory Syndrome",,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2004.09750,,Yes,,,2021,2021-03-21,Preprint,arXiv,0,miniseg: an extremely minimum network for efficient covid-19 segmentation,"The rapid spread of the new pandemic, i.e., COVID-19, has severely threatened global health. Deep-learning-based computer-aided screening, e.g., COVID-19 infected CT area segmentation, has attracted much attention. However, the publicly available COVID-19 training data are limited, easily causing overfitting for traditional deep learning methods that are usually data-hungry with millions of parameters. On the other hand, fast training/testing and low computational cost are also necessary for quick deployment and development of COVID-19 screening systems, but traditional deep learning methods are usually computationally intensive. To address the above problems, we propose MiniSeg, a lightweight deep learning model for efficient COVID-19 segmentation. Compared with traditional segmentation methods, MiniSeg has several significant strengths: i) it only has 83K parameters and is thus not easy to overfit; ii) it has high computational efficiency and is thus convenient for practical deployment; iii) it can be fast retrained by other users using their private COVID-19 data for further improving performance. In addition, we build a comprehensive COVID-19 segmentation benchmark for comparing MiniSeg to traditional methods.",169,COVID-19,,,Other Topics,,,,,,External,Segmentation-only,CT
2004.09803,,Yes,,,2020,2020-04-21,Preprint,arXiv,0,covidaid: covid-19 detection using chest x-ray,"The exponential increase in COVID-19 patients is overwhelming healthcare systems across the world. With limited testing kits, it is impossible for every patient with respiratory illness to be tested using conventional techniques (RT-PCR). The tests also have long turn-around time, and limited sensitivity. Detecting possible COVID-19 infections on Chest X-Ray may help quarantine high risk patients while test results are awaited. X-Ray machines are already available in most healthcare systems, and with most modern X-Ray systems already digitized, there is no transportation time involved for the samples either. In this work we propose the use of chest X-Ray to prioritize the selection of patients for further RT-PCR testing. This may be useful in an inpatient setting where the present systems are struggling to decide whether to keep the patient in the ward along with other patients or isolate them in COVID-19 areas. It would also help in identifying patients with high likelihood of COVID with a false negative RT-PCR who would need repeat testing. Further, we propose the use of modern AI techniques to detect the COVID-19 patients using X-Ray images in an automated manner, particularly in settings where radiologists are not available, and help make the proposed testing technology scalable. We present CovidAID: COVID-19 AI Detector, a novel deep neural network based model to triage patients for appropriate testing. On the publicly available covid-chestxray-dataset, our model gives 90.5% accuracy with 100% sensitivity (recall) for the COVID-19 infection. We significantly improve upon the results of Covid-Net on the same dataset.",250,COVID-19;Infections,,,Health Care;Polymerase Chain Reaction;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2004.10507,,Yes,,,2020,2020-08-21,Preprint,arXiv,0,deep learning for screening covid-19 using chest x-ray images,"With the ever increasing demand for screening millions of prospective ""novel coronavirus"" or COVID-19 cases, and due to the emergence of high false negatives in the commonly used PCR tests, the necessity for probing an alternative simple screening mechanism of COVID-19 using radiological images (like chest X-Rays) assumes importance. In this scenario, machine learning (ML) and deep learning (DL) offer fast, automated, effective strategies to detect abnormalities and extract key features of the altered lung parenchyma, which may be related to specific signatures of the COVID-19 virus. However, the available COVID-19 datasets are inadequate to train deep neural networks. Therefore, we propose a new concept called domain extension transfer learning (DETL). We employ DETL, with pre-trained deep convolutional neural network, on a related large chest X-Ray dataset that is tuned for classifying between four classes \viz. normal, pneumonia, other\_disease, and Covid-19. A 5-fold cross validation is performed to estimate the feasibility of using chest X-Rays to diagnose COVID-19. The initial results show promise, with the possibility of replication on bigger and more diverse data sets. The overall accuracy was measured as 90.13\%. In order to get an idea about the COVID-19 detection transparency, we employed the concept of Gradient Class Activation Map (Grad-CAM) for detecting the regions where the model paid more attention during the classification. This was found to strongly correlate with clinical findings, as validated by experts.",229,COVID-19;Pneumonia,,,Transfer Learning;Lung;Polymerase Chain Reaction;Other Topics;Lung Diseases;Map,,,,,,External,2. Detection/Diagnosis,X-Ray
2004.10987,,Yes,,,2020,2020-04-25,Preprint,arXiv,0,covid-19 chest ct image segmentation -- a deep convolutional neural network solution,"A novel coronavirus disease 2019 (COVID-19) was detected and has spread rapidly across various countries around the world since the end of the year 2019, Computed Tomography (CT) images have been used as a crucial alternative to the time-consuming RT-PCR test. However, pure manual segmentation of CT images faces a serious challenge with the increase of suspected cases, resulting in urgent requirements for accurate and automatic segmentation of COVID-19 infections. Unfortunately, since the imaging characteristics of the COVID-19 infection are diverse and similar to the backgrounds, existing medical image segmentation methods cannot achieve satisfactory performance. In this work, we try to establish a new deep convolutional neural network tailored for segmenting the chest CT images with COVID-19 infections. We firstly maintain a large and new chest CT image dataset consisting of 165,667 annotated chest CT images from 861 patients with confirmed COVID-19. Inspired by the observation that the boundary of the infected lung can be enhanced by adjusting the global intensity, in the proposed deep CNN, we introduce a feature variation block which adaptively adjusts the global properties of the features for segmenting COVID-19 infection. The proposed FV block can enhance the capability of feature representation effectively and adaptively for diverse cases. We fuse features at different scales by proposing Progressive Atrous Spatial Pyramid Pooling to handle the sophisticated infection areas with diverse appearance and shapes. We conducted experiments on the data collected in China and Germany and show that the proposed deep CNN can produce impressive performance effectively.",249,COVID-19;Infections,,,Polymerase Chain Reaction;Other Topics,,,,,,Self-recorded/clinical,Segmentation-only,CT
2004.12084,,Yes,,,2021,2021-01-24,Preprint,arXiv,0,pocovid-net: automatic detection of covid-19 from a new lung ultrasound imaging dataset (pocus),"With the rapid development of COVID-19 into a global pandemic, there is an ever more urgent need for cheap, fast and reliable tools that can assist physicians in diagnosing COVID-19. Medical imaging such as CT can take a key role in complementing conventional diagnostic tools from molecular biology, and, using deep learning techniques, several automatic systems were demonstrated promising performances using CT or X-ray data. Here, we advocate a more prominent role of point-of-care ultrasound imaging to guide COVID-19 detection. Ultrasound is non-invasive and ubiquitous in medical facilities around the globe. Our contribution is threefold. First, we gather a lung ultrasound (POCUS) dataset consisting of 1103 images (654 COVID-19, 277 bacterial pneumonia and 172 healthy controls), sampled from 64 videos. This dataset was assembled from various online sources, processed specifically for deep learning models and is intended to serve as a starting point for an open-access initiative. Second, we train a deep convolutional neural network (POCOVID-Net) on this 3-class dataset and achieve an accuracy of 89% and, by a majority vote, a video accuracy of 92%. For detecting COVID-19 in particular, the model performs with a sensitivity of 0.96, a specificity of 0.79 and F1-score of 0.92 in a 5-fold cross validation. Third, we provide an open-access web service (POCOVIDScreen) that is available at:. The website deploys the predictive model, allowing to perform predictions on ultrasound lung images. In addition, it grants medical staff the option to (bulk) upload their own screenings in order to contribute to the growing public database of pathological lung ultrasound images. Dataset and code are available from: GitHub This preprint is superseded by our paper in Applied Sciences:",273,"COVID-19;Pneumonia, Bacterial",,,Point-of-Care Systems;Ultrasonography,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
2004.12592,,Yes,,,2020,2020-05-21,Preprint,arXiv,0,robust screening of covid-19 from chest x-ray via discriminative cost-sensitive learning,"This paper addresses the new problem of automated screening of coronavirus disease 2019 (COVID-19) based on chest X-rays, which is urgently demanded toward fast stopping the pandemic. However, robust and accurate screening of COVID-19 from chest X-rays is still a globally recognized challenge because of two bottlenecks: 1) imaging features of COVID-19 share some similarities with other pneumonia on chest X-rays, and 2) the misdiagnosis rate of COVID-19 is very high, and the misdiagnosis cost is expensive. While a few pioneering works have made much progress, they underestimate both crucial bottlenecks. In this paper, we report our solution, discriminative cost-sensitive learning (DCSL), which should be the choice if the clinical needs the assisted screening of COVID-19 from chest X-rays. DCSL combines both advantages from fine-grained classification and cost-sensitive learning. Firstly, DCSL develops a conditional center loss that learns deep discriminative representation. Secondly, DCSL establishes score-level cost-sensitive learning that can adaptively enlarge the cost of misclassifying COVID-19 examples into other classes. DCSL is so flexible that it can apply in any deep neural network. We collected a large-scale multi-class dataset comprised of 2,239 chest X-ray examples: 239 examples from confirmed COVID-19 cases, 1,000 examples with confirmed bacterial or viral pneumonia cases, and 1,000 examples of healthy people. Extensive experiments on the three-class classification show that our algorithm remarkably outperforms state-of-the-art algorithms. It achieves an accuracy of 97.01%, a precision of 97%, a sensitivity of 97.09%, and an F1-score of 96.98%. These results endow our algorithm as an efficient tool for the fast large-scale screening of COVID-19.",255,"COVID-19;Pneumonia;Pneumonia, Viral",,,Art;Algorithms,,,,,,External,2. Detection/Diagnosis,X-Ray
2004.12786,,Yes,,,2020,2020-04-30,Preprint,arXiv,0,a cascaded learning strategy for robust covid-19 pneumonia chest x-ray screening,"We introduce a comprehensive screening platform for the COVID-19 (a.k.a., SARS-CoV-2) pneumonia. The proposed AI-based system works on chest x-ray (CXR) images to predict whether a patient is infected with the COVID-19 disease. Although the recent international joint effort on making the availability of all sorts of open data, the public collection of CXR images is still relatively small for reliably training a deep neural network (DNN) to carry out COVID-19 prediction. To better address such inefficiency, we design a cascaded learning strategy to improve both the sensitivity and the specificity of the resulting DNN classification model. Our approach leverages a large CXR image dataset of non-COVID-19 pneumonia to generalize the original well-trained classification model via a cascaded learning scheme. The resulting screening system is shown to achieve good classification performance on the expanded dataset, including those newly added COVID-19 CXR images.",142,COVID-19;Pneumonia,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2004.12852,,Yes,,,2020,2020-04-20,Preprint,arXiv,0,ai-driven ct-based quantification staging and short-term outcome prediction of covid-19 pneumonia,"Chest computed tomography (CT) is widely used for the management of Coronavirus disease 2019 (COVID-19) pneumonia because of its availability and rapidity. The standard of reference for confirming COVID-19 relies on microbiological tests but these tests might not be available in an emergency setting and their results are not immediately available, contrary to CT. In addition to its role for early diagnosis, CT has a prognostic role by allowing visually evaluating the extent of COVID-19 lung abnormalities. The objective of this study is to address prediction of short-term outcomes, especially need for mechanical ventilation. In this multi-centric study, we propose an end-to-end artificial intelligence solution for automatic quantification and prognosis assessment by combining automatic CT delineation of lung disease meeting performance of experts and data-driven identification of biomarkers for its prognosis. AI-driven combination of variables with CT-based biomarkers offers perspectives for optimal patient management given the shortage of intensive care beds and ventilators.",153,COVID-19;Lung Diseases;Pneumonia,,,Other Topics,,,,,,Self-recorded/clinical,4. Prognosis/Treatment,CT
2004.13122,,Yes,,,2020,2020-04-24,Preprint,arXiv,0,development of a machine-learning system to classify lung ct scan images into normal/covid-19 class,"Recently, the lung infection due to Coronavirus Disease (COVID-19) affected a large human group worldwide and the assessment of the infection rate in the lung is essential for treatment planning. This research aims to propose a Machine-Learning-System (MLS) to detect the COVID-19 infection using the CT scan Slices (CTS). This MLS implements a sequence of methods, such as multi-thresholding, image separation using threshold filter, feature-extraction, feature-selection, feature-fusion and classification. The initial part implements the Chaotic-Bat-Algorithm and Kapur's Entropy (CBA+KE) thresholding to enhance the CTS. The threshold filter separates the image into two segments based on a chosen threshold 'Th'. The texture features of these images are extracted, refined and selected using the chosen procedures. Finally, a two-class classifier system is implemented to categorize the chosen CTS (n=500 with a pixel dimension of 512x512x1) into normal/COVID-19 group. In this work, the classifiers, such as Naive Bayes (NB), k-Nearest Neighbors (KNN), Decision Tree (DT), Random Forest (RF) and Support Vector Machine with linear kernel (SVM) are implemented and the classification task is performed using various feature vectors. The experimental outcome of the SVM with Fused-Feature-Vector (FFV) helped to attain a detection accuracy of 89.80%.",192,COVID-19;Infections,,,Humans;Other Topics;Entropy;Decision Trees;Support Vector Machine,,,,,,External,2. Detection/Diagnosis,CT
2005.00845,,Yes,,,2020,2020-05-02,Preprint,arXiv,0,deep convolutional neural networks to diagnose covid-19 and other pneumonia diseases from posteroanterior chest x-rays,"The article explores different deep convolutional neural network architectures trained and tested on posteroanterior chest X-rays of 327 patients who are healthy (152 patients), diagnosed with COVID-19, and other types of pneumonia. In particular, this paper looks at the deep convolutional neural networks VGG16 and VGG19, InceptionResNetV2 and InceptionV3, as well as Xception, all followed by a flat multi-layer perceptron and a final 30% drop-out. The paper has found that the best performing network is VGG16 with a final 30% drop-out trained over 3 classes (COVID-19, No Finding, Other Pneumonia). It has an internal cross-validated accuracy of 93.9%, a COVID-19 sensitivity of 87.7%, and a No Finding sensitivity of 96.8%. The respective external cross-validated values are 84.1%, and 96.8%. The model optimizer was Adam with a 1e-4 learning rate, and categorical cross-entropy loss. It is hoped that, once this research will be put to practice in hospitals, healthcare professionals will be able in the medium to long-term to diagnosing through machine learning tools possible pneumonia, and if detected, whether it is linked to a COVID-19 infection, allowing the detection of new possible COVID-19 foyers after the end of possible ""stop-and-go"" lockdowns as expected by until a vaccine is found and widespread. Furthermore, in the short-term, it is hoped practitioners can compare the diagnosis from the deep convolutional neural networks with possible RT-PCR testing results, and if clashing, a Computed Tomography could be performed as they are more accurate in showing COVID-19 pneumonia.",242,COVID-19;Infections;Pneumonia,,,Health Care;Polymerase Chain Reaction;Neural Networks;Other Topics;Paper,,,,,,External,2. Detection/Diagnosis,X-Ray
2005.01468,,Yes,,,2020,2020-05-01,Preprint,arXiv,0,a cascade network for detecting covid-19 using chest x-rays,"The worldwide spread of pneumonia caused by a novel coronavirus poses an unprecedented challenge to the world's medical resources and prevention and control measures. Covid-19 attacks not only the lungs, making it difficult to breathe and life-threatening, but also the heart, kidneys, brain and other vital organs of the body, with possible sequela. At present, the detection of COVID-19 needs to be realized by the reverse transcription-polymerase Chain Reaction (RT-PCR). However, many countries are in the outbreak period of the epidemic, and the medical resources are very limited. They cannot provide sufficient numbers of gene sequence detection, and many patients may not be isolated and treated in time. Given this situation, we researched the analytical and diagnostic capabilities of deep learning on chest radiographs and proposed Cascade-SEMEnet which is cascaded with SEME-ResNet50 and SEME-DenseNet169. The two cascade networks of Cascade - SEMEnet both adopt large input sizes and SE-Structure and use MoEx and histogram equalization to enhance the data. We first used SEME-ResNet50 to screen chest X-ray and diagnosed three classes: normal, bacterial, and viral pneumonia. Then we used SEME-DenseNet169 for fine-grained classification of viral pneumonia and determined if it is caused by COVID-19. To exclude the influence of non-pathological features on the network, we preprocessed the data with U-Net during the training of SEME-DenseNet169. The results showed that our network achieved an accuracy of 85.6\% in determining the type of pneumonia infection and 97.1\% in the fine-grained classification of COVID-19. We used Grad-CAM to visualize the judgment based on the model and help doctors understand the chest radiograph while verifying the effectivene.",263,"COVID-19;Infections;Pneumonia;Pneumonia, Viral",,,Coronavirus Infections;Disease Outbreaks;Polymerase Chain Reaction;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,X-Ray
2005.01577,,Yes,,,2020,2020-04-29,Preprint,arXiv,0,covid-da: deep domain adaptation from typical pneumonia to covid-19,"The outbreak of novel coronavirus disease 2019 (COVID-19) has already infected millions of people and is still rapidly spreading all over the globe. Most COVID-19 patients suffer from lung infection, so one important diagnostic method is to screen chest radiography images, e.g., X-Ray or CT images. However, such examinations are time-consuming and labor-intensive, leading to limited diagnostic efficiency. To solve this issue, AI-based technologies, such as deep learning, have been used recently as effective computer-aided means to improve diagnostic efficiency. However, one practical and critical difficulty is the limited availability of annotated COVID-19 data, due to the prohibitive annotation costs and urgent work of doctors to fight against the pandemic. This makes the learning of deep diagnosis models very challenging. To address this, motivated by that typical pneumonia has similar characteristics with COVID-19 and many pneumonia datasets are publicly available, we propose to conduct domain knowledge adaptation from typical pneumonia to COVID-19. There are two main challenges: 1) the discrepancy of data distributions between domains; 2) the task difference between the diagnosis of typical pneumonia and COVID-19. To address them, we propose a new deep domain adaptation method for COVID-19 diagnosis, namely COVID-DA. Specifically, we alleviate the domain discrepancy via feature adversarial adaptation and handle the task difference issue via a novel classifier separation scheme. In this way, COVID-DA is able to diagnose COVID-19 effectively with only a small number of COVID-19 annotations. Extensive experiments verify the effectiveness of COVID-DA and its great potential for real-world applications.",247,COVID-19;Infections;Pneumonia,,,Disease Outbreaks;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2005.01578,10.1007/s42600-021-00132-9,Yes,,,2021,2021-01-12,Preprint,arXiv,0,a deep convolutional neural network for covid-19 detection using chest x-rays,"We present image classifiers based on Dense Convolutional Networks and transfer learning to classify chest X-ray images according to three labels: COVID-19, pneumonia and normal. We fine-tuned neural networks pretrained on ImageNet and applied a twice transfer learning approach, using NIH ChestX-ray14 dataset as an intermediate step. We also suggested a novelty called output neuron keeping, which changes the twice transfer learning technique. In order to clarify the modus operandi of the models, we used Layer-wise Relevance Propagation (LRP) to generate heatmaps. We were able to reach test accuracy of 100% on our test dataset. Twice transfer learning and output neuron keeping showed promising results improving performances, mainly in the beginning of the training process. Although LRP revealed that words on the X-rays can influence the networks' predictions, we discovered this had only a very small effect on accuracy. Although clinical studies and larger datasets are still needed to further ensure good generalization, the state-of-the-art performances we achieved show that, with the help of artificial intelligence, chest X-rays can become a cheap and accurate auxiliary method for COVID-19 diagnosis. Heatmaps generated by LRP improve the interpretability of the deep neural networks and indicate an analytical path for future research on diagnosis. Twice transfer learning with output neuron keeping improved performances.",210,COVID-19;Pneumonia,,,Art;Transfer Learning;Other Topics,8.639495113515313e-07,0.0,5.502367381973795e-07,0.0,0.0,External,2. Detection/Diagnosis,X-Ray
2005.01903,,Yes,,,2020,2020-05-04,Preprint,arXiv,0,3d tomographic pattern synthesis for enhancing the quantification of covid-19,"The Coronavirus Disease (COVID-19) has affected 1.8 million people and resulted in more than 110,000 deaths as of April 12, 2020. Several studies have shown that tomographic patterns seen on chest Computed Tomography (CT), such as ground-glass opacities, consolidations, and crazy paving pattern, are correlated with the disease severity and progression. CT imaging can thus emerge as an important modality for the management of COVID-19 patients. AI-based solutions can be used to support CT based quantitative reporting and make reading efficient and reproducible if quantitative biomarkers, such as the Percentage of Opacity (PO), can be automatically computed. However, COVID-19 has posed unique challenges to the development of AI, specifically concerning the availability of appropriate image data and annotations at scale. In this paper, we propose to use synthetic datasets to augment an existing COVID-19 database to tackle these challenges. We train a Generative Adversarial Network (GAN) to inpaint COVID-19 related tomographic patterns on chest CTs from patients without infectious diseases. Additionally, we leverage location priors derived from manually labeled COVID-19 chest CTs patients to generate appropriate abnormality distributions. Synthetic data are used to improve both lung segmentation and segmentation of COVID-19 patterns by adding 20% of synthetic data to the real COVID-19 training data. We collected 2143 chest CTs, containing 327 COVID-19 positive cases, acquired from 12 sites across 7 countries. By testing on 100 COVID-19 positive and 100 control cases, we show that synthetic data can help improve both lung segmentation (+6.02% lesion inclusion rate) and abnormality segmentation (+2.78% dice coefficient), leading to an overall more accurate PO computation (+2.82% Pearson coefficient).",263,COVID-19;Communicable Diseases;Death,,,Other Topics,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
2005.02167,,Yes,,,2020,2020-04-30,Preprint,arXiv,0,intra-model variability in covid-19 classification using chest x-ray images,"X-ray and computed tomography (CT) scanning technologies for COVID-19 screening have gained significant traction in AI research since the start of the coronavirus pandemic. Despite these continuous advancements for COVID-19 screening, many concerns remain about model reliability when used in a clinical setting. Much has been published, but with limited transparency in expected model performance. We set out to address this limitation through a set of experiments to quantify baseline performance metrics and variability for COVID-19 detection in chest x-ray for 12 common deep learning architectures. Specifically, we adopted an experimental paradigm controlling for train-validation-test split and model architecture where the source of prediction variability originates from model weight initialization, random data augmentation transformations, and batch shuffling. Each model architecture was trained 5 separate times on identical train-validation-test splits of a publicly available x-ray image dataset provided by Cohen et al.. Results indicate that even within model architectures, model behavior varies in a meaningful way between trained models. Best performing models achieve a false negative rate of 3 out of 20 for detecting COVID-19 in a hold-out set. While these results show promise in using AI for COVID-19 screening, they further support the urgent need for diverse medical imaging datasets for model training in a way that yields consistent prediction outcomes. It is our hope that these modeling results accelerate work in building a more robust dataset and a viable screening tool for COVID-19.",234,COVID-19,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2005.03059,,Yes,,,2020,2020-05-15,Preprint,arXiv,0,covidctnet: an open-source deep learning approach to identify covid-19 using ct image,"Coronavirus disease 2019 (Covid-19) is highly contagious with limited treatment options. Early and accurate diagnosis of Covid-19 is crucial in reducing the spread of the disease and its accompanied mortality. Currently, detection by reverse transcriptase polymerase chain reaction (RT-PCR) is the gold standard of outpatient and inpatient detection of Covid-19. RT-PCR is a rapid method, however, its accuracy in detection is only approx. 70-75%. Another approved strategy is computed tomography (CT) imaging. CT imaging has a much higher sensitivity of approx. 80-98%, but similar accuracy of 70%. To enhance the accuracy of CT imaging detection, we developed an open-source set of algorithms called CovidCTNet that successfully differentiates Covid-19 from community-acquired pneumonia (CAP) and other lung diseases. CovidCTNet increases the accuracy of CT imaging detection to 90% compared to radiologists. The model is designed to work with heterogeneous and small sample sizes independent of the CT imaging hardware. In order to facilitate the detection of Covid-19 globally and assist radiologists and physicians in the screening process, we are releasing all algorithms and parametric details in an open-source format. Open-source sharing of our CovidCTNet enables developers to rapidly improve and optimize services, while preserving user privacy and data ownership.",197,COVID-19;Lung Diseases;Pneumonia,,,Polymerase Chain Reaction;Other Topics,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,CT
2005.04562,,Yes,,,2020,2020-05-25,Preprint,arXiv,0,fast and accurate detection of covid-19-related pneumonia from chest x-ray images with novel deep learning model,"Novel coronavirus disease has spread rapidly worldwide. As recent radiological literatures on Covid-19 related pneumonia is primarily focused on CT findings, the American College of Radiology (ACR) recommends using portable chest X-radiograph (CXR). A tool to assist for detection and monitoring of Covid-19 cases from CXR is highly required. To develop a fully automatic framework to detect Covid-19 related pneumonia using CXR images and evaluate its performance. In this study, a novel deep learning model, named CovIDNet (Covid-19 Indonesia Neural-Network), was developed to extract visual features from chest x-ray images for the detection of Covid-19 related pneumonia. The model was trained and validated by chest x-rays datasets collected from several open source provided by GitHub and Kaggle. In the validation stage using open-source data, the accuracy to recognize Covid-19 and others classes reaches 98.44%, that is, 100% Covid-19 precision and 97% others precision. The use of the model to classify Covid-19 and other pathologies might slightly decrease the accuracy. Although SoftMax was used to handle classification bias, this indicates the benefit of additional training upon the introduction of new set of data. The model has been tested and get 98.4% accuracy for open source datasets, the sensitivity and specificity are 100% and 96.97%, respectively.",204,COVID-19;Pneumonia,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2005.12855,,Yes,,,2021,2021-04-16,Preprint,arXiv,0,covid-net s: towards computer-aided severity assessment via training and validation of deep neural networks for geographic extent and opacity extent scoring of chest x-rays for sars-cov-2 lung disease severity,"A critical step in effective care and treatment planning for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the cause of the COVID-19 pandemic, is the assessment of the severity of disease progression. Chest x-rays (CXRs) are often used to assess SARS-CoV-2 severity, with two important assessment metrics being extent of lung involvement and degree of opacity. In this proof-of-concept study, we assess the feasibility of computer-aided scoring of CXRs of SARS-CoV-2 lung disease severity using a deep learning system. Data consisted of 396 CXRs from SARS-CoV-2 positive patient cases. Geographic extent and opacity extent were scored by two board-certified expert chest radiologists (with 20+ years of experience) and a 2nd-year radiology resident. The deep neural networks used in this study, which we name COVID-Net S, are based on a COVID-Net network architecture. 100 versions of the network were independently learned (50 to perform geographic extent scoring and 50 to perform opacity extent scoring) using random subsets of CXRs from the study, and we evaluated the networks using stratified Monte Carlo cross-validation experiments. The COVID-Net S deep neural networks yielded R^2 of 0.664 and 0.635 between predicted scores and radiologist scores for geographic extent and opacity extent, respectively, in stratified Monte Carlo cross-validation experiments. The best performing networks achieved R^2 of 0.739 and 0.741 between predicted scores and radiologist scores for geographic extent and opacity extent, respectively. The results are promising and suggest that the use of deep neural networks on CXRs could be an effective tool for computer-aided assessment of SARS-CoV-2 lung disease severity, although additional studies are needed before adoption for routine clinical use.",265,COVID-19 Pandemic;Disease Progression;Lung Diseases;Severe Acute Respiratory Syndrome,,,Other Topics,,,,,,External,3. Monitoring/Severity assessment,X-Ray
2005.13928,,Yes,,,2020,2020-05-28,Preprint,arXiv,0,early screening of sars-cov-2 by intelligent analysis of x-ray images,"Future SARS-CoV-2 virus outbreak COVID-XX might possibly occur during the next years. However the pathology in humans is so recent that many clinical aspects, like early detection of complications, side effects after recovery or early screening, are currently unknown. In spite of the number of cases of COVID-19, its rapid spread putting many sanitary systems in the edge of collapse has hindered proper collection and analysis of the data related to COVID-19 clinical aspects. We describe an interdisciplinary initiative that integrates clinical research, with image diagnostics and the use of new technologies such as artificial intelligence and radiomics with the aim of clarifying some of SARS-CoV-2 open questions. The whole initiative addresses 3 main points: 1) collection of standardize data including images, clinical data and analytics; 2) COVID-19 screening for its early diagnosis at primary care centers; 3) define radiomic signatures of COVID-19 evolution and associated pathologies for the early treatment of complications. In particular, in this paper we present a general overview of the project, the experimental design and first results of X-ray COVID-19 detection using a classic approach based on HoG and feature selection. Our experiments include a comparison to some recent methods for COVID-19 screening in X-Ray and an exploratory analysis of the feasibility of X-Ray COVID-19 screening. Results show that classic approaches can outperform deep-learning methods in this experimental setting, indicate the feasibility of early COVID-19 screening and that non-COVID infiltration is the group of patients most similar to COVID-19 in terms of radiological description of X-ray. Therefore, an efficient COVID-19 screening should be complemented with other clinical data to better discriminate these cases.",268,COVID-19,,,Health Care;Disease Outbreaks;Early Diagnosis,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
2006.05018,,Yes,,,2020,2020-06-08,Preprint,arXiv,0,deep learning to estimate the physical proportion of infected region of lung for covid-19 pneumonia with ct image set,"Utilizing computed tomography (CT) images to quickly estimate the severity of cases with COVID-19 is one of the most straightforward and efficacious methods. Two tasks were studied in this present paper. One was to segment the mask of intact lung in case of pneumonia. Another was to generate the masks of regions infected by COVID-19. The masks of these two parts of images then were converted to corresponding volumes to calculate the physical proportion of infected region of lung. A total of 129 CT image set were herein collected and studied. The intrinsic Hounsfiled value of CT images was firstly utilized to generate the initial dirty version of labeled masks both for intact lung and infected regions. Then, the samples were carefully adjusted and improved by two professional radiologists to generate the final training set and test benchmark. Two deep learning models were evaluated: UNet and 2.5D UNet. For the segment of infected regions, a deep learning based classifier was followed to remove unrelated blur-edged regions that were wrongly segmented out such as air tube and blood vessel tissue etc. For the segmented masks of intact lung and infected regions, the best method could achieve 0.972 and 0.757 measure in mean Dice similarity coefficient on our test benchmark. As the overall proportion of infected region of lung, the final result showed 0.961 (Pearson's correlation coefficient) and 11.7% (mean absolute percent error). The instant proportion of infected regions of lung could be used as a visual evidence to assist clinical physician to determine the severity of the case. Furthermore, a quantified report of infected regions can help predict the prognosis for COVID-19 cases which were scanned periodically within the treatment cycle.",280,COVID-19;Pneumonia,,,Other Topics,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
2006.05274,,Yes,,,2020,2020-06-06,Preprint,arXiv,0,umls-chestnet: a deep convolutional neural network for radiological findings differential diagnoses and localizations of covid-19 in chest x-rays,"In this work we present a method for the detection of radiological findings, their location and differential diagnoses from chest x-rays. Unlike prior works that focus on the detection of few pathologies, we use a hierarchical taxonomy mapped to the Unified Medical Language System (UMLS) terminology to identify 189 radiological findings, 22 differential diagnosis and 122 anatomic locations, including ground glass opacities, infiltrates, consolidations and other radiological findings compatible with COVID-19. We train the system on one large database of 92,594 frontal chest x-rays (AP or PA, standing, supine or decubitus) and a second database of 2,065 frontal images of COVID-19 patients identified by at least one positive Polymerase Chain Reaction (PCR) test. The reference labels are obtained through natural language processing of the radiological reports. On 23,159 test images, the proposed neural network obtains an AUC of 0.94 for the diagnosis of COVID-19. To our knowledge, this work uses the largest chest x-ray dataset of COVID-19 positive cases to date and is the first one to use a hierarchical labeling schema and to provide interpretability of the results, not only by using network attention methods, but also by indicating the radiological findings that have led to the diagnosis.",199,COVID-19,,,Polymerase Chain Reaction;Area under Curve,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
2006.11988,,Yes,,,2020,2020-12-14,Preprint,arXiv,0,covid-19 image data collection: prospective predictions are the future,"Across the world's coronavirus disease 2019 (COVID-19) hot spots, the need to streamline patient diagnosis and management has become more pressing than ever. As one of the main imaging tools, chest X-rays (CXRs) are common, fast, non-invasive, relatively cheap, and potentially bedside to monitor the progression of the disease. This paper describes the first public COVID-19 image data collection as well as a preliminary exploration of possible use cases for the data. This dataset currently contains hundreds of frontal view X-rays and is the largest public resource for COVID-19 image and prognostic data, making it a necessary resource to develop and evaluate tools to aid in the treatment of COVID-19. It was manually aggregated from publication figures as well as various web based repositories into a machine learning (ML) friendly format with accompanying dataloader code. We collected frontal and lateral view imagery and metadata such as the time since first symptoms, intensive care unit (ICU) status, survival status, intubation status, or hospital location. We present multiple possible use cases for the data such as predicting the need for the ICU, predicting patient survival, and understanding a patient's trajectory during treatment. Data can be accessed here: GitHub",196,COVID-19,,,Other Topics,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,Multimodal
2006.13262,,Yes,,,2020,2020-06-23,Preprint,arXiv,0,was there covid-19 back in 2012? challenge for ai in diagnosis with similar indications,"Since the recent COVID-19 outbreak, there has been an avalanche of research papers applying deep learning based image processing to chest radiographs for detection of the disease. To test the performance of the two top models for CXR COVID-19 diagnosis on external datasets to assess model generalizability. In this paper, we present our argument regarding the efficiency and applicability of existing deep learning models for COVID-19 diagnosis. We provide results from two popular models - COVID-Net and CoroNet evaluated on three publicly available datasets and an additional institutional dataset collected from EMORY Hospital between January and May 2020, containing patients tested for COVID-19 infection using RT-PCR. There is a large false positive rate (FPR) for COVID-Net on both ChexPert and MIMIC-CXR dataset. On the EMORY Dataset, COVID-Net has 61.4% sensitivity, 0.54 F1-score and 0.49 precision value. The FPR of the CoroNet model is significantly lower across all the datasets as compared to COVID-Net - EMORY, ChexPert, ChestX-ray14, MIMIC-CXR. The models reported good to excellent performance on their internal datasets, however we observed from our testing that their performance dramatically worsened on external data. This is likely from several causes including overfitting models due to lack of appropriate control patients and ground truth labels. The fourth institutional dataset was labeled using RT-PCR, which could be positive without radiographic findings and vice versa. Therefore, a fusion model of both clinical and radiographic data may have better performance and generalization.",237,COVID-19;Infections,,,Disease Outbreaks;Polymerase Chain Reaction;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2006.13817,,Yes,,,2020,2020-06-22,Preprint,arXiv,0,stacked convolutional neural network for diagnosis of covid-19 disease from x-ray images,"Automatic and rapid screening of COVID-19 from the chest X-ray images has become an urgent need in this pandemic situation of SARS-CoV-2 worldwide in 2020. However, accurate and reliable screening of patients is a massive challenge due to the discrepancy between COVID-19 and other viral pneumonia in X-ray images. In this paper, we design a new stacked convolutional neural network model for the automatic diagnosis of COVID-19 disease from the chest X-ray images. We obtain different sub-models from the VGG19 and developed a 30-layered CNN model (named as CovNet30) during the training, and obtained sub-models are stacked together using logistic regression. The proposed CNN model combines the discriminating power of the different CNN`s sub-models and classifies chest X-ray images into COVID-19, Normal, and Pneumonia classes. In addition, we generate X-ray images dataset referred to as COVID19CXr, which includes 2764 chest x-ray images of 1768 patients from the three publicly available data repositories. The proposed stacked CNN achieves an accuracy of 92.74%, the sensitivity of 93.33%, PPV of 92.13%, and F1-score of 0.93 for the classification of X-ray images. Our proposed approach shows its superiority over the existing methods for the diagnosis of the COVID-19 from the X-ray images.",198,"COVID-19;Pneumonia;Pneumonia, Viral",,,Neural Networks;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2006.13873,,Yes,,,2020,2020-06-18,Preprint,arXiv,0,covidlite: a depth-wise separable deep neural network with white balance and clahe for detection of covid-19,"Currently, the whole world is facing a pandemic disease, novel Coronavirus also known as COVID-19, which spread in more than 200 countries with around 3.3 million active cases and 4.4 lakh deaths approximately. Due to rapid increase in number of cases and limited supply of testing kits, availability of alternative diagnostic method is necessary for containing the spread of COVID-19 cases at an early stage and reducing the death count. For making available an alternative diagnostic method, we proposed a deep neural network based diagnostic method which can be easily integrated with mobile devices for detection of COVID-19 and viral pneumonia using Chest X-rays (CXR) images. In this study, we have proposed a method named COVIDLite, which is a combination of white balance followed by Contrast Limited Adaptive Histogram Equalization (CLAHE) and depth-wise separable convolutional neural network (DSCNN). In this method, white balance followed by CLAHE is used as an image preprocessing step for enhancing the visibility of CXR images and DSCNN trained using sparse cross entropy is used for image classification with lesser parameters and significantly lighter in size, i.e., 8.4 MB without quantization. The proposed COVIDLite method resulted in improved performance in comparison to vanilla DSCNN with no pre-processing. The proposed method achieved higher accuracy of 99.58% for binary classification, whereas 96.43% for multiclass classification and out-performed various state-of-the-art methods. Our proposed method, COVIDLite achieved exceptional results on various performance metrics. With detailed model interpretations, COVIDLite can assist radiologists in detecting COVID-19 patients from CXR images and can reduce the diagnosis time significantly.",255,"COVID-19;Death;Pneumonia, Viral",,,Art;Radiologists;Other Topics;Entropy,,,,,,External,2. Detection/Diagnosis,X-Ray
2006.14419,,Yes,,,2020,2020-06-26,Preprint,arXiv,0,a novel and reliable deep learning web-based tool to detect covid-19 infection from chest ct-scan,"The corona virus is already spread around the world in many countries, and it has taken many lives. Furthermore, the world health organization (WHO) has announced that COVID-19 has reached the global epidemic stage. Early and reliable diagnosis using chest CT-scan can assist medical specialists in vital circumstances. In this work, we introduce a computer aided diagnosis (CAD) web service to detect COVID- 19 online. One of the largest public chest CT-scan databases, containing 746 participants was used in this experiment. A number of well-known deep neural network architectures consisting of ResNet, Inception and MobileNet were inspected to find the most efficient model for the hybrid system. A combination of the Densely connected convolutional network (DenseNet) in order to reduce image dimensions and Nu-SVM as an anti-overfitting bottleneck was chosen to distinguish between COVID-19 and healthy controls. The proposed methodology achieved 90.80% recall, 89.76% precision and 90.61% accuracy. The method also yields an AUC of 95.05%. Ultimately a flask web service is made public through ngrok using the trained models to provide a RESTful COVID-19 detector, which takes only 39 milliseconds to process one image. The source code is also available at GitHub Based on the findings, it can be inferred that it is feasible to use the proposed technique as an automated tool for diagnosis of COVID-19.",218,COVID-19;Infections,,,Other Topics,,,,,,External,2. Detection/Diagnosis,CT
2006.16106,10.1109/ICMLA51294.2020.00211,Yes,,,2020,2020-10-20,Preprint,arXiv,0,covid-19 screening using residual attention network an artificial intelligence approach,"Coronavirus Disease 2019 (COVID-19) is caused by severe acute respiratory syndrome coronavirus 2 virus (SARS-CoV-2). The virus transmits rapidly; it has a basic reproductive number R of 2.2-2.7. In March 2020, the World Health Organization declared the COVID-19 outbreak a pandemic. COVID-19 is currently affecting more than 200 countries with 6M active cases. An effective testing strategy for COVID-19 is crucial to controlling the outbreak but the demand for testing surpasses the availability of test kits that use Reverse Transcription Polymerase Chain Reaction (RT-PCR). In this paper, we present a technique to screen for COVID-19 using artificial intelligence. Our technique takes only seconds to screen for the presence of the virus in a patient. We collected a dataset of chest X-ray images and trained several popular deep convolution neural network-based models (VGG, MobileNet, Xception, DenseNet, InceptionResNet) to classify the chest X-rays. Unsatisfied with these models, we then designed and built a Residual Attention Network that was able to screen COVID-19 with a testing accuracy of 98% and a validation accuracy of 100%. A feature maps visual of our model show areas in a chest X-ray which are important for classification. Our work can help to increase the adaptation of AI-assisted applications in clinical practice. The code and dataset used in this project are available at GitHub",216,COVID-19;COVID-19 Pandemic;Severe Acute Respiratory Syndrome,,,World Health Organization;Disease Outbreaks;Health;Polymerase Chain Reaction;Map;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,X-Ray
2007.01108,,Yes,,,2020,2020-06-30,Preprint,arXiv,0,evaluation of contemporary convolutional neural network architectures for detecting covid-19 from chest radiographs,"Interpreting chest radiograph, a.ka. chest x-ray, images is a necessary and crucial diagnostic tool used by medical professionals to detect and identify many diseases that may plague a patient. Although the images themselves contain a wealth of valuable information, their usefulness may be limited by how well they are interpreted, especially when the reviewing radiologist may be fatigued or when or an experienced radiologist is unavailable. Research in the use of deep learning models to analyze chest radiographs yielded impressive results where, in some instances, the models outperformed practicing radiologists. Amidst the COVID-19 pandemic, researchers have explored and proposed the use of said deep models to detect COVID-19 infections from radiographs as a possible way to help ease the strain on medical resources. In this study, we train and evaluate three model architectures, proposed for chest radiograph analysis, under varying conditions, find issues that discount the impressive model performances proposed by contemporary studies on this subject, and propose methodologies to train models that yield more reliable results.. Code, scripts, pre-trained models, and visualizations are available at GitHub",177,COVID-19;COVID-19 Pandemic;Infections;Plague,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2007.04774,10.1016/j.imu.2021.100681.,Yes,,,2020,2020-06-24,Preprint,arXiv,0,automated chest ct image segmentation of covid-19 lung infection based on 3d u-net,"The coronavirus disease 2019 (COVID-19) affects billions of lives around the world and has a significant impact on public healthcare. Due to rising skepticism towards the sensitivity of RT-PCR as screening method, medical imaging like computed tomography offers great potential as alternative. For this reason, automated image segmentation is highly desired as clinical decision support for quantitative assessment and disease monitoring. However, publicly available COVID-19 imaging data is limited which leads to overfitting of traditional approaches. To address this problem, we propose an innovative automated segmentation pipeline for COVID-19 infected regions, which is able to handle small datasets by utilization as variant databases. Our method focuses on on-the-fly generation of unique and random image patches for training by performing several preprocessing methods and exploiting extensive data augmentation. For further reduction of the overfitting risk, we implemented a standard 3D U-Net architecture instead of new or computational complex neural network architectures. Through a 5-fold cross-validation on 20 CT scans of COVID-19 patients, we were able to develop a highly accurate as well as robust segmentation model for lungs and COVID-19 infected regions without overfitting on the limited data. Our method achieved Dice similarity coefficients of 0.956 for lungs and 0.761 for infection. We demonstrated that the proposed method outperforms related approaches, advances the state-of-the-art for COVID-19 segmentation and improves medical image analysis with limited data. The code and model are available under the following link: GitHub",235,COVID-19;Infections,,,Art;Health Care;Architecture;Polymerase Chain Reaction;Tomography;Other Topics;Lung Diseases,,,,,,External,Segmentation-only,CT
2007.05494,,Yes,,,2020,2020-07-01,Preprint,arXiv,0,automatic detection of covid-19 cases on x-ray images using convolutional neural networks,"In recent months the world has been surprised by the rapid advance of COVID-19. In order to face this disease and minimize its socio-economic impacts, in addition to surveillance and treatment, diagnosis is a crucial procedure. However, the realization of this is hampered by the delay and the limited access to laboratory tests, demanding new strategies to carry out case triage. In this scenario, deep learning models are being proposed as a possible option to assist the diagnostic process based on chest X-ray and computed tomography images. Therefore, this research aims to automate the process of detecting COVID-19 cases from chest images, using convolutional neural networks (CNN) through deep learning techniques. The results can contribute to expand access to other forms of detection of COVID-19 and to speed up the process of identifying this disease. All databases used, the codes built, and the results obtained from the models' training are available for open access. This action facilitates the involvement of other researchers in enhancing these models since this can contribute to the improvement of results and, consequently, the progress in confronting COVID-19.",182,COVID-19,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2007.05592,,Yes,,,2020,2020-07-05,Preprint,arXiv,0,experiments of federated learning for covid-19 chest x-ray images,"AI plays an important role in COVID-19 identification. Computer vision and deep learning techniques can assist in determining COVID-19 infection with Chest X-ray Images. However, for the protection and respect of the privacy of patients, the hospital's specific medical-related data did not allow leakage and sharing without permission. Collecting such training data was a major challenge. To a certain extent, this has caused a lack of sufficient data samples when performing deep learning approaches to detect COVID-19. Federated Learning is an available way to address this issue. It can effectively address the issue of data silos and get a shared model without obtaining local data. In the work, we propose the use of federated learning for COVID-19 data training and deploy experiments to verify the effectiveness. And we also compare performances of four popular models (MobileNet, ResNet18, MoblieNet, and COVID-Net) with the federated learning framework and without the framework. This work aims to inspire more researches on federated learning about COVID-19.",161,COVID-19;Infections,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2007.08028,,Yes,PMC7373136,32699815.0,2021,2021-07-01,Preprint,arXiv,0,predicting clinical outcomes in covid-19 using radiomics and deep learning on chest radiographs: a multi-institutional study,"We predict mechanical ventilation requirement and mortality using computational modeling of chest radiographs (CXRs) for coronavirus disease 2019 (COVID-19) patients. This two-center, retrospective study analyzed 530 deidentified CXRs from 515 COVID-19 patients treated at Stony Brook University Hospital and Newark Beth Israel Medical Center between March and August 2020. DL and machine learning classifiers to predict mechanical ventilation requirement and mortality were trained and evaluated using patient CXRs. A novel radiomic embedding framework was also explored for outcome prediction. All results are compared against radiologist grading of CXRs (zone-wise expert severity scores). Radiomic and DL classification models had mAUCs of 0.78 and 0.81, compared with expert scores mAUCs of 0.75 and 0.79 for mechanical ventilation requirement and mortality prediction, respectively. Combined classifiers using both radiomics and expert severity scores resulted in mAUCs of 0.79 and 0.83 for each prediction task, demonstrating improvement over either artificial intelligence or radiologist interpretation alone. Our results also suggest instances where inclusion of radiomic features in DL improves model predictions, something that might be explored in other pathologies. The models proposed in this study and the prognostic information they provide might aid physician decision making and resource allocation during the COVID-19 pandemic.",197,COVID-19;COVID-19 Pandemic,,,Classification;Other Topics;Retrospective Studies;Area under Curve,1.875998051088978e-06,30.896000000000026,2.4525457363120674e-06,72.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,X-Ray
2007.08223,10.1007/978-3-030-69744-0_6,Yes,,,2020,2020-07-16,Preprint,arXiv,0,an efficient mixture of deep and machine learning models for covid-19 and tuberculosis detection using x-ray images in resource limited settings,"Clinicians in the frontline need to assess quickly whether a patient with symptoms indeed has COVID-19 or not. The difficulty of this task is exacerbated in low resource settings that may not have access to biotechnology tests. Furthermore, Tuberculosis (TB) remains a major health problem in several low- and middle-income countries and its common symptoms include fever, cough and tiredness, similarly to COVID-19. In order to help in the detection of COVID-19, we propose the extraction of deep features (DF) from chest X-ray images, a technology available in most hospitals, and their subsequent classification using machine learning methods that do not require large computational resources. We compiled a five-class dataset of X-ray chest images including a balanced number of COVID-19, viral pneumonia, bacterial pneumonia, TB, and healthy cases. We compared the performance of pipelines combining 14 individual state-of-the-art pre-trained deep networks for DF extraction with traditional machine learning classifiers. A pipeline consisting of ResNet-50 for DF computation and ensemble of subspace discriminant classifier was the best performer in the classification of the five classes, achieving a detection accuracy of 91.6+ 2.6% (accuracy + 95% Confidence Interval). Furthermore, the same pipeline achieved accuracies of 98.6+1.4% and 99.9+0.5% in simpler three-class and two-class classification problems focused on distinguishing COVID-19, TB and healthy cases; and COVID-19 and healthy images, respectively. The pipeline was computationally efficient requiring just 0.19 second to extract DF per X-ray image and 2 minutes for training a traditional classifier with more than 2000 images on a CPU machine. The results suggest the potential benefits of using our pipeline in the detection of COVID-19, particularly in resource-limited settings and it can run with limited computational resources.",276,"COVID-19;Cough;Fever;Pneumonia, Bacterial;Pneumonia, Viral;Tuberculosis",,,Art;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2007.08637,,Yes,,,2021,2021-09-28,Preprint,arXiv,0,cov-elm classifier: an extreme learning machine based identification of covid-19 using chest x-ray images,"Coronaviruses constitute a family of viruses that gives rise to respiratory diseases. As COVID-19 is highly contagious, early diagnosis of COVID-19 is crucial for an effective treatment strategy. However, the RT-PCR test which is considered to be a gold standard in the diagnosis of COVID-19 suffers from a high false-negative rate. Chest X-ray (CXR) image analysis has emerged as a feasible and effective diagnostic technique towards this objective. In this work, we propose the COVID-19 classification problem as a three-class classification problem to distinguish between COVID-19, normal, and pneumonia classes. We propose a three-stage framework, named COV-ELM. Stage one deals with preprocessing and transformation while stage two deals with feature extraction. These extracted features are passed as an input to the ELM at the third stage, resulting in the identification of COVID-19. The choice of ELM in this work has been motivated by its faster convergence, better generalization capability, and shorter training time in comparison to the conventional gradient-based learning algorithms. As bigger and diverse datasets become available, ELM can be quickly retrained as compared to its gradient-based competitor models. The proposed model achieved a macro average F1-score of 0.95 and the overall sensitivity of 0.94 at a 95% confidence interval. When compared to state-of-the-art machine learning algorithms, the COV-ELM is found to outperform its competitors in this three-class classification scenario. Further, LIME has been integrated with the proposed COV-ELM model to generate annotated CXR images. The annotations are based on the superpixels that have contributed to distinguish between the different classes. It was observed that the superpixels correspond to the regions of the human lungs that are clinically observed in COVID-19 and Pneumonia cases.",275,COVID-19;Pneumonia,,,Art;Algorithms;Polymerase Chain Reaction;Other Topics;Lung Diseases;Early Diagnosis,,,,,,External,2. Detection/Diagnosis,X-Ray
2007.09695,,Yes,,,2020,2020-07-19,Preprint,arXiv,0,using deep convolutional neural networks to diagnose covid-19 from chest x-ray images,"The COVID-19 epidemic has become a major safety and health threat worldwide. Imaging diagnosis is one of the most effective ways to screen COVID-19. This project utilizes several open-source or public datasets to present an open-source dataset of COVID-19 CXRs, named COVID-19-CXR-Dataset, and introduces a deep convolutional neural network model. The model validates on 740 test images and achieves 87.3% accuracy, 89.67 % precision, and 84.46% recall, and correctly classifies 98 out of 100 COVID-19 x-ray images in test set with more than 81% prediction probability under the condition of 95% confidence interval. This project may serve as a reference for other researchers aiming to advance the development of deep learning applications in medical imaging.",115,COVID-19,,,Research Personnel;Neural Networks,,,,,,External,2. Detection/Diagnosis,X-Ray
2007.10785,,Yes,,,2020,2020-07-27,Preprint,arXiv,0,automated detection and forecasting of covid-19 using deep learning techniques: a review,"Coronavirus, or COVID-19, is a hazardous disease that has endangered the health of many people around the world by directly affecting the lungs. COVID-19 is a medium-sized, coated virus with a single-stranded RNA. This virus has one of the largest RNA genomes and is approximately 120 nm. The X-Ray and computed tomography (CT) imaging modalities are widely used to obtain a fast and accurate medical diagnosis. Identifying COVID-19 from these medical images is extremely challenging as it is time-consuming, demanding, and prone to human errors. Hence, artificial intelligence (AI) methodologies can be used to obtain consistent high performance. Among the AI methodologies, deep learning (DL) networks have gained much popularity compared to traditional machine learning (ML) methods. Unlike ML techniques, all stages of feature extraction, feature selection, and classification are accomplished automatically in DL models. In this paper, a complete survey of studies on the application of DL techniques for COVID-19 diagnostic and automated segmentation of lungs is discussed, concentrating on works that used X-Ray and CT images. Additionally, a review of papers on the forecasting of coronavirus prevalence in different parts of the world with DL techniques is presented. Lastly, the challenges faced in the automated detection of COVID-19 using DL techniques and directions for future research are discussed.",210,COVID-19,,,Other Topics,,,,,,External,Review,Multimodal
2007.11993,,Yes,,,2020,2020-07-21,Preprint,arXiv,0,cvr-net: a deep convolutional neural network for coronavirus recognition from chest radiography images,"The novel Coronavirus Disease 2019 (COVID-19) is a global pandemic disease spreading rapidly around the world. A robust and automatic early recognition of COVID-19, via auxiliary computer-aided diagnostic tools, is essential for disease cure and control. The chest radiography images, such as Computed Tomography (CT) and X-ray, and deep Convolutional Neural Networks (CNNs), can be a significant and useful material for designing such tools. However, designing such an automated tool is challenging as a massive number of manually annotated datasets are not publicly available yet, which is the core requirement of supervised learning systems. In this article, we propose a robust CNN-based network, called CVR-Net (Coronavirus Recognition Network), for the automatic recognition of the coronavirus from CT or X-ray images. The proposed end-to-end CVR-Net is a multi-scale-multi-encoder ensemble model, where we have aggregated the outputs from two different encoders and their different scales to obtain the final prediction probability. We train and test the proposed CVR-Net on three different datasets, where the images have collected from different open-source repositories. We compare our proposed CVR-Net with state-of-the-art methods, which are trained and tested on the same datasets. We split three datasets into five different tasks, where each task has a different number of classes, to evaluate the multi-tasking CVR-Net. Our model achieves an overall F1-score and accuracy of 0.997 and 0.998; 0.963 and 0.964; 0.816 and 0.820; 0.961 and 0.961; and 0.780 and 0.780, respectively, for task-1 to task-5. As the CVR-Net provides promising results on the small datasets, it can be an auspicious computer-aided diagnostic tool for the diagnosis of coronavirus to assist the clinical practitioners and radiologists. Our source codes and model are publicly available at GitHub",278,COVID-19,,,Art;Tomography,,,,,,External,2. Detection/Diagnosis,X-Ray
2007.12525,10.3390/make2040027,Yes,,,2020,2020-07-24,Preprint,arXiv,0,study of different deep learning approach with explainable ai for screening patients with covid-19 symptoms: using ct scan and chest x-ray image dataset,"The outbreak of COVID-19 disease caused more than 100,000 deaths so far in the USA alone. It is necessary to conduct an initial screening of patients with the symptoms of COVID-19 disease to control the spread of the disease. However, it is becoming laborious to conduct the tests with the available testing kits due to the growing number of patients. Some studies proposed CT scan or chest X-ray images as an alternative solution. Therefore, it is essential to use every available resource, instead of either a CT scan or chest X-ray to conduct a large number of tests simultaneously. As a result, this study aims to develop a deep learning-based model that can detect COVID-19 patients with better accuracy both on CT scan and chest X-ray image dataset. In this work, eight different deep learning approaches such as VGG16, InceptionResNetV2, ResNet50, DenseNet201, VGG19, MobilenetV2, NasNetMobile, and ResNet15V2 have been tested on two dataset-one dataset includes 400 CT scan images, and another dataset includes 400 chest X-ray images studied. Besides, Local Interpretable Model-agnostic Explanations (LIME) is used to explain the model's interpretability. Using LIME, test results demonstrate that it is conceivable to interpret top features that should have worked to build a trust AI framework to distinguish between patients with COVID-19 symptoms with other patients.",214,COVID-19;Death,,,Disease Outbreaks;Other Topics,,,,,,External,2. Detection/Diagnosis,Multimodal
2007.14318,,Yes,,,2020,2020-08-29,Preprint,arXiv,0,covmunet: a multiple loss approach towards detection of covid-19 from chest x-ray,"The recent outbreak of COVID-19 has halted the whole world, bringing a devastating effect on public health, global economy, and educational systems. As the vaccine of the virus is still not available, the most effective way to combat the virus is testing and social distancing. Among all other detection techniques, the Chest X-ray (CXR) based method can be a good solution for its simplicity, rapidity, cost, efficiency, and accessibility. In this paper, we propose CovMUNET, which is a multiple loss deep neural network approach to detect COVID-19 cases from CXR images. Extensive experiments are performed to ensure the robustness of the proposed algorithm and the performance is evaluated in terms of precision, recall, accuracy, and F1-score. The proposed method outperforms the state-of-the-art approaches with an accuracy of 96.97% for 3-class classification (COVID-19 vs normal vs pneumonia) and 99.41% for 2-class classification (COVID vs non-COVID). The proposed neural architecture also successfully detects the abnormality in CXR images.",156,COVID-19;Pneumonia,,,Public Health;Art;Algorithms;Architecture;Disease Outbreaks,,,,,,External,2. Detection/Diagnosis,X-Ray
2007.15546,,Yes,,,2022,2022-01-10,Preprint,arXiv,0,comparative study of deep learning methods for the automatic segmentation of lung lesion and lesion type in ct scans of covid-19 patients,"Recent research on COVID-19 suggests that CT imaging provides useful information to assess disease progression and assist diagnosis, in addition to help understanding the disease. There is an increasing number of studies that propose to use deep learning to provide fast and accurate quantification of COVID-19 using chest CT scans. The main tasks of interest are the automatic segmentation of lung and lung lesions in chest CT scans of confirmed or suspected COVID-19 patients. In this study, we compare twelve deep learning algorithms using a multi-center dataset, including both open-source and in-house developed algorithms. Results show that ensembling different methods can boost the overall test set performance for lung segmentation, binary lesion segmentation and multiclass lesion segmentation, resulting in mean Dice scores of 0.982, 0.724 and 0.469, respectively. The resulting binary lesions were segmented with a mean absolute volume error of 91.3 ml. In general, the task of distinguishing different lesion types was more difficult, with a mean absolute volume difference of 152 ml and mean Dice scores of 0.369 and 0.523 for consolidation and ground glass opacity, respectively. All methods perform binary lesion segmentation with an average volume error that is better than visual assessment by human raters, suggesting these methods are mature enough for a large-scale evaluation for use in clinical practice.",214,COVID-19;Disease Progression,,,Other Topics,,,,,,Self-recorded/clinical,Segmentation-only,CT
2008.02866,,Yes,,,2020,2020-08-15,Preprint,arXiv,0,improving explainability of image classification in scenarios with class overlap: application to covid-19 and pneumonia,"Trust in predictions made by machine learning models is increased if the model generalizes well on previously unseen samples and when inference is accompanied by cogent explanations of the reasoning behind predictions. In the image classification domain, generalization can be assessed through accuracy, sensitivity, and specificity. Explainability can be assessed by how well the model localizes the object of interest within an image. However, both generalization and explainability through localization are degraded in scenarios with significant overlap between classes. We propose a method based on binary expert networks that enhances the explainability of image classifications through better localization by mitigating the model uncertainty induced by class overlap. Our technique performs discriminative localization on images that contain features with significant class overlap, without explicitly training for localization. Our method is particularly promising in real-world class overlap scenarios, such as COVID-19 and pneumonia, where expertly labeled data for localization is not readily available. This can be useful for early, rapid, and trustworthy screening for COVID-19.",163,COVID-19;Pneumonia,,,Other Topics,,,,,,External,5. Post-hoc,X-Ray
2008.06330,,Yes,,,2020,2020-08-13,Preprint,arXiv,0,automated detection and quantification of covid-19 airspace disease on chest radiographs: a novel approach achieving radiologist-level performance using a cnn trained on digital reconstructed radiographs (drrs) from ct-based ground-truth,"To leverage volumetric quantification of airspace disease (AD) derived from a superior modality (CT) serving as ground truth, projected onto digitally reconstructed radiographs (DRRs) to: 1) train a convolutional neural network to quantify airspace disease on paired CXRs; and 2) compare the DRR-trained CNN to expert human readers in the CXR evaluation of patients with confirmed COVID-19. We retrospectively selected a cohort of 86 COVID-19 patients (with positive RT-PCR), from March-May 2020 at a tertiary hospital in the northeastern USA, who underwent chest CT and CXR within 48 hrs. The ground truth volumetric percentage of COVID-19 related AD (POv) was established by manual AD segmentation on CT. The resulting 3D masks were projected into 2D anterior-posterior digitally reconstructed radiographs (DRR) to compute area-based AD percentage (POa). A convolutional neural network (CNN) was trained with DRR images generated from a larger-scale CT dataset of COVID-19 and non-COVID-19 patients, automatically segmenting lungs, AD and quantifying POa on CXR. CNN POa results were compared to POa quantified on CXR by two expert readers and to the POv ground-truth, by computing correlations and mean absolute errors. Bootstrap mean absolute error (MAE) and correlations between POa and POv were 11.98% and 0.77 for average of expert readers, and 9.56%-9.78% and 0.78-0.81 for the CNN, respectively. Our CNN trained with DRR using CT-derived airspace quantification achieved expert radiologist level of accuracy in the quantification of airspace disease on CXR, in patients with positive RT-PCR for COVID-19.",240,COVID-19,,,Polymerase Chain Reaction;Other Topics,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,Multimodal
2008.08840,,Yes,,,2021,2021-01-18,Preprint,arXiv,0,image quality assessment for closed-loop computer-assisted lung ultrasound,"We describe a novel, two-stage computer assistance system for lung anomaly detection using ultrasound imaging in the intensive care setting to improve operator performance and patient stratification during coronavirus pandemics. The proposed system consists of two deep-learning-based models: a quality assessment module that automates predictions of image quality, and a diagnosis assistance module that determines the likelihood-oh-anomaly in ultrasound images of sufficient quality. Our two-stage strategy uses a novelty detection algorithm to address the lack of control cases available for training the quality assessment classifier. The diagnosis assistance module can then be trained with data that are deemed of sufficient quality, guaranteed by the closed-loop feedback mechanism from the quality assessment module. Using more than 25000 ultrasound images from 37 COVID-19-positive patients scanned at two hospitals, plus 12 control cases, this study demonstrates the feasibility of using the proposed machine learning approach. We report an accuracy of 86% when classifying between sufficient and insufficient quality images by the quality assessment module. For data of sufficient quality - as determined by the quality assessment module - the mean classification accuracy, sensitivity, and specificity in detecting COVID-19-positive cases were 0.95, 0.91, and 0.97, respectively, across five holdout test data sets unseen during the training of any networks within the proposed system. Overall, the integration of the two modules yields accurate, fast, and practical acquisition guidance and diagnostic assistance for patients with suspected respiratory conditions at point-of-care.",234,COVID-19,,,Point-of-Care Systems;Ultrasonography,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
2008.09713,,Yes,,,2020,2020-08-21,Preprint,arXiv,0,comparative performance analysis of the resnet backbones of mask rcnn to segment the signs of covid-19 in chest ct scans,"COVID-19 has been detrimental in terms of the number of fatalities and rising number of critical patients across the world. According to the UNDP (United National Development Programme) Socio-Economic programme, aimed at the COVID-19 crisis, the pandemic is far more than a health crisis: it is affecting societies and economies at their core. There has been greater developments recently in the chest X-ray-based imaging technique as part of the COVID-19 diagnosis especially using Convolution Neural Networks (CNN) for recognising and classifying images. However, given the limitation of supervised labelled imaging data, the classification and predictive risk modelling of medical diagnosis tend to compromise. This paper aims to identify and monitor the effects of COVID-19 on the human lungs by employing Deep Neural Networks on axial CT (Chest Computed Tomography) scan of lungs. We have adopted Mask RCNN, with ResNet50 and ResNet101 as its backbone, to segment the regions, affected by COVID-19 coronavirus. Using the regions of human lungs, where symptoms have manifested, the model classifies condition of the patient as either ""Mild"" or ""Alarming"". Moreover, the model is deployed on the Google Cloud Platform (GCP) to simulate the online usage of the model for performance evaluation and accuracy improvement. The ResNet101 backbone model produces an F1 score of 0.85 and faster prediction scores with an average time of 9.04 seconds per inference.",222,COVID-19,,,Other Topics,,,,,,External,2. Detection/Diagnosis,CT
2008.09866,,Yes,,,2020,2020-08-22,Preprint,arXiv,0,symbolic semantic segmentation and interpretation of covid-19 lung infections in chest ct volumes based on emergent languages,"The coronavirus disease (COVID-19) has resulted in a pandemic crippling the a breadth of services critical to daily life. Segmentation of lung infections in computerized tomography (CT) slices could be be used to improve diagnosis and understanding of COVID-19 in patients. Deep learning systems lack interpretability because of their black box nature. Inspired by human communication of complex ideas through language, we propose a symbolic framework based on emergent languages for the segmentation of COVID-19 infections in CT scans of lungs. We model the cooperation between two artificial agents - a Sender and a Receiver. These agents synergistically cooperate using emergent symbolic language to solve the task of semantic segmentation. Our game theoretic approach is to model the cooperation between agents unlike Generative Adversarial Networks (GANs). The Sender retrieves information from one of the higher layers of the deep network and generates a symbolic sentence sampled from a categorical distribution of vocabularies. The Receiver ingests the stream of symbols and cogenerates the segmentation mask. A private emergent language is developed that forms the communication channel used to describe the task of segmentation of COVID infections. We augment existing state of the art semantic segmentation architectures with our symbolic generator to form symbolic segmentation models. Our symbolic segmentation framework achieves state of the art performance for segmentation of lung infections caused by COVID-19. Our results show direct interpretation of symbolic sentences to discriminate between normal and infected regions, infection morphology and image characteristics. We show state of the art results for segmentation of COVID-19 lung infections in CT.",257,COVID-19;Infections,,,Coronavirus Infections;Art;Pandemics;Architecture;Semantics;Tomography;Lung Diseases;Masks;Cone-Beam Computed Tomography,,,,,,External,Segmentation-only,CT
2008.11639,,Yes,,,2020,2020-10-09,Preprint,arXiv,0,a comparison of deep machine learning algorithms in covid-19 disease diagnosis,"The aim of the work is to use deep neural network models for solving the problem of image recognition. These days, every human being is threatened by a harmful coronavirus disease, also called COVID-19 disease. The spread of coronavirus affects the economy of many countries in the world. To find COVID-19 patients early is very essential to avoid the spread and harm to society. Pathological tests and Chromatography (CT) scans are helpful for the diagnosis of COVID-19. However, these tests are having drawbacks such as a large number of false positives, and cost of these tests are so expensive. Hence, it requires finding an easy, accurate, and less expensive way for the detection of the harmful COVID-19 disease. Chest-x-ray can be useful for the detection of this disease. Therefore, in this work chest, x-ray images are used for the diagnosis of suspected COVID-19 patients using modern machine learning techniques. The analysis of the results is carried out and conclusions are made about the effectiveness of deep machine learning algorithms in image recognition problems.",173,COVID-19,,,Neural Networks;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2009.01657,,Yes,,,2020,2020-08-27,Preprint,arXiv,0,a free web service for fast covid-19 classification of chest x-ray images,"The coronavirus outbreak became a major concern for society worldwide. Technological innovation and ingenuity are essential to fight COVID-19 pandemic and bring us one step closer to overcome it. Researchers over the world are working actively to find available alternatives in different fields, such as the Healthcare System, pharmaceutic, health prevention, among others. With the rise of artificial intelligence (AI) in the last 10 years, IA-based applications have become the prevalent solution in different areas because of its higher capability, being now adopted to help combat against COVID-19. This work provides a fast detection system of COVID-19 characteristics in X-Ray images based on deep learning (DL) techniques. This system is available as a free web deployed service for fast patient classification, alleviating the high demand for standards method for COVID-19 diagnosis. It is constituted of two deep learning models, one to differentiate between X-Ray and non-X-Ray images based on Mobile-Net architecture, and another one to identify chest X-Ray images with characteristics of COVID-19 based on the DenseNet architecture. For real-time inference, it is provided a pair of dedicated GPUs, which reduce the computational time. The whole system can filter out non-chest X-Ray images, and detect whether the X-Ray presents characteristics of COVID-19, highlighting the most sensitive regions.",207,COVID-19;COVID-19 Pandemic,,,Health Care;Research Personnel;Architecture;Disease Outbreaks,,,,,,External,2. Detection/Diagnosis,X-Ray
2009.05096,,Yes,,,2020,2020-09-10,Preprint,arXiv,0,covid ct-net: predicting covid-19 from chest ct images using attentional convolutional network,"The novel corona-virus disease (COVID-19) pandemic has caused a major outbreak in more than 200 countries around the world, leading to a severe impact on the health and life of many people globally. As of Aug 25th of 2020, more than 20 million people are infected, and more than 800,000 death are reported. Computed Tomography (CT) images can be used as a as an alternative to the time-consuming ""reverse transcription polymerase chain reaction (RT-PCR)"" test, to detect COVID-19. In this work we developed a deep learning framework to predict COVID-19 from CT images. We propose to use an attentional convolution network, which can focus on the infected areas of chest, enabling it to perform a more accurate prediction. We trained our model on a dataset of more than 2000 CT images, and report its performance in terms of various popular metrics, such as sensitivity, specificity, AUC, and also precision-recall curve, and achieve very promising results. We also provide a visualization of the attention maps of the model for several test images, and show that our model is attending to the infected regions as intended. In addition to developing a machine learning modeling framework, we also provide the manual annotation of the potentionally infected regions of chest, with the help of a board-certified radiologist, and make that publicly available for other researchers.",221,COVID-19;Death,,,Specificity;Research Personnel;Disease Outbreaks;Health;Polymerase Chain Reaction;Radiologists;Map;Reverse Transcription,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,CT
2009.05436,,Yes,,,2021,2021-02-28,Preprint,arXiv,0,semi-supervised active learning for covid-19 lung ultrasound multi-symptom classification,"Ultrasound (US) is a non-invasive yet effective medical diagnostic imaging technique for the COVID-19 global pandemic. However, due to complex feature behaviors and expensive annotations of US images, it is difficult to apply Artificial Intelligence (AI) assisting approaches for lung's multi-symptom (multi-label) classification. To overcome these difficulties, we propose a novel semi-supervised Two-Stream Active Learning (TSAL) method to model complicated features and reduce labeling costs in an iterative procedure. The core component of TSAL is the multi-label learning mechanism, in which label correlations information is used to design multi-label margin (MLM) strategy and confidence validation for automatically selecting informative samples and confident labels. On this basis, a multi-symptom multi-label (MSML) classification network is proposed to learn discriminative features of lung symptoms, and a human-machine interaction is exploited to confirm the final annotations that are used to fine-tune MSML with progressively labeled data. Moreover, a novel lung US dataset named COVID19-LUSMS is built, currently containing 71 clinical patients with 6,836 images sampled from 678 videos. Experimental evaluations show that TSAL using only 20% data can achieve superior performance to the baseline and the state-of-the-art. Qualitatively, visualization of both attention map and sample distribution confirms the good consistency with the clinic knowledge.",200,COVID-19,,,Diagnostic Imaging;Art;Other Topics;Map,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
2009.06116,10.3390/app11020672,Yes,,,2020,2020-09-13,Preprint,arXiv,0,accelerating covid-19 differential diagnosis with explainable ultrasound image analysis,"Controlling the COVID-19 pandemic largely hinges upon the existence of fast, safe, and highly-available diagnostic tools. Ultrasound, in contrast to CT or X-Ray, has many practical advantages and can serve as a globally-applicable first-line examination technique. We provide the largest publicly available lung ultrasound (US) dataset for COVID-19 consisting of 106 videos from three classes (COVID-19, bacterial pneumonia, and healthy controls); curated and approved by medical experts. On this dataset, we perform an in-depth study of the value of deep learning methods for differential diagnosis of COVID-19. We propose a frame-based convolutional neural network that correctly classifies COVID-19 US videos with a sensitivity of 0.98 and a specificity of 0.91 (frame-based sensitivity 0.93, specificity 0.87). We further employ class activation maps for the spatio-temporal localization of pulmonary biomarkers, which we subsequently validate for human-in-the-loop scenarios in a blindfolded study with medical experts. Aiming for scalability and robustness, we perform ablation studies comparing mobile-friendly, frame- and video-based architectures and show reliability of the best model by aleatoric and epistemic uncertainty estimates. We hope to pave the road for a community effort toward an accessible, efficient and interpretable screening method and we have started to work on a clinical validation of the proposed method. Data and code are publicly available.",208,"COVID-19;COVID-19 Pandemic;Pneumonia, Bacterial",,,Specificity;Architecture;Map,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
2009.06412,,Yes,,,2022,2022-05-16,Preprint,arXiv,0,comprehensive comparison of deep learning models for lung and covid-19 lesion segmentation in ct scans,"Recently there has been an explosion in the use of Deep Learning (DL) methods for medical image segmentation. However the field's reliability is hindered by the lack of a common base of reference for accuracy/performance evaluation and the fact that previous research uses different datasets for evaluation. In this paper, an extensive comparison of DL models for lung and COVID-19 lesion segmentation in Computerized Tomography (CT) scans is presented, which can also be used as a benchmark for testing medical image segmentation models. Four DL architectures (Unet, Linknet, FPN, PSPNet) are combined with 25 randomly initialized and pretrained encoders (variations of VGG, DenseNet, ResNet, ResNext, DPN, MobileNet, Xception, Inception-v4, EfficientNet), to construct 200 tested models. Three experimental setups are conducted for lung segmentation, lesion segmentation and lesion segmentation using the original lung masks. A public COVID-19 dataset with 100 CT scan images (80 for train, 20 for validation) is used for training/validation and a different public dataset consisting of 829 images from 9 CT scan volumes for testing. Multiple findings are provided including the best architecture-encoder models for each experiment as well as mean Dice results for each experiment, architecture and encoder independently. Finally, the upper bounds improvements when using lung masks as a preprocessing step or when using pretrained models are quantified. The source code and 600 pretrained models for the three experiments are provided, suitable for fine-tuning in experimental setups without GPU capabilities.",235,COVID-19,,,Other Topics,,,,,,External,Segmentation-only,CT
2009.08831,,Yes,,,2020,2020-09-14,Preprint,arXiv,0,fused deep convolutional neural network for precision diagnosis of covid-19 using chest x-ray images,"With a Coronavirus disease (COVID-19) case count exceeding 10 million worldwide, there is an increased need for a diagnostic capability. The main variables in increasing diagnostic capability are reduced cost, turnaround or diagnosis time, and upfront equipment cost and accessibility. Two candidates for machine learning COVID-19 diagnosis are Computed Tomography (CT) scans and plain chest X-rays. While CT scans score higher in sensitivity, they have a higher cost, maintenance requirement, and turnaround time as compared to plain chest X-rays. The use of portable chest X-radiograph (CXR) is recommended by the American College of Radiology (ACR) since using CT places a massive burden on radiology services. Therefore, X-ray imagery paired with machine learning techniques is proposed a first-line triage tool for COVID-19 diagnostics. In this paper we propose a computer-aided diagnosis (CAD) to accurately classify chest X-ray scans of COVID-19 and normal subjects by fine-tuning several neural networks (ResNet18, ResNet50, DenseNet201) pre-trained on the ImageNet dataset. These neural networks are fused in a parallel architecture and the voting criteria are applied in the final classification decision between the candidate object classes where the output of each neural network is representing a single vote. Several experiments are conducted on the weakly labeled COVID-19-CT-CXR dataset consisting of 263 COVID-19 CXR images extracted from PubMed Central Open Access subsets combined with 25 normal classification CXR images. These experiments show an optimistic result and a capability of the proposed model to outperforming many state-of-the-art algorithms on several measures. Using k-fold cross-validation and a bagging classifier ensemble, we achieve an accuracy of 99.7% and a sensitivity of 100%.",262,COVID-19,,,Art;Algorithms;Architecture;Tomography,,,,,,External,2. Detection/Diagnosis,X-Ray
2009.08864,,Yes,,,2020,2020-09-15,Preprint,arXiv,0,classification and region analysis of covid-19 infection using lung ct images and deep convolutional neural networks,"COVID-19 is a global health problem. Consequently, early detection and analysis of the infection patterns are crucial for controlling infection spread as well as devising a treatment plan. This work proposes a two-stage deep Convolutional Neural Networks (CNNs) based framework for delineation of COVID-19 infected regions in Lung CT images. In the first stage, initially, COVID-19 specific CT image features are enhanced using a two-level discrete wavelet transformation. These enhanced CT images are then classified using the proposed custom-made deep CoV-CTNet. In the second stage, the CT images classified as infectious images are provided to the segmentation models for the identification and analysis of COVID-19 infectious regions. In this regard, we propose a novel semantic segmentation model CoV-RASeg, which systematically uses average and max pooling operations in the encoder and decoder blocks. This systematic utilization of max and average pooling operations helps the proposed CoV-RASeg in simultaneously learning both the boundaries and region homogeneity. Moreover, the idea of attention is incorporated to deal with mildly infected regions. The proposed two-stage framework is evaluated on a standard Lung CT image dataset, and its performance is compared with the existing deep CNN models. The performance of the proposed CoV-CTNet is evaluated using Mathew Correlation Coefficient (MCC) measure and that of proposed CoV-RASeg using Dice Similarity (DS) score. The promising results on an unseen test set suggest that the proposed framework has the potential to help the radiologists in the identification and analysis of COVID-19 infected regions.",244,COVID-19;Infections,,,Health;Semantics,,,,,,External,2. Detection/Diagnosis,CT
2009.09247,,Yes,,,2021,2021-05-03,Preprint,arXiv,0,bias field poses a threat to dnn-based x-ray recognition,"The chest X-ray plays a key role in screening and diagnosis of many lung diseases including the COVID-19. More recently, many works construct deep neural networks (DNNs) for chest X-ray images to realize automated and efficient diagnosis of lung diseases. However, bias field caused by the improper medical image acquisition process widely exists in the chest X-ray images while the robustness of DNNs to the bias field is rarely explored, which definitely poses a threat to the X-ray-based automated diagnosis system. In this paper, we study this problem based on the recent adversarial attack and propose a brand new attack, i.e., the adversarial bias field attack where the bias field instead of the additive noise works as the adversarial perturbations for fooling the DNNs. This novel attack posts a key problem: how to locally tune the bias field to realize high attack success rate while maintaining its spatial smoothness to guarantee high realisticity. These two goals contradict each other and thus has made the attack significantly challenging. To overcome this challenge, we propose the adversarial-smooth bias field attack that can locally tune the bias field with joint smooth and adversarial constraints. As a result, the adversarial X-ray images can not only fool the DNNs effectively but also retain very high level of realisticity. We validate our method on real chest X-ray datasets with powerful DNNs, e.g., ResNet50, DenseNet121, and MobileNet, and show different properties to the state-of-the-art attacks in both image realisticity and attack transferability. Our method reveals the potential threat to the DNN-based X-ray automated diagnosis and can definitely benefit the development of bias-field-robust automated diagnosis system.",268,COVID-19;Lung Diseases,,,Art;Noise;Other Topics;Lung Diseases,,,,,,External,2. Detection/Diagnosis,X-Ray
2009.09725,,Yes,,,2020,2020-09-21,Preprint,arXiv,0,improving automated covid-19 grading with convolutional neural networks in computed tomography scans: an ablation study,"Amidst the ongoing pandemic, several studies have shown that COVID-19 classification and grading using computed tomography (CT) images can be automated with convolutional neural networks (CNNs). Many of these studies focused on reporting initial results of algorithms that were assembled from commonly used components. The choice of these components was often pragmatic rather than systematic. For instance, several studies used 2D CNNs even though these might not be optimal for handling 3D CT volumes. This paper identifies a variety of components that increase the performance of CNN-based algorithms for COVID-19 grading from CT images. We investigated the effectiveness of using a 3D CNN instead of a 2D CNN, of using transfer learning to initialize the network, of providing automatically computed lesion maps as additional network input, and of predicting a continuous instead of a categorical output. A 3D CNN with these components achieved an AUC of 0.934 on our test set of 105 CT scans and an AUC of 0.923 on a publicly available set of 742 CT scans, a substantial improvement in comparison with a previously published 2D CNN. An ablation study demonstrated that in addition to using a 3D CNN instead of a 2D CNN transfer learning contributed the most and continuous output contributed the least to improving the model performance.",213,COVID-19,,,Transfer Learning;Algorithms;Tomography;ROC Curve;Area under Curve;Map;Cone-Beam Computed Tomography,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,Multimodal
2009.10141,10.1007/s42600-020-00110-7,Yes,,,2020,2020-09-21,Preprint,arXiv,0,ccblock: an effective use of deep learning for automatic diagnosis of covid-19 using x-ray images,"Troubling countries one after another, the COVID-19 pandemic has dramatically affected the health and well-being of the world's population. The disease may continue to persist more extensively due to the increasing number of new cases daily, the rapid spread of the virus, and delay in the PCR analysis results. Therefore, it is necessary to consider developing assistive methods for detecting and diagnosing the COVID-19 to eradicate the spread of the novel coronavirus among people. Based on convolutional neural networks (CNNs), automated detection systems have shown promising results of diagnosing patients with the COVID-19 through radiography; thus, they are introduced as a workable solution to the COVID-19 diagnosis. Based on the enhancement of the classical visual geometry group (VGG) network with the convolutional COVID block (CCBlock), an efficient screening model was proposed in this study to diagnose and distinguish patients with the COVID-19 from those with pneumonia and the healthy people through radiography. The model testing dataset included 1,828 x-ray images available on public platforms. 310 images were showing confirmed COVID-19 cases, 864 images indicating pneumonia cases, and 654 images showing healthy people. According to the test results, enhancing the classical VGG network with radiography provided the highest diagnosis performance and overall accuracy of 98.52% for two classes as well as accuracy of 95.34% for three classes. According to the results, using the enhanced VGG deep neural network can help radiologists automatically diagnose the COVID-19 through radiography.",236,COVID-19;COVID-19 Pandemic;Pneumonia,,,Polymerase Chain Reaction;Other Topics,8.639495113515313e-07,0.0,4.538773658024894e-07,0.0,0.0,External,2. Detection/Diagnosis,X-Ray
2009.10401,,Yes,,,2020,2020-10-25,Preprint,arXiv,0,dynamic fusion based federated learning for covid-19 detection,"Medical diagnostic image analysis (e.g., CT scan or X-Ray) using machine learning is an efficient and accurate way to detect COVID-19 infections. However, sharing diagnostic images across medical institutions is usually not allowed due to the concern of patients' privacy. This causes the issue of insufficient datasets for training the image classification model. Federated learning is an emerging privacy-preserving machine learning paradigm that produces an unbiased global model based on the received updates of local models trained by clients without exchanging clients' local data. Nevertheless, the default setting of federated learning introduces huge communication cost of transferring model updates and can hardly ensure model performance when data heterogeneity of clients heavily exists. To improve communication efficiency and model performance, in this paper, we propose a novel dynamic fusion-based federated learning approach for medical diagnostic image analysis to detect COVID-19 infections. First, we design an architecture for dynamic fusion-based federated learning systems to analyse medical diagnostic images. Further, we present a dynamic fusion method to dynamically decide the participating clients according to their local model performance and schedule the model fusion-based on participating clients' training time. In addition, we summarise a category of medical diagnostic image datasets for COVID-19 detection, which can be used by the machine learning community for image analysis. The evaluation results show that the proposed approach is feasible and performs better than the default setting of federated learning in terms of model performance, communication efficiency and fault tolerance.",241,COVID-19;Infections,,,Other Topics,,,,,,External,2. Detection/Diagnosis,Multimodal
2009.10608,,Yes,,,2020,2020-10-26,Preprint,arXiv,0,dual encoder fusion u-net (defu-net) for cross-manufacturer chest x-ray segmentation,"A number of methods based on deep learning have been applied to medical image segmentation and have achieved state-of-the-art performance. Due to the importance of chest x-ray data in studying COVID-19, there is a demand for state-of-the-art models capable of precisely segmenting soft tissue on the chest x-rays. The dataset for exploring best segmentation model is from Montgomery and Shenzhen hospital which had opened in 2014. The most famous technique is U-Net which has been used to many medical datasets including the Chest X-rays. However, most variant U-Nets mainly focus on extraction of contextual information and skip connections. There is still a large space for improving extraction of spatial features. In this paper, we propose a dual encoder fusion U-Net framework for Chest X-rays based on Inception Convolutional Neural Network with dilation, Densely Connected Recurrent Convolutional Neural Network, which is named DEFU-Net. The densely connected recurrent path extends the network deeper for facilitating contextual feature extraction. In order to increase the width of network and enrich representation of features, the inception blocks with dilation are adopted. The inception blocks can capture globally and locally spatial information from various receptive fields. At the same time, the two paths are fused by summing features, thus preserving the contextual and spatial information for decoding part. This multi-learning-scale model is benefiting in Chest X-ray dataset from two different manufacturers (Montgomery and Shenzhen hospital). The DEFU-Net achieves the better performance than basic U-Net, residual U-Net, BCDU-Net, R2U-Net and attention R2U-Net. This model has proved the feasibility for mixed dataset and approaches state-of-the-art. The source code for this proposed framework is public GitHub",267,COVID-19,,,Art;Other Topics,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
2009.12597,,Yes,,,2021,2021-01-21,Preprint,arXiv,0,potential features of icu admission in x-ray images of covid-19 patients,"X-ray images may present non-trivial features with predictive information of patients that develop severe symptoms of COVID-19. If true, this hypothesis may have practical value in allocating resources to particular patients while using a relatively inexpensive imaging technique. The difficulty of testing such a hypothesis comes from the need for large sets of labelled data, which need to be well-annotated and should contemplate the post-imaging severity outcome. This paper presents an original methodology for extracting semantic features that correlate to severity from a data set with patient ICU admission labels through interpretable models. The methodology employs a neural network trained to recognise lung pathologies to extract the semantic features, which are then analysed with low-complexity models to limit overfitting while increasing interpretability. This analysis points out that only a few features explain most of the variance between patients that developed severe symptoms. When applied to an unrelated larger data set with pathology-related clinical notes, the method has shown to be capable of selecting images for the learned features, which could translate some information about their common locations in the lung. Besides attesting separability on patients that eventually develop severe symptoms, the proposed methods represent a statistical approach highlighting the importance of features related to ICU admission that may have been only qualitatively reported. While handling limited data sets, notable methodological aspects are adopted, such as presenting a state-of-the-art lung segmentation network and the use of low-complexity models to avoid overfitting. The code for methodology and experiments is also available.",249,COVID-19,,,Art;Semantics;Other Topics,,,,,,External,4. Prognosis/Treatment,X-Ray
2010.00958,,Yes,,,2020,2020-10-09,Preprint,arXiv,0,identification of images of covid-19 from chest computed tomography (ct) images using deep learning: comparing cognex visionpro deep learning 10 software with open source convolutional neural networks,"For testing patients infected with COVID-19, along with RT-PCR testing, chest radiology images are being used. For the detection of COVID-19 from radiology images, many organizations are proposing the use of Deep Learning. University of Waterloo and DarwinAI, have designed their own Deep Learning model COVIDNet-CT to detect COVID-19 from infected chest CT images. Additionally, they have introduced a CT image dataset COVIDx-CT, from CT images collected by the China National Center for Bioinformation. COVIDx-CT contains 104,009 CT image slices across 1,489 patient cases. After obtaining remarkable results on the identification of COVID-19 from chest X-ray images by using the COGNEX VisionPro Deep Learning Software 1.0 this time we test the performance of the software on the identification of COVID-19 from CT images. COGNEX Deep Learning VisionPro Deep Learning, is a Deep Learning software that is used across various domains ranging from factory automation to life sciences. In this study, we train the classification model on 82,818 chest CT training and validation images from the COVIDx-CT dataset in 3 classes - normal, pneumonia, and COVID-19 and then test the results of the classification on the 21,191 test images are compared with the results of COVIDNet-CT and various other state of the art Deep Learning models from the open-source community. Also, we test how reducing the number of images in the training set effects the results of the software. Overall, VisionPro Deep Learning gives the best results with F-scores over 99%, even as the number of images in the training set is reduced significantly. This software is by no means a stand-alone solution in the detection of COVID-19 but can aid radiologists and clinicians in achieving faster and understandable diagnosis using the full potential of Deep Learning, without the prerequisite of having to code in any programming language.",297,COVID-19;Pneumonia,,,Art;Polymerase Chain Reaction;Tomography;Other Topics,,,,,,External,2. Detection/Diagnosis,CT
2010.02715,10.20944/preprints202009.0647.v1,Yes,,,2020,2020-10-03,Preprint,arXiv,0,assessing automated machine learning service to detect covid-19 from x-ray and ct images: a real-time smartphone application case study,"The recent outbreak of SARS COV-2 gave us a unique opportunity to study for a non interventional and sustainable AI solution. Lung disease remains a major healthcare challenge with high morbidity and mortality worldwide. The predominant lung disease was lung cancer. Until recently, the world has witnessed the global pandemic of COVID19, the Novel coronavirus outbreak. We have experienced how viral infection of lung and heart claimed thousands of lives worldwide. With the unprecedented advancement of Artificial Intelligence in recent years, Machine learning can be used to easily detect and classify medical imagery. It is much faster and most of the time more accurate than human radiologists. Once implemented, it is more cost-effective and time-saving. In our study, we evaluated the efficacy of Microsoft Cognitive Service to detect and classify COVID19 induced pneumonia from other Viral/Bacterial pneumonia based on X-Ray and CT images. We wanted to assess the implication and accuracy of the Automated ML-based Rapid Application Development (RAD) environment in the field of Medical Image diagnosis. This study will better equip us to respond with an ML-based diagnostic Decision Support System (DSS) for a Pandemic situation like COVID19. After optimization, the trained network achieved 96.8% Average Precision which was implemented as a Web Application for consumption. However, the same trained network did not perform the same like Web Application when ported to Smartphone for Real-time inference. Which was our main interest of study. The authors believe, there is scope for further study on this issue. One of the main goal of this study was to develop and evaluate the performance of AI-powered Smartphone-based Real-time Application. Facilitating primary diagnostic services in less equipped and understaffed rural healthcare centers of the world with unreliable internet service.",285,"COVID-19;Lung Cancer;Lung Diseases;Pneumonia;Pneumonia, Bacterial;Virus Diseases",,,Health Care;Disease Outbreaks;Radiologists;Other Topics,,,,,,External,2. Detection/Diagnosis,Multimodal
2010.04420,,Yes,,,2020,2020-10-09,Preprint,arXiv,0,prognosis prediction in covid-19 patients from lab tests and x-ray data through randomized decision trees,"AI and Machine Learning can offer powerful tools to help in the fight against Covid-19. In this paper we present a study and a concrete tool based on machine learning to predict the prognosis of hospitalised patients with Covid-19. In particular we address the task of predicting the risk of death of a patient at different times of the hospitalisation, on the base of some demographic information, chest X-ray scores and several laboratory findings. Our machine learning models use ensembles of decision trees trained and tested using data from more than 2000 patients. An experimental evaluation of the models shows good performance in solving the addressed task.",107,COVID-19;Death,,,Other Topics;Paper,,,,,,External,4. Prognosis/Treatment,X-Ray
2010.04936,,Yes,,,2020,2020-10-10,Preprint,arXiv,0,an empirical study on detecting covid-19 in chest x-ray images using deep learning based methods,"Spreading of COVID-19 virus has increased the efforts to provide testing kits. Not only the preparation of these kits had been hard, rare, and expensive but also using them is another issue. Results have shown that these kits take some crucial time to recognize the virus, in addition to the fact that they encounter with 30% loss. In this paper, we have studied the usage of x-ray pictures which are ubiquitous, for the classification of COVID-19 chest Xray images, by the existing convolutional neural networks (CNNs). We intend to train chest x-rays of infected and not infected ones with different CNNs architectures including VGG19, Densnet-121, and Xception. Training these architectures resulted in different accuracies which were much faster and more precise than usual ways of testing.",126,COVID-19,,,Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2010.09456,,Yes,,,2020,2020-10-19,Preprint,arXiv,0,gasnet: weakly-supervised framework for covid-19 lesion segmentation,"Segmentation of infected areas in chest CT volumes is of great significance for further diagnosis and treatment of COVID-19 patients. Due to the complex shapes and varied appearances of lesions, a large number of voxel-level labeled samples are generally required to train a lesion segmentation network, which is a main bottleneck for developing deep learning based medical image segmentation algorithms. In this paper, we propose a weakly-supervised lesion segmentation framework by embedding the Generative Adversarial training process into the Segmentation Network, which is called GASNet. GASNet is optimized to segment the lesion areas of a COVID-19 CT by the segmenter, and to replace the abnormal appearance with a generated normal appearance by the generator, so that the restored CT volumes are indistinguishable from healthy CT volumes by the discriminator. GASNet is supervised by chest CT volumes of many healthy and COVID-19 subjects without voxel-level annotations. Experiments on three public databases show that when using as few as one voxel-level labeled sample, the performance of GASNet is comparable to fully-supervised segmentation algorithms trained on dozens of voxel-level labeled samples.",178,COVID-19,,,Other Topics,,,,,,External,Segmentation-only,CT
2010.12967,,Yes,,,2020,2020-10-24,Preprint,arXiv,0,automated triage of covid-19 from various lung abnormalities using chest ct features,"The outbreak of COVID-19 has lead to a global effort to decelerate the pandemic spread. For this purpose chest computed-tomography (CT) based screening and diagnosis of COVID-19 suspected patients is utilized, either as a support or replacement to reverse transcription-polymerase chain reaction (RT-PCR) test. In this paper, we propose a fully automated AI based system that takes as input chest CT scans and triages COVID-19 cases. More specifically, we produce multiple descriptive features, including lung and infections statistics, texture, shape and location, to train a machine learning based classifier that distinguishes between COVID-19 and other lung abnormalities (including community acquired pneumonia). We evaluated our system on a dataset of 2191 CT cases and demonstrated a robust solution with 90.8% sensitivity at 85.4% specificity with 94.0% ROC-AUC. In addition, we present an elaborated feature analysis and ablation study to explore the importance of each feature.",144,COVID-19;Infections;Pneumonia,,,Disease Outbreaks;Polymerase Chain Reaction;Area under Curve;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,CT
2010.14091,,Yes,,,2020,2020-10-27,Preprint,arXiv,0,triple-view convolutional neural networks for covid-19 diagnosis with chest x-ray,"The Coronavirus Disease 2019 (COVID-19) is affecting increasingly large number of people worldwide, posing significant stress to the health care systems. Early and accurate diagnosis of COVID-19 is critical in screening of infected patients and breaking the person-to-person transmission. Chest X-ray (CXR) based computer-aided diagnosis of COVID-19 using deep learning becomes a promising solution to this end. However, the diverse and various radiographic features of COVID-19 make it challenging, especially when considering each CXR scan typically only generates one single image. Data scarcity is another issue since collecting large-scale medical CXR data set could be difficult at present. Therefore, how to extract more informative and relevant features from the limited samples available becomes essential. To address these issues, unlike traditional methods processing each CXR image from a single view, this paper proposes triple-view convolutional neural networks for COVID-19 diagnosis with CXR images. Specifically, the proposed networks extract individual features from three views of each CXR image, i.e., the left lung view, the right lung view and the overall view, in three streams and then integrate them for joint diagnosis. The proposed network structure respects the anatomical structure of human lungs and is well aligned with clinical diagnosis of COVID-19 in practice. In addition, the labeling of the views does not require experts' domain knowledge, which is needed by many existing methods. The experimental results show that the proposed method achieves state-of-the-art performance, especially in the more challenging three class classification task, and admits wide generality and high flexibility.",248,COVID-19,,,Art;Health Care;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
2010.16043,,Yes,,,2020,2020-10-29,Preprint,arXiv,0,ct-caps: feature extraction-based automated framework for covid-19 disease identification from chest ct scans using capsule networks,"The global outbreak of the novel corona virus (COVID-19) disease has drastically impacted the world and led to one of the most challenging crisis across the globe since World War II. The early diagnosis and isolation of COVID-19 positive cases are considered as crucial steps towards preventing the spread of the disease and flattening the epidemic curve. Chest Computed Tomography (CT) scan is a highly sensitive, rapid, and accurate diagnostic technique that can complement Reverse Transcription Polymerase Chain Reaction (RT-PCR) test. Recently, deep learning-based models, mostly based on Convolutional Neural Networks (CNN), have shown promising diagnostic results. CNNs, however, are incapable of capturing spatial relations between image instances and require large datasets. Capsule Networks, on the other hand, can capture spatial relations, require smaller datasets, and have considerably fewer parameters. In this paper, a Capsule network framework, referred to as the ""CT-CAPS"", is presented to automatically extract distinctive features of chest CT scans. These features, which are extracted from the layer before the final capsule layer, are then leveraged to differentiate COVID-19 from Non-COVID cases. The experiments on our in-house dataset of 307 patients show the state-of-the-art performance with the accuracy of 90.8%, sensitivity of 94.5%, and specificity of 86.0%.",200,COVID-19,,,Art;Disease Outbreaks;Polymerase Chain Reaction;Tomography;Early Diagnosis;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,CT
2011.00631,,Yes,,,2020,2020-11-01,Preprint,arXiv,0,bifurcated autoencoder for segmentation of covid-19 infected regions in ct images,"The new coronavirus infection has shocked the world since early 2020 with its aggressive outbreak. Rapid detection of the disease saves lives, and relying on medical imaging (Computed Tomography and X-ray) to detect infected lungs has shown to be effective. Deep learning and convolutional neural networks have been used for image analysis in this context. However, accurate identification of infected regions has proven challenging for two main reasons. Firstly, the characteristics of infected areas differ in different images. Secondly, insufficient training data makes it challenging to train various machine learning algorithms, including deep-learning models. This paper proposes an approach to segment lung regions infected by COVID-19 to help cardiologists diagnose the disease more accurately, faster, and more manageable. We propose a bifurcated 2-D model for two types of segmentation. This model uses a shared encoder and a bifurcated connection to two separate decoders. One decoder is for segmentation of the healthy region of the lungs, while the other is for the segmentation of the infected regions. Experiments on publically available images show that the bifurcated structure segments infected regions of the lungs better than state of the art.",188,COVID-19;Coronavirus Infections,,,Coronavirus Infections;Art;Algorithms;Disease Outbreaks;Tomography;Lung Diseases,,,,,,External,2. Detection/Diagnosis,CT
2011.01789,,Yes,,,2020,2020-11-10,Preprint,arXiv,0,point of care image analysis for covid-19,"Early detection of COVID-19 is key in containing the pandemic. Disease detection and evaluation based on imaging is fast and cheap and therefore plays an important role in COVID-19 handling. COVID-19 is easier to detect in chest CT, however, it is expensive, non-portable, and difficult to disinfect, making it unfit as a point-of-care (POC) modality. On the other hand, chest X-ray (CXR) and lung ultrasound (LUS) are widely used, yet, COVID-19 findings in these modalities are not always very clear. Here we train deep neural networks to significantly enhance the capability to detect, grade and monitor COVID-19 patients using CXRs and LUS. Collaborating with several hospitals in Israel we collect a large dataset of CXRs and use this dataset to train a neural network obtaining above 90% detection rate for COVID-19. In addition, in collaboration with ULTRa (Ultrasound Laboratory Trento, Italy) and hospitals in Italy we obtained POC ultrasound data with annotations of the severity of disease and trained a deep network for automatic severity grading.",166,COVID-19,,,Other Topics,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,Multimodal
2011.03585,,Yes,,,2021,2021-04-14,Preprint,arXiv,0,chest x-ray image phase features for improved diagnosis of covid-19 using convolutional neural network,"Recently, the outbreak of the novel Coronavirus disease 2019 (COVID-19) pandemic has seriously endangered human health and life. Due to limited availability of test kits, the need for auxiliary diagnostic approach has increased. Recent research has shown radiography of COVID-19 patient, such as CT and X-ray, contains salient information about the COVID-19 virus and could be used as an alternative diagnosis method. Chest X-ray (CXR) due to its faster imaging time, wide availability, low cost and portability gains much attention and becomes very promising. Computational methods with high accuracy and robustness are required for rapid triaging of patients and aiding radiologist in the interpretation of the collected data. In this study, we design a novel multi-feature convolutional neural network (CNN) architecture for multi-class improved classification of COVID-19 from CXR images. CXR images are enhanced using a local phase-based image enhancement method. The enhanced images, together with the original CXR data, are used as an input to our proposed CNN architecture. Using ablation studies, we show the effectiveness of the enhanced images in improving the diagnostic accuracy. We provide quantitative evaluation on two datasets and qualitative results for visual inspection. Quantitative evaluation is performed on data consisting of 8,851 normal (healthy), 6,045 pneumonia, and 3,323 Covid-19 CXR scans. In Dataset-1, our model achieves 95.57\% average accuracy for a three classes classification, 99\% precision, recall, and F1-scores for COVID-19 cases. For Dataset-2, we have obtained 94.44\% average accuracy, and 95\% precision, recall, and F1-scores for detection of COVID-19. Our proposed multi-feature guided CNN achieves improved results compared to single-feature CNN proving the importance of the local phase-based CXR image enhancement (GitHub).",269,COVID-19;COVID-19 Pandemic;Pneumonia,,,Architecture;Disease Outbreaks;Radiologists,,,,,,External,2. Detection/Diagnosis,X-Ray
2011.05186,,Yes,,,2020,2020-11-10,Preprint,arXiv,0,pristine annotations-based multi-modal trained artificial intelligence solution to triage chest x-ray for covid-19,"The COVID-19 pandemic continues to spread and impact the well-being of the global population. The front-line modalities including computed tomography (CT) and X-ray play an important role for triaging COVID patients. Considering the limited access of resources (both hardware and trained personnel) and decontamination considerations, CT may not be ideal for triaging suspected subjects. Artificial intelligence (AI) assisted X-ray based applications for triaging and monitoring require experienced radiologists to identify COVID patients in a timely manner and to further delineate the disease region boundary are seen as a promising solution. Our proposed solution differs from existing solutions by industry and academic communities, and demonstrates a functional AI model to triage by inferencing using a single x-ray image, while the deep-learning model is trained using both X-ray and CT data. We report on how such a multi-modal training improves the solution compared to X-ray only training. The multi-modal solution increases the AUC (AUC) from 0.89 to 0.93 and also positively impacts the Dice coefficient (0.59 to 0.62) for localizing the pathology. To the best our knowledge, it is the first X-ray solution by leveraging multi-modal information for the development.",188,COVID-19;COVID-19 Pandemic,,,Other Topics,,,,,,External,2. Detection/Diagnosis,Multimodal
2011.05746,,Yes,,,2020,2020-11-11,Preprint,arXiv,0,classification of covid-19 in chest ct images using convolutional support vector machines,"Coronavirus 2019 (COVID-19), which emerged in Wuhan, China and affected the whole world, has cost the lives of thousands of people. Manual diagnosis is inefficient due to the rapid spread of this virus. For this reason, automatic COVID-19 detection studies are carried out with the support of artificial intelligence algorithms. In this study, a deep learning model that detects COVID-19 cases with high performance is presented. The proposed method is defined as Convolutional Support Vector Machine (CSVM) and can automatically classify Computed Tomography (CT) images. Unlike the pre-trained Convolutional Neural Networks (CNN) trained with the transfer learning method, the CSVM model is trained as a scratch. To evaluate the performance of the CSVM method, the dataset is divided into two parts as training and testing. The CSVM model consists of blocks containing three different numbers of SVM kernels. When the performance of pre-trained CNN networks and CSVM models is assessed, CSVM (7x7, 3x3, 1x1) model shows the highest performance with 94.03% ACC, 96.09% SEN, 92.01% SPE, 92.19% PRE, 94.10% F1-Score, 88.15% MCC and 88.07% Kappa metric values. The proposed method is more effective than other methods. It has proven in experiments performed to be an inspiration for combating COVID and for future studies.",203,COVID-19,,,Transfer Learning;Algorithms;Tomography,,,,,,External,2. Detection/Diagnosis,CT
2011.11736,,Yes,,,2021,2021-01-08,Preprint,arXiv,0,accurate and rapid diagnosis of covid-19 pneumonia with batch effect removal of chest ct-scans and interpretable artificial intelligence,"COVID-19 is a virus with high transmission rate that demands rapid identification of the infected patients to reduce the spread of the disease. The current gold-standard test, Reverse-Transcription Polymerase Chain Reaction (RT-PCR), has a high rate of false negatives. Diagnosing from CT-scan images as a more accurate alternative has the challenge of distinguishing COVID-19 from other pneumonia diseases. Artificial intelligence can help radiologists and physicians to accelerate the process of diagnosis, increase its accuracy, and measure the severity of the disease. We designed a new interpretable deep neural network to distinguish healthy people, patients with COVID-19, and patients with other pneumonia diseases from axial lung CT-scan images. Our model also detects the infected areas and calculates the percentage of the infected lung volume. We first preprocessed the images to eliminate the batch effects of different devices, and then adopted a weakly supervised method to train the model without having any tags for the infected parts. We trained and evaluated the model on a large dataset of 3359 samples from 6 different medical centers. The model reached sensitivities of 97.75% and 98.15%, and specificities of 87% and 81.03% in separating healthy people from the diseased and COVID-19 from other diseases, respectively. It also demonstrated similar performance for 1435 samples from 6 different medical centers which proves its generalizability. The performance of the model on a large diverse dataset, its generalizability, and interpretability makes it suitable to be used as a reliable diagnostic system.",242,COVID-19;Pneumonia,,,Polymerase Chain Reaction;Reverse Transcription,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,CT
2011.14871,,Yes,,,2020,2020-11-30,Preprint,arXiv,0,vidi: descriptive visual data clustering as radiologist assistant in covid-19 streamline diagnostic,"In the light of the COVID-19 pandemic, deep learning methods have been widely investigated in detecting COVID-19 from chest X-rays. However, a more pragmatic approach to applying AI methods to a medical diagnosis is designing a framework that facilitates human-machine interaction and expert decision making. Studies have shown that categorization can play an essential rule in accelerating real-world decision making. Inspired by descriptive document clustering, we propose a domain-independent explanatory clustering framework to group contextually related instances and support radiologists' decision making. While most descriptive clustering approaches employ domain-specific characteristics to form meaningful clusters, we focus on model-level explanation as a more general-purpose element of every learning process to achieve cluster homogeneity. We employ DeepSHAP to generate homogeneous clusters in terms of disease severity and describe the clusters using favorable and unfavorable saliency maps, which visualize the class discriminating regions of an image. These human-interpretable maps complement radiologist knowledge to investigate the whole cluster at once. Besides, as part of this study, we evaluate a model based on VGG-19, which can identify COVID and pneumonia cases with a positive predictive value of 95% and 97%, respectively, comparable to the recent explainable approaches for COVID diagnosis.",195,COVID-19;COVID-19 Pandemic;Pneumonia,,,Proteins;Other Topics;Map;Cluster Analysis,,,,,,External,2. Detection/Diagnosis,X-Ray
2011.14894,,Yes,,,2020,2020-11-27,Preprint,arXiv,0,uncertainty-driven ensembles of deep architectures for multiclass classification application to covid-19 diagnosis in chest x-ray images,"Respiratory diseases kill million of people each year. Diagnosis of these pathologies is a manual, time-consuming process that has inter and intra-observer variability, delaying diagnosis and treatment. The recent COVID-19 pandemic has demonstrated the need of developing systems to automatize the diagnosis of pneumonia, whilst Convolutional Neural Network (CNNs) have proved to be an excellent option for the automatic classification of medical images. However, given the need of providing a confidence classification in this context it is crucial to quantify the reliability of the model's predictions. In this work, we propose a multi-level ensemble classification system based on a Bayesian Deep Learning approach in order to maximize performance while quantifying the uncertainty of each classification decision. This tool combines the information extracted from different architectures by weighting their results according to the uncertainty of their predictions. Performance of the Bayesian network is evaluated in a real scenario where simultaneously differentiating between four different pathologies: control vs bacterial pneumonia vs viral pneumonia vs COVID-19 pneumonia. A three-level decision tree is employed to divide the 4-class classification into three binary classifications, yielding an accuracy of 98.06% and overcoming the results obtained by recent literature. The reduced preprocessing needed for obtaining this high performance, in addition to the information provided about the reliability of the predictions evidence the applicability of the system to be used as an aid for clinicians.",227,"COVID-19;COVID-19 Pandemic;Pneumonia;Pneumonia, Bacterial;Pneumonia, Viral",,,Pneumonia;Decision Trees,,,,,,External,2. Detection/Diagnosis,X-Ray
2011.14983,,Yes,,,2021,2021-02-02,Preprint,arXiv,0,mavidh score: a covid-19 severity scoring using chest x-ray pathology features,"The application of computer vision for COVID-19 diagnosis is complex and challenging, given the risks associated with patient misclassifications. Arguably, the primary value of medical imaging for COVID-19 lies rather on patient prognosis. Radiological images can guide physicians assessing the severity of the disease, and a series of images from the same patient at different stages can help to gauge disease progression. Hence, a simple method based on lung-pathology interpretable features for scoring disease severity from Chest X-rays is proposed here. As the primary contribution, this method correlates well to patient severity in different stages of disease progression with competitive results compared to other existing, more complex methods. An original data selection approach is also proposed, allowing the simple model to learn the severity-related features. It is hypothesized that the resulting competitive performance presented here is related to the method being feature-based rather than reliant on lung involvement or opacity as others in the literature. A second contribution comes from the validation of the results, conceptualized as the scoring of patients groups from different stages of the disease. Besides performing such validation on an independent data set, the results were also compared with other proposed scoring methods in the literature. The results show that there is a significant correlation between the scoring system (MAVIDH) and patient outcome, which could potentially help physicians rating and following disease progression in COVID-19 patients.",230,COVID-19;Disease Progression,,,Other Topics,,,,,,External,3. Monitoring/Severity assessment,X-Ray
2012.01473,,Yes,,,2020,2020-12-02,Preprint,arXiv,0,covsegnet: a multi encoder-decoder architecture for improved lesion segmentation of covid-19 chest ct scans,"Automatic lung lesions segmentation of chest CT scans is considered a pivotal stage towards accurate diagnosis and severity measurement of COVID-19. Traditional U-shaped encoder-decoder architecture and its variants suffer from diminutions of contextual information in pooling/upsampling operations with increased semantic gaps among encoded and decoded feature maps as well as instigate vanishing gradient problems for its sequential gradient propagation that result in sub-optimal performance. Moreover, operating with 3D CT-volume poses further limitations due to the exponential increase of computational complexity making the optimization difficult. In this paper, an automated COVID-19 lesion segmentation scheme is proposed utilizing a highly efficient neural network architecture, namely CovSegNet, to overcome these limitations. Additionally, a two-phase training scheme is introduced where a deeper 2D-network is employed for generating ROI-enhanced CT-volume followed by a shallower 3D-network for further enhancement with more contextual information without increasing computational burden. Along with the traditional vertical expansion of Unet, we have introduced horizontal expansion with multi-stage encoder-decoder modules for achieving optimum performance. Additionally, multi-scale feature maps are integrated into the scale transition process to overcome the loss of contextual information. Moreover, a multi-scale fusion module is introduced with a pyramid fusion scheme to reduce the semantic gaps between subsequent encoder/decoder modules while facilitating the parallel optimization for efficient gradient propagation. Outstanding performances have been achieved in three publicly available datasets that largely outperform other state-of-the-art approaches. The proposed scheme can be easily extended for achieving optimum segmentation performances in a wide variety of applications.",244,COVID-19,,,Art;Architecture;Semantics;Tomography;Map;Cone-Beam Computed Tomography,,,,,,Self-recorded/clinical,Segmentation-only,CT
2012.05073,,Yes,,,2020,2020-12-17,Preprint,arXiv,0,covid-19 detection in chest x-ray images using a new channel boosted cnn,"COVID-19 is a highly contagious respiratory infection that has affected a large population across the world and continues with its devastating consequences. It is imperative to detect COVID-19 at the earliest to limit the span of infection. In this work, a new classification technique CB-STM-RENet based on deep Convolutional Neural Network (CNN) and Channel Boosting is proposed for the screening of COVID-19 in chest X-Rays. In this connection, to learn the COVID-19 specific radiographic patterns, a new convolution block based on split-transform-merge (STM) is developed. This new block systematically incorporates region and edge-based operations at each branch to capture the diverse set of features at various levels, especially those related to region homogeneity, textural variations, and boundaries of the infected region. The learning and discrimination capability of the proposed CNN architecture is enhanced by exploiting the Channel Boosting idea that concatenates the auxiliary channels along with the original channels. The auxiliary channels are generated from the pre-trained CNNs using Transfer Learning. The effectiveness of the proposed technique CB-STM-RENet is evaluated on three different datasets of chest X-Rays namely CoV-Healthy-6k, CoV-NonCoV-10k, and CoV-NonCoV-15k. The performance comparison of the proposed CB-STM-RENet with the existing techniques exhibits high performance both in discriminating COVID-19 chest infections from Healthy, as well as, other types of chest infections. CB-STM-RENet provides the highest performance on all these three datasets; especially on the stringent CoV-NonCoV-15k dataset. The good detection rate, and high precision of the proposed technique suggest that it can be adapted for the diagnosis of COVID-19 infected patients.GitHub",252,COVID-19;Infections;Respiratory Tract Infections,,,Transfer Learning;Architecture,,,,,,External,2. Detection/Diagnosis,X-Ray
2012.05525,,Yes,,,2020,2020-12-10,Preprint,arXiv,0,detection of covid-19 patients with convolutional neural network based features on multi-class x-ray chest images,"Covid-19 is a very serious deadly disease that has been announced as a pandemic by the world health organization (WHO). The whole world is working with all its might to end Covid-19 pandemic, which puts countries in serious health and economic problems, as soon as possible. The most important of these is to correctly identify those who get the Covid-19. Methods and approaches to support the reverse transcription polymerase chain reaction (RT-PCR) test have begun to take place in the literature. In this study, chest X-ray images, which can be accessed easily and quickly, were used because the covid-19 attacked the respiratory systems. Classification performances with support vector machines have been obtained by using the features extracted with residual networks (ResNet-50), one of the convolutional neural network models, from these images. While Covid-19 detection is obtained with support vector machines (SVM)-quadratic with the highest sensitivity value of 96.35% with the 5-fold cross-validation method, the highest overall performance value has been detected with both SVM-quadratic and SVM-cubic above 99%. According to these high results, it is thought that this method, which has been studied, will help radiology specialists and reduce the rate of false detection.",194,COVID-19;COVID-19 Pandemic,,,World Health Organization;Polymerase Chain Reaction;Neural Networks;Support Vector Machine;Reverse Transcription,,,,,,External,2. Detection/Diagnosis,X-Ray
2012.09132,,Yes,,,2020,2020-12-24,Preprint,arXiv,0,ensemble-cvdnet: a deep learning based end-to-end classification framework for covid-19 detection using ensembles of networks,"The new type of coronavirus disease (COVID-19), which started in Wuhan, China in December 2019, continues to spread rapidly affecting the whole world. It is essential to have a highly sensitive diagnostic screening tool to detect the disease as early as possible. Currently, chest CT imaging is preferred as the primary screening tool for evaluating the COVID-19 pneumonia by radiological imaging. However, CT imaging requires larger radiation doses, longer exposure time, higher cost, and may suffer from patient movements. X-Ray imaging is a fast, cheap, more patient-friendly and available in almost every healthcare facility. Therefore, we have focused on X-Ray images and developed an end-to-end deep learning model, i.e. Ensemble-CVDNet, to distinguish COVID-19 pneumonia from non-COVID pneumonia and healthy cases in this work. The proposed model is based on a combination of three lightweight pre-trained models SqueezeNet, ShuffleNet, and EfficientNet-B0 at different depths, and combines feature maps in different abstraction levels. In the proposed end to-end model, networks are used as feature extractors in parallel after fine-tuning, and some additional layers are used at the top of them. The proposed model is evaluated in the COVID-19 Radiography Database, a public data set consisting of 219 COVID-19, 1341 Healthy, and 1345 Viral Pneumonia chest X-Ray images. Experimental results show that our lightweight Ensemble-CVDNet model provides 98.30% accuracy, 97.78% sensitivity, and 97.61% F1 score using only 5.62M parameters. Moreover, it takes about 10ms to process and predict an X-Ray image using the proposed method using a mid level GPU. We believe that the method proposed in this study can be a helpful diagnostic screening tool for radiologists in the early diagnosis of the disease.",272,"COVID-19;Pneumonia;Pneumonia, Viral",,,Health Care;Health;Early Diagnosis;Map,,,,,,External,2. Detection/Diagnosis,X-Ray
2012.10787,,Yes,,,2021,2021-02-12,Preprint,arXiv,0,constructing and evaluating an explainable model for covid-19 diagnosis from chest x-rays,"In this paper, our focus is on constructing models to assist a clinician in the diagnosis of COVID-19 patients in situations where it is easier and cheaper to obtain X-ray data than to obtain high-quality images like those from CT scans. Deep neural networks have repeatedly been shown to be capable of constructing highly predictive models for disease detection directly from image data. However, their use in assisting clinicians has repeatedly hit a stumbling block due to their black-box nature. Some of this difficulty can be alleviated if predictions were accompanied by explanations expressed in clinically relevant terms. In this paper, deep neural networks are used to extract domain-specific features(morphological features like ground-glass opacity and disease indications like pneumonia) directly from the image data. Predictions about these features are then used to construct a symbolic model (a decision tree) for the diagnosis of COVID-19 from chest X-rays, accompanied with two kinds of explanations: visual (saliency maps, derived from the neural stage), and textual (logical descriptions, derived from the symbolic stage). A radiologist rates the usefulness of the visual and textual explanations. Our results demonstrate that neural models can be employed usefully in identifying domain-specific features from low-level image data; that textual explanations in terms of clinically relevant features may be useful; and that visual explanations will need to be clinically meaningful to be useful.",224,COVID-19;Pneumonia,,,Pneumonia;Other Topics;Decision Trees;Map,,,,,,External,2. Detection/Diagnosis,X-Ray
2012.14106,,Yes,,,2020,2020-12-28,Preprint,arXiv,0,diagnosis/prognosis of covid-19 images: challenges opportunities and applications,"The novel Coronavirus disease, COVID-19, has rapidly and abruptly changed the world as we knew in 2020. It becomes the most unprecedent challenge to analytic epidemiology in general and signal processing theories in specific. Given its high contingency nature and adverse effects across the world, it is important to develop efficient processing/learning models to overcome this pandemic and be prepared for potential future ones. In this regard, medical imaging plays an important role for the management of COVID-19. Human-centered interpretation of medical images is, however, tedious and can be subjective. This has resulted in a surge of interest to develop Radiomics models for analysis and interpretation of medical images. Signal Processing (SP) and Deep Learning (DL) models can assist in development of robust Radiomics solutions for diagnosis/prognosis, severity assessment, treatment response, and monitoring of COVID-19 patients. In this article, we aim to present an overview of the current state, challenges, and opportunities of developing SP/DL-empowered models for diagnosis (screening/monitoring) and prognosis (outcome prediction and severity assessment) of COVID-19 infection. More specifically, the article starts by elaborating the latest development on the theoretical framework of analytic epidemiology and hypersignal processing for COVID-19. Afterwards, imaging modalities and Radiological characteristics of COVID-19 are discussed. SL/DL-based Radiomic models specific to the analysis of COVID-19 infection are then described covering the following four domains: Segmentation of COVID-19 lesions; Predictive models for outcome prediction; Severity assessment, and; Diagnosis/classification models. Finally, open problems and opportunities are presented in detail.",242,COVID-19;Infections,,,Other Topics,,,,,,,Review,Multimodal
2012.14204,,Yes,,,2020,2020-12-29,Preprint,arXiv,0,screening covid-19 based on ct/cxr images and building a publicly available ct-scan dataset of covid-19,"The rapid outbreak of COVID-19 threatens humans life all around the world. Due to insufficient diagnostic infrastructures, developing an accurate, efficient, inexpensive, and quick diagnostic tool is of great importance. As chest radiography, such as chest X-ray (CXR) and CT computed tomography (CT), is a possible way for screening COVID-19, developing an automatic image classification tool is immensely helpful for detecting the patients with COVID-19. To date, researchers have proposed several different screening methods; however, none of them could achieve a reliable and highly sensitive performance yet. The main drawbacks of current methods are the lack of having enough training data, low generalization performance, and a high rate of false-positive detection. To tackle such limitations, this study firstly builds a large-size publicly available CT-scan dataset, consisting of more than 13k CT-images of more than 1000 individuals, in which 8k images are taken from 500 patients infected with COVID-19. Secondly, we propose a deep learning model for screening COVID-19 using our proposed CT dataset and report the baseline results. Finally, we extend the proposed CT model for screening COVID-19 from CXR images using a transfer learning approach. The experimental results show that the proposed CT and CXR methods achieve the AUC scores of 0.886 and 0.984 respectively.",206,COVID-19,,,Transfer Learning;Research Personnel;Disease Outbreaks;Tomography;Area under Curve,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,CT
2012.15442,,Yes,,,2020,2020-12-30,Preprint,arXiv,0,survey of the detection and classification of pulmonary lesions via ct and x-ray,"In recent years, the prevalence of several pulmonary diseases, especially the coronavirus disease 2019 (COVID-19) pandemic, has attracted worldwide attention. These diseases can be effectively diagnosed and treated with the help of lung imaging. With the development of deep learning technology and the emergence of many public medical image datasets, the diagnosis of lung diseases via medical imaging has been further improved. This article reviews pulmonary CT and X-ray image detection and classification in the last decade. It also provides an overview of the detection of lung nodules, pneumonia, and other common lung lesions based on the imaging characteristics of various lesions. Furthermore, this review introduces 26 commonly used public medical image datasets, summarizes the latest technology, and discusses current challenges and future research directions.",125,COVID-19;COVID-19 Pandemic;Lung Diseases;Pneumonia,,,Other Topics,,,,,,,Review,Multimodal
202303.0208,10.20944/preprints202303.0208.v1,Yes,,,2023,2023-03-13,Preprint,Preprints.org,0,efficient lung ultrasound classification,"A machine learning method for classifying Lung UltraSound is here proposed to pro-_x000D_ vide a point of care tool for supporting a safe, fast and accurate diagnosis, that can also be useful during a pandemic like as SARS-CoV-2. Given the advantages (e.g. safety, rapidity, portability, cost-effectiveness) provided by the ultrasound technology over other methods (e.g. X-ray, computer tomography, magnetic resonance imaging), our method was validated on the largest LUS public dataset. Focusing on both accuracy and efficiency, our solution is based on an efficient adaptive ensembling of two EfficientNet-b0 models reaching 100% of accuracy, which, to our knowledge, outperforms the previous state-of-the-art. The complexity of this solution keeps the number of parameters in the same order as an EfficientNet-b0 by adopting specific design choices that are adaptive ensembling with a combination layer, ensembling performed on the deep features, minimal ensemble only two weak models. Moreover, a visual analysis of the saliency maps on sample images of all the classes of the dataset reveals where the focus is on an inaccurate weak model versus an accurate model.",176,,,,Magnetic Resonance Imaging;Art;Pneumonia;Lung;Classification;Tomography;Other Topics;Map,,,,,,External,2. Detection/Diagnosis,Ultrasound
2101.04909,,Yes,,,2021,2021-01-24,Preprint,arXiv,0,covid-19 prognosis via self-supervised representation learning and multi-image prediction,"The rapid spread of COVID-19 cases in recent months has strained hospital resources, making rapid and accurate triage of patients presenting to emergency departments a necessity. Machine learning techniques using clinical data such as chest X-rays have been used to predict which patients are most at risk of deterioration. We consider the task of predicting two types of patient deterioration based on chest X-rays: adverse event deterioration (i.e., transfer to the intensive care unit, intubation, or mortality) and increased oxygen requirements beyond 6 L per day. Due to the relative scarcity of COVID-19 patient data, existing solutions leverage supervised pretraining on related non-COVID images, but this is limited by the differences between the pretraining data and the target COVID-19 patient data. In this paper, we use self-supervised learning based on the momentum contrast (MoCo) method in the pretraining phase to learn more general image representations to use for downstream tasks. We present three results. The first is deterioration prediction from a single image, where our model achieves an AUC of 0.742 for predicting an adverse event within 96 hours (compared to 0.703 with supervised pretraining) and an AUC of 0.765 for predicting oxygen requirements greater than 6 L a day at 24 hours (compared to 0.749 with supervised pretraining). We then propose a new transformer-based architecture that can process sequences of multiple images for prediction and show that this model can achieve an improved AUC of 0.786 for predicting an adverse event at 96 hours and an AUC of 0.848 for predicting mortalities at 96 hours. A small pilot clinical study suggested that the prediction accuracy of our model is comparable to that of experienced radiologists analyzing the same information.",280,COVID-19,,,Other Topics,,,,,,External,4. Prognosis/Treatment,X-Ray
2104.01509,,Yes,,,2021,2021-04-11,Preprint,arXiv,0,detection of covid-19 disease using deep neural networks with ultrasound imaging,"The new coronavirus 2019 (COVID-2019) has rapidly become a pandemic and has had a devastating effect on both everyday life, public health and the global economy. It is critical to detect positive cases as early as possible to prevent the further spread of this epidemic and to treat affected patients quickly. The need for auxiliary diagnostic tools has increased as accurate automated tool kits are not available. This paper presents a work in progress that proposes the analysis of images of lung ultrasound scans using a convolutional neural network. The trained model will be used on a Raspberry Pi to predict on new images.",104,COVID-19,,,Ultrasonography;Other Topics,,,,,,,2. Detection/Diagnosis,Ultrasound
2105.09913,,Yes,,,2021,2021-05-20,Preprint,arXiv,0,pocformer: a lightweight transformer architecture for detection of covid-19 using point of care ultrasound,"The rapid and seemingly endless expansion of COVID-19 can be traced back to the inefficiency and shortage of testing kits that offer accurate results in a timely manner. An emerging popular technique, which adopts improvements made in mobile ultrasound technology, allows for healthcare professionals to conduct rapid screenings on a large scale. We present an image-based solution that aims at automating the testing process which allows for rapid mass testing to be conducted with or without a trained medical professional that can be applied to rural environments and third world countries. Our contributions towards rapid large-scale testing include a novel deep learning architecture capable of analyzing ultrasound data that can run in real-time and significantly improve the current state-of-the-art detection accuracies using image-based COVID-19 detection.",125,COVID-19,,,Art;Health Care;Architecture;Other Topics,,,,,,,2. Detection/Diagnosis,Ultrasound
2105.11241,,Yes,,,2021,2021-05-20,Preprint,arXiv,0,generation of covid-19 chest ct scan images using generative adversarial networks,"SARS-CoV-2, also known as COVID-19 or Coronavirus, is a viral contagious disease that is infected by a novel coronavirus, and has been rapidly spreading across the globe. It is very important to test and isolate people to reduce spread, and from here comes the need to do this quickly and efficiently. According to some studies, Chest-CT outperforms RT-PCR lab testing, which is the current standard, when diagnosing COVID-19 patients. Due to this, computer vision researchers have developed various deep learning systems that can predict COVID-19 using a Chest-CT scan correctly to a certain degree. The accuracy of these systems is limited since deep learning neural networks such as CNNs (Convolutional Neural Networks) need a significantly large quantity of data for training in order to produce good quality results. Since the disease is relatively recent and more focus has been on CXR (Chest XRay) images, the available chest CT Scan image dataset is much less. We propose a method, by utilizing GANs, to generate synthetic chest CT images of both positive and negative COVID-19 patients. Using a pre-built predictive model, we concluded that around 40% of the generated images are correctly predicted as COVID-19 positive. The dataset thus generated can be used to train a CNN-based classifier which can help determine COVID-19 in a patient with greater accuracy.",217,COVID-19,,,Research Personnel;Polymerase Chain Reaction,,,,,,External,5. Post-hoc,CT
2106.06980,,Yes,,,2021,2021-06-13,Preprint,arXiv,0,an approach towards physics informed lung ultrasound image scoring neural network for diagnostic assistance in covid-19,"Ultrasound is fast becoming an inevitable diagnostic tool for regular and continuous monitoring of the lung with the recent outbreak of COVID-19. In this work, a novel approach is presented to extract acoustic propagation-based features to automatically highlight the region below pleura, which is an important landmark in lung ultrasound (LUS). Subsequently, a multichannel input formed by using the acoustic physics-based feature maps is fused to train a neural network, referred to as LUSNet, to classify the LUS images into five classes of varying severity of lung infection to track the progression of COVID-19. In order to ensure that the proposed approach is agnostic to the type of acquisition, the LUSNet, which consists of a U-net architecture is trained in an unsupervised manner with the acoustic feature maps to ensure that the encoder-decoder architecture is learning features in the pleural region of interest. A novel combination of the U-net output and the U-net encoder output is employed for the classification of severity of infection in the lung. A detailed analysis of the proposed approach on LUS images over the infection to full recovery period of ten confirmed COVID-19 subjects shows an average five-fold cross-validation accuracy, sensitivity, and specificity of 97%, 93%, and 98% respectively over 5000 frames of COVID-19 videos. The analysis also shows that, when the input dataset is limited and diverse as in the case of COVID-19 pandemic, an aided effort of combining acoustic propagation-based features along with the gray scale images, as proposed in this work, improves the performance of the neural network significantly and also aids the labelling and triaging process.",265,COVID-19;COVID-19 Pandemic;Infections,,,Specificity;Architecture;Disease Outbreaks;Lung Diseases;Map,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
2106.09759,,Yes,,,2021,2021-06-17,Preprint,arXiv,0,synthetic covid-19 chest x-ray dataset for computer-aided diagnosis,"We introduce a new dataset called Synthetic COVID-19 Chest X-ray Dataset for training machine learning models. The dataset consists of 21,295 synthetic COVID-19 chest X-ray images to be used for computer-aided diagnosis. These images, generated via an unsupervised domain adaptation approach, are of high quality. We find that the synthetic images not only improve performance of various deep learning architectures when used as additional training data under heavy imbalance conditions, but also detect the target class with high confidence. We also find that comparable performance can also be achieved when trained only on synthetic images. Further, salient features of the synthetic COVID-19 images indicate that the distribution is significantly different from Non-COVID-19 classes, enabling a proper decision boundary. We hope the availability of such high fidelity chest X-ray images of COVID-19 will encourage advances in the development of diagnostic and/or management tools.",142,COVID-19,,,Other Topics,,,,,,Self-recorded/clinical,5. Post-hoc,X-Ray
2106.10651,,Yes,,,2021,2021-06-20,Preprint,arXiv,0,implementing a detection system for covid-19 based on lung ultrasound imaging and deep learning,"The COVID-19 pandemic started in China in December 2019 and quickly spread to several countries. The consequences of this pandemic are incalculable, causing the death of millions of people and damaging the global economy. To achieve large-scale control of this pandemic, fast tools for detection and treatment of patients are needed. Thus, the demand for alternative tools for the diagnosis of COVID-19 has increased dramatically since accurated and automated tools are not available. In this paper we present the ongoing work on a system for COVID-19 detection using ultrasound imaging and using Deep Learning techniques. Furthermore, such a system is implemented on a Raspberry Pi to make it portable and easy to use in remote regions without an Internet connection.",120,COVID-19;COVID-19 Pandemic;Death,,,Ultrasonography;Other Topics,,,,,,,2. Detection/Diagnosis,Ultrasound
2108.03131,,Yes,,,2021,2021-08-05,Preprint,arXiv,0,covid-net us: a tailored highly efficient self-attention deep convolutional neural network design for detection of covid-19 patient cases from point-of-care ultrasound imaging,"The Coronavirus Disease 2019 (COVID-19) pandemic has impacted many aspects of life globally, and a critical factor in mitigating its effects is screening individuals for infections, thereby allowing for both proper treatment for those individuals as well as action to be taken to prevent further spread of the virus. Point-of-care ultrasound (POCUS) imaging has been proposed as a screening tool as it is a much cheaper and easier to apply imaging modality than others that are traditionally used for pulmonary examinations, namely chest x-ray and computed tomography. Given the scarcity of expert radiologists for interpreting POCUS examinations in many highly affected regions around the world, low-cost deep learning-driven clinical decision support solutions can have a large impact during the on-going pandemic. Motivated by this, we introduce COVID-Net US, a highly efficient, self-attention deep convolutional neural network design tailored for COVID-19 screening from lung POCUS images. Experimental results show that the proposed COVID-Net US can achieve an AUC of over 0.98 while achieving 353X lower architectural complexity, 62X lower computational complexity, and 14.3X faster inference times on a Raspberry Pi. Clinical validation was also conducted, where select cases were reviewed and reported on by a practicing clinician (20 years of clinical practice) specializing in intensive care (ICU) and 15 years of expertise in POCUS interpretation. To advocate affordable healthcare and artificial intelligence for resource-constrained environments, we have made COVID-Net US open source and publicly available as part of the COVID-Net open source initiative.",242,COVID-19;COVID-19 Pandemic;Infections,,,Health Care;Point-of-Care Systems;Ultrasonography;Tomography;Area under Curve,,,,,,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
2108.03138,,Yes,,,2021,2021-08-06,Preprint,arXiv,0,lung ultrasound segmentation and adaptation between covid-19 and community-acquired pneumonia,"Lung ultrasound imaging has been shown effective in detecting typical patterns for interstitial pneumonia, as a point-of-care tool for both patients with COVID-19 and other community-acquired pneumonia (CAP). In this work, we focus on the hyperechoic B-line segmentation task. Using deep neural networks, we automatically outline the regions that are indicative of pathology-sensitive artifacts and their associated sonographic patterns. With a real-world data-scarce scenario, we investigate approaches to utilize both COVID-19 and CAP lung ultrasound data to train the networks; comparing fine-tuning and unsupervised domain adaptation. Segmenting either type of lung condition at inference may support a range of clinical applications during evolving epidemic stages, but also demonstrates value in resource-constrained clinical scenarios. Adapting real clinical data acquired from COVID-19 patients to those from CAP patients significantly improved Dice scores from 0.60 to 0.87 (p < 0.001) and from 0.43 to 0.71 (p < 0.001), on independent COVID-19 and CAP test cases, respectively. It is of practical value that the improvement was demonstrated with only a small amount of data in both training and adaptation data sets, a common constraint for deploying machine learning models in clinical practice. Interestingly, we also report that the inverse adaptation, from labelled CAP data to unlabeled COVID-19 data, did not demonstrate an improvement when tested on either condition. Furthermore, we offer a possible explanation that correlates the segmentation performance to label consistency and data domain diversity in this point-of-care lung ultrasound application.",238,"COVID-19;Pneumonia;Pneumonia, Interstitial",,,Point-of-Care Systems;Ultrasonography,,,,,,Self-recorded/clinical,Segmentation-only,Ultrasound
2108.08895,,Yes,,,2021,2021-08-25,Preprint,arXiv,0,segmentation of lungs covid infected regions by attention mechanism and synthetic data,"Coronavirus has caused hundreds of thousands of deaths. Fatalities could decrease if every patient could get suitable treatment by the healthcare system. Machine learning, especially computer vision methods based on deep learning, can help healthcare professionals diagnose and treat COVID-19 infected cases more efficiently. Hence, infected patients can get better service from the healthcare system and decrease the number of deaths caused by the coronavirus. This research proposes a method for segmenting infected lung regions in a CT image. For this purpose, a convolutional neural network with an attention mechanism is used to detect infected areas with complex patterns. Attention blocks improve the segmentation accuracy by focusing on informative parts of the image. Furthermore, a generative adversarial network generates synthetic images for data augmentation and expansion of small available datasets. Experimental results show the superiority of the proposed method compared to some existing procedures.",144,COVID-19;Death,,,Health Care;Other Topics,,,,,,External,Segmentation-only,CT
2109.03793,,Yes,,,2021,2021-09-08,Preprint,arXiv,0,adaptive few-shot learning poc ultrasound covid-19 diagnostic system,"This paper presents a novel ultrasound imaging point-of-care (PoC) COVID-19 diagnostic system. The adaptive visual diagnostics utilize few-shot learning (FSL) to generate encoded disease state models that are stored and classified using a dictionary of knowns. The novel vocabulary based feature processing of the pipeline adapts the knowledge of a pretrained deep neural network to compress the ultrasound images into discrimative descriptions. The computational efficiency of the FSL approach enables high diagnostic deep learning performance in PoC settings, where training data is limited and the annotation process is not strictly controlled. The algorithm performance is evaluated on the open source COVID-19 POCUS Dataset to validate the system's ability to distinguish COVID-19, pneumonia, and healthy disease states. The results of the empirical analyses demonstrate the appropriate efficiency and accuracy for scalable PoC use. The code for this work will be made publicly available on GitHub upon acceptance.",146,COVID-19;Pneumonia,,,Point-of-Care Systems;Ultrasonography,,,,,,External,2. Detection/Diagnosis,Ultrasound
2109.06486,,Yes,,,2021,2021-09-14,Preprint,arXiv,0,conditional synthetic data generation for robust machine learning applications with limited pandemic data,"At the onset of a pandemic, such as COVID-19, data with proper labeling/attributes corresponding to the new disease might be unavailable or sparse. Machine Learning (ML) models trained with the available data, which is limited in quantity and poor in diversity, will often be biased and inaccurate. At the same time, ML algorithms designed to fight pandemics must have good performance and be developed in a time-sensitive manner. To tackle the challenges of limited data, and label scarcity in the available data, we propose generating conditional synthetic data, to be used alongside real data for developing robust ML models. We present a hybrid model consisting of a conditional generative flow and a classifier for conditional synthetic data generation. The classifier decouples the feature representation for the condition, which is fed to the flow to extract the local noise. We generate synthetic data by manipulating the local noise with fixed conditional feature representation. We also propose a semi-supervised approach to generate synthetic samples in the absence of labels for a majority of the available data. We performed conditional synthetic generation for chest computed tomography (CT) scans corresponding to normal, COVID-19, and pneumonia afflicted patients. We show that our method significantly outperforms existing models both on qualitative and quantitative performance, and our semi-supervised approach can efficiently synthesize conditional samples under label scarcity. As an example of downstream use of synthetic data, we show improvement in COVID-19 detection from CT scans with conditional synthetic data augmentation.",243,COVID-19;Pneumonia,,,Noise;Tomography,,,,,,External,5. Post-hoc,CT
2111.00116,,Yes,,,2021,2021-11-01,Preprint,arXiv,0,visual explanations for convolutional neural networks via latent traversal of generative adversarial networks,"Lack of explainability in artificial intelligence, specifically deep neural networks, remains a bottleneck for implementing models in practice. Popular techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM) provide a coarse map of salient features in an image, which rarely tells the whole story of what a convolutional neural network (CNN) learned. Using COVID-19 chest X-rays, we present a method for interpreting what a CNN has learned by utilizing Generative Adversarial Networks (GANs). Our GAN framework disentangles lung structure from COVID-19 features. Using this GAN, we can visualize the transition of a pair of COVID negative lungs in a chest radiograph to a COVID positive pair by interpolating in the latent space of the GAN, which provides fine-grained visualization of how the CNN responds to varying features within the lungs.",129,COVID-19,,,Other Topics;Map,,,,,,External,5. Post-hoc,X-Ray
2201.07357,,Yes,,,2022,2022-01-18,Preprint,arXiv,0,weakly supervised contrastive learning for better severity scoring of lung ultrasound,"With the onset of the COVID-19 pandemic, ultrasound has emerged as an effective tool for bedside monitoring of patients. Due to this, a large amount of lung ultrasound scans have been made available which can be used for AI based diagnosis and analysis. Several AI-based patient severity scoring models have been proposed that rely on scoring the appearance of the ultrasound scans. AI models are trained using ultrasound-appearance severity scores that are manually labeled based on standardized visual features. We address the challenge of labeling every ultrasound frame in the video clips. Our contrastive learning method treats the video clip severity labels as noisy weak severity labels for individual frames, thus requiring only video-level labels. We show that it performs better than the conventional cross-entropy loss based training. We combine frame severity predictions to come up with video severity predictions and show that the frame based model achieves comparable performance to a video based TSM model, on a large dataset combining public and private sources.",165,COVID-19 Pandemic,,,Other Topics;Entropy,,,,,,External,3. Monitoring/Severity assessment,Ultrasound
2202.10185,,Yes,,,2022,2022-05-30,Preprint,arXiv,0,osegnet: operational segmentation network for covid-19 detection using chest x-ray images,"Coronavirus disease 2019 (COVID-19) has been diagnosed automatically using Machine Learning algorithms over chest X-ray (CXR) images. However, most of the earlier studies used Deep Learning models over scarce datasets bearing the risk of overfitting. Additionally, previous studies have revealed the fact that deep networks are not reliable for classification since their decisions may originate from irrelevant areas on the CXRs. Therefore, in this study, we propose Operational Segmentation Network (OSegNet) that performs detection by segmenting COVID-19 pneumonia for a reliable diagnosis. To address the data scarcity encountered in training and especially in evaluation, this study extends the largest COVID-19 CXR dataset: QaTa-COV19 with 121,378 CXRs including 9258 COVID-19 samples with their corresponding ground-truth segmentation masks that are publicly shared with the research community. Consequently, OSegNet has achieved a detection performance with the highest accuracy of 99.65% among the state-of-the-art deep models with 98.09% precision.",145,COVID-19;Pneumonia,,,Art;Algorithms;Masks,,,,,,External,2. Detection/Diagnosis,X-Ray
2203.06338,,Yes,,,2022,2022-08-31,Preprint,arXiv,0,auto-fedrl: federated hyperparameter optimization for multi-institutional medical image segmentation,"Federated learning (FL) is a distributed machine learning technique that enables collaborative model training while avoiding explicit data sharing. The inherent privacy-preserving property of FL algorithms makes them especially attractive to the medical field. However, in case of heterogeneous client data distributions, standard FL methods are unstable and require intensive hyperparameter tuning to achieve optimal performance. Conventional hyperparameter optimization algorithms are impractical in real-world FL applications as they involve numerous training trials, which are often not affordable with limited compute budgets. In this work, we propose an efficient reinforcement learning (RL)-based federated hyperparameter optimization algorithm, termed Auto-FedRL, in which an online RL agent can dynamically adjust hyperparameters of each client based on the current training progress. Extensive experiments are conducted to investigate different search strategies and RL agents. The effectiveness of the proposed method is validated on a heterogeneous data split of the CIFAR-10 dataset as well as two real-world medical image segmentation datasets for COVID-19 lesion segmentation in chest CT and pancreas segmentation in abdominal CT.",167,COVID-19,,,Other Topics,,,,,,External,Segmentation-only,CT
2204.02839,,Yes,,,2022,2022-04-06,Preprint,arXiv,0,ccat-net: a novel transformer based semi-supervised framework for covid-19 lung lesion segmentation,"The spread of the novel coronavirus disease 2019 (COVID-19) has claimed millions of lives. Automatic segmentation of lesions from CT images can assist doctors with screening, treatment, and monitoring. However, accurate segmentation of lesions from CT images can be very challenging due to data and model limitations. Recently, Transformer-based networks have attracted a lot of attention in the area of computer vision, as Transformer outperforms CNN at a bunch of tasks. In this work, we propose a novel network structure that combines CNN and Transformer for the segmentation of COVID-19 lesions. We further propose an efficient semi-supervised learning framework to address the shortage of labeled data. Extensive experiments showed that our proposed network outperforms most existing networks and the semi-supervised learning framework can outperform the base network by 3.0% and 8.2% in terms of Dice coefficient and sensitivity.",138,COVID-19,,,Other Topics,,,,,,External,Segmentation-only,CT
2204.13851,,Yes,,,2022,2022-04-28,Preprint,arXiv,0,covid-net us-x: enhanced deep neural network for detection of covid-19 patient cases from convex ultrasound imaging through extended linear-convex ultrasound augmentation learning,"As the global population continues to face significant negative impact by the on-going COVID-19 pandemic, there has been an increasing usage of point-of-care ultrasound (POCUS) imaging as a low-cost and effective imaging modality of choice in the COVID-19 clinical workflow. A major barrier with widespread adoption of POCUS in the COVID-19 clinical workflow is the scarcity of expert clinicians that can interpret POCUS examinations, leading to considerable interest in deep learning-driven clinical decision support systems to tackle this challenge. A major challenge to building deep neural networks for COVID-19 screening using POCUS is the heterogeneity in the types of probes used to capture ultrasound images (e.g., convex vs. linear probes), which can lead to very different visual appearances. In this study, we explore the impact of leveraging extended linear-convex ultrasound augmentation learning on producing enhanced deep neural networks for COVID-19 assessment, where we conduct data augmentation on convex probe data alongside linear probe data that have been transformed to better resemble convex probe data. Experimental results using an efficient deep columnar anti-aliased convolutional neural network designed via a machined-driven design exploration strategy (which we name COVID-Net US-X) show that the proposed extended linear-convex ultrasound augmentation learning significantly increases performance, with a gain of 5.1% in test accuracy and 13.6% in AUC.",211,COVID-19;COVID-19 Pandemic,,,Point-of-Care Systems;Ultrasonography,,,,,,,2. Detection/Diagnosis,Ultrasound
2205.02152,,Yes,,,2022,2022-05-20,Preprint,arXiv,0,evaluating transferability for covid 3d localization using ct sars-cov-2 segmentation models,"Recent studies indicate that detecting radiographic patterns on CT scans can yield high sensitivity and specificity for Covid-19 localization. In this paper, we investigate the appropriateness of deep learning models transferability, for semantic segmentation of pneumonia-infected areas in CT images. Transfer learning allows for the fast initialization/reutilization of detection models, given that large volumes of training data are not available. Our work explores the efficacy of using pre-trained U-Net architectures, on a specific CT data set, for identifying Covid-19 side-effects over images from different datasets. Experimental results indicate improvement in the segmentation accuracy of identifying Covid-19 infected regions.",98,COVID-19;Pneumonia,,,Transfer Learning;Architecture;Semantics;Sensitivity and Specificity,,,,,,External,Segmentation-only,CT
2205.08932,,Yes,,,2022,2022-05-18,Preprint,arXiv,0,covid-net uv: an end-to-end spatio-temporal deep neural network architecture for automated diagnosis of covid-19 infection from ultrasound videos,"Besides vaccination, as an effective way to mitigate the further spread of COVID-19, fast and accurate screening of individuals to test for the disease is yet necessary to ensure public health safety. We propose COVID-Net UV, an end-to-end hybrid spatio-temporal deep neural network architecture, to detect COVID-19 infection from lung point-of-care ultrasound videos captured by convex transducers. COVID-Net UV comprises a convolutional neural network that extracts spatial features and a recurrent neural network that learns temporal dependence. After careful hyperparameter tuning, the network achieves an average accuracy of 94.44% with no false-negative cases for COVID-19 cases. The goal with COVID-Net UV is to assist front-line clinicians in the fight against COVID-19 via accelerating the screening of lung point-of-care ultrasound videos and automatic detection of COVID-19 positive cases.",127,COVID-19;Infections,,,Other Topics,,,,,,,2. Detection/Diagnosis,Ultrasound
2205.09722,,Yes,,,2022,2022-05-19,Preprint,arXiv,0,light in the black: an evaluation of data augmentation techniques for covid-19 ct's semantic segmentation,"With the COVID-19 global pandemic, computer-assisted diagnoses of medical images have gained much attention, and robust methods of Semantic Segmentation of Computed Tomography (CT) became highly desirable. Semantic Segmentation of CT is one of many research fields of automatic detection of COVID-19 and has been widely explored since the COVID-19 outbreak. In this work, we propose an extensive analysis of how different data augmentation techniques improve the training of encoder-decoder neural networks on this problem. Twenty different data augmentation techniques were evaluated on five different datasets. Each dataset was validated through a five-fold cross-validation strategy, thus resulting in over 3,000 experiments. Our findings show that spatial level transformations are the most promising to improve the learning of neural networks on this problem.",122,COVID-19,,,Black Americans;Pandemics;Techniques;Disease Outbreaks;Semantics;Dataset;Other Topics,,,,,,External,5. Post-hoc,CT
2206.10183,,Yes,,,2022,2022-06-21,Preprint,arXiv,0,covecho resource constrained lung ultrasound image analysis tool for faster triaging and active learning,"Lung ultrasound (LUS) is possibly the only medical imaging modality which could be used for continuous and periodic monitoring of the lung. This is extremely useful in tracking the lung manifestations either during the onset of lung infection or to track the effect of vaccination on lung as in pandemics such as COVID-19. There have been many attempts in automating the classification of severity of lung into various classes or automatic segmentation of various LUS landmarks and manifestations. However, all these approaches are based on training static machine learning models which require a significantly clinically annotated large dataset and are computationally heavy and most of the time non-real time. In this work, a real-time light weight active learning-based approach is presented for faster triaging in COVID-19 subjects in resource constrained settings. The tool, based on the you look only once (YOLO) network, has the capability of providing the quality of images based on the identification of various LUS landmarks, artefacts and manifestations, prediction of severity of lung infection, possibility of active learning based on the feedback from clinicians or on the image quality and a summarization of the significant frames which are having high severity of infection and high image quality for further analysis. The results show that the proposed tool has a mean average precision (mAP) of 66% at an Intersection over Union (IoU) threshold of 0.5 for the prediction of LUS landmarks. The 14MB lightweight YOLOv5s network achieves 123 FPS while running in a Quadro P4000 GPU. The tool is available for usage and analysis upon request from the authors.",262,COVID-19;Infections,,,Other Topics,,,,,,External,3. Monitoring/Severity assessment,Ultrasound
2206.13394,,Yes,,,2022,2022-06-20,Preprint,arXiv,0,cs$^2$: a controllable and simultaneous synthesizer of images and annotations with minimal human intervention,"The destitution of image data and corresponding expert annotations limit the training capacities of AI diagnostic models and potentially inhibit their performance. To address such a problem of data and label scarcity, generative models have been developed to augment the training datasets. Previously proposed generative models usually require manually adjusted annotations (e.g., segmentation masks) or need pre-labeling. However, studies have found that these pre-labeling based methods can induce hallucinating artifacts, which might mislead the downstream clinical tasks, while manual adjustment could be onerous and subjective. To avoid manual adjustment and pre-labeling, we propose a novel controllable and simultaneous synthesizer (dubbed CS^2) in this study to generate both realistic images and corresponding annotations at the same time. Our CS^2 model is trained and validated using high resolution CT (HRCT) data collected from COVID-19 patients to realize an efficient infections segmentation with minimal human intervention. Our contributions include 1) a conditional image synthesis network that receives both style information from reference CT images and structural information from unsupervised segmentation masks, and 2) a corresponding segmentation mask synthesis network to automatically segment these synthesized images simultaneously. Our experimental studies on HRCT scans collected from COVID-19 patients demonstrate that our CS^2 model can lead to realistic synthesized datasets and promising segmentation results of COVID infections compared to the state-of-the-art nnUNet trained and fine-tuned in a fully supervised manner.",224,COVID-19;Infections,,,Art;Masks,,,,,,External,5. Post-hoc,CT
2207.02322,,Yes,,,2022,2022-07-05,Preprint,arXiv,0,a deep ensemble learning approach to lung ct segmentation for covid-19 severity assessment,"We present a novel deep learning approach to categorical segmentation of lung CTs of COVID-19 patients. Specifically, we partition the scans into healthy lung tissues, non-lung regions, and two different, yet visually similar, pathological lung tissues, namely, ground-glass opacity and consolidation. This is accomplished via a unique, end-to-end hierarchical network architecture and ensemble learning, which contribute to the segmentation and provide a measure for segmentation uncertainty. The proposed framework achieves competitive results and outstanding generalization capabilities for three COVID-19 datasets. Our method is ranked second in a public Kaggle competition for COVID-19 CT images segmentation. Moreover, segmentation uncertainty regions are shown to correspond to the disagreements between the manual annotations of two different radiologists. Finally, preliminary promising correspondence results are shown for our private dataset when comparing the patients' COVID-19 severity scores (based on clinical measures), and the segmented lung pathologies. Code and data are available at our repository: GitHub",150,COVID-19,,,Other Topics,,,,,,External,Segmentation-only,CT
2207.10998,,Yes,,,2022,2022-07-22,Preprint,arXiv,0,rapid lung ultrasound covid-19 severity scoring with resource-efficient deep feature extraction,"Artificial intelligence-based analysis of lung ultrasound imaging has been demonstrated as an effective technique for rapid diagnostic decision support throughout the COVID-19 pandemic. However, such techniques can require days- or weeks-long training processes and hyper-parameter tuning to develop intelligent deep learning image analysis models. This work focuses on leveraging 'off-the-shelf' pre-trained models as deep feature extractors for scoring disease severity with minimal training time. We propose using pre-trained initializations of existing methods ahead of simple and compact neural networks to reduce reliance on computational capacity. This reduction of computational capacity is of critical importance in time-limited or resource-constrained circumstances, such as the early stages of a pandemic. On a dataset of 49 patients, comprising over 20,000 images, we demonstrate that the use of existing methods as feature extractors results in the effective classification of COVID-19-related pneumonia severity while requiring only minutes of training time. Our methods can achieve an accuracy of over 0.93 on a 4-level severity score scale and provides comparable per-patient region and global scores compared to expert annotated ground truths. These results demonstrate the capability for rapid deployment and use of such minimally-adapted methods for progress monitoring, patient stratification and management in clinical practice for COVID-19 patients, and potentially in other respiratory diseases.",206,COVID-19;COVID-19 Pandemic;Pneumonia;Respiratory Tract Diseases,,,Diagnostic Tests;COVID-19 Testing;Respiratory Tract;Ultrasonography,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
2208.08343,,Yes,,,2022,2022-07-25,Preprint,arXiv,0,transferability limitations for covid 3d localization using sars-cov-2 segmentation models in 4d ct images,"In this paper, we investigate the transferability limitations when using deep learning models, for semantic segmentation of pneumonia-infected areas in CT images. The proposed approach adopts a 4 channel input; 3 channels based on Hounsfield scale, plus one channel (binary) denoting the lung area. We used 3 different, publicly available, CT datasets. If the lung area mask was not available, a deep learning model generates a proxy image. Experimental results suggesting that transferability should be used carefully, when creating Covid segmentation models; retraining the model more than one times in large sets of data results in a decrease in segmentation accuracy.",101,Pneumonia,,,Semantics;Masks,,,,,,External,Segmentation-only,CT
2212.12264,,Yes,,,2022,2022-12-23,Preprint,arXiv,0,collective intelligent strategy for improved segmentation of covid-19 from ct,"The devastation caused by the coronavirus pandemic makes it imperative to design automated techniques for a fast and accurate detection. We propose a novel non-invasive tool, using deep learning and imaging, for delineating COVID-19 infection in lungs. The Ensembling Attention-based Multi-scaled Convolution network (EAMC), employing Leave-One-Patient-Out (LOPO) training, exhibits high sensitivity and precision in outlining infected regions along with assessment of severity. The Attention module combines contextual with local information, at multiple scales, for accurate segmentation. Ensemble learning integrates heterogeneity of decision through different base classifiers. The superiority of EAMC, even with severe class imbalance, is established through comparison with existing state-of-the-art learning models over four publicly-available COVID-19 datasets. The results are suggestive of the relevance of deep learning in providing assistive intelligence to medical practitioners, when they are overburdened with patients as in pandemics. Its clinical significance lies in its unprecedented scope in providing low-cost decision-making for patients lacking specialized healthcare at remote locations.",155,COVID-19;Infections,,,Coronavirus Infections;Art;Health Care,,,,,,External,Segmentation-only,CT
2212.14084,,Yes,,,2022,2022-12-28,Preprint,arXiv,0,multimodal explainability via latent shift applied to covid-19 stratification,"We are witnessing a widespread adoption of artificial intelligence in healthcare. However, most of the advancements in deep learning (DL) in this area consider only unimodal data, neglecting other modalities. Their multimodal interpretation necessary for supporting diagnosis, prognosis and treatment decisions. In this work we present a deep architecture, explainable by design, which jointly learns modality reconstructions and sample classifications using tabular and imaging data. The explanation of the decision taken is computed by applying a latent shift that, simulates a counterfactual prediction revealing the features of each modality that contribute the most to the decision and a quantitative score indicating the modality importance. We validate our approach in the context of COVID-19 pandemic using the AIforCOVID dataset, which contains multimodal data for the early identification of patients at risk of severe outcome. The results show that the proposed method provides meaningful explanations without degrading the classification performance.",148,COVID-19;COVID-19 Pandemic,,,Health Care;Other Topics,,,,,,External,5. Post-hoc,Multimodal
2301.01679,,Yes,,,2023,2023-01-04,Preprint,arXiv,0,covid-net uspro: an open-source explainable few-shot deep prototypical network to monitor and detect covid-19 infection from point-of-care ultrasound images,"As the Coronavirus Disease 2019 (COVID-19) continues to impact many aspects of life and the global healthcare systems, the adoption of rapid and effective screening methods to prevent further spread of the virus and lessen the burden on healthcare providers is a necessity. As a cheap and widely accessible medical image modality, point-of-care ultrasound (POCUS) imaging allows radiologists to identify symptoms and assess severity through visual inspection of the chest ultrasound images. Combined with the recent advancements in computer science, applications of deep learning techniques in medical image analysis have shown promising results, demonstrating that artificial intelligence-based solutions can accelerate the diagnosis of COVID-19 and lower the burden on healthcare professionals. However, the lack of a huge amount of well-annotated data poses a challenge in building effective deep neural networks in the case of novel diseases and pandemics. Motivated by this, we present COVID-Net USPro, an explainable few-shot deep prototypical network, that monitors and detects COVID-19 positive cases with high precision and recall from minimal ultrasound images. COVID-Net USPro achieves 99.65% overall accuracy, 99.7% recall and 99.67% precision for COVID-19 positive cases when trained with only 5 shots. The analytic pipeline and results were verified by our contributing clinician with extensive experience in POCUS interpretation, ensuring that the network makes decisions based on actual patterns.",215,COVID-19;Infections,,,Health Care;Other Topics,,,,,,External,2. Detection/Diagnosis,Ultrasound
2304.09067,,Yes,,,2023,2023-04-18,Preprint,arXiv,0,performance of gan-based augmentation for deep learning covid-19 image classification,"The biggest challenge in the application of deep learning to the medical domain is the availability of training data. Data augmentation is a typical methodology used in machine learning when confronted with a limited data set. In a classical approach image transformations i.e. rotations, cropping and brightness changes are used. In this work, a StyleGAN2-ADA model of Generative Adversarial Networks is trained on the limited COVID-19 chest X-ray image set. After assessing the quality of generated images they are used to increase the training data set improving its balance between classes. We consider the multi-class classification problem of chest X-ray images including the COVID-19 positive class that hasn't been yet thoroughly explored in the literature. Results of transfer learning-based classification of COVID-19 chest X-ray images are presented. The performance of several deep convolutional neural network models is compared. The impact on the detection performance of classical image augmentations i.e. rotations, cropping, and brightness changes are studied. Furthermore, classical image augmentation is compared with GAN-based augmentation. The most accurate model is an EfficientNet-B0 with an accuracy of 90.2 percent, trained on a dataset with a simple class balancing. The GAN augmentation approach is found to be subpar to classical methods for the considered dataset.",203,COVID-19,,,Transfer Learning;Neural Networks;Other Topics,,,,,,External,5. Post-hoc,X-Ray
32305937,10.1109/RBME.2020.2987975,Yes,,32305937.0,2020,2020-04-20,Journal Article;Review,Peer reviewed (PubMed),1,review of artificial intelligence techniques in imaging data acquisition segmentation and diagnosis for covid-19,"The pandemic of coronavirus disease 2019 (COVID-19) is spreading all over the world. Medical imaging such as X-ray and computed tomography (CT) plays an essential role in the global fight against COVID-19, whereas the recently emerging artificial intelligence (AI) technologies further strengthen the power of the imaging tools and help medical specialists. We hereby review the rapid responses in the community of medical imaging (empowered by AI) toward COVID-19. For example, AI-empowered image acquisition can significantly help automate the scanning procedure and also reshape the workflow with minimal contact to patients, providing the best protection to the imaging technicians. Also, AI can improve work efficiency by accurate delineation of infections in X-ray and CT images, facilitating subsequent quantification. Moreover, the computer-aided platforms help radiologists make clinical decisions, i.e., for disease diagnosis, tracking, and prognosis. In this review paper, we thus cover the entire pipeline of medical imaging and analysis techniques involved with COVID-19, including image acquisition, segmentation, diagnosis, and follow-up. We particularly focus on the integration of AI with X-ray and CT, both of which are widely used in the frontline hospitals, in order to depict the latest progress of medical imaging and radiology fighting against COVID-19.",197,COVID-19;Infections,423.0,IEEE Rev Biomed Eng,Other Topics,5.183363305517027e-06,178.6399999999992,8.872711258392516e-06,406.0,0.0,External,Review,Multimodal
32337662,10.1007/s10096-020-03901-z,Yes,PMC7183816,32337662.0,2020,2020-04-28,Journal Article,Peer reviewed (PubMed),1,classification of covid-19 patients from chest ct images using multi-objective differential evolution-based convolutional neural networks,"Early classification of 2019 novel coronavirus disease (COVID-19) is essential for disease cure and control. Compared with reverse-transcription polymerase chain reaction (RT-PCR), chest computed tomography (CT) imaging may be a significantly more trustworthy, useful, and rapid technique to classify and evaluate COVID-19, specifically in the epidemic region. Almost all hospitals have CT imaging machines; therefore, the chest CT images can be utilized for early classification of COVID-19 patients. However, the chest CT-based COVID-19 classification involves a radiology expert and considerable time, which is valuable when COVID-19 infection is growing at rapid rate. Therefore, an automated analysis of chest CT images is desirable to save the medical professionals' precious time. In this paper, a convolutional neural networks (CNN) is used to classify the COVID-19-infected patients as infected (+ve) or not (-ve). Additionally, the initial parameters of CNN are tuned using multi-objective differential evolution (MODE). Extensive experiments are performed by considering the proposed and the competitive machine learning techniques on the chest CT images. Extensive analysis shows that the proposed model can classify the chest CT images at a good accuracy rate.",180,COVID-19;Infections,204.0,Eur J Clin Microbiol Infect Dis,Coronavirus Infections;COVID-19 Testing;Sensitivity and Specificity;Polymerase Chain Reaction;Neural Networks;Paper;Reverse Transcription,8.968990624350209e-06,202.56799999999905,1.3206755156031167e-05,507.0,0.0,External,2. Detection/Diagnosis,CT
32344309,10.1016/j.mehy.2020.109761,Yes,PMC7179515,32344309.0,2020,2020-04-29,Journal Article,Peer reviewed (PubMed),1,covidiagnosis-net: deep bayes-squeezenet based diagnosis of the coronavirus disease 2019 (covid-19) from x-ray images,"The Coronavirus Disease 2019 (COVID-19) outbreak has a tremendous impact on global health and the daily life of people still living in more than two hundred countries. The crucial action to gain the force in the fight of COVID-19 is to have powerful monitoring of the site forming infected patients. Most of the initial tests rely on detecting the genetic material of the coronavirus, and they have a poor detection rate with the time-consuming operation. In the ongoing process, radiological imaging is also preferred where chest X-rays are highlighted in the diagnosis. Early studies express the patients with an abnormality in chest X-rays pointing to the presence of the COVID-19. On this motivation, there are several studies cover the deep learning-based solutions to detect the COVID-19 using chest X-rays. A part of the existing studies use non-public datasets, others perform on complicated Artificial Intelligent (AI) structures. In our study, we demonstrate an AI-based structure to outperform the existing studies. The SqueezeNet that comes forward with its light network design is tuned for the COVID-19 diagnosis with Bayesian optimization additive. Fine-tuned hyperparameters and augmented dataset make the proposed network perform much better than existing network designs and to obtain a higher COVID-19 diagnosis accuracy.",203,COVID-19,241.0,Med Hypotheses,Coronavirus Infections;Disease Outbreaks;Image Processing;Neural Networks;Early Diagnosis,8.258372157436537e-06,210.86399999999915,1.2156169916696058e-05,544.0,0.0,External,2. Detection/Diagnosis,X-Ray
32350794,10.1007/s11547-020-01197-9,Yes,PMC7189175,32350794.0,2020,2020-05-01,Journal Article,Peer reviewed (PubMed),1,use of ct and artificial intelligence in suspected or covid-19 positive patients: statement of the italian society of medical and interventional radiology,"The COVID-19 pandemic started in Italy in February 2020 with an exponential growth that has exceeded the number of cases reported in China. Italian radiology departments found themselves at the forefront in the management of suspected and positive COVID cases, both in diagnosis, in estimating the severity of the disease and in follow-up. In this context SIRM recommends chest X-ray as first-line imaging tool, CT as additional tool that shows typical features of COVID pneumonia, and ultrasound of the lungs as monitoring tool. SIRM recommends, as high priority, to ensure appropriate sanitation procedures on the scan equipment after detecting any suspected or positive COVID-19 patients. In this emergency situation, several expectations have been raised by the scientific community about the role that artificial intelligence can have in improving the diagnosis and treatment of coronavirus infection, and SIRM wishes to deliver clear statements to the radiological community, on the usefulness of artificial intelligence as a radiological decision support system in COVID-19 positive patients. SIRM supports the research on the use of artificial intelligence as a predictive and prognostic decision support system, especially in hospitalized patients and those admitted to intensive care, and welcomes single center of multicenter studies for a clinical validation of the test. SIRM does not support the use of CT with artificial intelligence for screening or as first-line test to diagnose COVID-19. Chest CT with artificial intelligence cannot replace molecular diagnosis tests with nose-pharyngeal swab (rRT-PCR) in suspected for COVID-19 patients.",243,COVID-19;COVID-19 Pandemic;Coronavirus Infections;Pneumonia,78.0,Radiol Med,Coronavirus Infections;Polymerase Chain Reaction,5.660410026657749e-06,96.57599999999974,4.595413392790656e-06,294.0,0.0,,Review,CT
32356760,10.1109/RBME.2020.2990959,Yes,,32356760.0,2020,2020-05-02,Journal Article;Review,Peer reviewed (PubMed),1,the role of imaging in the detection and management of covid-19: a review,"Coronavirus disease 2019 (COVID-19) caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is spreading rapidly around the world, resulting in a massive death toll. Lung infection or pneumonia is the common complication of COVID-19, and imaging techniques, especially computed tomography (CT), have played an important role in diagnosis and treatment assessment of the disease. Herein, we review the imaging characteristics and computing models that have been applied for the management of COVID-19. CT, positron emission tomography - CT (PET/CT), lung ultrasound, and magnetic resonance imaging (MRI) have been used for detection, treatment, and follow-up. The quantitative analysis of imaging data using artificial intelligence (AI) is also explored. Our findings indicate that typical imaging characteristics and their changes can play crucial roles in the detection and management of COVID-19. In addition, AI or other quantitative image analysis methods are urgently needed to maximize the value of imaging in the management of COVID-19.",153,COVID-19;Death;Infections;Pneumonia;Severe Acute Respiratory Syndrome,130.0,IEEE Rev Biomed Eng,Magnetic Resonance Imaging;Pneumonia;Lung;Ultrasonography;Tomography;Review,2.00353834384556e-06,77.87999999999991,3.8549345834660925e-06,173.0,0.0,External,Review,Multimodal
32367319,10.1007/s11547-020-01195-x,Yes,PMC7197034,32367319.0,2020,2020-05-06,Journal Article,Peer reviewed (PubMed),1,artificial intelligence to codify lung ct in covid-19 patients,"The spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has already assumed pandemic proportions, affecting over 100 countries in few weeks. A global response is needed to prepare health systems worldwide. Covid-19 can be diagnosed both on chest X-ray and on computed tomography (CT). Asymptomatic patients may also have lung lesions on imaging. CT investigation in patients with suspicion Covid-19 pneumonia involves the use of the high-resolution technique (HRCT). Artificial intelligence (AI) software has been employed to facilitate CT diagnosis. AI software must be useful categorizing the disease into different severities, integrating the structured report, prepared according to subjective considerations, with quantitative, objective assessments of the extent of the lesions. In this communication, we present an example of a good tool for the radiologist (Thoracic VCAR software, GE Healthcare, Italy) in Covid-19 diagnosis (Pan et al. in Radiology, 2020. ). Thoracic VCAR offers quantitative measurements of the lung involvement. Thoracic VCAR can generate a clear, fast and concise report that communicates vital medical information to referring physicians. In the post-processing phase, software, thanks to the help of a colorimetric map, recognizes the ground glass and differentiates it from consolidation and quantifies them as a percentage with respect to the healthy parenchyma. AI software therefore allows to accurately calculate the volume of each of these areas. Therefore, keeping in mind that CT has high diagnostic sensitivity in identifying lesions, but not specific for Covid-19 and similar to other infectious viral diseases, it is mandatory to have an AI software that expresses objective evaluations of the percentage of ventilated lung parenchyma compared to the affected one.",265,COVID-19;Pneumonia;Severe Acute Respiratory Syndrome;Virus Diseases,64.0,Radiol Med,Coronavirus Infections;Health Care;Health;Lung Diseases;Communicable Diseases;Map,5.462506151943501e-06,106.79199999999965,5.404480791828752e-06,305.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
32386147,10.1109/TMI.2020.2992546,Yes,,32386147.0,2020,2020-05-10,Journal Article,Peer reviewed (PubMed),1,diagnosis of coronavirus disease 2019 (covid-19) with structured latent multi-view representation learning,"Recently, the outbreak of Coronavirus Disease 2019 (COVID-19) has spread rapidly across the world. Due to the large number of infected patients and heavy labor for doctors, computer-aided diagnosis with machine learning algorithm is urgently needed, and could largely reduce the efforts of clinicians and accelerate the diagnosis process. Chest computed tomography (CT) has been recognized as an informative tool for diagnosis of the disease. In this study, we propose to conduct the diagnosis of COVID-19 with a series of features extracted from CT images. To fully explore multiple features describing CT images from different views, a unified latent representation is learned which can completely encode information from different aspects of features and is endowed with promising class structure for separability. Specifically, the completeness is guaranteed with a group of backward neural networks (each for one type of features), while by using class labels the representation is enforced to be compact within COVID-19/community-acquired pneumonia (CAP) and also a large margin is guaranteed between different types of pneumonia. In this way, our model can well avoid overfitting compared to the case of directly projecting high-dimensional features into classes. Extensive experimental results show that the proposed method outperforms all comparison methods, and rather stable performances are observed when varying the number of training data.",212,COVID-19;Pneumonia,94.0,IEEE Trans Med Imaging,Coronavirus Infections;Disease Outbreaks,3.2564405162809933e-06,46.46399999999998,2.8852381287092526e-06,150.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32396075,10.1109/TMI.2020.2993291,Yes,,32396075.0,2020,2020-05-13,Journal Article,Peer reviewed (PubMed),1,deep learning covid-19 features on cxr using limited training data sets,"Under the global pandemic of COVID-19, the use of artificial intelligence to analyze chest X-ray (CXR) image for COVID-19 diagnosis and patient triage is becoming important. Unfortunately, due to the emergent nature of the COVID-19 pandemic, a systematic collection of CXR data set for deep neural network training is difficult. To address this problem, here we propose a patch-based convolutional neural network approach with a relatively small number of trainable parameters for COVID-19 diagnosis. The proposed method is inspired by our statistical analysis of the potential imaging biomarkers of the CXR radiographs. Experimental results show that our method achieves state-of-the-art performance and provides clinically interpretable saliency maps, which are useful for COVID-19 diagnosis and patient triage.",116,COVID-19;COVID-19 Pandemic,298.0,IEEE Trans Med Imaging,Coronavirus Infections;Art;Algorithms;Map,7.449282484284978e-06,174.59199999999936,1.019867616074229e-05,464.0,0.0,External,2. Detection/Diagnosis,X-Ray
32397844,10.1080/07391102.2020.1767212,Yes,PMC7256347,32397844.0,2020,2020-05-14,Journal Article,Peer reviewed (PubMed),1,using x-ray images and deep learning for automated detection of coronavirus disease,"Coronavirus is still the leading cause of death worldwide. There are a set number of COVID-19 test units accessible in emergency clinics because of the expanding cases daily. Therefore, it is important to implement an automatic detection and classification system as a speedy elective finding choice to forestall COVID-19 spreading among individuals. Medical images analysis is one of the most promising research areas, it provides facilities for diagnosis and making decisions of a number of diseases such as Coronavirus. This paper conducts a comparative study of the use of the recent deep learning models (VGG16, VGG19, DenseNet201, Inception_ResNet_V2, Inception_V3, Resnet50, and MobileNet_V2) to deal with detection and classification of coronavirus pneumonia. The experiments were conducted using chest X-ray and CT dataset of 6087 images (2780 images of bacterial pneumonia, 1493 of coronavirus, 231 of Covid19, and 1583 normal) and confusion matrices are used to evaluate model performances. Results found out that the use of inception_Resnet_V2 and Densnet201 provide better results compared to other models used in this work (92.18% accuracy for Inception-ResNetV2 and 88.09% accuracy for Densnet201).Communicated by Ramaswamy H. Sarma.",181,"COVID-19;Confusion;Death;Pneumonia;Pneumonia, Bacterial",101.0,J Biomol Struct Dyn,Other Topics,3.336993809399896e-06,80.36799999999987,5.687746373795312e-06,194.0,0.0,External,2. Detection/Diagnosis,X-Ray
32406829,10.1109/TMI.2020.2994459,Yes,,32406829.0,2020,2020-05-15,Journal Article,Peer reviewed (PubMed),1,deep learning for classification and localization of covid-19 markers in point-of-care lung ultrasound,"Deep learning (DL) has proved successful in medical imaging and, in the wake of the recent COVID-19 pandemic, some works have started to investigate DL-based solutions for the assisted diagnosis of lung diseases. While existing works focus on CT scans, this paper studies the application of DL techniques for the analysis of lung ultrasonography (LUS) images. Specifically, we present a novel fully-annotated dataset of LUS images collected from several Italian hospitals, with labels indicating the degree of disease severity at a frame-level, video-level, and pixel-level (segmentation masks). Leveraging these data, we introduce several deep models that address relevant tasks for the automatic analysis of LUS images. In particular, we present a novel deep network, derived from Spatial Transformer Networks, which simultaneously predicts the disease severity score associated to a input frame and provides localization of pathological artefacts in a weakly-supervised way. Furthermore, we introduce a new method based on uninorms for effective frame score aggregation at a video-level. Finally, we benchmark state of the art deep models for estimating pixel-level segmentations of COVID-19 imaging biomarkers. Experiments on the proposed dataset demonstrate satisfactory results on all the considered tasks, paving the way to future research on DL for the assisted diagnosis of COVID-19 from LUS data.",205,COVID-19;COVID-19 Pandemic;Lung Diseases,162.0,IEEE Trans Med Imaging,Coronavirus Infections;Art;Point-of-Care Systems;Ultrasonography;Lung Diseases;Masks,5.10963419415673e-06,82.18399999999983,4.7532633314700406e-06,243.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
32408222,10.1016/j.ejrad.2020.109041,Yes,PMC7198437,32408222.0,2020,2020-05-15,Journal Article;Multicenter Study,Peer reviewed (PubMed),1,deep learning-based multi-view fusion model for screening 2019 novel coronavirus pneumonia: a multicentre study,"To develop a deep learning-based method to assist radiologists to fast and accurately identify patients with COVID-19 by CT images. We retrospectively collected chest CT images of 495 patients from three hospitals in China. 495 datasets were randomly divided into 395 cases (80%, 294 of COVID-19, 101 of other pneumonia) of the training set, 50 cases (10%, 37 of COVID-19, 13 of other pneumonia) of the validation set and 50 cases (10%, 37 of COVID-19, 13 of other pneumonia) of the testing set. We trained a multi-view fusion model using deep learning network to screen patients with COVID-19 using CT images with the maximum lung regions in axial, coronal and sagittal views. The performance of the proposed model was evaluated by both the validation and testing sets. The multi-view deep learning fusion model achieved the AUC of 0.732, accuracy of 0.700, sensitivity of 0.730 and specificity of 0.615 in validation set. In the testing set, we can achieve AUC, accuracy, sensitivity and specificity of 0.819, 0.760, 0.811 and 0.615 respectively. Based on deep learning method, the proposed diagnosis model trained on multi-view images of chest CT images showed great potential to improve the efficacy of diagnosis and mitigate the heavy workload of radiologists for the initial screening of COVID-19 pneumonia.",210,COVID-19;Pneumonia,100.0,Eur J Radiol,Coronavirus Infections;Radiologists;ROC Curve;Retrospective Studies;Age;Receiver Operating Characteristic,7.077604856129694e-06,162.8159999999994,9.058863258655914e-06,440.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32412551,10.1007/s40846-020-00529-4,Yes,PMC7221329,32412551.0,2020,2020-05-16,Journal Article,Peer reviewed (PubMed),1,extracting possibly representative covid-19 biomarkers from x-ray images with deep learning approach and image data related to pulmonary diseases,"While the spread of COVID-19 is increased, new, automatic, and reliable methods for accurate detection are essential to reduce the exposure of the medical experts to the outbreak. X-ray imaging, although limited to specific visualizations, may be helpful for the diagnosis. In this study, the problem of automatic classification of pulmonary diseases, including the recently emerged COVID-19, from X-ray images, is considered. Deep Learning has proven to be a remarkable method to extract massive high-dimensional features from medical images. Specifically, in this paper, the state-of-the-art Convolutional Neural Network called Mobile Net is employed and trained from scratch to investigate the importance of the extracted features for the classification task. A large-scale dataset of 3905 X-ray images, corresponding to 6 diseases, is utilized for training MobileNet v2, which has been proven to achieve excellent results in related tasks. Training the CNNs from scratch outperforms the other transfer learning techniques, both in distinguishing the X-rays between the seven classes and between Covid-19 and non-Covid-19. A classification accuracy between the seven classes of 87.66% is achieved. Besides, this method achieves 99.18% accuracy, 97.36% Sensitivity, and 99.42% Specificity in the detection of COVID-19. The results suggest that training CNNs from scratch may reveal vital biomarkers related but not limited to the COVID-19 disease, while the top classification accuracy suggests further examination of the X-ray imaging potential.",222,COVID-19;Lung Diseases,126.0,J Med Biol Eng,Art;Transfer Learning;Disease Outbreaks;Lung;Other Topics;Lung Diseases,3.4685359700443097e-06,72.26399999999991,4.862838800332138e-06,185.0,0.0,External,2. Detection/Diagnosis,X-Ray
32427226,10.1016/j.chemolab.2020.104054,Yes,PMC7233238,32427226.0,2020,2020-05-20,Journal Article,Peer reviewed (PubMed),1,an automated residual exemplar local binary pattern and iterative relieff based covid-19 detection method using chest x-ray image,"Coronavirus is normally transmitted from animal to person, but nowadays it is transmitted from person to person by changing its form. Covid-19 appeared as a very dangerous virus and unfortunately caused a worldwide pandemic disease. Radiology doctors use X-ray or CT images for the diagnosis of Covid-19. It has become crucial to help diagnose such images using image processing methods. Therefore, a novel intelligent computer vision method to automatically detect the Covid-19 virus was proposed. The proposed automatic Covid-19 detection method consists of preprocessing, feature extraction, and feature selection stages. Image resizing and grayscale conversion are used in the preprocessing phase. The proposed feature generation method is called Residual Exemplar Local Binary Pattern (ResExLBP). In the feature selection phase, a novel iterative ReliefF (IRF) based feature selection is used. Decision tree (DT), linear discriminant (LD), support vector machine (SVM), k nearest neighborhood (kNN), and subspace discriminant (SD) methods are chosen as classifiers in the classification phase. Leave one out cross-validation (LOOCV), 10-fold cross-validation, and holdout validation are used for training and testing. In this work, SVM classifier achieved 100.0% classification accuracy by using 10-fold cross-validation. This result clearly has shown that the perfect classification rate by using X-ray image for Covid-19 detection. The proposed ResExLBP and IRF based method is also cognitive, lightweight, and highly accurate.",216,COVID-19,65.0,Chemometr Intell Lab Syst,Viruses;Decision Trees,3.023951756622941e-06,46.696000000000026,3.5324428434258483e-06,111.0,0.0,External,2. Detection/Diagnosis,X-Ray
32427924,10.1038/s41591-020-0931-3,Yes,PMC7446729,32427924.0,2020,2020-05-20,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,artificial intelligence-enabled rapid diagnosis of patients with covid-19,"For diagnosis of coronavirus disease 2019 (COVID-19), a SARS-CoV-2 virus-specific reverse transcriptase polymerase chain reaction (RT-PCR) test is routinely used. However, this test can take up to 2 d to complete, serial testing may be required to rule out the possibility of false negative results and there is currently a shortage of RT-PCR test kits, underscoring the urgent need for alternative methods for rapid and accurate diagnosis of patients with COVID-19. Chest computed tomography (CT) is a valuable component in the evaluation of patients with suspected SARS-CoV-2 infection. Nevertheless, CT alone may have limited negative predictive value for ruling out SARS-CoV-2 infection, as some patients may have normal radiological findings at early stages of the disease. In this study, we used artificial intelligence (AI) algorithms to integrate chest CT findings with clinical symptoms, exposure history and laboratory testing to rapidly diagnose patients who are positive for COVID-19. Among a total of 905 patients tested by real-time RT-PCR assay and next-generation sequencing RT-PCR, 419 tested positive for SARS-CoV-2. In a test set of 279 patients, the AI system achieved an AUC of 0.92 and had equal sensitivity as compared to a senior thoracic radiologist. The AI system also improved the detection of patients who were positive for COVID-19 via RT-PCR who presented with normal CT scans, correctly identifying 17 of 25 patients, whereas radiologists classified all of these patients as COVID-19 negative. When CT scans and associated clinical history are available, the proposed AI system can help to rapidly diagnose COVID-19 patients.",251,COVID-19,412.0,Nat Med,Coronavirus Infections;Predictive Value;Polymerase Chain Reaction;Real-Time Polymerase Chain Reaction,9.557602028063567e-06,222.11199999999988,1.1240061488846206e-05,608.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32436845,10.5152/dir.2019.20294,Yes,PMC7490030,32436845.0,2020,2020-05-22,Journal Article;Review,Peer reviewed (PubMed),1,a review on the use of artificial intelligence for medical imaging of the lungs of patients with coronavirus disease 2019,"The results of research on the use of artificial intelligence (AI) for medical imaging of the lungs of patients with coronavirus disease 2019 (COVID-19) has been published in various forms. In this study, we reviewed the AI for diagnostic imaging of COVID-19 pneumonia. PubMed, arXiv, medRxiv, and Google scholar were used to search for AI studies. There were 15 studies of COVID-19 that used AI for medical imaging. Of these, 11 studies used AI for computed tomography (CT) and 4 used AI for chest radiography. Eight studies presented independent test data, 5 used disclosed data, and 4 disclosed the AI source codes. The number of datasets ranged from 106 to 5941, with sensitivities ranging from 0.67-1.00 and specificities ranging from 0.81-1.00 for prediction of COVID-19 pneumonia. Four studies with independent test datasets showed a breakdown of the data ratio and reported prediction of COVID-19 pneumonia with sensitivity, specificity, and AUC. These 4 studies showed very high sensitivity, specificity, and AUC, in the range of 0.9-0.98, 0.91-0.96, and 0.96-0.99, respectively.",169,COVID-19;Pneumonia,21.0,Diagn Interv Radiol,Other Topics,4.449329458535532e-06,82.14399999999983,4.31371284576285e-06,252.0,0.0,External,Review,Multimodal
32444412,10.1183/13993003.00775-2020,Yes,PMC7243395,32444412.0,2020,2020-05-24,Journal Article,Peer reviewed (PubMed),1,a fully automatic deep learning system for covid-19 diagnostic and prognostic analysis,"Coronavirus disease 2019 (COVID-19) has spread globally, and medical resources become insufficient in many regions. Fast diagnosis of COVID-19 and finding high-risk patients with worse prognosis for early prevention and medical resource optimisation is important. Here, we proposed a fully automatic deep learning system for COVID-19 diagnostic and prognostic analysis by routinely used computed tomography.We retrospectively collected 5372 patients with computed tomography images from seven cities or provinces. Firstly, 4106 patients with computed tomography images were used to pre-train the deep learning system, making it learn lung features. Following this, 1266 patients (924 with COVID-19 (471 had follow-up for >5 days) and 342 with other pneumonia) from six cities or provinces were enrolled to train and externally validate the performance of the deep learning system.In the four external validation sets, the deep learning system achieved good performance in identifying COVID-19 from other pneumonia (AUC 0.87 and 0.88, respectively) and viral pneumonia (AUC 0.86). Moreover, the deep learning system succeeded to stratify patients into high- and low-risk groups whose hospital-stay time had significant difference (p=0.013 and p=0.014, respectively). Without human assistance, the deep learning system automatically focused on abnormal areas that showed consistent characteristics with reported radiological findings.Deep learning provides a convenient tool for fast screening of COVID-19 and identifying potential high-risk patients, which may be helpful for medical resource optimisation and early prevention before patients show severe symptoms.",228,"COVID-19;Pneumonia;Pneumonia, Viral",214.0,Eur Respir J,Coronavirus Infections;Retrospective Studies,6.014583110723726e-06,137.62399999999946,7.877821805842889e-06,371.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32462445,10.1007/s00330-020-06956-w,Yes,PMC7253230,32462445.0,2020,2020-05-29,Journal Article,Peer reviewed (PubMed),1,any unique image biomarkers associated with covid-19?,"To define the uniqueness of chest CT infiltrative features associated with COVID-19 image characteristics as potential diagnostic biomarkers. We retrospectively collected chest CT exams including n = 498 on 151 unique patients RT-PCR positive for COVID-19 and n = 497 unique patients with community-acquired pneumonia (CAP). Both COVID-19 and CAP image sets were partitioned into three groups for training, validation, and testing respectively. In an attempt to discriminate COVID-19 from CAP, we developed several classifiers based on three-dimensional (3D) convolutional neural networks (CNNs). We also asked two experienced radiologists to visually interpret the testing set and discriminate COVID-19 from CAP. The classification performance of the computer algorithms and the radiologists was assessed using the receiver operating characteristic (ROC) analysis, and the nonparametric approaches with multiplicity adjustments when necessary. One of the considered models showed non-trivial, but moderate diagnostic ability overall. This model allowed for the identification of 8-50% of CAP patients with only 2% of COVID-19 patients. Professional or automated interpretation of CT exams has a moderately low ability to distinguish between COVID-19 and CAP cases. However, the automated image analysis is promising for targeted decision-making due to being able to accurately identify a sizable subsect of non-COVID-19 cases. Both human experts and artificial intelligent models were used to classify the CT scans. ROC analysis and the nonparametric approaches were used to analyze the performance of the radiologists and computer algorithms. Unique image features or patterns may not exist for reliably distinguishing all COVID-19 from CAP; however, there may be imaging markers that can identify a sizable subset of non-COVID-19 cases.",261,COVID-19;Pneumonia,23.0,Eur Radiol,Coronavirus Infections;Algorithms;Polymerase Chain Reaction;Radiologists;ROC Curve;Retrospective Studies;Area under Curve;Receiver Operating Characteristic,3.185853980564446e-06,43.24000000000003,2.911313883572244e-06,151.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32486140,10.3390/diagnostics10060358,Yes,PMC7345787,32486140.0,2020,2020-06-04,Journal Article,Peer reviewed (PubMed),1,weakly labeled data augmentation for deep learning: a study on covid-19 detection in chest x-rays,"The novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a pandemic resulting in over 2.7 million infected individuals and over 190,000 deaths and growing. Assertions in the literature suggest that respiratory disorders due to COVID-19 commonly present with pneumonia-like symptoms which are radiologically confirmed as opacities. Radiology serves as an adjunct to the reverse transcription-polymerase chain reaction test for confirmation and evaluating disease progression. While computed tomography (CT) imaging is more specific than chest X-rays (CXR), its use is limited due to cross-contamination concerns. CXR imaging is commonly used in high-demand situations, placing a significant burden on radiology services. The use of artificial intelligence (AI) has been suggested to alleviate this burden. However, there is a dearth of sufficient training data for developing image-based AI tools. We propose increasing training data for recognizing COVID-19 pneumonia opacities using weakly labeled data augmentation. This follows from a hypothesis that the COVID-19 manifestation would be similar to that caused by other viral pathogens affecting the lungs. We expand the training data distribution for supervised learning through the use of weakly labeled CXR images, automatically pooled from publicly available pneumonia datasets, to classify them into those with bacterial or viral pneumonia opacities. Next, we use these selected images in a stage-wise, strategic approach to train convolutional neural network-based algorithms and compare against those trained with non-augmented data. Weakly labeled data augmentation expands the learned feature space in an attempt to encompass variability in unseen test distributions, enhance inter-class discrimination, and reduce the generalization error. Empirical evaluations demonstrate that simple weakly labeled data augmentation (Acc: 0.5555 and Acc: 0.6536) is better than baseline non-augmented training (Acc: 0.2885 and Acc: 0.5028) in identifying COVID-19 manifestations as viral pneumonia. Interestingly, adding COVID-19 CXRs to simple weakly labeled augmented training data significantly improves the performance (Acc: 0.7095 and Acc: 0.8889), suggesting that COVID-19, though viral in origin, creates a uniquely different presentation in CXRs compared with other viral pneumonia manifestations.",324,"COVID-19;Death;Disease Progression;Pneumonia;Pneumonia, Viral;Severe Acute Respiratory Syndrome",45.0,Diagnostics (Basel),Polymerase Chain Reaction;Reverse Transcription,3.0890835306642724e-06,53.12000000000002,4.168329737622464e-06,134.0,0.0,External,2. Detection/Diagnosis,X-Ray
32496988,10.2174/1573405616666200604163954,Yes,,32496988.0,2020,2020-06-05,Journal Article,Peer reviewed (PubMed),1,a deep neural network to distinguish covid-19 from other chest diseases using x-ray images,"Scanning a patient's lungs to detect Coronavirus 2019 (COVID-19) may lead to similar imaging of other chest diseases. Thus, a multidisciplinary approach is strongly required to confirm the diagnosis. There are only a few works targeted at pathological x-ray images. Most of the works only target single disease detection which is not good enough. Some works have been provided for all classes. However, the results suffer due to lack of data for rare classes and data unbalancing problem. Due to the rise in COVID-19 cases, medical facilities in many countries are overwhelmed and there is a need for an intelligent system to detect it. Few works have been done regarding the detection of the coronavirus but there are many cases where it can be misclassified as some techniques are not efficient and can only identify specific diseases. This work is a deep learning- based model to distinguish COVID-19 cases from other chest diseases. A Deep Neural Network model provides a significant contribution in terms of detecting COVID-19 and provides an effective analysis of chest-related diseases taking into account both age and gender. Our model achieves 87% accuracy in terms of GAN-based synthetic data and presents four different types of deep learning-based models that provide comparable results to other state-of-the-art techniques. The healthcare industry may face unfavorable consequences if the gap in the identification of all types of pneumonia is not filled with effective automation.",234,COVID-19;Pneumonia,19.0,Curr Med Imaging,Art;Health Care;Neural Networks;Other Topics;Lung Diseases,1.3100750834266398e-06,19.44,1.3275694883224486e-06,48.0,0.0,External,2. Detection/Diagnosis,X-Ray
32501424,10.1016/j.imu.2020.100360,Yes,PMC7255267,32501424.0,2020,2020-06-06,Journal Article,Peer reviewed (PubMed),1,a modified deep convolutional neural network for detecting covid-19 and pneumonia from chest x-ray images based on the concatenation of xception and resnet50v2,"In this paper, we have trained several deep convolutional networks with introduced training techniques for classifying X-ray images into three classes: normal, pneumonia, and COVID-19, based on two open-source datasets. Our data contains 180 X-ray images that belong to persons infected with COVID-19, and we attempted to apply methods to achieve the best possible results. In this research, we introduce some training techniques that help the network learn better when we have an unbalanced dataset (fewer cases of COVID-19 along with more cases from other classes). We also propose a neural network that is a concatenation of the Xception and ResNet50V2 networks. This network achieved the best accuracy by utilizing multiple features extracted by two robust networks. For evaluating our network, we have tested it on 11302 images to report the actual accuracy achievable in real circumstances. The average accuracy of the proposed network for detecting COVID-19 cases is 99.50%, and the overall average accuracy for all classes is 91.4%.",160,COVID-19;Pneumonia,162.0,Inform Med Unlocked,Transfer Learning;Other Topics,7.392764071657701e-06,138.35199999999938,9.402302806070544e-06,342.0,0.0,External,2. Detection/Diagnosis,X-Ray
32524445,10.1007/s13246-020-00865-4,Yes,PMC7118364,32524445.0,2020,2020-06-12,Journal Article,Peer reviewed (PubMed),1,covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks,"In this study, a dataset of X-ray images from patients with common bacterial pneumonia, confirmed Covid-19 disease, and normal incidents, was utilized for the automatic detection of the Coronavirus disease. The aim of the study is to evaluate the performance of state-of-the-art convolutional neural network architectures proposed over the recent years for medical image classification. Specifically, the procedure called Transfer Learning was adopted. With transfer learning, the detection of various abnormalities in small medical image datasets is an achievable target, often yielding remarkable results. The datasets utilized in this experiment are two. Firstly, a collection of 1427 X-ray images including 224 images with confirmed Covid-19 disease, 700 images with confirmed common bacterial pneumonia, and 504 images of normal conditions. Secondly, a dataset including 224 images with confirmed Covid-19 disease, 714 images with confirmed bacterial and viral pneumonia, and 504 images of normal conditions. The data was collected from the available X-ray images on public medical repositories. The results suggest that Deep Learning with X-ray imaging may extract significant biomarkers related to the Covid-19 disease, while the best accuracy, sensitivity, and specificity obtained is 96.78%, 98.66%, and 96.46% respectively. Since by now, all diagnostic tests show failure rates such as to raise concerns, the probability of incorporating X-rays into the diagnosis of the disease could be assessed by the medical community, based on the findings, while more research to evaluate the X-ray approach from different aspects may be conducted.",238,"COVID-19;Pneumonia, Bacterial;Pneumonia, Viral",680.0,Phys Eng Sci Med,Radiography;Coronavirus Infections;Art;Transfer Learning;Diagnostic Tests;Architecture;COVID-19 Testing;Sensitivity and Specificity;Neural Networks,1.4787709883134722e-05,330.2240000000037,2.125696400683522e-05,812.0,0.0,External,2. Detection/Diagnosis,X-Ray
32534344,10.1016/j.cmpb.2020.105581,Yes,PMC7274128,32534344.0,2020,2020-06-14,Journal Article,Peer reviewed (PubMed),1,coronet: a deep neural network for detection and diagnosis of covid-19 from chest x-ray images,"The novel Coronavirus also called COVID-19 originated in Wuhan, China in December 2019 and has now spread across the world. It has so far infected around 1.8 million people and claimed approximately 114,698 lives overall. As the number of cases are rapidly increasing, most of the countries are facing shortage of testing kits and resources. The limited quantity of testing kits and increasing number of daily cases encouraged us to come up with a Deep Learning model that can aid radiologists and clinicians in detecting COVID-19 cases using chest X-rays. In this study, we propose CoroNet, a Deep Convolutional Neural Network model to automatically detect COVID-19 infection from chest X-ray images. The proposed model is based on Xception architecture pre-trained on ImageNet dataset and trained end-to-end on a dataset prepared by collecting COVID-19 and other chest pneumonia X-ray images from two different publically available databases. CoroNet has been trained and tested on the prepared dataset and the experimental results show that our proposed model achieved an overall accuracy of 89.6%, and more importantly the precision and recall rate for COVID-19 cases are 93% and 98.2% for 4-class cases (COVID vs Pneumonia bacterial vs pneumonia viral vs normal). For 3-class classification (COVID vs Pneumonia vs normal), the proposed model produced a classification accuracy of 95%. The preliminary results of this study look promising which can be further improved as more training data becomes available. CoroNet achieved promising results on a small prepared dataset which indicates that given more data, the proposed model can achieve better results with minimum pre-processing of data. Overall, the proposed model substantially advances the current radiology based methodology and during COVID-19 pandemic, it can be very helpful tool for clinical practitioners and radiologists to aid them in diagnosis, quantification and follow-up of COVID-19 cases.",297,"COVID-19;COVID-19 Pandemic;Infections;Pneumonia;Pneumonia, Bacterial;Pneumonia, Viral",384.0,Comput Methods Programs Biomed,Coronavirus Infections;Architecture;Neural Networks,1.20249421694183e-05,434.2720000000076,2.7077316152457155e-05,978.0,0.0,External,2. Detection/Diagnosis,X-Ray
32536759,10.1016/j.chaos.2020.109944,Yes,PMC7254021,32536759.0,2020,2020-06-17,Journal Article,Peer reviewed (PubMed),1,application of deep learning for fast detection of covid-19 in x-rays using ncovnet,"Presently, COVID-19 has posed a serious threat to researchers, scientists, health professionals, and administrations around the globe from its detection to its treatment. The whole world is witnessing a lockdown like situation because of COVID-19 pandemic. Persistent efforts are being made by the researchers to obtain the possible solutions to control this pandemic in their respective areas. One of the most common and effective methods applied by the researchers is the use of CT-Scans and X-rays to analyze the images of lungs for COVID-19. However, it requires several radiology specialists and time to manually inspect each report which is one of the challenging tasks in a pandemic. In this paper, we have proposed a deep learning neural network-based method nCOVnet, an alternative fast screening method that can be used for detecting the COVID-19 by analyzing the X-rays of patients which will look for visual indicators found in the chest radiography imaging of COVID-19 patients.",154,COVID-19;COVID-19 Pandemic,192.0,Chaos Solitons Fractals,Other Topics,4.297596973256733e-06,88.87999999999981,6.017208025668132e-06,210.0,0.0,External,2. Detection/Diagnosis,X-Ray
32555006,10.1097/RTI.0000000000000544,Yes,PMC7682797,32555006.0,2020,2020-06-20,Journal Article,Peer reviewed (PubMed),1,a novel machine learning-derived radiomic signature of the whole lung differentiates stable from progressive covid-19 infection: a retrospective cohort study,"This study aimed to use the radiomics signatures of a machine learning-based tool to evaluate the prognosis of patients with coronavirus disease 2019 (COVID-19) infection. The clinical and imaging data of 64 patients with confirmed diagnoses of COVID-19 were retrospectively selected and divided into a stable group and a progressive group according to the data obtained from the ongoing treatment process. Imaging features from whole-lung images from baseline computed tomography (CT) scans were extracted and dimensionality reduction was performed. Support vector machines were used to construct radiomics signatures and to compare differences between the 2 groups. We also compared the differences of signature scores in the clinical, laboratory, and CT image feature subgroups and finally analyzed the correlation between the radiomics features of the constructed signature and the other features including clinical, laboratory, and CT imaging features. The signature has a good classification effect for the stable group and the progressive group, with AUC, sensitivity, and specificity of 0.833, 80.95%, and 74.42%, respectively. Signature score differences in laboratory and CT imaging features between subgroups were not statistically significant (P>0.05); cough was negatively correlated with GLCM Entropy_angle 90_offset4 (r=-0.578), but was positively correlated with ShortRunEmphhasis_AllDirect_offset4_SD (r=0.454); C-reactive protein was positively correlated with Cluster Prominence_ AllDirect_offset 4_ SD (r=0.47). The radiomics signature of the whole lung based on machine learning may reveal the changes of lung microstructure in the early stage and help to indicate the progression of the disease.",238,COVID-19;Cough;Infections,25.0,J Thorac Imaging,Severity of Illness Index;Sensitivity;C-Reactive Protein;Humans;Retrospective Studies;Entropy;Support Vector Machine;Area under Curve;Age,2.3619875289251663e-06,36.312,2.131773165745306e-06,103.0,0.0,External,4. Prognosis/Treatment,CT
32568675,10.1016/j.compbiomed.2020.103792,Yes,PMC7187882,32568675.0,2020,2020-06-23,Evaluation Study;Journal Article,Peer reviewed (PubMed),1,automated detection of covid-19 cases using deep neural networks with x-ray images,"The novel coronavirus 2019 (COVID-2019), which first appeared in Wuhan city of China in December 2019, spread rapidly around the world and became a pandemic. It has caused a devastating effect on both daily lives, public health, and the global economy. It is critical to detect the positive cases as early as possible so as to prevent the further spread of this epidemic and to quickly treat affected patients. The need for auxiliary diagnostic tools has increased as there are no accurate automated toolkits available. Recent findings obtained using radiology imaging techniques suggest that such images contain salient information about the COVID-19 virus. Application of advanced artificial intelligence (AI) techniques coupled with radiological imaging can be helpful for the accurate detection of this disease, and can also be assistive to overcome the problem of a lack of specialized physicians in remote villages. In this study, a new model for automatic COVID-19 detection using raw chest X-ray images is presented. The proposed model is developed to provide accurate diagnostics for binary classification (COVID vs. No-Findings) and multi-class classification (COVID vs. No-Findings vs. Pneumonia). Our model produced a classification accuracy of 98.08% for binary classes and 87.02% for multi-class cases. The DarkNet model was used in our study as a classifier for the you only look once (YOLO) real time object detection system. We implemented 17 convolutional layers and introduced different filtering on each layer. Our model (available at (GitHub)) can be employed to assist radiologists in validating their initial screening, and can also be employed via cloud to immediately screen patients.",260,COVID-19;Pneumonia,752.0,Comput Biol Med,Coronavirus Infections;Public Health;Neural Networks,1.5825939495258034e-05,429.48000000001065,2.447654812741296e-05,1081.0,0.0,External,2. Detection/Diagnosis,X-Ray
32568676,10.1016/j.compbiomed.2020.103795,Yes,PMC7190523,32568676.0,2020,2020-06-23,Journal Article,Peer reviewed (PubMed),1,application of deep learning technique to manage covid-19 in routine clinical practice using ct images: results of 10 convolutional neural networks,"Fast diagnostic methods can control and prevent the spread of pandemic diseases like coronavirus disease 2019 (COVID-19) and assist physicians to better manage patients in high workload conditions. Although a laboratory test is the current routine diagnostic tool, it is time-consuming, imposing a high cost and requiring a well-equipped laboratory for analysis. Computed tomography (CT) has thus far become a fast method to diagnose patients with COVID-19. However, the performance of radiologists in diagnosis of COVID-19 was moderate. Accordingly, additional investigations are needed to improve the performance in diagnosing COVID-19. In this study is suggested a rapid and valid method for COVID-19 diagnosis using an artificial intelligence technique based. 1020 CT slices from 108 patients with laboratory proven COVID-19 (the COVID-19 group) and 86 patients with other atypical and viral pneumonia diseases (the non-COVID-19 group) were included. Ten well-known convolutional neural networks were used to distinguish infection of COVID-19 from non-COVID-19 groups: AlexNet, VGG-16, VGG-19, SqueezeNet, GoogleNet, MobileNet-V2, ResNet-18, ResNet-50, ResNet-101, and Xception. Among all networks, the best performance was achieved by ResNet-101 and Xception. ResNet-101 could distinguish COVID-19 from non-COVID-19 cases with an AUC of 0.994 (sensitivity, 100%; specificity, 99.02%; accuracy, 99.51%). Xception achieved an AUC of 0.994 (sensitivity, 98.04%; specificity, 100%; accuracy, 99.02%). However, the performance of the radiologist was moderate with an AUC of 0.873 (sensitivity, 89.21%; specificity, 83.33%; accuracy, 86.27%). ResNet-101 can be considered as a high sensitivity model to characterize and diagnose COVID-19 infections, and can be used as an adjuvant tool in radiology departments.",250,"COVID-19;Infections;Pneumonia, Viral",291.0,Comput Biol Med,Coronavirus Infections;Sensitivity and Specificity;Neural Networks;Area under Curve,1.205652898901161e-05,302.0400000000031,1.653578383726119e-05,791.0,0.0,External,2. Detection/Diagnosis,CT
32568679,10.1016/j.compbiomed.2020.103805,Yes,PMC7202857,32568679.0,2020,2020-06-23,Journal Article,Peer reviewed (PubMed),1,covid-19 detection using deep learning models to exploit social mimic optimization and structured chest x-ray images using fuzzy color and stacking approaches,"Coronavirus causes a wide variety of respiratory infections and it is an RNA-type virus that can infect both humans and animal species. It often causes pneumonia in humans. Artificial intelligence models have been helpful for successful analyses in the biomedical field. In this study, Coronavirus was detected using a deep learning model, which is a sub-branch of artificial intelligence. Our dataset consists of three classes namely: coronavirus, pneumonia, and normal X-ray imagery. In this study, the data classes were restructured using the Fuzzy Color technique as a preprocessing step and the images that were structured with the original images were stacked. In the next step, the stacked dataset was trained with deep learning models (MobileNetV2, SqueezeNet) and the feature sets obtained by the models were processed using the Social Mimic optimization method. Thereafter, efficient features were combined and classified using Support Vector Machines (SVM). The overall classification rate obtained with the proposed approach was 99.27%. With the proposed approach in this study, it is evident that the model can efficiently contribute to the detection of COVID-19 disease.",177,COVID-19;Pneumonia;Respiratory Tract Infections,197.0,Comput Biol Med,Other Topics,7.46073700140422e-06,131.65599999999955,8.46869646688305e-06,355.0,0.0,External,2. Detection/Diagnosis,X-Ray
32568730,10.2196/19569,Yes,PMC7332254,32568730.0,2020,2020-06-23,Journal Article;Validation Study,Peer reviewed (PubMed),1,covid-19 pneumonia diagnosis using a simple 2d deep learning framework with a single chest ct image: model development and validation,"Coronavirus disease (COVID-19) has spread explosively worldwide since the beginning of 2020. According to a multinational consensus statement from the Fleischner Society, computed tomography (CT) is a relevant screening tool due to its higher sensitivity for detecting early pneumonic changes. However, physicians are extremely occupied fighting COVID-19 in this era of worldwide crisis. Thus, it is crucial to accelerate the development of an artificial intelligence (AI) diagnostic tool to support physicians. We aimed to rapidly develop an AI technique to diagnose COVID-19 pneumonia in CT images and differentiate it from non-COVID-19 pneumonia and nonpneumonia diseases. A simple 2D deep learning framework, named the fast-track COVID-19 classification network (FCONet), was developed to diagnose COVID-19 pneumonia based on a single chest CT image. FCONet was developed by transfer learning using one of four state-of-the-art pretrained deep learning models (VGG16, ResNet-50, Inception-v3, or Xception) as a backbone. For training and testing of FCONet, we collected 3993 chest CT images of patients with COVID-19 pneumonia, other pneumonia, and nonpneumonia diseases from Wonkwang University Hospital, Chonnam National University Hospital, and the Italian Society of Medical and Interventional Radiology public database. These CT images were split into a training set and a testing set at a ratio of 8:2. For the testing data set, the diagnostic performance of the four pretrained FCONet models to diagnose COVID-19 pneumonia was compared. In addition, we tested the FCONet models on an external testing data set extracted from embedded low-quality chest CT images of COVID-19 pneumonia in recently published papers. Among the four pretrained models of FCONet, ResNet-50 showed excellent diagnostic performance (sensitivity 99.58%, specificity 100.00%, and accuracy 99.87%) and outperformed the other three pretrained models in the testing data set. In the additional external testing data set using low-quality CT images, the detection accuracy of the ResNet-50 model was the highest, followed by Xception, Inception-v3, and VGG16 (90.71%, 89.38%, and 87.12%, respectively). FCONet, a simple 2D deep learning framework based on a single chest CT image, provides excellent diagnostic performance in detecting COVID-19 pneumonia. Based on our testing data set, the FCONet model based on ResNet-50 appears to be the best model, as it outperformed other FCONet models based on VGG16, Xception, and Inception-v3.",365,COVID-19;Pneumonia,103.0,J Med Internet Res,Coronavirus Infections;Art;Transfer Learning;Tomography,2.005901055234068e-05,621.8400000000181,3.564835152690893e-05,1496.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32571748,10.1016/j.diii.2020.06.001,Yes,PMC7287482,32571748.0,2020,2020-06-24,Journal Article;Review,Peer reviewed (PubMed),1,chest ct in covid-19 pneumonia: a review of current knowledge,"The current COVID-19 pandemic has highlighted the essential role of chest computed tomography (CT) examination in patient triage in the emergency departments, allowing them to be referred to ""COVID"" or ""non-COVID"" wards. Initial chest CT examination must be performed without intravenous administration of iodinated contrast material, but contrast material administration is required when pulmonary embolism is suspected, which seems to be frequent in severe forms of the disease. Typical CT features consist of bilateral ground-glass opacities with peripheral, posterior and basal predominance. Lung disease extent on CT correlates with clinical severity. Artificial intelligence could assist radiologists for diagnosis and prognosis evaluation.",101,COVID-19;COVID-19 Pandemic;Lung Diseases;Pneumonia;Pulmonary Embolism,63.0,Diagn Interv Imaging,Other Topics,3.615347435512473e-06,70.216,2.9424477739038942e-06,241.0,0.0,,Review,CT
32588200,10.1007/s13246-020-00888-x,Yes,PMC7315909,32588200.0,2020,2020-06-27,Journal Article,Peer reviewed (PubMed),1,truncated inception net: covid-19 outbreak screening using chest x-rays,"Since December 2019, the Coronavirus Disease (COVID-19) pandemic has caused world-wide turmoil in a short period of time, and the infection, caused by SARS-CoV-2, is spreading rapidly. AI-driven tools are used to identify Coronavirus outbreaks as well as forecast their nature of spread, where imaging techniques are widely used, such as CT scans and chest X-rays (CXRs). In this paper, motivated by the fact that X-ray imaging systems are more prevalent and cheaper than CT scan systems, a deep learning-based Convolutional Neural Network (CNN) model, which we call Truncated Inception Net, is proposed to screen COVID-19 positive CXRs from other non-COVID and/or healthy cases. To validate our proposal, six different types of datasets were employed by taking the following CXRs: COVID-19 positive, Pneumonia positive, Tuberculosis positive, and healthy cases into account. The proposed model achieved an accuracy of 99.96% (AUC of 1.0) in classifying COVID-19 positive cases from combined Pneumonia and healthy cases. Similarly, it achieved an accuracy of 99.92% (AUC of 0.99) in classifying COVID-19 positive cases from combined Pneumonia, Tuberculosis, and healthy CXRs. To the best of our knowledge, as of now, the achieved results outperform the existing AI-driven tools for screening COVID-19 using the acquired CXRs, and proves the viability of using the proposed Truncated Inception Net as a screening tool.",214,COVID-19;COVID-19 Pandemic;Infections;Pneumonia;Tuberculosis,104.0,Phys Eng Sci Med,Coronavirus Infections;Disease Outbreaks;Neural Networks;ROC Curve;Lung Diseases;Area under Curve,4.476042048254512e-06,88.79199999999977,5.761626773879061e-06,255.0,0.0,External,2. Detection/Diagnosis,X-Ray
32589673,10.1371/journal.pone.0235187,Yes,PMC7319603,32589673.0,2020,2020-06-27,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,new machine learning method for image-based diagnosis of covid-19,"COVID-19 is a worldwide epidemic, as announced by the World Health Organization (WHO) in March 2020. Machine learning (ML) methods can play vital roles in identifying COVID-19 patients by visually analyzing their chest x-ray images. In this paper, a new ML-method proposed to classify the chest x-ray images into two classes, COVID-19 patient or non-COVID-19 person. The features extracted from the chest x-ray images using new Fractional Multichannel Exponent Moments (FrMEMs). A parallel multi-core computational framework utilized to accelerate the computational process. Then, a modified Manta-Ray Foraging Optimization based on differential evolution used to select the most significant features. The proposed method evaluated using two COVID-19 x-ray datasets. The proposed method achieved accuracy rates of 96.09% and 98.09% for the first and second datasets, respectively.",125,COVID-19,106.0,PLoS One,Other Topics,4.511060197831433e-06,71.35999999999993,4.4100604355094896e-06,204.0,0.0,External,2. Detection/Diagnosis,X-Ray
32599338,10.1016/j.cmpb.2020.105608,Yes,PMC7831868,32599338.0,2020,2020-07-01,Journal Article,Peer reviewed (PubMed),1,explainable deep learning for pulmonary disease and coronavirus covid-19 detection from x-rays,"Coronavirus disease (COVID-19) is an infectious disease caused by a new virus never identified before in humans. This virus causes respiratory disease (for instance, flu) with symptoms such as cough, fever and, in severe cases, pneumonia. The test to detect the presence of this virus in humans is performed on sputum or blood samples and the outcome is generally available within a few hours or, at most, days. Analysing biomedical imaging the patient shows signs of pneumonia. In this paper, with the aim of providing a fully automatic and faster diagnosis, we propose the adoption of deep learning for COVID-19 detection from X-rays. In particular, we propose an approach composed by three phases: the first one to detect if in a chest X-ray there is the presence of a pneumonia. The second one to discern between COVID-19 and pneumonia. The last step is aimed to localise the areas in the X-ray symptomatic of the COVID-19 presence. Experimental analysis on 6,523 chest X-rays belonging to different institutions demonstrated the effectiveness of the proposed approach, with an average time for COVID-19 detection of approximately 2.5 seconds and an average accuracy equal to 0.97.",191,COVID-19;Communicable Diseases;Cough;Fever;Lung Diseases;Pneumonia;Respiratory Tract Diseases,182.0,Comput Methods Programs Biomed,Coronavirus Infections;Transfer Learning;Algorithms;Image Processing;Lung;Neural Networks;Communicable Diseases,5.903099007340539e-06,133.5279999999994,8.317404791604287e-06,339.0,0.0,External,2. Detection/Diagnosis,X-Ray
32604588,10.3233/SHTI200481,Yes,,32604588.0,2020,2020-07-02,Journal Article,Peer reviewed (PubMed),1,setting up an easy-to-use machine learning pipeline for medical decision support: a case study for covid-19 diagnosis based on deep learning with ct scans,"Coronavirus disease (COVID-19) constitutes an ongoing global health problem with significant morbidity and mortality. It usually presents characteristic findings on a chest CT scan, which may lead to early detection of the disease. A timely and accurate diagnosis of COVID-19 is the cornerstone for the prompt management of the patients. The aim of the present study was to evaluate the performance of an automated machine learning algorithm in the diagnosis of Covid-19 pneumonia using chest CT scans. Diagnostic performance was assessed by the AUC, sensitivity, and positive predictive value. The method's average precision was 0.932. We suggest that auto-ML platforms help users with limited ML expertise train image recognition models by only uploading the examined dataset and performing some basic settings. Such methods could deliver significant potential benefits for patients in the future by allowing for earlier disease detection and care.",141,COVID-19;Pneumonia,26.0,Stud Health Technol Inform,Other Topics,4.728462268257507e-06,86.37599999999973,4.823488952341635e-06,257.0,0.0,External,2. Detection/Diagnosis,CT
32611980,10.7883/yoken.JJID.2020.264,Yes,,32611980.0,2020,2020-07-03,Journal Article,Peer reviewed (PubMed),1,chest ct evaluation of 11 persistent asymptomatic patients with sars-cov-2 infection,"In total, 11 asymptomatic carriers who underwent nasal or oropharyngeal swab tests for SARS-CoV-2 after being in close contact with patients who developed symptomatic 2019 coronavirus disease (COVID-19) were enrolled in this study. The chest multidetector computed tomography (CT) images of the enrolled patients were qualitatively and quantitatively analyzed. The findings of the first chest CT were normal in 3 patients, 2 of whom were aged below 15 years. The lesions of 2 patients involved 1 lobe with unifocal presence. Subpleural lesions were observed in 7 patients. Ground glass opacity (GGO) was the most common sign observed in 7 patients. Crazy-paving pattern and consolidation were detected in 2 and 4 patients, respectively. Based on deep learning and quantitative analysis, the mean volume of intrapulmonary lesions in the first CT image was 85.73 cm3. In patients with positive findings on CT images, the average interval between positive real-time reverse transcriptase polymerase chain reaction assay and peak volume on CT images was 5.1 days. In conclusion, typical CT findings can be detected in over 70% of asymptomatic SARS-CoV-2 carriers. The initial presentation is typically GGO along the subpleural regions and bronchi, which absorbs in approximately 5 days.",195,COVID-19,3.0,Jpn J Infect Dis,Polymerase Chain Reaction;Other Topics,1.0286447961085569e-06,12.6,9.108278873559256e-07,31.0,0.0,Self-recorded/clinical,1. Risk identification,CT
32617690,10.1007/s00330-020-07044-9,Yes,PMC7331494,32617690.0,2020,2020-07-04,Comparative Study;Journal Article;Multicenter Study,Peer reviewed (PubMed),1,a deep learning approach to characterize 2019 coronavirus disease (covid-19) pneumonia in chest ct images,"To utilize a deep learning model for automatic detection of abnormalities in chest CT images from COVID-19 patients and compare its quantitative determination performance with radiological residents. A deep learning algorithm consisted of lesion detection, segmentation, and location was trained and validated in 14,435 participants with chest CT images and definite pathogen diagnosis. The algorithm was tested in a non-overlapping dataset of 96 confirmed COVID-19 patients in three hospitals across China during the outbreak. Quantitative detection performance of the model was compared with three radiological residents with two experienced radiologists' reading reports as reference standard by assessing the accuracy, sensitivity, specificity, and F1 score. Of 96 patients, 88 had pneumonia lesions on CT images and 8 had no abnormities on CT images. For per-patient basis, the algorithm showed superior sensitivity of 1.00 0.95, 1.00) and F1 score of 0.97 in detecting lesions from CT images of COVID-19 pneumonia patients. While for per-lung lobe basis, the algorithm achieved a sensitivity of 0.96 and a slightly inferior F1 score of 0.86. The median volume of lesions calculated by algorithm was 40.10 cm3. An average running speed of 20.3 s per case demonstrated the algorithm was much faster than the residents in assessing CT images (all p < 0.017). The deep learning algorithm can also assist radiologists make quicker diagnosis (all p < 0.0001) with superior diagnostic performance. The algorithm showed excellent performance in detecting COVID-19 pneumonia on chest CT images compared with resident radiologists. The higher sensitivity of deep learning model in detecting COVID-19 pneumonia were found compared with radiological residents on a per-lobe and per-patient basis. The deep learning model improves diagnosis efficiency by shortening processing time. The deep learning model can automatically calculate the volume of the lesions and whole lung.",291,COVID-19;Pneumonia,89.0,Eur Radiol,Coronavirus Infections;Disease Outbreaks;Radiologists,6.812225487248172e-06,210.44799999999887,1.3437166910709672e-05,498.0,0.0,External,2. Detection/Diagnosis,CT
32619398,10.1080/07391102.2020.1788642,Yes,,32619398.0,2020,2020-07-04,Journal Article,Peer reviewed (PubMed),1,classification of the covid-19 infected patients using densenet201 based deep transfer learning,"Deep learning models are widely used in the automatic analysis of radiological images. These techniques can train the weights of networks on large datasets as well as fine tuning the weights of pre-trained networks on small datasets. Due to the small COVID-19 dataset available, the pre-trained neural networks can be used for diagnosis of coronavirus. However, these techniques applied on chest CT image is very limited till now. Hence, the main aim of this paper to use the pre-trained deep learning architectures as an automated tool to detection and diagnosis of COVID-19 in chest CT. A DenseNet201 based deep transfer learning (DTL) is proposed to classify the patients as COVID infected or not i.e. COVID-19 or COVID. The proposed model is utilized to extract features by using its own learned weights on the ImageNet dataset along with a convolutional neural structure. Extensive experiments are performed to evaluate the performance of the propose DTL model on COVID-19 chest CT scan images. Comparative analyses reveal that the proposed DTL based COVID-19 classification model outperforms the competitive approaches.Communicated by Ramaswamy H. Sarma.",179,COVID-19,174.0,J Biomol Struct Dyn,Transfer Learning;Architecture;Neural Networks;Tomography,6.302995964819796e-06,218.75999999999885,1.2548188951994238e-05,477.0,0.0,External,2. Detection/Diagnosis,CT
32624700,10.7150/ijms.46684,Yes,PMC7330663,32624700.0,2020,2020-07-07,Journal Article;Validation Study,Peer reviewed (PubMed),1,efficient gan-based chest radiographs (cxr) augmentation to diagnose coronavirus disease pneumonia,"As 2019 ends coronavirus disease start expanding all over the world. It is highly transmissible disease that can affect respiratory tract and can leads to organ failure. In 2020 it is declared by world health organization as ""Public health emergency of international concerns"". The current situation of Covid-19 and chest related diseases have already gone through radical change with the advancements of image processing tools. There is no effective method which can accurately identify all chest related diseases and tackle the multiple class problems with reliable results. There are many potentially impactful applications of Deep Learning to fighting the Covid-19 from Chest X-Ray/CT Images, however, most are still in their early stages due to lack of data sharing as it continues to inhibit overall progress in a variety of medical research problems. Based on COVID-19 radiographical changes in CT images, this work aims to detect the possibility of COVID-19 in the patient. This work provides a significant contribution in terms of Gan based synthetic data and four different types of deep learning- based models which provided state of the art comparable results. A Deep Neural Network model provides a significant contribution in terms of detecting COVID-19 and provides effective analysis of chest related diseases with respect to age and gender. Our model achieves 89% accuracy in terms of Gan based synthetic data and four different types of deep learning- based models which provided state of the art comparable results. If the gap in identifying of all viral pneumonias is not filled with effective automation of chest disease detection the healthcare industry may have to bear unfavorable circumstances.",267,"COVID-19;Pneumonia;Pneumonia, Viral",23.0,Int J Med Sci,Coronavirus Infections;Public Health;Art;Health Care;World Health Organization;Neural Networks;Tomography,3.521578267472728e-06,41.34399999999998,3.1964263331502333e-06,134.0,0.0,External,2. Detection/Diagnosis,X-Ray
32646771,10.1016/j.jiph.2020.06.028,Yes,PMC7328559,32646771.0,2020,2020-07-11,Journal Article;Systematic Review,Peer reviewed (PubMed),1,systematic review of artificial intelligence techniques in the detection and classification of covid-19 medical images in terms of evaluation and benchmarking: taxonomy analysis challenges future solutions and methodological aspects,"This study presents a systematic review of artificial intelligence (AI) techniques used in the detection and classification of coronavirus disease 2019 (COVID-19) medical images in terms of evaluation and benchmarking. Five reliable databases, namely, IEEE Xplore, Web of Science, PubMed, ScienceDirect and Scopus were used to obtain relevant studies of the given topic. Several filtering and scanning stages were performed according to the inclusion/exclusion criteria to screen the 36 studies obtained; however, only 11 studies met the criteria. Taxonomy was performed, and the 11 studies were classified on the basis of two categories, namely, review and research studies. Then, a deep analysis and critical review were performed to highlight the challenges and critical gaps outlined in the academic literature of the given subject. Results showed that no relevant study evaluated and benchmarked AI techniques utilised in classification tasks (i.e. binary, multi-class, multi-labelled and hierarchical classifications) of COVID-19 medical images. In case evaluation and benchmarking will be conducted, three future challenges will be encountered, namely, multiple evaluation criteria within each classification task, trade-off amongst criteria and importance of these criteria. According to the discussed future challenges, the process of evaluation and benchmarking AI techniques used in the classification of COVID-19 medical images considered multi-complex attribute problems. Thus, adopting multi-criteria decision analysis (MCDA) is an essential and effective approach to tackle the problem complexity. Moreover, this study proposes a detailed methodology for the evaluation and benchmarking of AI techniques used in all classification tasks of COVID-19 medical images as future directions; such methodology is presented on the basis of three sequential phases. Firstly, the identification procedure for the construction of four decision matrices, namely, binary, multi-class, multi-labelled and hierarchical, is presented on the basis of the intersection of evaluation criteria of each classification task and AI classification techniques. Secondly, the development of the MCDA approach for benchmarking AI classification techniques is provided on the basis of the integrated analytic hierarchy process and VlseKriterijumska Optimizacija I Kompromisno Resenje methods. Lastly, objective and subjective validation procedures are described to validate the proposed benchmarking solutions.",340,COVID-19,84.0,J Infect Public Health,Radiography;Coronavirus Infections;Systematic Review;Classification;Tomography,8.448020544482756e-06,162.79199999999932,9.671786713354524e-06,407.0,0.0,,Review,Multimodal
32658740,10.1016/j.compbiomed.2020.103869,Yes,PMC7305745,32658740.0,2020,2020-07-14,Journal Article,Peer reviewed (PubMed),1,covxnet: a multi-dilation convolutional neural network for automatic covid-19 and other pneumonia detection from chest x-ray images with transferable multi-receptive feature optimization,"With the recent outbreak of COVID-19, fast diagnostic testing has become one of the major challenges due to the critical shortage of test kit. Pneumonia, a major effect of COVID-19, needs to be urgently diagnosed along with its underlying reasons. In this paper, deep learning aided automated COVID-19 and other pneumonia detection schemes are proposed utilizing a small amount of COVID-19 chest X-rays. A deep convolutional neural network (CNN) based architecture, named as CovXNet, is proposed that utilizes depthwise convolution with varying dilation rates for efficiently extracting diversified features from chest X-rays. Since the chest X-ray images corresponding to COVID-19 caused pneumonia and other traditional pneumonias have significant similarities, at first, a large number of chest X-rays corresponding to normal and (viral/bacterial) pneumonia patients are used to train the proposed CovXNet. Learning of this initial training phase is transferred with some additional fine-tuning layers that are further trained with a smaller number of chest X-rays corresponding to COVID-19 and other pneumonia patients. In the proposed method, different forms of CovXNets are designed and trained with X-ray images of various resolutions and for further optimization of their predictions, a stacking algorithm is employed. Finally, a gradient-based discriminative localization is integrated to distinguish the abnormal regions of X-ray images referring to different types of pneumonia. Extensive experimentations using two different datasets provide very satisfactory detection performance with accuracy of 97.4% for COVID/Normal, 96.9% for COVID/Viral pneumonia, 94.7% for COVID/Bacterial pneumonia, and 90.2% for multiclass COVID/normal/Viral/Bacterial pneumonias. Hence, the proposed schemes can serve as an efficient tool in the current state of COVID-19 pandemic. All the architectures are made publicly available at: GitHub",270,"COVID-19;COVID-19 Pandemic;Pneumonia;Pneumonia, Bacterial;Pneumonia, Viral",166.0,Comput Biol Med,Radiography;Coronavirus Infections;Reproducibility of Results;Algorithms;Transfer Learning;Diagnostic Tests;Architecture;Disease Outbreaks;COVID-19 Testing;Image Processing;Neural Networks;Paper,1.852652226323401e-05,526.5280000000143,3.2020292284443666e-05,1256.0,0.0,External,2. Detection/Diagnosis,X-Ray
32666395,10.1007/s00259-020-04953-1,Yes,PMC7358997,32666395.0,2020,2020-07-16,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,automated detection and quantification of covid-19 pneumonia: ct imaging analysis by a deep learning-based software,"The novel coronavirus disease 2019 (COVID-19) is an emerging worldwide threat to public health. While chest computed tomography (CT) plays an indispensable role in its diagnosis, the quantification and localization of lesions cannot be accurately assessed manually. We employed deep learning-based software to aid in detection, localization and quantification of COVID-19 pneumonia. A total of 2460 RT-PCR tested SARS-CoV-2-positive patients (1250 men and 1210 women; mean age, 57.7 years (age range, 11-93 years) were retrospectively identified from Huoshenshan Hospital in Wuhan from February 11 to March 16, 2020. Basic clinical characteristics were reviewed. The uAI Intelligent Assistant Analysis System was used to assess the CT scans. CT scans of 2215 patients showed multiple lesions of which 36 and 50 patients had left and right lung infections, respectively (> 50% of each affected lung's volume), while 27 had total lung infection (> 50% of the total volume of both lungs). Overall, 298 and 1300 patients exhibited pure ground glass opacities (GGOs), GGOs with sub-solid lesions and GGOs with both sub-solid and solid lesions, respectively. Moreover, 2305 and 71 patients presented primarily with GGOs and sub-solid lesions, respectively. Elderly patients (≥ 60 years) were more likely to exhibit sub-solid lesions. The generalized linear mixed model showed that the dorsal segment of the right lower lobe was the favoured site of COVID-19 pneumonia. Chest CT combined with analysis by the uAI Intelligent Assistant Analysis System can accurately evaluate pneumonia in COVID-19 patients.",239,COVID-19;Infections;Pneumonia,49.0,Eur J Nucl Med Mol Imaging,Coronavirus Infections;Public Health;COVID-19 Testing;Polymerase Chain Reaction;Retrospective Studies,4.962980085240952e-06,122.1919999999996,6.14413451785593e-06,358.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32683550,10.1007/s00330-020-07042-x,Yes,PMC7368602,32683550.0,2020,2020-07-20,Journal Article,Peer reviewed (PubMed),1,from community-acquired pneumonia to covid-19: a deep learning-based method for quantitative analysis of covid-19 on thick-section ct scans,"To develop a fully automated AI system to quantitatively assess the disease severity and disease progression of COVID-19 using thick-section chest CT images. In this retrospective study, an AI system was developed to automatically segment and quantify the COVID-19-infected lung regions on thick-section chest CT images. Five hundred thirty-one CT scans from 204 COVID-19 patients were collected from one appointed COVID-19 hospital. The automatically segmented lung abnormalities were compared with manual segmentation of two experienced radiologists using the Dice coefficient on a randomly selected subset (30 CT scans). Two imaging biomarkers were automatically computed, i.e., the portion of infection (POI) and the average infection HU (iHU), to assess disease severity and disease progression. The assessments were compared with patient status of diagnosis reports and key phrases extracted from radiology reports using the AUC and Cohen's kappa, respectively. The dice coefficient between the segmentation of the AI system and two experienced radiologists for the COVID-19-infected lung abnormalities was 0.74 and 0.76, respectively, which were close to the inter-observer agreement. The computed two imaging biomarkers can distinguish between the severe and non-severe stages with an AUC of 0.97 (p value < 0.001). Very good agreement between the AI system and the radiologists was achieved on evaluating the changes in infection volumes. A deep learning-based AI system built on the thick-section CT imaging can accurately quantify the COVID-19-associated lung abnormalities and assess the disease severity and its progressions. A deep learning-based AI system was able to accurately segment the infected lung regions by COVID-19 using the thick-section CT scans (Dice coefficient ≥ 0.74). The computed imaging biomarkers were able to distinguish between the non-severe and severe COVID-19 stages (AUC 0.97). The infection volume changes computed by the AI system were able to assess the COVID-19 progression (Cohen's kappa 0.8220).",296,COVID-19;Disease Progression;Infections;Pneumonia,54.0,Eur Radiol,Coronavirus Infections;Radiologists;ROC Curve;Retrospective Studies;Lung Diseases;Age;Receiver Operating Characteristic,6.409555672356609e-06,212.7359999999988,1.3260696739773588e-05,498.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
32700269,10.1007/s11356-020-10133-3,Yes,PMC7375456,32700269.0,2020,2020-07-24,Journal Article,Peer reviewed (PubMed),1,drawing insights from covid-19-infected patients using ct scan images and machine learning techniques: a study on 200 patients,"As the whole world is witnessing what novel coronavirus (COVID-19) can do to the mankind, it presents several unique features also. In the absence of specific vaccine for COVID-19, it is essential to detect the disease at an early stage and isolate an infected patient. Till today there is a global shortage of testing labs and testing kits for COVID-19. This paper discusses about the role of machine learning techniques for getting important insights like whether lung computed tomography (CT) scan should be the first screening/alternative test for real-time reverse transcriptase-polymerase chain reaction (RT-PCR), is COVID-19 pneumonia different from other viral pneumonia and if yes how to distinguish it using lung CT scan images from the carefully selected data of lung CT scan COVID-19-infected patients from the hospitals of Italy, China, Moscow and India? For training and testing the proposed system, custom vision software of Microsoft azure based on machine learning techniques is used. An overall accuracy of almost 91% is achieved for COVID-19 classification using the proposed methodology.",169,"COVID-19;Pneumonia;Pneumonia, Viral",34.0,Environ Sci Pollut Res Int,Coronavirus Infections;Polymerase Chain Reaction,2.7538286469447265e-06,44.368000000000016,2.8655607961636097e-06,142.0,0.0,External,2. Detection/Diagnosis,CT
32703538,10.1067/j.cpradiol.2020.06.009,Yes,PMC7320858,32703538.0,2020,2020-07-25,Journal Article;Review,Peer reviewed (PubMed),1,current landscape of imaging and the potential role for artificial intelligence in the management of covid-19,"The clinical management of COVID-19 is challenging. Medical imaging plays a critical role in the early detection, clinical monitoring and outcomes assessment of this disease. Chest x-ray radiography and computed tomography) are the standard imaging modalities used for the structural assessment of the disease status, while functional imaging (namely, positron emission tomography) has had limited application. Artificial intelligence can enhance the predictive power and utilization of these imaging approaches and new approaches focusing on detection, stratification and prognostication are showing encouraging results. We review the current landscape of these imaging modalities and artificial intelligence approaches as applied in COVID-19 management.",100,COVID-19,8.0,Curr Probl Diagn Radiol,Health Care;Other Topics,1.501707335457858e-06,17.928,1.3308825493222297e-06,53.0,0.0,,Review,Multimodal
32706819,10.1371/journal.pone.0236858,Yes,PMC7380626,32706819.0,2020,2020-07-25,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,quantitative lung lesion features and temporal changes on chest ct in patients with common and severe sars-cov-2 pneumonia,"The purpose of this study was to describe the temporal evolution of quantitative lung lesion features on chest computed tomography (CT) in patients with common and severe types of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pneumonia. Records of patients diagnosed with SARS-CoV-2 pneumonia were reviewed retrospectively from 24 January 2020 to 15 March 2020. Patients were classified into common and severe groups according to the diagnostic criteria of severe pneumonia. The quantitative CT features of lung lesions were automatically calculated using artificial intelligence algorithms, and the percentages of ground-glass opacity volume (PGV), consolidation volume (PCV) and total lesion volume (PTV) were determined in both lungs. PGV, PCV and PTV were analyzed based on the time from the onset of initial symptoms in the common and severe groups. In the common group, PTV increased slowly and peaked at approximately 12 days from the onset of the initial symptoms. In the severe group, PTV peaked at approximately 17 days. The severe pneumonia group exhibited increased PGV, PCV and PTV compared with the common group. These features started to appear in Stage 2 (4-7 days from onset of initial symptoms) and were observed in all subsequent stages (p<0.05). In severe SARS-CoV-2 pneumonia patients, PGV, PCV and PTV began to significantly increase in Stage 2 and decrease in Stage 5 (22-30 days). Compared with common SARS-CoV-2 pneumonia patients, the patients in the severe group exhibited increased PGV, PCV and PTV as well as a later peak time of lesion and recovery time.",249,Pneumonia;Severe Acute Respiratory Syndrome,10.0,PLoS One,Coronavirus Infections;Retrospective Studies,4.785470043044064e-06,107.0559999999998,4.475632623127384e-06,348.0,0.0,Self-recorded/clinical,5. Post-hoc,CT
32719039,10.1136/annrheumdis-2020-218048,Yes,PMC7456556,32719039.0,2020,2020-07-29,Comparative Study;Journal Article,Peer reviewed (PubMed),1,lung involvement in macrophage activation syndrome and severe covid-19: results from a cross-sectional study to assess clinical laboratory and artificial intelligence-radiological differences,"To evaluate the clinical pictures, laboratory tests and imaging of patients with lung involvement, either from severe COVID-19 or macrophage activation syndrome (MAS), in order to assess how similar these two diseases are. The present work has been designed as a cross-sectional single-centre study to compare characteristics of patients with lung involvement either from MAS or severe COVID-19. Chest CT scans were assessed by using an artificial intelligence (AI)-based software. Ten patients with MAS and 47 patients with severe COVID-19 with lung involvement were assessed. Although all patients showed fever and dyspnoea, patients with MAS were characterised by thrombocytopaenia, whereas patients with severe COVID-19 were characterised by lymphopaenia and neutrophilia. Higher values of H-score characterised patients with MAS when compared with severe COVID-19. AI-reconstructed images of chest CT scan showed that apical, basal, peripheral and bilateral distributions of ground-glass opacities (GGOs), as well as apical consolidations, were more represented in severe COVID-19 than in MAS. C reactive protein directly correlated with GGOs extension in both diseases. Furthermore, lymphopaenia inversely correlated with GGOs extension in severe COVID-19. Our data could suggest laboratory and radiological differences between MAS and severe COVID-19, paving the way for further hypotheses to be investigated in future confirmatory studies.",202,COVID-19;Fever;Macrophage Activation Syndrome,28.0,Ann Rheum Dis,Coronavirus Infections;C-Reactive Protein;Retrospective Studies,2.818243720315901e-06,30.552,1.7478158886238013e-06,121.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
32722697,10.1371/journal.pone.0236621,Yes,PMC7386587,32722697.0,2020,2020-07-30,Journal Article,Peer reviewed (PubMed),1,deep transfer learning artificial intelligence accurately stages covid-19 lung disease severity on portable chest radiographs,"This study employed deep-learning convolutional neural networks to stage lung disease severity of Coronavirus Disease 2019 (COVID-19) infection on portable chest x-ray (CXR) with radiologist score of disease severity as ground truth. This study consisted of 131 portable CXR from 84 COVID-19 patients (51M 55.1yo; 29F 60.1yo; 4 missing information). Three expert chest radiologists scored the left and right lung separately based on the degree of opacity and geographic extent. Deep-learning convolutional neural network (CNN) was used to predict lung disease severity scores. Data were split into 80% training and 20% testing datasets. Correlation analysis between AI-predicted versus radiologist scores were analyzed. Comparison was made with traditional and transfer learning. The average opacity score was 2.52 (range: 0-6) with a standard deviation of 0.25 across three readers. The average geographic extent score was 3.42 (range: 0-8) with a standard deviation of 0.57 across three readers. The inter-rater agreement yielded a Fleiss' Kappa of 0.45 for opacity score and 0.71 for extent score. AI-predicted scores strongly correlated with radiologist scores, with the top model yielding a correlation coefficient (R2) of 0.90 (range: 0.73-0.90 for traditional learning and 0.83-0.90 for transfer learning) and a mean absolute error of 8.5% (ranges: 17.2-21.0% and 8.5%-15.5, respectively). Transfer learning generally performed better. In conclusion, deep-learning CNN accurately stages disease severity on portable chest x-ray of COVID-19 lung infection. This approach may prove useful to stage lung disease severity, prognosticate, and predict treatment response and survival, thereby informing risk management and resource allocation.",247,COVID-19;Infections;Lung Diseases,65.0,PLoS One,Other Topics,4.260308412047282e-06,83.4559999999998,5.107425485021558e-06,230.0,0.0,External,3. Monitoring/Severity assessment,X-Ray
32729263,10.3348/kjr.2020.0536,Yes,PMC7458860,32729263.0,2020,2020-07-31,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,implementation of a deep learning-based computer-aided detection system for the interpretation of chest radiographs in patients suspected for covid-19,"To describe the experience of implementing a deep learning-based computer-aided detection (CAD) system for the interpretation of chest X-ray radiographs (CXR) of suspected coronavirus disease (COVID-19) patients and investigate the diagnostic performance of CXR interpretation with CAD assistance. In this single-center retrospective study, initial CXR of patients with suspected or confirmed COVID-19 were investigated. A commercialized deep learning-based CAD system that can identify various abnormalities on CXR was implemented for the interpretation of CXR in daily practice. The diagnostic performance of radiologists with CAD assistance were evaluated based on two different reference standards: 1) real-time reverse transcriptase-polymerase chain reaction (rRT-PCR) results for COVID-19 and 2) pulmonary abnormality suggesting pneumonia on chest CT. The turnaround times (TATs) of radiology reports for CXR and rRT-PCR results were also evaluated. Among 332 patients (male:female, 173:159; mean age, 57 years) with available rRT-PCR results, 16 patients were diagnosed with COVID-19. Using CXR, radiologists with CAD assistance identified rRT-PCR positive COVID-19 patients with sensitivity and specificity of 68.8% and 66.7%, respectively. Among 119 patients (male:female, 75:44; mean age, 69 years) with available chest CTs, radiologists assisted by CAD reported pneumonia on CXR with a sensitivity of 81.5% and a specificity of 72.3%. The TATs of CXR reports were significantly shorter than those of rRT-PCR results (median 51 vs. 507 minutes; p < 0.001). Radiologists with CAD assistance could identify patients with rRT-PCR-positive COVID-19 or pneumonia on CXR with a reasonably acceptable performance. In patients suspected with COVID-19, CXR had much faster TATs than rRT-PCRs.",249,COVID-19;Pneumonia,33.0,Korean J Radiol,Coronavirus Infections;COVID-19 Testing;Polymerase Chain Reaction;Retrospective Studies,6.777693798141202e-06,145.0639999999996,8.001561283330044e-06,423.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,Multimodal
32729810,10.1148/radiol.2020202439,Yes,PMC7393955,32729810.0,2020,2020-07-31,Journal Article;Multicenter Study,Peer reviewed (PubMed),1,automated assessment of covid-19 reporting and data system and chest ct severity scores in patients suspected of having covid-19 using artificial intelligence,"Background The coronavirus disease 2019 (COVID-19) pandemic has spread across the globe with alarming speed, morbidity, and mortality. Immediate triage of patients with chest infections suspected to be caused by COVID-19 using chest CT may be of assistance when results from definitive viral testing are delayed. Purpose To develop and validate an artificial intelligence (AI) system to score the likelihood and extent of pulmonary COVID-19 on chest CT scans using the COVID-19 Reporting and Data System (CO-RADS) and CT severity scoring systems. The CO-RADS AI system consists of three deep-learning algorithms that automatically segment the five pulmonary lobes, assign a CO-RADS score for the suspicion of COVID-19, and assign a CT severity score for the degree of parenchymal involvement per lobe. This study retrospectively included patients who underwent a nonenhanced chest CT examination because of clinical suspicion of COVID-19 at two medical centers. The system was trained, validated, and tested with data from one of the centers. Data from the second center served as an external test set. Diagnostic performance and agreement with scores assigned by eight independent observers were measured using receiver operating characteristic analysis, linearly weighted κ values, and classification accuracy. Results A total of 105 patients (mean age, 62 years ; 61 men) and 262 patients (mean age, 64 years ; 154 men) were evaluated in the internal and external test sets, respectively. The system discriminated between patients with COVID-19 and those without COVID-19, with areas under the receiver operating characteristic curve of 0.95 and 0.88, for the internal and external test sets, respectively. Agreement with the eight human observers was moderate to substantial, with mean linearly weighted κ values of 0.60 for CO-RADS scores and 0.54 for CT severity scores. Conclusion With high diagnostic performance, the CO-RADS AI system correctly identified patients with COVID-19 using chest CT scans and assigned standardized CO-RADS and CT severity scores that demonstrated good agreement with findings from eight independent observers and generalized well to external data.",326,COVID-19;COVID-19 Pandemic;Infections,82.0,Radiology,Severity of Illness Index;Retrospective Studies;Receiver Operating Characteristic,5.01738479577851e-06,146.29599999999934,7.769154831326799e-06,371.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32730214,10.1109/TMI.2020.3001810,Yes,PMC8769013,32730214.0,2020,2020-07-31,Journal Article,Peer reviewed (PubMed),1,a rapid accurate and machine-agnostic segmentation and quantification method for ct-based covid-19 diagnosis,"COVID-19 has caused a global pandemic and become the most urgent threat to the entire world. Tremendous efforts and resources have been invested in developing diagnosis, prognosis and treatment strategies to combat the disease. Although nucleic acid detection has been mainly used as the gold standard to confirm this RNA virus-based disease, it has been shown that such a strategy has a high false negative rate, especially for patients in the early stage, and thus CT imaging has been applied as a major diagnostic modality in confirming positive COVID-19. Despite the various, urgent advances in developing artificial intelligence (AI)-based computer-aided systems for CT-based COVID-19 diagnosis, most of the existing methods can only perform classification, whereas the state-of-the-art segmentation method requires a high level of human intervention. In this paper, we propose a fully-automatic, rapid, accurate, and machine-agnostic method that can segment and quantify the infection regions on CT scans from different sources. Our method is founded upon two innovations: 1) the first CT scan simulator for COVID-19, by fitting the dynamic change of real patients' data measured at different time points, which greatly alleviates the data scarcity issue; and 2) a novel deep learning algorithm to solve the large-scene-small-object problem, which decomposes the 3D segmentation problem into three 2D ones, and thus reduces the model complexity by an order of magnitude and, at the same time, significantly improves the segmentation accuracy. Comprehensive experimental results over multi-country, multi-hospital, and multi-machine datasets demonstrate the superior performance of our method over the existing ones and suggest its important application value in combating the disease.",261,COVID-19;Infections,69.0,IEEE Trans Med Imaging,Coronavirus Infections;Art;Algorithms;Tomography;Lung Diseases,3.9922331171424415e-06,69.49600000000001,4.633574448259453e-06,201.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
32730215,10.1109/TMI.2020.3000314,Yes,,32730215.0,2020,2020-07-31,Journal Article,Peer reviewed (PubMed),1,a noise-robust framework for automatic segmentation of covid-19 pneumonia lesions from ct images,"Segmentation of pneumonia lesions from CT scans of COVID-19 patients is important for accurate diagnosis and follow-up. Deep learning has a potential to automate this task but requires a large set of high-quality annotations that are difficult to collect. Learning from noisy training labels that are easier to obtain has a potential to alleviate this problem. To this end, we propose a novel noise-robust framework to learn from noisy labels for the segmentation task. We first introduce a noise-robust Dice loss that is a generalization of Dice loss for segmentation and Mean Absolute Error (MAE) loss for robustness against noise, then propose a novel COVID-19 Pneumonia Lesion segmentation network (COPLE-Net) to better deal with the lesions with various scales and appearances. The noise-robust Dice loss and COPLE-Net are combined with an adaptive self-ensembling framework for training, where an Exponential Moving Average (EMA) of a student model is used as a teacher model that is adaptively updated by suppressing the contribution of the student to EMA when the student has a large training loss. The student model is also adaptive by learning from the teacher only when the teacher outperforms the student. Experimental results showed that: our noise-robust Dice loss outperforms existing noise-robust loss functions, the proposed COPLE-Net achieves higher performance than state-of-the-art image segmentation networks, and our framework with adaptive self-ensembling significantly outperforms a standard training process and surpasses other noise-robust training approaches in the scenario of learning from noisy labels for COVID-19 pneumonia lesion segmentation.",246,COVID-19;Pneumonia,129.0,IEEE Trans Med Imaging,Coronavirus Infections;Art;Algorithms;Noise;Tomography,6.421126175913337e-06,102.83199999999964,7.052472584414951e-06,264.0,0.0,Self-recorded/clinical,Segmentation-only,CT
32730216,10.1109/TMI.2020.2995108,Yes,PMC7393217,32730216.0,2020,2020-07-31,"Journal Article;Research Support, N.I.H., Extramural",Peer reviewed (PubMed),1,relational modeling for robust and efficient pulmonary lobe segmentation in ct scans,"Pulmonary lobe segmentation in computed tomography scans is essential for regional assessment of pulmonary diseases. Recent works based on convolution neural networks have achieved good performance for this task. However, they are still limited in capturing structured relationships due to the nature of convolution. The shape of the pulmonary lobes affect each other and their borders relate to the appearance of other structures, such as vessels, airways, and the pleural wall. We argue that such structural relationships play a critical role in the accurate delineation of pulmonary lobes when the lungs are affected by diseases such as COVID-19 or COPD. In this paper, we propose a relational approach (RTSU-Net) that leverages structured relationships by introducing a novel non-local neural network module. The proposed module learns both visual and geometric relationships among all convolution features to produce self-attention weights. With a limited amount of training data available from COVID-19 subjects, we initially train and validate RTSU-Net on a cohort of 5000 subjects from the COPDGene study (4000 for training and 1000 for evaluation). Using models pre-trained on COPDGene, we apply transfer learning to retrain and evaluate RTSU-Net on 470 COVID-19 suspects (370 for retraining and 100 for evaluation). Experimental results show that RTSU-Net outperforms three baselines and performs robustly on cases with severe lung infection due to COVID-19.",217,"COVID-19;Infections;Lung Diseases;Pulmonary Disease, Chronic Obstructive",45.0,IEEE Trans Med Imaging,Coronavirus Infections;Transfer Learning;Algorithms;Lung;Neural Networks;Tomography,2.431832081617769e-06,29.344,2.0253439241673902e-06,90.0,0.0,Self-recorded/clinical,Segmentation-only,CT
32742318,10.3892/etm.2020.8797,Yes,PMC7388253,32742318.0,2020,2020-08-04,Journal Article,Peer reviewed (PubMed),1,interpretable artificial intelligence framework for covid-19 screening on chest x-rays,"COVID-19 has led to an unprecedented healthcare crisis with millions of infected people across the globe often pushing infrastructures, healthcare workers and entire economies beyond their limits. The scarcity of testing kits, even in developed countries, has led to extensive research efforts towards alternative solutions with high sensitivity. Chest radiological imaging paired with artificial intelligence (AI) can offer significant advantages in diagnosis of novel coronavirus infected patients. To this end, transfer learning techniques are used for overcoming the limitations emanating from the lack of relevant big datasets, enabling specialized models to converge on limited data, as in the case of X-rays of COVID-19 patients. In this study, we present an interpretable AI framework assessed by expert radiologists on the basis on how well the attention maps focus on the diagnostically-relevant image regions. The proposed transfer learning methodology achieves an overall AUC of 1 for a binary classification problem across a 5-fold training/testing dataset.",153,COVID-19,45.0,Exp Ther Med,Health Care;Transfer Learning;Research Personnel;Health;Map,1.9982100521248745e-06,22.032000000000007,1.6959236671478226e-06,62.0,0.0,External,2. Detection/Diagnosis,X-Ray
32750973,10.1109/JBHI.2020.3012383,Yes,PMC8545159,32750973.0,2020,2020-08-06,"Journal Article;Research Support, Non-U.S. Gov't;Validation Study",Peer reviewed (PubMed),1,introducing the gev activation function for highly unbalanced data to develop covid-19 diagnostic models,"Fast and accurate diagnosis is essential for the efficient and effective control of the COVID-19 pandemic that is currently disrupting the whole world. Despite the prevalence of the COVID-19 outbreak, relatively few diagnostic images are openly available to develop automatic diagnosis algorithms. Traditional deep learning methods often struggle when data is highly unbalanced with many cases in one class and only a few cases in another; new methods must be developed to overcome this challenge. We propose a novel activation function based on the generalized extreme value (GEV) distribution from extreme value theory, which improves performance over the traditional sigmoid activation function when one class significantly outweighs the other. We demonstrate the proposed activation function on a publicly available dataset and externally validate on a dataset consisting of 1,909 healthy chest X-rays and 84 COVID-19 X-rays. The proposed method achieves an improved AUC (DeLong's p-value < 0.05) compared to the sigmoid activation. Our method is also demonstrated on a dataset of healthy and pneumonia vs. COVID-19 X-rays and a set of computerized tomography images, achieving improved sensitivity. The proposed GEV activation function significantly improves upon the previously used sigmoid activation for binary classification. This new paradigm is expected to play a significant role in the fight against COVID-19 and other diseases, with relatively few training cases available.",217,COVID-19;COVID-19 Pandemic;Pneumonia,11.0,IEEE J Biomed Health Inform,Coronavirus Infections;Disease Outbreaks;COVID-19 Testing;Neural Networks,3.0411813079235347e-06,36.184000000000005,2.519138556921805e-06,131.0,0.0,External,2. Detection/Diagnosis,Multimodal
32758014,10.1259/bjr.20200538,Yes,PMC7465853,32758014.0,2020,2020-08-08,Journal Article;Review,Peer reviewed (PubMed),1,imaging of covid-19 pneumonia: patterns pathogenesis and advances,"COVID-19 pneumonia is a newly recognized lung infection. Initially, CT imaging was demonstrated to be one of the most sensitive tests for the detection of infection. Currently, with broader availability of polymerase chain reaction for disease diagnosis, CT is mainly used for the identification of complications and other defined clinical indications in hospitalized patients. Nonetheless, radiologists are interpreting lung imaging in unsuspected patients as well as in suspected patients with imaging obtained to rule out other relevant clinical indications. The knowledge of pathological findings is also crucial for imagers to better interpret various imaging findings. Identification of the imaging findings that are commonly seen with the disease is important to diagnose and suggest confirmatory testing in unsuspected cases. Proper precautionary measures will be important in such unsuspected patients to prevent further spread. In addition to understanding the imaging findings for the diagnosis of the disease, it is important to understand the growing set of tools provided by artificial intelligence. The goal of this review is to highlight common imaging findings using illustrative examples, describe the evolution of disease over time, discuss differences in imaging appearance of adult and pediatric patients and review the available literature on quantitative CT for COVID-19. We briefly address the known pathological findings of the COVID-19 lung disease that may help better understand the imaging appearance, and we provide a demonstration of novel display methodologies and artificial intelligence applications serving to support clinical observations.",238,COVID-19;Infections;Lung Diseases;Pneumonia,20.0,Br J Radiol,Coronavirus Infections;Polymerase Chain Reaction,2.0060019633991088e-06,25.70399999999999,1.4342286326444234e-06,97.0,0.0,,Review,Multimodal
32760732,10.3389/fmed.2020.00427,Yes,PMC7371960,32760732.0,2020,2020-08-08,Journal Article,Peer reviewed (PubMed),1,deep learning-based decision-tree classifier for covid-19 diagnosis from chest x-ray imaging,"The global pandemic of coronavirus disease 2019 (COVID-19) has resulted in an increased demand for testing, diagnosis, and treatment. Reverse transcription polymerase chain reaction (RT-PCR) is the definitive test for the diagnosis of COVID-19; however, chest X-ray radiography (CXR) is a fast, effective, and affordable test that identifies the possible COVID-19-related pneumonia. This study investigates the feasibility of using a deep learning-based decision-tree classifier for detecting COVID-19 from CXR images. The proposed classifier comprises three binary decision trees, each trained by a deep learning model with convolution neural network based on the PyTorch frame. The first decision tree classifies the CXR images as normal or abnormal. The second tree identifies the abnormal images that contain signs of tuberculosis, whereas the third does the same for COVID-19. The accuracies of the first and second decision trees are 98 and 80%, respectively, whereas the average accuracy of the third decision tree is 95%. The proposed deep learning-based decision-tree classifier may be used in pre-screening patients to conduct triage and fast-track decision making before RT-PCR results are available.",175,COVID-19;Pneumonia;Tuberculosis,81.0,Front Med (Lausanne),Pneumonia;Polymerase Chain Reaction;Decision Trees;Reverse Transcription,5.35046498858908e-06,71.83199999999997,5.609686466101447e-06,183.0,0.0,External,2. Detection/Diagnosis,X-Ray
32767351,10.26355/eurrev_202008_22510,Yes,,32767351.0,2020,2020-08-09,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,analysis of clinical features and imaging signs of covid-19 with the assistance of artificial intelligence,"To explore the CT imaging features/signs of patients with different clinical types of Coronavirus Disease 2019 (COVID-19) via the application of artificial intelligence (AI), thus improving the understanding of COVID-19. Clinical data and chest CT imaging features of 58 patients confirmed with COVID-19 in the Fifth Medical Center of PLA General Hospital were retrospectively analyzed. According to the Guidelines on Novel Coronavirus-Infected Pneumonia Diagnosis and Treatment (Provisional 6th Edition), COVID-19 patients were divided into mild type, common type, severe type and critical type (10 patients). The CT imaging features of the patients with different clinical types of COVID-19 types were analyzed, and the volume percentage of pneumonia lesions with respect to the lung lobes (where the lesion was located) and to the whole lung was calculated with the use of AI software. SPSS 21.0 software was used for statistical analysis. Common clinical manifestations of COVID-19 patients: fever was found in 47 patients, cough in 31 and weakness in 10. Laboratory examinations: normal or decreased white blood cell (WBC) counts were observed in 52 patients, decreased lymphocyte counts (LCs) in 14 and increased C-reactive protein (CRP) levels in 18. CT imaging features: there were 48 patients with lesions distributed in both lungs and 46 patients had lesions most visible in the lower lungs; the primary manifestations in patients with common type COVID-19 were ground-glass opacities (GGOs) or mixed type, with lesions mainly distributed in the periphery of the lungs ; the primary manifestations of patients with severe/critical type COVID-19 were consolidations or mixed type, with lesions distributed in both the peripheral and central areas of lungs ; other common signs, including pleural parallel signs, halo signs, vascular thickening signs, crazy-paving signs and air bronchogram signs, were visible in patients with different clinical types, and pleural effusion was found in 5 patients with severe/critical COVID-19. AI software was used to calculate the volume percentages of pneumonia lesions with respect to the lung lobes (where the lesion was located) and to the whole lung. There were significant differences in the volume percentages of pneumonia lesions for the superior lobe of the left lung, the inferior lobe of the left lung, the superior lobe of the right lung, the inferior lobe of the right lung and the whole lung among patients with different clinical types (p<0.05). The AUC of the volume percentage of pneumonia lesions for the whole lung for the diagnosis of severe/critical type COVID-19 was 0.740, with sensitivity and specificity of 91.2% and 58.8%, respectively. The clinical and CT imaging features of COVID-19 patients were characteristic to a certain degree; thus, the clinical course and severity of COVID-19 could be evaluated with a combination of an analysis of clinical features and CT imaging features and assistant diagnosis by AI software.",458,COVID-19;Clinical Course;Cough;Fever;Pleural Effusion;Pneumonia,10.0,Eur Rev Med Pharmacol Sci,Severity of Illness Index;Coronavirus Infections;C-Reactive Protein;Critical Illness;ROC Curve;Retrospective Studies;Age,1.455366378299023e-05,384.280000000008,1.548802293260227e-05,1195.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
32773400,10.3233/XST-200715,Yes,PMC7592691,32773400.0,2020,2020-08-11,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,identification of covid-19 samples from chest x-ray images using deep learning: a comparison of transfer learning approaches,"The novel coronavirus disease 2019 (COVID-19) constitutes a public health emergency globally. The number of infected people and deaths are proliferating every day, which is putting tremendous pressure on our social and healthcare system. Rapid detection of COVID-19 cases is a significant step to fight against this virus as well as release pressure off the healthcare system. One of the critical factors behind the rapid spread of COVID-19 pandemic is a lengthy clinical testing time. The imaging tool, such as Chest X-ray (CXR), can speed up the identification process. Therefore, our objective is to develop an automated CAD system for the detection of COVID-19 samples from healthy and pneumonia cases using CXR images. Due to the scarcity of the COVID-19 benchmark dataset, we have employed deep transfer learning techniques, where we examined 15 different pre-trained CNN models to find the most suitable one for this task. A total of 860 images (260 COVID-19 cases, 300 healthy and 300 pneumonia cases) have been employed to investigate the performance of the proposed algorithm, where 70% images of each class are accepted for training, 15% is used for validation, and rest is for testing. It is observed that the VGG19 obtains the highest classification accuracy of 89.3% with an average precision, recall, and F1 score of 0.90, 0.89, 0.90, respectively. This study demonstrates the effectiveness of deep transfer learning techniques for the identification of COVID-19 cases using CXR images.",236,COVID-19;COVID-19 Pandemic;Death;Pneumonia,94.0,J Xray Sci Technol,Coronavirus Infections;Public Health;Health Care;Transfer Learning;Algorithms;Neural Networks;Health Care Systems;Tomography,1.1703676298860871e-05,339.3600000000041,2.0449767396099103e-05,834.0,0.0,External,2. Detection/Diagnosis,X-Ray
32781377,10.1016/j.media.2020.101794,Yes,PMC7372265,32781377.0,2020,2020-08-12,"Journal Article;Research Support, N.I.H., Extramural",Peer reviewed (PubMed),1,deep-covid: predicting covid-19 from chest x-ray images using deep transfer learning,"The COVID-19 pandemic is causing a major outbreak in more than 150 countries around the world, having a severe impact on the health and life of many people globally. One of the crucial step in fighting COVID-19 is the ability to detect the infected patients early enough, and put them under special care. Detecting this disease from radiography and radiology images is perhaps one of the fastest ways to diagnose the patients. Some of the early studies showed specific abnormalities in the chest radiograms of patients infected with COVID-19. Inspired by earlier works, we study the application of deep learning models to detect COVID-19 patients from their chest radiography images. We first prepare a dataset of 5000 Chest X-rays from the publicly available datasets. Images exhibiting COVID-19 disease presence were identified by board-certified radiologist. Transfer learning on a subset of 2000 radiograms was used to train four popular convolutional neural networks, including ResNet18, ResNet50, SqueezeNet, and DenseNet-121, to identify COVID-19 disease in the analyzed chest X-ray images. We evaluated these models on the remaining 3000 images, and most of these networks achieved a sensitivity rate of 98%, while having a specificity rate of around 90%. Besides sensitivity and specificity rates, we also present the receiver operating characteristic (ROC) curve, precision-recall curve, average prediction, and confusion matrix of each model. We also used a technique to generate heatmaps of lung regions potentially infected by COVID-19 and show that the generated heatmaps contain most of the infected areas annotated by our board certified radiologist. While the achieved performance is very encouraging, further analysis is required on a larger set of COVID-19 images, to have a more reliable estimation of accuracy rates. The dataset, model implementations (in PyTorch), and evaluations, are all made publicly available for research community at GitHub",297,COVID-19;COVID-19 Pandemic;Confusion,275.0,Med Image Anal,Coronavirus Infections;Transfer Learning;COVID-19 Testing;Lung;Radiologists;Neural Networks;Research;Radiography;Disease Outbreaks;Predictive Value;Sensitivity and Specificity;ROC Curve;Lung Diseases;Receiver Operating Characteristic,1.1703208375032349e-05,372.59200000000567,2.1671861998899573e-05,878.0,0.0,External,2. Detection/Diagnosis,X-Ray
32787937,10.1186/s12938-020-00807-x,Yes,PMC7422684,32787937.0,2020,2020-08-14,Journal Article,Peer reviewed (PubMed),1,rapid identification of covid-19 severity in ct scans through classification of deep features,"Chest CT is used for the assessment of the severity of patients infected with novel coronavirus 2019 (COVID-19). We collected chest CT scans of 202 patients diagnosed with the COVID-19, and try to develop a rapid, accurate and automatic tool for severity screening follow-up therapeutic treatment. A total of 729 2D axial plan slices with 246 severe cases and 483 non-severe cases were employed in this study. By taking the advantages of the pre-trained deep neural network, four pre-trained off-the-shelf deep models (Inception-V3, ResNet-50, ResNet-101, DenseNet-201) were exploited to extract the features from these CT scans. These features are then fed to multiple classifiers (linear discriminant, linear SVM, cubic SVM, KNN and Adaboost decision tree) to identify the severe and non-severe COVID-19 cases. Three validation strategies (holdout validation, tenfold cross-validation and leave-one-out) are employed to validate the feasibility of proposed pipelines. The experimental results demonstrate that classification of the features from pre-trained deep models shows the promising application in COVID-19 severity screening, whereas the DenseNet-201 with cubic SVM model achieved the best performance. Specifically, it achieved the highest severity classification accuracy of 95.20% and 95.34% for tenfold cross-validation and leave-one-out, respectively. The established pipeline was able to achieve a rapid and accurate identification of the severity of COVID-19. This may assist the physicians to make more efficient and reliable decisions.",220,COVID-19,30.0,Biomed Eng Online,Pneumonia;Decision Trees,3.4165090007170704e-06,56.56,3.720979462260113e-06,164.0,0.0,External,3. Monitoring/Severity assessment,CT
32793703,10.21037/atm-20-3026,Yes,PMC7396749,32793703.0,2020,2020-08-15,Journal Article,Peer reviewed (PubMed),1,machine learning-based ct radiomics method for predicting hospital stay in patients with pneumonia associated with sars-cov-2 infection: a multicenter study,"The coronavirus disease 2019 (COVID-19) has become a global challenge since the December 2019. The hospital stay is one of the prognostic indicators, and its predicting model based on CT radiomics features is important for assessing the patients' clinical outcome. The study aimed to develop and test machine learning-based CT radiomics models for predicting hospital stay in patients with COVID-19 pneumonia. This retrospective, multicenter study enrolled patients with laboratory-confirmed SARS-CoV-2 infection and their initial CT images from 5 designated hospitals in Ankang, Lishui, Lanzhou, Linxia, and Zhenjiang between January 23, 2020 and February 8, 2020. Patients were classified into short-term (≤10 days) and long-term hospital stay (>10 days). CT radiomics models based on logistic regression (LR) and random forest (RF) were developed on features from pneumonia lesions in first four centers. The predictive performance was evaluated in fifth center (test dataset) on lung lobe- and patients-level. A total of 52 patients were enrolled from designated hospitals. As of February 20, 21 patients remained in hospital or with non-findings in CT were excluded. Therefore, 31 patients with 72 lesion segments were included in analysis. The CT radiomics models based on 6 second-order features were effective in discriminating short- and long-term hospital stay in patients with COVID-19 pneumonia, with areas under the curves of 0.97 and 0.92 by LR and RF, respectively, in test. The LR and RF model showed a sensitivity and specificity of 1.0 and 0.89, 0.75 and 1.0 in test respectively. As of February 28, a prospective cohort of six discharged patients were all correctly recognized as long-term stay using RF and LR models. The machine learning-based CT radiomics features and models showed feasibility and accuracy for predicting hospital stay in patients with COVID-19 pneumonia.",286,COVID-19;Pneumonia,98.0,Ann Transl Med,Other Topics,2.657672056250536e-06,49.72800000000001,2.968934399645458e-06,136.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
32796848,10.1038/s41467-020-17971-2,Yes,PMC7429815,32796848.0,2020,2020-08-17,"Journal Article;Research Support, N.I.H., Intramural;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,artificial intelligence for the detection of covid-19 pneumonia on chest ct using multinational datasets,"Chest CT is emerging as a valuable diagnostic tool for clinical management of COVID-19 associated lung disease. Artificial intelligence (AI) has the potential to aid in rapid evaluation of CT scans for differentiation of COVID-19 findings from other clinical entities. Here we show that a series of deep learning algorithms, trained in a diverse multinational cohort of 1280 patients to localize parietal pleura/lung parenchyma followed by classification of COVID-19 pneumonia, can achieve up to 90.8% accuracy, with 84% sensitivity and 93% specificity, as evaluated in an independent test set (not included in training and validation) of 1337 patients. Normal controls included chest CTs from oncology, emergency, and pneumonia-related indications. The false positive rate in 140 patients with laboratory confirmed other (non COVID-19) pneumonias was 10%. AI-based algorithms can readily identify CT scans with COVID-19 associated pneumonia, as well as distinguish non-COVID related pneumonias with high specificity in diverse patient populations.",150,COVID-19;Lung Diseases;Pneumonia,211.0,Nat Commun,Coronavirus Infections;COVID-19 Testing,6.170004766637922e-06,139.12799999999947,7.706646179162709e-06,369.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32804113,10.3233/XST-200720,Yes,PMC7592683,32804113.0,2020,2020-08-18,Comparative Study;Journal Article,Peer reviewed (PubMed),1,detection of coronavirus disease from x-ray images using deep learning and transfer learning algorithms,"This study aims to employ the advantages of computer vision and medical image analysis to develop an automated model that has the clinical potential for early detection of novel coronavirus (COVID-19) infected disease. This study applied transfer learning method to develop deep learning models for detecting COVID-19 disease. Three existing state-of-the-art deep learning models namely, Inception ResNetV2, InceptionNetV3 and NASNetLarge, were selected and fine-tuned to automatically detect and diagnose COVID-19 disease using chest X-ray images. A dataset involving 850 images with the confirmed COVID-19 disease, 500 images of community-acquired (non-COVID-19) pneumonia cases and 915 normal chest X-ray images was used in this study. Among the three models, InceptionNetV3 yielded the best performance with accuracy levels of 98.63% and 99.02% with and without using data augmentation in model training, respectively. All the performed networks tend to overfitting (with high training accuracy) when data augmentation is not used, this is due to the limited amount of image data used for training and validation. This study demonstrated that a deep transfer learning is feasible to detect COVID-19 disease automatically from chest X-ray by training the learning model with chest X-ray images mixed with COVID-19 patients, other pneumonia affected patients and people with healthy lungs, which may help doctors more effectively make their clinical decisions. The study also gives an insight to how transfer learning was used to automatically detect the COVID-19 disease. In future studies, as the amount of available dataset increases, different convolution neutral network models could be designed to achieve the goal more efficiently.",253,COVID-19;Pneumonia,18.0,J Xray Sci Technol,Coronavirus Infections;Art;Transfer Learning;Algorithms;Lung;Neural Networks;Tomography;Lung Diseases;Early Diagnosis,1.5956617212768343e-05,446.2720000000111,2.632192767327799e-05,1092.0,0.0,External,2. Detection/Diagnosis,X-Ray
32804639,10.1109/MPULS.2020.3008354,Yes,,32804639.0,2020,2020-08-18,Journal Article,Peer reviewed (PubMed),1,ai-driven covid-19 tools to interpret quantify lung images,"Qualitative interpretation is a good thing when it comes to reading lung images in the fight against coronavirus 2019 disease (COVID-19), but quantitative analysis makes radiology reporting much more comprehensive. To that end, several research groups have begun looking to artificial intelligence (AI) as a tool for reading and analyzing X-rays and computed tomography (CT) scans, and helping to diagnose and monitor COVID-19.",63,COVID-19,5.0,IEEE Pulse,Other Topics,3.643544899900546e-06,49.752000000000045,2.6247291768531824e-06,185.0,0.0,,Review,Multimodal
32814568,10.1186/s12938-020-00809-9,Yes,PMC7436068,32814568.0,2020,2020-08-21,Journal Article,Peer reviewed (PubMed),1,differentiating novel coronavirus pneumonia from general pneumonia based on machine learning,"Chest CT screening as supplementary means is crucial in diagnosing novel coronavirus pneumonia (COVID-19) with high sensitivity and popularity. Machine learning was adept in discovering intricate structures from CT images and achieved expert-level performance in medical image analysis. An integrated machine learning framework on chest CT images for differentiating COVID-19 from general pneumonia (GP) was developed and validated. Seventy-three confirmed COVID-19 cases were consecutively enrolled together with 27 confirmed general pneumonia patients from Ruian People's Hospital, from January 2020 to March 2020. To accurately classify COVID-19, region of interest (ROI) delineation was implemented based on ground-glass opacities (GGOs) before feature extraction. Then, 34 statistical texture features of COVID-19 and GP ROI images were extracted, including 13 gray-level co-occurrence matrix (GLCM) features, 15 gray-level-gradient co-occurrence matrix (GLGCM) features and 6 histogram features. High-dimensional features impact the classification performance. Thus, ReliefF algorithm was leveraged to select features. The relevance of each feature was the average weights calculated by ReliefF in n times. Features with relevance larger than the empirically set threshold T were selected. After feature selection, the optimal feature set along with 4 other selected feature combinations for comparison were applied to the ensemble of bagged tree (EBT) and four other machine learning classifiers including support vector machine (SVM), logistic regression (LR), decision tree (DT), and K-nearest neighbor with Minkowski distance equal weight (KNN) using tenfold cross-validation. The classification accuracy (ACC), sensitivity (SEN), specificity (SPE) of our proposed method yield 94.16%, 88.62% and 100.00%, respectively. The AUC was 0.99. The experimental results indicate that the EBT algorithm with statistical textural features based on GGOs for differentiating COVID-19 from general pneumonia achieved high transferability, efficiency, specificity, sensitivity, and impressive accuracy, which is beneficial for inexperienced doctors to more accurately diagnose COVID-19 and essential for controlling the spread of the disease.",298,COVID-19;Pneumonia,22.0,Biomed Eng Online,Pneumonia;Logistic Regression;Decision Trees;Area under Curve,9.83718175698603e-06,212.751999999999,1.2801592726956448e-05,518.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32815519,10.5152/dir.2020.20205,Yes,PMC7837735,32815519.0,2020,2020-08-21,Journal Article,Peer reviewed (PubMed),1,determination of disease severity in covid-19 patients using deep learning in chest x-ray images,"Chest X-ray plays a key role in diagnosis and management of COVID-19 patients and imaging features associated with clinical elements may assist with the development or validation of automated image analysis tools. We aimed to identify associations between clinical and radiographic features as well as to assess the feasibility of deep learning applied to chest X-rays in the setting of an acute COVID-19 outbreak. A retrospective study of X-rays, clinical, and laboratory data was performed from 48 SARS-CoV-2 RT-PCR positive patients (age 60 years, 15 women) between February 22 and March 6, 2020 from a tertiary care hospital in Milan, Italy. Sixty-five chest X-rays were reviewed by two radiologists for alveolar and interstitial opacities and classified by severity on a scale from 0 to 3. Clinical factors (age, symptoms, comorbidities) were investigated for association with opacity severity and also with placement of central line or endotracheal tube. Deep learning models were then trained for two tasks: lung segmentation and opacity detection. Imaging characteristics were compared to clinical datapoints using the unpaired student's t-test or Mann-Whitney U test. Cohen's kappa analysis was used to evaluate the concordance of deep learning to conventional radiologist interpretation. Fifty-six percent of patients presented with alveolar opacities, 73% had interstitial opacities, and 23% had normal X-rays. The presence of alveolar or interstitial opacities was statistically correlated with age (P = 0.008) and comorbidities (P = 0.005). The extent of alveolar or interstitial opacities on baseline X-ray was significantly associated with the presence of endotracheal tube (P = 0.0008 and P = 0.049) or central line (P = 0.003 and P = 0.007). In comparison to human interpretation, the deep learning model achieved a kappa concordance of 0.51 for alveolar opacities and 0.71 for interstitial opacities. Chest X-ray analysis in an acute COVID-19 outbreak showed that the severity of opacities was associated with advanced age, comorbidities, as well as acuity of care. Artificial intelligence tools based upon deep learning of COVID-19 chest X-rays are feasible in the acute outbreak setting.",333,COVID-19,33.0,Diagn Interv Radiol,Severity of Illness Index;Health Care;Disease Outbreaks;Polymerase Chain Reaction;Radiologists;Other Topics;Retrospective Studies,2.925601837949686e-06,113.95999999999948,5.523739095368314e-06,261.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,X-Ray
32834523,10.1007/s00138-020-01101-5,Yes,PMC7386599,32834523.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,deep learning applications in pulmonary medical imaging: recent updates and insights on covid-19,"Shortly after deep learning algorithms were applied to Image Analysis, and more importantly to medical imaging, their applications increased significantly to become a trend. Likewise, deep learning applications (DL) on pulmonary medical images emerged to achieve remarkable advances leading to promising clinical trials. Yet, coronavirus can be the real trigger to open the route for fast integration of DL in hospitals and medical centers. This paper reviews the development of deep learning applications in medical image analysis targeting pulmonary imaging and giving insights of contributions to COVID-19. It covers more than 160 contributions and surveys in this field, all issued between February 2017 and May 2020 inclusively, highlighting various deep learning tasks such as classification, segmentation, and detection, as well as different pulmonary pathologies like airway diseases, lung cancer, COVID-19 and other infections. It summarizes and discusses the current state-of-the-art approaches in this research domain, highlighting the challenges, especially with COVID-19 pandemic current situation.",154,COVID-19;COVID-19 Pandemic;Cancer;Infections;Lung Diseases,20.0,Mach Vis Appl,Coronavirus Infections;Art;Algorithms;Lung Diseases,3.262286755548999e-06,14.631999999999998,1.9071014286521904e-06,39.0,0.0,,Review,Multimodal
32834627,10.1016/j.chaos.2020.110071,Yes,PMC7332960,32834627.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,recognition of covid-19 disease from x-ray images by hybrid model consisting of 2d curvelet transform chaotic salp swarm algorithm and deep learning technique,"The novel coronavirus disease 2019 (COVID-19), detected in Wuhan City, Hubei Province, China in late December 2019, is rapidly spreading and affecting all countries in the world. Real-time reverse transcription-polymerase chain reaction (RT-PCR) test has been described by the World Health Organization (WHO) as the standard test method for the diagnosis of the disease. However, considering that the results of this test are obtained between a few hours and two days, it is very important to apply another diagnostic method as an alternative to this test. The fact that RT-PCR test kits are limited in number, the test results are obtained in a long time, and the high probability of healthcare personnel becoming infected with the disease during the test, necessitates the use of other diagnostic methods as an alternative to these test kits. In this study, a hybrid model consisting of two-dimensional (2D) curvelet transformation, chaotic salp swarm algorithm (CSSA) and deep learning technique is developed in order to determine the patient infected with coronavirus pneumonia from X-ray images. In the proposed model, 2D Curvelet transformation is applied to the images obtained from the patient's chest X-ray radiographs and a feature matrix is formed using the obtained coefficients. The coefficients in the feature matrix are optimized with the help of the CSSA and COVID-19 disease is diagnosed by the EfficientNet-B0 model, which is one of the deep learning methods. Experimental results show that the proposed hybrid model can diagnose COVID-19 disease with high accuracy from chest X-ray images.",249,COVID-19;Pneumonia,84.0,Chaos Solitons Fractals,Occupational Groups;Health Care;World Health Organization;Polymerase Chain Reaction;Reverse Transcription,4.071315806099701e-06,50.35199999999999,4.0085097767165786e-06,144.0,0.0,External,2. Detection/Diagnosis,X-Ray
32834634,10.1016/j.chaos.2020.110122,Yes,PMC7357532,32834634.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,convolutional capsnet: a novel artificial neural network approach to detect covid-19 disease from x-ray images using capsule networks,"Coronavirus is an epidemic that spreads very quickly. For this reason, it has very devastating effects in many areas worldwide. It is vital to detect COVID-19 diseases as quickly as possible to restrain the spread of the disease. The similarity of COVID-19 disease with other lung infections makes the diagnosis difficult. In addition, the high spreading rate of COVID-19 increased the need for a fast system for the diagnosis of cases. For this purpose, interest in various computer-aided (such as CNN, DNN, etc.) deep learning models has been increased. In these models, mostly radiology images are applied to determine the positive cases. Recent studies show that, radiological images contain important information in the detection of coronavirus. In this study, a novel artificial neural network, Convolutional CapsNet for the detection of COVID-19 disease is proposed by using chest X-ray images with capsule networks. The proposed approach is designed to provide fast and accurate diagnostics for COVID-19 diseases with binary classification (COVID-19, and No-Findings), and multi-class classification (COVID-19, and No-Findings, and Pneumonia). The proposed method achieved an accuracy of 97.24%, and 84.22% for binary class, and multi-class, respectively. It is thought that the proposed method may help physicians to diagnose COVID-19 disease and increase the diagnostic performance. In addition, we believe that the proposed method may be an alternative method to diagnose COVID-19 by providing fast screening.",225,COVID-19;Infections;Pneumonia,102.0,Chaos Solitons Fractals,Other Topics,5.866841534682108e-06,114.5279999999995,7.631377703474402e-06,284.0,0.0,External,2. Detection/Diagnosis,X-Ray
32834641,10.1016/j.chaos.2020.110153,Yes,PMC7381895,32834641.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,automatic distinction between covid-19 and common pneumonia using multi-scale convolutional neural network on chest ct scans,"The COVID-19 pneumonia is a global threat since it emerged in early December 2019. Driven by the desire to develop a computer-aided system for the rapid diagnosis of COVID-19 to assist radiologists and clinicians to combat with this pandemic, we retrospectively collected 206 patients with positive reverse-transcription polymerase chain reaction (RT-PCR) for COVID-19 and their 416 chest computed tomography (CT) scans with abnormal findings from two hospitals, 412 non-COVID-19 pneumonia and their 412 chest CT scans with clear sign of pneumonia are also retrospectively selected from participating hospitals. Based on these CT scans, we design an artificial intelligence (AI) system that uses a multi-scale convolutional neural network (MSCNN) and evaluate its performance at both slice level and scan level. Experimental results show that the proposed AI has promising diagnostic performance in the detection of COVID-19 and differentiating it from other common pneumonia under limited number of training data, which has great potential to assist radiologists and physicians in performing a quick diagnosis and mitigate the heavy workload of them especially when the health system is overloaded. The data is publicly available for further research at .",186,COVID-19;Pneumonia,43.0,Chaos Solitons Fractals,Polymerase Chain Reaction;Reverse Transcription,2.864872465102951e-06,50.008,3.1840676873621302e-06,139.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32834651,10.1016/j.chaos.2020.110170,Yes,PMC7388764,32834651.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,diagnosis and detection of infected tissue of covid-19 patients based on lung x-ray image using convolutional neural network approaches,"COVID-19 pandemic has challenged the world science. The international community tries to find, apply, or design novel methods for diagnosis and treatment of COVID-19 patients as soon as possible. Currently, a reliable method for the diagnosis of infected patients is a reverse transcription-polymerase chain reaction. The method is expensive and time-consuming. Therefore, designing novel methods is important. In this paper, we used three deep learning-based methods for the detection and diagnosis of COVID-19 patients with the use of X-Ray images of lungs. For the diagnosis of the disease, we presented two algorithms include deep neural network (DNN) on the fractal feature of images and convolutional neural network (CNN) methods with the use of the lung images, directly. Results classification shows that the presented CNN architecture with higher accuracy and sensitivity is outperforming than the DNN method with an accuracy of 83.4% and sensitivity of 86%. In the segmentation process, we presented a CNN architecture to find infected tissue in lung images. Results show that the presented method can almost detect infected regions with high accuracy of 83.84%. This finding also can be used to monitor and control patients from infected region growth.",192,COVID-19;COVID-19 Pandemic,83.0,Chaos Solitons Fractals,Polymerase Chain Reaction;Reverse Transcription,4.646310526891472e-06,54.99200000000002,4.2743741781268655e-06,138.0,0.0,External,2. Detection/Diagnosis,CT
32834658,10.1016/j.chaos.2020.110182,Yes,PMC7392156,32834658.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,data science and the role of artificial intelligence in achieving the fast diagnosis of covid-19,"The rapid spread of novel coronavirus (namely Covid-19) worldwide has alarmed a pandemic since its outbreak in the city of Wuhan, China in December 2019. While the world still tries to wrap its head around as to how to contain the rapid spread of the novel coronavirus, the pandemic has already claimed several thousand lives throughout the world. Yet, the diagnosis of virus spread in humans has proven complexity. A blend of computed tomography imaging, entire genome sequencing, and electron microscopy have been at first adapted to screen and distinguish SARS-CoV-2, the viral etiology of Covid-19. There are a less number of Covid-19 test kits accessible in hospitals because of the expanding cases every day. Accordingly, it is required to utensil a self-exposure framework as a fast substitute analysis to contain Covid-19 spreading among individuals considering the world at large. In the present work, we have elaborated a prudent methodology that helps identify Covid-19 infected people among the normal individuals by utilizing CT scan and chest x-ray images using Artificial Intelligence (AI). The strategy works with a dataset of Covid-19 and normal chest x-ray images. The image diagnosis tool utilizes decision tree classifier for finding novel corona virus infected person. The percentage accuracy of an image is analyzed in terms of precision, recall score and F1 score. The outcome depends on the information accessible in the store of Kaggle and Open-I according to their approved chest X-ray and CT scan images. Interestingly, the test methodology demonstrates that the intended algorithm is robust, accurate and precise. Our technique accomplishes the exactness focused on the AI innovation which provides faster results during both training and inference.",274,COVID-19,19.0,Chaos Solitons Fractals,Disease Outbreaks;Other Topics;Viruses;Decision Trees,2.463325079326652e-06,36.640000000000015,2.6192098074815094e-06,98.0,0.0,,Review,Multimodal
32835082,10.1016/j.imu.2020.100405,Yes,PMC7395610,32835082.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,covid faster r-cnn: a novel framework to diagnose novel coronavirus disease (covid-19) in x-ray images,"COVID-19 or novel coronavirus disease, which has already been declared as a worldwide pandemic, at first had an outbreak in a large city of China, named Wuhan. More than two hundred countries around the world have already been affected by this severe virus as it spreads by human interaction. Moreover, the symptoms of novel coronavirus are quite similar to the general seasonal flu. Screening of infected patients is considered as a critical step in the fight against COVID-19. As there are no distinctive COVID-19 positive case detection tools available, the need for supporting diagnostic tools has increased. Therefore, it is highly relevant to recognize positive cases as early as possible to avoid further spreading of this epidemic. However, there are several methods to detect COVID-19 positive patients, which are typically performed based on respiratory samples and among them, a critical approach for treatment is radiologic imaging or X-Ray imaging. Recent findings from X-Ray imaging techniques suggest that such images contain relevant information about the SARS-CoV-2 virus. Application of Deep Neural Network (DNN) techniques coupled with radiological imaging can be helpful in the accurate identification of this disease, and can also be supportive in overcoming the issue of a shortage of trained physicians in remote communities. In this article, we have introduced a VGG-16 (Visual Geometry Group, also called OxfordNet) Network-based Faster Regions with Convolutional Neural Networks (Faster R-CNN) framework to detect COVID-19 patients from chest X-Ray images using an available open-source dataset. Our proposed approach provides a classification accuracy of 97.36%, 97.65% of sensitivity, and a precision of 99.28%. Therefore, we believe this proposed method might be of assistance for health professionals to validate their initial assessment towards COVID-19 patients.",280,COVID-19,54.0,Inform Med Unlocked,Disease Outbreaks;Other Topics,4.4489117710904135e-06,74.15999999999991,5.135080531554685e-06,200.0,0.0,External,2. Detection/Diagnosis,X-Ray
32836613,10.1007/s40009-020-01009-8,Yes,PMC7391230,32836613.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,non-invasive technique-based novel corona(covid-19) virus detection using cnn,"A novel human coronavirus 2 (SARS-CoV-2) is an extremely acute respiratory syndrome which was reported in Wuhan, China in the later half 2019. Most of its primary epidemiological aspects are not appropriately known, which has a direct effect on monitoring, practices and controls. The main objective of this work is to propose a high speed, accurate and highly sensitive CT scan approach for diagnosis of COVID19. The CT scan images display several small patches of shadows and interstitial shifts, particularly in the lung periphery. The proposed method utilizes the ResNet architecture Convolution Neural Network for training the images provided by the CT scan to diagnose the coronavirus-affected patients effectively. By comparing the testing images with the training images, the affected patient is identified accurately. The accuracy and specificity are obtained 95.09% and 81.89%, respectively, on the sample dataset based on CT images without the inclusion of another set of data such as geographical location, population density, etc. Also, the sensitivity is obtained 100% in this method. Based on the results, it is evident that the COVID-19 positive patients can be classified perfectly by using the proposed method.",187,COVID-19;Syndrome,5.0,Natl Acad Sci Lett,Other Topics,1.952539207284332e-06,21.192,1.8728588956449256e-06,65.0,0.0,External,2. Detection/Diagnosis,X-Ray
32836918,10.1016/j.chaos.2020.110190,Yes,PMC7413068,32836918.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,a deep learning and grad-cam based color visualization approach for fast detection of covid-19 cases using chest x-ray and ct-scan images,"The world is suffering from an existential global health crisis known as the COVID-19 pandemic. Countries like India, Bangladesh, and other developing countries are still having a slow pace in the detection of COVID-19 cases. Therefore, there is an urgent need for fast detection with clear visualization of infection is required using which a suspected patient of COVID-19 could be saved. In the recent technological advancements, the fusion of deep learning classifiers and medical images provides more promising results corresponding to traditional RT-PCR testing while making detection and predictions about COVID-19 cases with increased accuracy. In this paper, we have proposed a deep transfer learning algorithm that accelerates the detection of COVID-19 cases by using X-ray and CT-Scan images of the chest. It is because, in COVID-19, initial screening of chest X-ray (CXR) may provide significant information in the detection of suspected COVID-19 cases. We have considered three datasets known as 1) COVID-chest X-ray, 2) SARS-COV-2 CT-scan, and 3) Chest X-Ray Images (Pneumonia). In the obtained results, the proposed deep learning model can detect the COVID-19 positive cases in ≤ 2 seconds which is faster than RT-PCR tests currently being used for detection of COVID-19 cases. We have also established a relationship between COVID-19 patients along with the Pneumonia patients which explores the pattern between Pneumonia and COVID-19 radiology images. In all the experiments, we have used the Grad-CAM based color visualization approach in order to clearly interpretate the detection of radiology images and taking further course of action.",249,COVID-19;COVID-19 Pandemic;Infections;Pneumonia,123.0,Chaos Solitons Fractals,Algorithms;Transfer Learning;Color;Polymerase Chain Reaction,5.803671922144276e-06,131.80799999999937,8.421386971098531e-06,322.0,0.0,External,2. Detection/Diagnosis,Multimodal
32837453,10.1016/j.asoc.2020.106580,Yes,PMC7385069,32837453.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,a novel medical diagnosis model for covid-19 infection detection based on deep features and bayesian optimization,"A pneumonia of unknown causes, which was detected in Wuhan, China, and spread rapidly throughout the world, was declared as Coronavirus disease 2019 (COVID-19). Thousands of people have lost their lives to this disease. Its negative effects on public health are ongoing. In this study, an intelligence computer-aided model that can automatically detect positive COVID-19 cases is proposed to support daily clinical applications. The proposed model is based on the convolution neural network (CNN) architecture and can automatically reveal discriminative features on chest X-ray images through its convolution with rich filter families, abstraction, and weight-sharing characteristics. Contrary to the generally used transfer learning approach, the proposed deep CNN model was trained from scratch. Instead of the pre-trained CNNs, a novel serial network consisting of five convolution layers was designed. This CNN model was utilized as a deep feature extractor. The extracted deep discriminative features were used to feed the machine learning algorithms, which were k-nearest neighbor, support vector machine (SVM), and decision tree. The hyperparameters of the machine learning models were optimized using the Bayesian optimization algorithm. The experiments were conducted on a public COVID-19 radiology database. The database was divided into two parts as training and test sets with 70% and 30% rates, respectively. As a result, the most efficient results were ensured by the SVM classifier with an accuracy of 98.97%, a sensitivity of 89.39%, a specificity of 99.75%, and an F-score of 96.72%. Consequently, a cheap, fast, and reliable intelligence tool has been provided for COVID-19 infection detection. The developed model can be used to assist field specialists, physicians, and radiologists in the decision-making process. Thanks to the proposed tool, the misdiagnosis rates can be reduced, and the proposed model can be used as a retrospective evaluation tool to validate positive COVID-19 infection cases.",297,COVID-19;Infections;Pneumonia,122.0,Appl Soft Comput,Public Health;Pneumonia;Algorithms;Transfer Learning;Architecture;Decision Trees,6.146787376932721e-06,138.63999999999936,8.774359192505742e-06,332.0,0.0,External,2. Detection/Diagnosis,X-Ray
32837591,10.1007/s12559-020-09751-3,Yes,PMC7429098,32837591.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,social group optimization-assisted kapur's entropy and morphological segmentation for automated detection of covid-19 infection from computed tomography images,"The coronavirus disease (COVID-19) caused by a novel coronavirus, SARS-CoV-2, has been declared a global pandemic. Due to its infection rate and severity, it has emerged as one of the major global threats of the current generation. To support the current combat against the disease, this research aims to propose a machine learning-based pipeline to detect COVID-19 infection using lung computed tomography scan images (CTI). This implemented pipeline consists of a number of sub-procedures ranging from segmenting the COVID-19 infection to classifying the segmented regions. The initial part of the pipeline implements the segmentation of the COVID-19-affected CTI using social group optimization-based Kapur's entropy thresholding, followed by k-means clustering and morphology-based segmentation. The next part of the pipeline implements feature extraction, selection, and fusion to classify the infection. Principle component analysis-based serial fusion technique is used in fusing the features and the fused feature vector is then employed to train, test, and validate four different classifiers namely Random Forest, K-Nearest Neighbors (KNN), Support Vector Machine with Radial Basis Function, and Decision Tree. Experimental results using benchmark datasets show a high accuracy for the morphology-based segmentation task; for the classification task, the KNN offers the highest accuracy among the compared classifiers. However, this should be noted that this method still awaits clinical validation, and therefore should not be used to clinically diagnose ongoing COVID-19 infection.",224,COVID-19;Infections,35.0,Cognit Comput,Entropy;Support Vector Machine;Decision Trees;Cluster Analysis;Random Forest,2.734811481847902e-06,33.248000000000005,2.5846687741309725e-06,82.0,0.0,External,2. Detection/Diagnosis,CT
32837679,10.1016/j.irbm.2020.07.001,Yes,PMC7333623,32837679.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,automated deep transfer learning-based approach for detection of covid-19 infection in chest x-rays,"The most widely used novel coronavirus (COVID-19) detection technique is a real-time polymerase chain reaction (RT-PCR). However, RT-PCR kits are costly and take 6-9 hours to confirm infection in the patient. Due to less sensitivity of RT-PCR, it provides high false-negative results. To resolve this problem, radiological imaging techniques such as chest X-rays and computed tomography (CT) are used to detect and diagnose COVID-19. In this paper, chest X-rays is preferred over CT scan. The reason behind this is that X-rays machines are available in most of the hospitals. X-rays machines are cheaper than the CT scan machine. Besides this, X-rays has low ionizing radiations than CT scan. COVID-19 reveals some radiological signatures that can be easily detected through chest X-rays. For this, radiologists are required to analyze these signatures. However, it is a time-consuming and error-prone task. Hence, there is a need to automate the analysis of chest X-rays. The automatic analysis of chest X-rays can be done through deep learning-based approaches, which may accelerate the analysis time. These approaches can train the weights of networks on large datasets as well as fine-tuning the weights of pre-trained networks on small datasets. However, these approaches applied to chest X-rays are very limited. Hence, the main objective of this paper is to develop an automated deep transfer learning-based approach for detection of COVID-19 infection in chest X-rays by using the extreme version of the Inception (Xception) model. Extensive comparative analyses show that the proposed model performs significantly better as compared to the existing models.",253,COVID-19;Infections,98.0,Ing Rech Biomed,Coronavirus Infections;Transfer Learning;Polymerase Chain Reaction;Tomography;Real-Time Polymerase Chain Reaction,3.978270516003803e-06,75.08799999999991,5.323151195104695e-06,192.0,0.0,External,2. Detection/Diagnosis,X-Ray
32837749,10.1016/j.eng.2020.04.010,Yes,PMC7320702,32837749.0,2020,2020-08-25,Journal Article,Peer reviewed (PubMed),1,a deep learning system to screen novel coronavirus disease 2019 pneumonia,"The real-time reverse transcription-polymerase chain reaction (RT-PCR) detection of viral RNA from sputum or nasopharyngeal swab had a relatively low positive rate in the early stage of coronavirus disease 2019 (COVID-19). Meanwhile, the manifestations of COVID-19 as seen through computed tomography (CT) imaging show individual characteristics that differ from those of other types of viral pneumonia such as influenza-A viral pneumonia (IAVP). This study aimed to establish an early screening model to distinguish COVID-19 from IAVP and healthy cases through pulmonary CT images using deep learning techniques. A total of 618 CT samples were collected: 219 samples from 110 patients with COVID-19 (mean age 50 years; 63 male patients); 224 samples from 224 patients with IAVP (mean age 61 years; 156 male patients); and 175 samples from 175 healthy cases (mean age 39 years; 97 male patients). All CT samples were contributed from three COVID-19-designated hospitals in Zhejiang Province, China. First, the candidate infection regions were segmented out from the pulmonary CT image set using a 3D deep learning model. These separated images were then categorized into the COVID-19, IAVP, and irrelevant to infection (ITI) groups, together with the corresponding confidence scores, using a location-attention classification model. Finally, the infection type and overall confidence score for each CT case were calculated using the Noisy-OR Bayesian function. The experimental result of the benchmark dataset showed that the overall accuracy rate was 86.7% in terms of all the CT cases taken together. The deep learning models established in this study were effective for the early screening of COVID-19 patients and were demonstrated to be a promising supplementary diagnostic method for frontline clinical doctors.",271,"COVID-19;Infections;Influenza, Human;Pneumonia;Pneumonia, Viral",394.0,Engineering (Beijing),Polymerase Chain Reaction;Reverse Transcription,5.516543975771113e-06,150.31999999999923,9.432015880192828e-06,348.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32840070,10.7507/1001-5515.202005056,Yes,,32840070.0,2020,2020-08-26,Journal Article,Peer reviewed (PubMed),1,research on covid-19 detection method based on depthwise separable densenet in chest x-ray images,"Coronavirus disease 2019 (COVID-19) has spread rapidly around the world. In order to diagnose COVID-19 more quickly, in this paper, a depthwise separable DenseNet was proposed. The paper constructed a deep learning model with 2 905 chest X-ray images as experimental dataset. In order to enhance the contrast, the contrast limited adaptive histogram equalization (CLAHE) algorithm was used to preprocess the X-ray image before network training, then the images were put into the training network and the parameters of the network were adjusted to the optimal. Meanwhile, Leaky ReLU was selected as the activation function. VGG16, ResNet18, ResNet34, DenseNet121 and SDenseNet models were used to compare with the model proposed in this paper. Compared with ResNet34, the proposed classification model of pneumonia had improved 2.0%, 2.3% and 1.5% in accuracy, sensitivity and specificity respectively. Compared with the SDenseNet network without depthwise separable convolution, number of parameters of the proposed model was reduced by 43.9%, but the classification effect did not decrease. It can be found that the proposed DWSDenseNet has a good classification effect on the COVID-19 chest X-ray images dataset. Under the condition of ensuring the accuracy as much as possible, the depthwise separable convolution can effectively reduce number of parameters of the model.",205,COVID-19;Pneumonia,2.0,Sheng Wu Yi Xue Gong Cheng Xue Za Zhi,Other Topics,4.804904039911482e-06,96.53599999999967,6.394269289119457e-06,263.0,0.0,External,2. Detection/Diagnosis,X-Ray
32843849,10.1016/j.procbio.2020.08.016,Yes,PMC7439988,32843849.0,2020,2020-08-28,Journal Article;Review,Peer reviewed (PubMed),1,a systematic review on recent trends in transmission diagnosis prevention and imaging features of covid-19,"As the new cases of COVID-19 are growing every daysince January 2020, the major way to control the spread wasthrough early diagnosis. Prevention and early diagnosis are the key strategies followed by most countries. This study presents the perspective of different modes of transmission of coronavirus,especially during clinical practices and among the pediatrics. Further, the diagnostic methods and the advancement of the computerized tomography have been discussed. Droplets, aerosol, and close contact are thesignificantfactors to transfer the infection to the suspect. This study predicts the possible transmission of the virus through medical practices such as ophthalmology, dental, and endoscopy procedures. With regard to pediatric transmission, as of now, only afew child fatalities had been reported. Childrenusually respond to the respiratory virus; however, COVID-19 response ison the contrary. The possibility of getting infected is minimal for the newborn. There has been no asymptomatic spread in children until now. Moreover, breastfeedingwould not transmit COVID-19, which is encouraging hygiene news for the pediatric. In addition, the current diagnostic methods for COVID-19 including Immunoglobulin M (IgM) and Immunoglobulin G (IgG)and chest computed topography (CT) scan, reverse transcription-polymerase chain reaction (RT-PCR) andimmunochromatographic fluorescence assay, are also discussed in detail. The introduction of artificial intelligence and deep learning algorithmhas the ability to diagnose COVID-19 in precise. However, the developments of a potential technology for the identification of the infection, such as a drone with thermal screening without human intervention, need to be encouraged.",237,COVID-19;Infections,47.0,Process Biochem,Coronavirus Infections;Systematic Review;Polymerase Chain Reaction;Tomography;Reverse Transcription,1.777524959257978e-06,20.112,1.3549766898669748e-06,56.0,0.0,,Review,Multimodal
32843887,10.1016/j.asoc.2020.106642,Yes,PMC7439973,32843887.0,2020,2020-08-28,Journal Article,Peer reviewed (PubMed),1,hsma_woa: a hybrid novel slime mould algorithm with whale optimization algorithm for tackling the image segmentation problem of chest x-ray images,"Recently, a novel virus called COVID-19 has pervasive worldwide, starting from China and moving to all the world to eliminate a lot of persons. Many attempts have been experimented to identify the infection with COVID-19. The X-ray images were one of the attempts to detect the influence of COVID-19 on the infected persons from involving those experiments. According to the X-ray analysis, bilateral pulmonary parenchymal ground-glass and consolidative pulmonary opacities can be caused by COVID-19 - sometimes with a rounded morphology and a peripheral lung distribution. But unfortunately, the specification or if the person infected with COVID-19 or not is so hard under the X-ray images. X-ray images could be classified using the machine learning techniques to specify if the person infected severely, mild, or not infected. To improve the classification accuracy of the machine learning, the region of interest within the image that contains the features of COVID-19 must be extracted. This problem is called the image segmentation problem (ISP). Many techniques have been proposed to overcome ISP. The most commonly used technique due to its simplicity, speed, and accuracy are threshold-based segmentation. This paper proposes a new hybrid approach based on the thresholding technique to overcome ISP for COVID-19 chest X-ray images by integrating a novel meta-heuristic algorithm known as a slime mold algorithm (SMA) with the whale optimization algorithm to maximize the Kapur's entropy. The performance of integrated SMA has been evaluated on 12 chest X-ray images with threshold levels up to 30 and compared with five algorithms: Lshade algorithm, whale optimization algorithm (WOA), FireFly algorithm (FFA), Harris-hawks algorithm (HHA), salp swarm algorithms (SSA), and the standard SMA. The experimental results demonstrate that the proposed algorithm outperforms SMA under Kapur's entropy for all the metrics used and the standard SMA could perform better than the other algorithms in the comparison under all the metrics.",307,COVID-19;Infections,45.0,Appl Soft Comput,Hybrids;Viruses;Entropy;Eyeglasses,4.4571990896372735e-06,47.77600000000004,4.261592623973368e-06,112.0,0.0,External,Segmentation-only,X-Ray
32845849,10.1109/JBHI.2020.3019505,Yes,,32845849.0,2020,2020-08-28,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,adaptive feature selection guided deep forest for covid-19 classification with chest ct,"Chest computed tomography (CT) becomes an effective tool to assist the diagnosis of coronavirus disease-19 (COVID-19). Due to the outbreak of COVID-19 worldwide, using the computed-aided diagnosis technique for COVID-19 classification based on CT images could largely alleviate the burden of clinicians. In this paper, we propose an Adaptive Feature Selection guided Deep Forest (AFS-DF) for COVID-19 classification based on chest CT images. Specifically, we first extract location-specific features from CT images. Then, in order to capture the high-level representation of these features with the relatively small-scale data, we leverage a deep forest model to learn high-level representation of the features. Moreover, we propose a feature selection method based on the trained deep forest model to reduce the redundancy of features, where the feature selection could be adaptively incorporated with the COVID-19 classification model. We evaluated our proposed AFS-DF on COVID-19 dataset with 1495 patients of COVID-19 and 1027 patients of community acquired pneumonia (CAP). The accuracy (ACC), sensitivity (SEN), specificity (SPE), AUC, precision and F1-score achieved by our method are 91.79%, 93.05%, 89.95%, 96.35%, 93.10% and 93.07%, respectively. Experimental results on the COVID-19 dataset suggest that the proposed AFS-DF achieves superior performance in COVID-19 vs. CAP classification, compared with 4 widely used machine learning methods.",206,COVID-19;Pneumonia,67.0,IEEE J Biomed Health Inform,Radiography;Coronavirus Infections;Disease Outbreaks;COVID-19 Testing;Sensitivity and Specificity;Neural Networks;Paper;Area under Curve,7.259040269473472e-06,173.1359999999994,9.433126793604332e-06,472.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32849861,10.1155/2020/8828855,Yes,PMC7439162,32849861.0,2020,2020-08-28,Journal Article,Peer reviewed (PubMed),1,covid-19 deep learning prediction model using publicly available radiologist-adjudicated chest x-ray images as training data: preliminary findings,"The key component in deep learning research is the availability of training data sets. With a limited number of publicly available COVID-19 chest X-ray images, the generalization and robustness of deep learning models to detect COVID-19 cases developed based on these images are questionable. We aimed to use thousands of readily available chest radiograph images with clinical findings associated with COVID-19 as a training data set, mutually exclusive from the images with confirmed COVID-19 cases, which will be used as the testing data set. We used a deep learning model based on the ResNet-101 convolutional neural network architecture, which was pretrained to recognize objects from a million of images and then retrained to detect abnormality in chest X-ray images. The performance of the model in terms of AUC, sensitivity, specificity, and accuracy was 0.82, 77.3%, 71.8%, and 71.9%, respectively. The strength of this study lies in the use of labels that have a strong clinical association with COVID-19 cases and the use of mutually exclusive publicly available data for training, validation, and testing.",173,COVID-19,46.0,Int J Biomed Imaging,Other Topics,2.5803013299082973e-06,32.23200000000001,2.6581837871828227e-06,85.0,0.0,External,2. Detection/Diagnosis,X-Ray
32850746,10.3389/fbioe.2020.00898,Yes,PMC7411489,32850746.0,2020,2020-08-28,Journal Article,Peer reviewed (PubMed),1,development and validation of a deep learning-based model using computed tomography imaging for predicting disease severity of coronavirus disease 2019,"Coronavirus disease 2019 (COVID-19) is sweeping the globe and has resulted in infections in millions of people. Patients with COVID-19 face a high fatality risk once symptoms worsen; therefore, early identification of severely ill patients can enable early intervention, prevent disease progression, and help reduce mortality. This study aims to develop an artificial intelligence-assisted tool using computed tomography (CT) imaging to predict disease severity and further estimate the risk of developing severe disease in patients suffering from COVID-19. Initial CT images of 408 confirmed COVID-19 patients were retrospectively collected between January 1, 2020 and March 18, 2020 from hospitals in Honghu and Nanchang. The data of 303 patients in the People's Hospital of Honghu were assigned as the training data, and those of 105 patients in The First Affiliated Hospital of Nanchang University were assigned as the test dataset. A deep learning based-model using multiple instance learning and residual convolutional neural network (ResNet34) was developed and validated. The discrimination ability and prediction accuracy of the model were evaluated using the receiver operating characteristic curve and confusion matrix, respectively. The deep learning-based model had an AUC of 0.987 and an accuracy of 97.4% in the training set, whereas it had an AUC of 0.892 and an accuracy of 81.9% in the test set. In the subgroup analysis of patients who had non-severe COVID-19 on admission, the model achieved AUCs of 0.955 and 0.923 and accuracies of 97.0 and 81.6% in the Honghu and Nanchang subgroups, respectively. Our deep learning-based model can accurately predict disease severity as well as disease progression in COVID-19 patients using CT imaging, offering promise for guiding clinical treatment.",271,COVID-19;Confusion;Disease Progression;Infections,44.0,Front Bioeng Biotechnol,Other Topics,2.376412351194549e-06,38.77600000000001,2.739763142620698e-06,105.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
32864270,10.7759/cureus.9448,Yes,PMC7451075,32864270.0,2020,2020-08-31,Journal Article,Peer reviewed (PubMed),1,predicting covid-19 pneumonia severity on chest x-ray with deep learning,"The need to streamline patient management for coronavirus disease-19 (COVID-19) has become more pressing than ever. Chest X-rays (CXRs) provide a non-invasive (potentially bedside) tool to monitor the progression of the disease. In this study, we present a severity score prediction model for COVID-19 pneumonia for frontal chest X-ray images. Such a tool can gauge the severity of COVID-19 lung infections (and pneumonia in general) that can be used for escalation or de-escalation of care as well as monitoring treatment efficacy, especially in the ICU. Methods Images from a public COVID-19 database were scored retrospectively by three blinded experts in terms of the extent of lung involvement as well as the degree of opacity. A neural network model that was pre-trained on large (non-COVID-19) chest X-ray datasets is used to construct features for COVID-19 images which are predictive for our task. Results This study finds that training a regression model on a subset of the outputs from this pre-trained chest X-ray model predicts our geographic extent score (range 0-8) with 1.14 mean absolute error (MAE) and our lung opacity score (range 0-6) with 0.78 MAE. Conclusions These results indicate that our model's ability to gauge the severity of COVID-19 lung infections could be used for escalation or de-escalation of care as well as monitoring treatment efficacy, especially in the ICU. To enable follow up work, we make our code, labels, and data available online.",234,COVID-19;Infections;Pneumonia,97.0,Cureus,Neural Networks;Other Topics,3.1255273307797466e-06,54.48000000000001,3.666798901242375e-06,146.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
32868956,10.1016/j.patcog.2020.107613,Yes,PMC7448783,32868956.0,2020,2020-09-02,Journal Article,Peer reviewed (PubMed),1,automatically discriminating and localizing covid-19 from community-acquired pneumonia on chest x-rays,"The COVID-19 outbreak continues to threaten the health and life of people worldwide. It is an immediate priority to develop and test a computer-aided detection (CAD) scheme based on deep learning (DL) to automatically localize and differentiate COVID-19 from community-acquired pneumonia (CAP) on chest X-rays. Therefore, this study aims to develop and test an efficient and accurate deep learning scheme that assists radiologists in automatically recognizing and localizing COVID-19. A retrospective chest X-ray image dataset was collected from open image data and the Xiangya Hospital, which was divided into a training group and a testing group. The proposed CAD framework is composed of two steps with DLs: the Discrimination-DL and the Localization-DL. The first DL was developed to extract lung features from chest X-ray radiographs for COVID-19 discrimination and trained using 3548 chest X-ray radiographs. The second DL was trained with 406-pixel patches and applied to the recognized X-ray radiographs to localize and assign them into the left lung, right lung or bipulmonary. X-ray radiographs of CAP and healthy controls were enrolled to evaluate the robustness of the model. Compared to the radiologists' discrimination and localization results, the accuracy of COVID-19 discrimination using the Discrimination-DL yielded 98.71%, while the accuracy of localization using the Localization-DL was 93.03%. This work represents the feasibility of using a novel deep learning-based CAD scheme to efficiently and accurately distinguish COVID-19 from CAP and detect localization with high accuracy and agreement with radiologists.",238,COVID-19;Pneumonia,67.0,Pattern Recognit,Disease Outbreaks;Radiologists,2.4750505851858657e-06,43.15200000000002,3.1255571538450874e-06,104.0,0.0,External,2. Detection/Diagnosis,X-Ray
32879987,10.1007/s00330-020-07225-6,Yes,PMC7467843,32879987.0,2020,2020-09-04,Journal Article,Peer reviewed (PubMed),1,ultra-low-dose chest ct imaging of covid-19 patients using a deep residual neural network,"The current study aimed to design an ultra-low-dose CT examination protocol using a deep learning approach suitable for clinical diagnosis of COVID-19 patients. In this study, 800, 170, and 171 pairs of ultra-low-dose and full-dose CT images were used as input/output as training, test, and external validation set, respectively, to implement the full-dose prediction technique. A residual convolutional neural network was applied to generate full-dose from ultra-low-dose CT images. The quality of predicted CT images was assessed using root mean square error (RMSE), structural similarity index (SSIM), and peak signal-to-noise ratio (PSNR). Scores ranging from 1 to 5 were assigned reflecting subjective assessment of image quality and related COVID-19 features, including ground glass opacities (GGO), crazy paving (CP), consolidation (CS), nodular infiltrates (NI), bronchovascular thickening (BVT), and pleural effusion (PE). The radiation dose in terms of CT dose index (CTDIvol) was reduced by up to 89%. The RMSE decreased from 0.16 to 0.09 and from 0.16 to 0.08 for the predicted compared with ultra-low-dose CT images in the test and external validation set, respectively. The overall scoring assigned by radiologists showed an acceptance rate of 4.72 out of 5 for reference full-dose CT images, while ultra-low-dose CT images rated 2.78. The predicted CT images using the deep learning algorithm achieved a score of 4.42. The results demonstrated that the deep learning algorithm is capable of predicting standard full-dose CT images with acceptable quality for the clinical diagnosis of COVID-19 positive patients with substantial radiation dose reduction. Ultra-low-dose CT imaging of COVID-19 patients would result in the loss of critical information about lesion types, which could potentially affect clinical diagnosis. Deep learning-based prediction of full-dose from ultra-low-dose CT images for the diagnosis of COVID-19 could reduce the radiation dose by up to 89%. Deep learning algorithms failed to recover the correct lesion structure/density for a number of patients considered outliers, and as such, further research and development is warranted to address these limitations.",322,COVID-19;Pleural Effusion,34.0,Eur Radiol,Drug;Image Processing;Neural Networks,9.424937325741295e-06,204.56799999999905,1.1878188152661978e-05,487.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
32915751,10.1109/JBHI.2020.3023246,Yes,,32915751.0,2020,2020-09-12,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,contrastive cross-site learning with redesigned net for covid-19 ct classification,"The pandemic of coronavirus disease 2019 (COVID-19) has lead to a global public health crisis spreading hundreds of countries. With the continuous growth of new infections, developing automated tools for COVID-19 identification with CT image is highly desired to assist the clinical diagnosis and reduce the tedious workload of image interpretation. To enlarge the datasets for developing machine learning methods, it is essentially helpful to aggregate the cases from different medical systems for learning robust and generalizable models. This paper proposes a novel joint learning framework to perform accurate COVID-19 identification by effectively learning with heterogeneous datasets with distribution discrepancy. We build a powerful backbone by redesigning the recently proposed COVID-Net in aspects of network architecture and learning strategy to improve the prediction accuracy and learning efficiency. On top of our improved backbone, we further explicitly tackle the cross-site domain shift by conducting separate feature normalization in latent space. Moreover, we propose to use a contrastive training objective to enhance the domain invariance of semantic embeddings for boosting the classification performance on each dataset. We develop and evaluate our method with two public large-scale COVID-19 diagnosis datasets made up of CT images. Extensive experiments show that our approach consistently improves the performanceson both datasets, outperforming the original COVID-Net trained on each dataset by 12.16% and 14.23% in AUC respectively, also exceeding existing state-of-the-art multi-site learning methods.",226,COVID-19;Infections,72.0,IEEE J Biomed Health Inform,Coronavirus Infections;Public Health;Art;Pandemics;Architecture;COVID-19 Testing;Semantics;Health;Tomography;Paper;Area under Curve;Tests,6.354335320921745e-06,132.3199999999996,7.170088497220353e-06,370.0,0.0,External,2. Detection/Diagnosis,CT
32921862,10.1016/j.bbe.2020.08.008,Yes,PMC7476608,32921862.0,2020,2020-09-15,Journal Article,Peer reviewed (PubMed),1,a deep learning approach to detect covid-19 coronavirus with x-ray images,"Rapid and accurate detection of COVID-19 coronavirus is necessity of time to prevent and control of this pandemic by timely quarantine and medical treatment in absence of any vaccine. Daily increase in cases of COVID-19 patients worldwide and limited number of available detection kits pose difficulty in identifying the presence of disease. Therefore, at this point of time, necessity arises to look for other alternatives. Among already existing, widely available and low-cost resources, X-ray is frequently used imaging modality and on the other hand, deep learning techniques have achieved state-of-the-art performances in computer-aided medical diagnosis. Therefore, an alternative diagnostic tool to detect COVID-19 cases utilizing available resources and advanced deep learning techniques is proposed in this work. The proposed method is implemented in four phases, viz., data augmentation, preprocessing, stage-I and stage-II deep network model designing. This study is performed with online available resources of 1215 images and further strengthen by utilizing data augmentation techniques to provide better generalization of the model and to prevent the model overfitting by increasing the overall length of dataset to 1832 images. Deep network implementation in two stages is designed to differentiate COVID-19 induced pneumonia from healthy cases, bacterial and other virus induced pneumonia on X-ray images of chest. Comprehensive evaluations have been performed to demonstrate the effectiveness of the proposed method with both training-validation-testing and 5-fold cross validation procedures. High classification accuracy as 97.77%, recall as 97.14% and precision as 97.14% in case of COVID-19 detection shows the efficacy of proposed method in present need of time. Further, the deep network architecture showing averaged accuracy/sensitivity/specificity/precision/F1-score of 98.93/98.93/98.66/96.39/98.15 with 5-fold cross validation makes a promising outcome in COVID-19 detection using X-ray images.",278,COVID-19;Pneumonia,77.0,Biocybern Biomed Eng,Art;Architecture,5.760489396749574e-06,122.17599999999946,7.712856972935418e-06,310.0,0.0,External,2. Detection/Diagnosis,X-Ray
32921934,10.1016/j.chaos.2020.110245,Yes,PMC7472981,32921934.0,2020,2020-09-15,Journal Article,Peer reviewed (PubMed),1,cvdnet: a novel deep learning architecture for detection of coronavirus (covid-19) from chest x-ray images,"The COVID-19 pandemic is an emerging respiratory infectious disease, also known as coronavirus 2019. It appears in November 2019 in Hubei province (in China), and more specifically in the city of Wuhan, then spreads in the whole world. As the number of cases increases with unprecedented speed, many parts of the world are facing a shortage of resources and testing. Faced with this problem, physicians, scientists and engineers, including specialists in Artificial Intelligence (AI), have encouraged the development of a Deep Learning model to help healthcare professionals to detect COVID-19 from chest X-ray images and to determine the severity of the infection in a very short time, with low cost. In this paper, we propose CVDNet, a Deep Convolutional Neural Network (CNN) model to classify COVID-19 infection from normal and other pneumonia cases using chest X-ray images. The proposed architecture is based on the residual neural network and it is constructed by using two parallel levels with different kernel sizes to capture local and global features of the inputs. This model is trained on a dataset publically available containing a combination of 219 COVID-19, 1341 normal and 1345 viral pneumonia chest x-ray images. The experimental results reveal that our CVDNet. These results represent a promising classification performance on a small dataset which can be further achieve better results with more training data. Overall, our CVDNet model can be an interesting tool to help radiologists in the diagnosis and early detection of COVID-19 cases.",243,"COVID-19;COVID-19 Pandemic;Communicable Diseases;Infections;Pneumonia;Pneumonia, Viral",73.0,Chaos Solitons Fractals,Coronavirus Infections;Health Care;Communicable Diseases,7.728906309954114e-06,171.51199999999926,1.0995869398609512e-05,433.0,0.0,External,2. Detection/Diagnosis,X-Ray
32927416,10.1016/j.ejrad.2020.109233,Yes,PMC7455238,32927416.0,2020,2020-09-15,Journal Article,Peer reviewed (PubMed),1,development and clinical implementation of tailored image analysis tools for covid-19 in the midst of the pandemic: the synergetic effect of an open clinically embedded software development platform and machine learning,"During the emerging COVID-19 pandemic, radiology departments faced a substantial increase in chest CT admissions coupled with the novel demand for quantification of pulmonary opacities. This article describes how our clinic implemented an automated software solution for this purpose into an established software platform in 10 days. The underlying hypothesis was that modern academic centers in radiology are capable of developing and implementing such tools by their own efforts and fast enough to meet the rapidly increasing clinical needs in the wake of a pandemic. Deep convolutional neural network algorithms for lung segmentation and opacity quantification on chest CTs were trained using semi-automatically and manually created ground-truth (Ntotal = 172). The performance of the in-house method was compared to an externally developed algorithm on a separate test subset (N = 66). The final algorithm was available at day 10 and achieved human-like performance (Dice coefficient = 0.97). For opacity quantification, a slight underestimation was seen both for the in-house and for the external algorithm. In contrast to the external reference, the underestimation for the in-house algorithm showed no dependency on total opacity load, making it more suitable for follow-up. The combination of machine learning and a clinically embedded software development platform enabled time-efficient development, instant deployment, and rapid adoption in clinical routine. The algorithm for fully automated lung segmentation and opacity quantification that we developed in the midst of the COVID-19 pandemic was ready for clinical use within just 10 days and achieved human-level performance even in complex cases.",249,COVID-19;COVID-19 Pandemic,12.0,Eur J Radiol,Coronavirus Infections;Neural Networks,3.554110468013058e-06,31.920000000000005,2.7260972184851173e-06,120.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
32945968,10.1007/s00330-020-07269-8,Yes,PMC7499014,32945968.0,2020,2020-09-19,Journal Article,Peer reviewed (PubMed),1,initial chest radiographs and artificial intelligence (ai) predict clinical outcomes in covid-19 patients: analysis of 697 italian patients,"To evaluate whether the initial chest X-ray (CXR) severity assessed by an AI system may have prognostic utility in patients with COVID-19. This retrospective single-center study included adult patients presenting to the emergency department (ED) between February 25 and April 9, 2020, with SARS-CoV-2 infection confirmed on real-time reverse transcriptase polymerase chain reaction (RT-PCR). Initial CXRs obtained on ED presentation were evaluated by a deep learning artificial intelligence (AI) system and compared with the Radiographic Assessment of Lung Edema (RALE) score, calculated by two experienced radiologists. Death and critical COVID-19 (admission to intensive care unit (ICU) or deaths occurring before ICU admission) were identified as clinical outcomes. Independent predictors of adverse outcomes were evaluated by multivariate analyses. Six hundred ninety-seven 697 patients were included in the study: 465 males, median age of 62 years (IQR 52-75). Multivariate analyses adjusting for demographics and comorbidities showed that an AI system-based score ≥ 30 on the initial CXR was an independent predictor both for mortality ) and critical COVID-19 ). Other independent predictors were RALE score, older age, male sex, coronary artery disease, COPD, and neurodegenerative disease. AI- and radiologist-assessed disease severity scores on CXRs obtained on ED presentation were independent and comparable predictors of adverse outcomes in patients with COVID-19. ClinicalTrials.gov NCT04318366. AI system-based score ≥ 30 and a RALE score ≥ 12 at CXRs performed at ED presentation are independent and comparable predictors of death and/or ICU admission in COVID-19 patients. Other independent predictors are older age, male sex, coronary artery disease, COPD, and neurodegenerative disease. The comparable performance of the AI system in relation to a radiologist-assessed score in predicting adverse outcomes may represent a game-changer in resource-constrained settings.",279,"COVID-19;Coronary Artery Disease;Death;Edema;Neurodegenerative Diseases;Pulmonary Disease, Chronic Obstructive;Rales",65.0,Eur Radiol,Severity of Illness Index;Intensive Care Units;Polymerase Chain Reaction;Retrospective Studies;Pulmonary Artery,1.3990739424788747e-05,479.4320000000131,2.1767881590785216e-05,1217.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,X-Ray
32953735,10.21037/atm-20-4004,Yes,PMC7475384,32953735.0,2020,2020-09-22,Journal Article,Peer reviewed (PubMed),1,temporal changes of covid-19 pneumonia by mass evaluation using ct: a retrospective multi-center study,"Coronavirus disease 2019 (COVID-19) has widely spread worldwide and caused a pandemic. Chest CT has been found to play an important role in the diagnosis and management of COVID-19. However, quantitatively assessing temporal changes of COVID-19 pneumonia over time using CT has still not been fully elucidated. The purpose of this study was to perform a longitudinal study to quantitatively assess temporal changes of COVID-19 pneumonia. This retrospective and multi-center study included patients with laboratory-confirmed COVID-19 infection from 16 hospitals between January 19 and March 27, 2020. Mass was used as an approach to quantitatively measure dynamic changes of pulmonary involvement in patients with COVID-19. Artificial intelligence (AI) was employed as image segmentation and analysis tool for calculating the mass of pulmonary involvement. A total of 581 confirmed patients with 1,309 chest CT examinations were included in this study. The median age was 46 years (IQR, 35-55; range, 4-87 years), and 311 patients were male. The mass of pulmonary involvement peaked on day 10 after the onset of initial symptoms. Furthermore, the mass of pulmonary involvement of older patients (>45 years) was significantly severer (P<0.001) and peaked later (day 11 vs. day 8) than that of younger patients (≤45 years). In addition, there were no significant differences in the peak time (day 10 vs. day 10) and median mass (P=0.679) of pulmonary involvement between male and female. Pulmonary involvement peaked on day 10 after the onset of initial symptoms in patients with COVID-19. Further, pulmonary involvement of older patients was severer and peaked later than that of younger patients. These findings suggest that AI-based quantitative mass evaluation of COVID-19 pneumonia hold great potential for monitoring the disease progression.",278,COVID-19;Disease Progression;Infections;Pneumonia,6.0,Ann Transl Med,Other Topics,2.1062886402877256e-06,31.032,2.026178390091516e-06,99.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
32953971,10.1016/j.imu.2020.100427,Yes,PMC7487744,32953971.0,2020,2020-09-22,Journal Article,Peer reviewed (PubMed),1,covid-19 detection in ct images with deep learning: a voting-based scheme and cross-datasets analysis,"Early detection and diagnosis are critical factors to control the COVID-19 spreading. A number of deep learning-based methodologies have been recently proposed for COVID-19 screening in CT scans as a tool to automate and help with the diagnosis. These approaches, however, suffer from at least one of the following problems: they treat each CT scan slice independently and the methods are trained and tested with sets of images from the same dataset. Treating the slices independently means that the same patient may appear in the training and test sets at the same time which may produce misleading results. It also raises the question of whether the scans from the same patient should be evaluated as a group or not. Moreover, using a single dataset raises concerns about the generalization of the methods. Different datasets tend to present images of varying quality which may come from different types of CT machines reflecting the conditions of the countries and cities from where they come from. In order to address these two problems, in this work, we propose an Efficient Deep Learning Technique for the screening of COVID-19 with a voting-based approach. In this approach, the images from a given patient are classified as group in a voting system. The approach is tested in the two biggest datasets of COVID-19 CT analysis with a patient-based split. A cross dataset study is also presented to assess the robustness of the models in a more realistic scenario in which data comes from different distributions. The cross-dataset analysis has shown that the generalization power of deep learning models is far from acceptable for the task since accuracy drops from 87.68% to 56.16% on the best evaluation scenario. These results highlighted that the methods that aim at COVID-19 detection in CT-images have to improve significantly to be considered as a clinical option and larger and more diverse datasets are needed to evaluate the methods in a realistic scenario.",321,COVID-19,72.0,Inform Med Unlocked,Other Topics,2.544906775053092e-06,39.95200000000004,3.142148480951076e-06,92.0,0.0,External,2. Detection/Diagnosis,CT
32958781,10.1038/s41598-020-71294-2,Yes,PMC7506559,32958781.0,2020,2020-09-23,Journal Article,Peer reviewed (PubMed),1,covid-19 image classification using deep features and fractional-order marine predators algorithm,"Currently, we witness the severe spread of the pandemic of the new Corona virus, COVID-19, which causes dangerous symptoms to humans and animals, its complications may lead to death. Although convolutional neural networks (CNNs) is considered the current state-of-the-art image classification technique, it needs massive computational cost for deployment and training. In this paper, we propose an improved hybrid classification approach for COVID-19 images by combining the strengths of CNNs (using a powerful architecture called Inception) to extract features and a swarm-based feature selection algorithm (Marine Predators Algorithm) to select the most relevant features. A combination of fractional-order and marine predators algorithm (FO-MPA) is considered an integration among a robust tool in mathematics named fractional-order calculus (FO). The proposed approach was evaluated on two public COVID-19 X-ray datasets which achieves both high performance and reduction of computational complexity. The two datasets consist of X-ray COVID-19 images by international Cardiothoracic radiologist, researchers and others published on Kaggle. The proposed approach selected successfully 130 and 86 out of 51 K features extracted by inception from dataset 1 and dataset 2, while improving classification accuracy at the same time. The results are the best achieved on these datasets when compared to a set of recent feature selection algorithms. By achieving 98.7%, 98.2% and 99.6%, 99% of classification accuracy and F-Score for dataset 1 and dataset 2, respectively, the proposed approach outperforms several CNNs and all recent works on COVID-19 images.",237,COVID-19;Calculi;Death,75.0,Sci Rep,Coronavirus Infections;Art;Algorithms;Architecture;Research Personnel;Image Processing;Neural Networks,6.04080816130422e-06,105.44799999999958,7.472997184659364e-06,269.0,0.0,External,2. Detection/Diagnosis,X-Ray
32958971,10.1016/j.patrec.2020.09.010,Yes,PMC7493761,32958971.0,2020,2020-09-23,Journal Article;Review,Peer reviewed (PubMed),1,covid-caps: a capsule network-based framework for identification of covid-19 cases from x-ray images,"Novel Coronavirus disease (COVID-19) has abruptly and undoubtedly changed the world as we know it at the end of the 2nd decade of the 21st century. COVID-19 is extremely contagious and quickly spreading globally making its early diagnosis of paramount importance. Early diagnosis of COVID-19 enables health care professionals and government authorities to break the chain of transition and flatten the epidemic curve. The common type of COVID-19 diagnosis test, however, requires specific equipment and has relatively low sensitivity. Computed tomography (CT) scans and X-ray images, on the other hand, reveal specific manifestations associated with this disease. Overlap with other lung infections makes human-centered diagnosis of COVID-19 challenging. Consequently, there has been an urgent surge of interest to develop Deep Neural Network (DNN)-based diagnosis solutions, mainly based on Convolutional Neural Networks (CNNs), to facilitate identification of positive COVID-19 cases. CNNs, however, are prone to lose spatial information between image instances and require large datasets. The paper presents an alternative modeling framework based on Capsule Networks, referred to as the COVID-CAPS, being capable of handling small datasets, which is of significant importance due to sudden and rapid emergence of COVID-19. Our results based on a dataset of X-ray images show that COVID-CAPS has advantage over previous CNN-based models. COVID-CAPS achieved an Accuracy of 95.7%, Sensitivity of 90%, Specificity of 95.8%, and AUC of 0.97, while having far less number of trainable parameters in comparison to its counterparts. To potentially and further improve diagnosis capabilities of the COVID-CAPS, pre-training and transfer learning are utilized based on a new dataset constructed from an external dataset of X-ray images. This is in contrary to existing works on COVID-19 detection where pre-training is performed based on natural images. Pre-training with a dataset of similar nature further improved accuracy to 98.3% and specificity to 98.6%.",299,COVID-19;Infections,212.0,Pattern Recognit Lett,Coronavirus Infections;Health Care;Transfer Learning;Sensitivity and Specificity;Lung;Tomography;Area under Curve;Early Diagnosis,5.00704098200516e-06,101.43199999999965,6.909907702234743e-06,251.0,0.0,External,2. Detection/Diagnosis,X-Ray
32959234,10.1007/s12539-020-00393-5,Yes,PMC7505483,32959234.0,2020,2020-09-23,Journal Article,Peer reviewed (PubMed),1,covid19xraynet: a two-step transfer learning model for the covid-19 detecting problem based on a limited number of chest x-ray images,"The novel coronavirus severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a major pandemic outbreak recently. Various diagnostic technologies have been under active development. The novel coronavirus disease (COVID-19) may induce pulmonary failures, and chest X-ray imaging becomes one of the major confirmed diagnostic technologies. The very limited number of publicly available samples has rendered the training of the deep neural networks unstable and inaccurate. This study proposed a two-step transfer learning pipeline and a deep residual network framework COVID19XrayNet for the COVID-19 detection problem based on chest X-ray images. COVID19XrayNet firstly tunes the transferred model on a large dataset of chest X-ray images, which is further tuned using a small dataset of annotated chest X-ray images. The final model achieved 0.9108 accuracy. The experimental data also suggested that the model may be improved with more training samples being released. COVID19XrayNet, a two-step transfer learning framework designed for biomedical images.",151,COVID-19;Severe Acute Respiratory Syndrome,18.0,Interdiscip Sci,Radiography;Coronavirus Infections;Transfer Learning;Algorithms;Disease Outbreaks;COVID-19 Testing;Lung;Neural Networks;Tomography,9.92114142766216e-06,298.3360000000025,1.63753494513048e-05,764.0,0.0,External,2. Detection/Diagnosis,X-Ray
32968435,10.3892/etm.2020.9210,Yes,PMC7500043,32968435.0,2020,2020-09-25,Journal Article,Peer reviewed (PubMed),1,advancing covid-19 differentiation with a robust preprocessing and integration of multi-institutional open-repository computer tomography datasets for deep learning analysis,"The coronavirus pandemic and its unprecedented consequences globally has spurred the interest of the artificial intelligence research community. A plethora of published studies have investigated the role of imaging such as chest X-rays and computer tomography in coronavirus disease 2019 (COVID-19) automated diagnosis. Οpen repositories of medical imaging data can play a significant role by promoting cooperation among institutes in a world-wide scale. However, they may induce limitations related to variable data quality and intrinsic differences due to the wide variety of scanner vendors and imaging parameters. In this study, a state-of-the-art custom U-Net model is presented with a dice similarity coefficient performance of 99.6% along with a transfer learning VGG-19 based model for COVID-19 versus pneumonia differentiation exhibiting an AUC of 96.1%. The above was significantly improved over the baseline model trained with no segmentation in selected tomographic slices of the same dataset. The presented study highlights the importance of a robust preprocessing protocol for image analysis within a heterogeneous imaging dataset and assesses the potential diagnostic value of the presented COVID-19 model by comparing its performance to the state of the art.",184,COVID-19;Pneumonia,4.0,Exp Ther Med,Art;Transfer Learning;Tomography;Area under Curve,1.091924942636562e-06,2.4,6.386404066857071e-07,8.0,0.0,External,2. Detection/Diagnosis,CT
32969761,10.1148/radiol.2020202944,Yes,PMC7841876,32969761.0,2020,2020-09-25,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,diagnosis of coronavirus disease 2019 pneumonia by using chest radiography: value of artificial intelligence,"Background Radiologists are proficient in differentiating between chest radiographs with and without symptoms of pneumonia but have found it more challenging to differentiate coronavirus disease 2019 (COVID-19) pneumonia from non-COVID-19 pneumonia on chest radiographs. Purpose To develop an artificial intelligence algorithm to differentiate COVID-19 pneumonia from other causes of abnormalities at chest radiography. In this retrospective study, a deep neural network, CV19-Net, was trained, validated, and tested on chest radiographs in patients with and without COVID-19 pneumonia. For the chest radiographs positive for COVID-19, patients with reverse transcription polymerase chain reaction results positive for severe acute respiratory syndrome coronavirus 2 with findings positive for pneumonia between February 1, 2020, and May 30, 2020, were included. For the non-COVID-19 chest radiographs, patients with pneumonia who underwent chest radiography between October 1, 2019, and December 31, 2019, were included. AUC, sensitivity, and specificity were calculated to characterize diagnostic performance. To benchmark the performance of CV19-Net, a randomly sampled test data set composed of 500 chest radiographs in 500 patients was evaluated by the CV19-Net and three experienced thoracic radiologists. Results A total of 2060 patients (5806 chest radiographs; mean age, 62 years ; 1059 men) with COVID-19 pneumonia and 3148 patients (5300 chest radiographs; mean age, 64 years ; 1578 men) with non-COVID-19 pneumonia were included and split into training and validation and test data sets. For the test set, CV19-Net achieved an AUC of 0.92. This corresponded to a sensitivity of 88% and a specificity of 79% by using a high-sensitivity operating threshold, or a sensitivity of 78% and a specificity of 89% by using a high-specificity operating threshold. For the 500 sampled chest radiographs, CV19-Net achieved an AUC of 0.94 compared with an AUC of 0.85 achieved by radiologists. Conclusion CV19-Net was able to differentiate coronavirus disease 2019-related pneumonia from other types of pneumonia, with performance exceeding that of experienced thoracic radiologists.",312,COVID-19;Pneumonia;Severe Acute Respiratory Syndrome,60.0,Radiology,Polymerase Chain Reaction;Retrospective Studies;Area under Curve;Reverse Transcription;Receiver Operating Characteristic,5.360432778062639e-06,142.9519999999995,6.849101165139264e-06,387.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
32969949,10.1097/RTI.0000000000000559,Yes,,32969949.0,2020,2020-09-25,Journal Article,Peer reviewed (PubMed),1,detection of covid-19 using deep learning algorithms on chest radiographs,"To evaluate the performance of a deep learning (DL) algorithm for the detection of COVID-19 on chest radiographs (CXR). In this retrospective study, a DL model was trained on 112,120 CXR images with 14 labeled classifiers (ChestX-ray14) and fine-tuned using initial CXR on hospital admission of 509 patients, who had undergone COVID-19 reverse transcriptase-polymerase chain reaction (RT-PCR). The test set consisted of a CXR on presentation of 248 individuals suspected of COVID-19 pneumonia between February 16 and March 3, 2020 from 4 centers (72 RT-PCR positives and 176 RT-PCR negatives). The CXR were independently reviewed by 3 radiologists and using the DL algorithm. Diagnostic performance was compared with radiologists' performance and was assessed by AUCs. The median age of the subjects in the test set was 61 (interquartile range: 39 to 79) years (51% male). The DL algorithm achieved an AUC of 0.81, sensitivity of 0.85, and specificity of 0.72 in detecting COVID-19 using RT-PCR as the reference standard. On subgroup analyses, the model achieved an AUC of 0.79, sensitivity of 0.80, and specificity of 0.74 in detecting COVID-19 in patients presented with fever or respiratory systems and an AUC of 0.87, sensitivity of 0.85, and specificity of 0.81 in distinguishing COVID-19 from other forms of pneumonia. The algorithm significantly outperforms human readers (P<0.001 using DeLong test) with higher sensitivity (P=0.01 using McNemar test). A DL algorithm (COV19NET) for the detection of COVID-19 on chest radiographs can potentially be an effective tool in triaging patients, particularly in resource-stretched health-care systems.",250,COVID-19;Fever;Pneumonia,4.0,J Thorac Imaging,Health Care;Sensitivity and Specificity;Polymerase Chain Reaction;Radiologists;Retrospective Studies;Area under Curve;Receiver Operating Characteristic,3.011618302772558e-06,71.23199999999994,3.838132985689196e-06,188.0,0.0,External,2. Detection/Diagnosis,X-Ray
32971995,10.3390/ijerph17186933,Yes,PMC7557723,32971995.0,2020,2020-09-26,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,unveiling covid-19 from chest x-ray with deep learning: a hurdles race with small data,"The possibility to use widespread and simple chest X-ray (CXR) imaging for early screening of COVID-19 patients is attracting much interest from both the clinical and the AI community. In this study we provide insights and also raise warnings on what is reasonable to expect by applying deep learning to COVID classification of CXR images. We provide a methodological guide and critical reading of an extensive set of statistical results that can be obtained using currently available datasets. In particular, we take the challenge posed by current small size COVID data and show how significant can be the bias introduced by transfer-learning using larger public non-COVID CXR datasets. We also contribute by providing results on a medium size COVID CXR dataset, just collected by one of the major emergency hospitals in Northern Italy during the peak of the COVID pandemic. These novel data allow us to contribute to validate the generalization capacity of preliminary results circulating in the scientific community. Our conclusions shed some light into the possibility to effectively discriminate COVID using CXR.",174,COVID-19,73.0,Int J Environ Res Public Health,Coronavirus Infections;Transfer Learning,3.06560507179106e-06,50.928,3.4196366215545474e-06,146.0,0.0,External,2. Detection/Diagnosis,X-Ray
32982615,10.1016/j.asoc.2020.106742,Yes,PMC7505822,32982615.0,2020,2020-09-29,Journal Article,Peer reviewed (PubMed),1,an optimized deep learning architecture for the diagnosis of covid-19 disease based on gravitational search optimization,"In this paper, a novel approach called GSA-DenseNet121-COVID-19 based on a hybrid convolutional neural network (CNN) architecture is proposed using an optimization algorithm. The CNN architecture that was used is called DenseNet121, and the optimization algorithm that was used is called the gravitational search algorithm (GSA). The GSA is used to determine the best values for the hyperparameters of the DenseNet121 architecture. To help this architecture to achieve a high level of accuracy in diagnosing COVID-19 through chest x-ray images. The obtained results showed that the proposed approach could classify 98.38% of the test set correctly. To test the efficacy of the GSA in setting the optimum values for the hyperparameters of DenseNet121. The GSA was compared to another approach called SSD-DenseNet121, which depends on the DenseNet121 and the optimization algorithm called social ski driver (SSD). The comparison results demonstrated the efficacy of the proposed GSA-DenseNet121-COVID-19. As it was able to diagnose COVID-19 better than SSD-DenseNet121 as the second was able to diagnose only 94% of the test set. The proposed approach was also compared to another method based on a CNN architecture called Inception-v3 and manual search to quantify hyperparameter values. The comparison results showed that the GSA-DenseNet121-COVID-19 was able to beat the comparison method, as the second was able to classify only 95% of the test set samples. The proposed GSA-DenseNet121-COVID-19 was also compared with some related work. The comparison results showed that GSA-DenseNet121-COVID-19 is very competitive.",239,COVID-19,51.0,Appl Soft Comput,Algorithms;Transfer Learning;Architecture,2.919961288256914e-06,37.504000000000005,3.038221452775461e-06,98.0,0.0,External,2. Detection/Diagnosis,X-Ray
32983419,10.1007/s13755-020-00119-3,Yes,PMC7505500,32983419.0,2020,2020-09-29,Journal Article,Peer reviewed (PubMed),1,pdcovidnet: a parallel-dilated convolutional neural network architecture for detecting covid-19 from chest x-ray images,"The COVID-19 pandemic continues to severely undermine the prosperity of the global health system. To combat this pandemic, effective screening techniques for infected patients are indispensable. There is no doubt that the use of chest X-ray images for radiological assessment is one of the essential screening techniques. Some of the early studies revealed that the patient's chest X-ray images showed abnormalities, which is natural for patients infected with COVID-19. In this paper, we proposed a parallel-dilated convolutional neural network (CNN) based COVID-19 detection system from chest X-ray images, named as Parallel-Dilated COVIDNet (PDCOVIDNet). First, the publicly available chest X-ray collection fully preloaded and enhanced, and then classified by the proposed method. Differing convolution dilation rate in a parallel form demonstrates the proof-of-principle for using PDCOVIDNet to extract radiological features for COVID-19 detection. Accordingly, we have assisted our method with two visualization methods, which are specifically designed to increase understanding of the key components associated with COVID-19 infection. Both visualization methods compute gradients for a given image category related to feature maps of the last convolutional layer to create a class-discriminative region. In our experiment, we used a total of 2905 chest X-ray images, comprising three cases (such as COVID-19, normal, and viral pneumonia), and empirical evaluations revealed that the proposed method extracted more significant features expeditiously related to suspected disease. The experimental results demonstrate that our proposed method significantly improves performance metrics: the accuracy, precision, recall and F1 scores reach 96.58 %, 96.58 %, 96.59 % and 96.58 %, respectively, which is comparable or enhanced compared with the state-of-the-art methods. We believe that our contribution can support resistance to COVID-19, and will adopt for COVID-19 screening in AI-based systems.",279,"COVID-19;COVID-19 Pandemic;Infections;Pneumonia, Viral",28.0,Health Inf Sci Syst,Art;Architecture;Health;Map,3.420366268885954e-06,67.00000000000006,5.346842401579086e-06,157.0,0.0,External,2. Detection/Diagnosis,X-Ray
32983909,10.1016/j.matpr.2020.09.352,Yes,PMC7508494,32983909.0,2020,2020-09-29,Journal Article,Peer reviewed (PubMed),1,machine learning and image analysis applications in the fight against covid-19 pandemic: datasets research directions challenges and opportunities,"COVID-19 pandemic has become the most devastating disease of the current century and spread over 216 countries around the world. The disease is spreading through outbreaks despite the availability of modern sophisticated medical treatment. Machine Learning and Image Analysis research has been making great progress in many directions in the healthcare field for providing support to subsequent medical diagnosis. In this paper, we have propose three research directions with methodologies in the fight against the pandemic namely: Chest X-Ray (CXR) images classification using deep convolution neural networks with transfer learning to assist diagnosis; Patient Risk prediction of pandemic based on risk factors such as patient characteristics, comorbidities, initial symptoms, vital signs for prognosis of disease; and forecasting of disease spread and case fatality rate using deep neural networks. Further, some of the challenges, open datasets and opportunities are discussed for researchers.",141,COVID-19 Pandemic,5.0,Mater Today Proc,Health Care;Transfer Learning;Research Personnel;Disease Outbreaks;Risk Factors,2.232652837161592e-06,36.20800000000002,2.9003162032761645e-06,90.0,0.0,,Review,X-Ray
32984796,10.1016/S2589-7500(20)30199-0,Yes,PMC7508506,32984796.0,2020,2020-09-29,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,deep learning-based triage and analysis of lesion burden for covid-19: a retrospective study with external validation,"Prompt identification of patients suspected to have COVID-19 is crucial for disease control. We aimed to develop a deep learning algorithm on the basis of chest CT for rapid triaging in fever clinics. We trained a U-Net-based model on unenhanced chest CT scans obtained from 2447 patients admitted to Tongji Hospital (Wuhan, China) between Feb 1, 2020, and March 3, 2020 (1647 patients with RT-PCR-confirmed COVID-19 and 800 patients without COVID-19) to segment lung opacities and alert cases with COVID-19 imaging manifestations. The ability of artificial intelligence (AI) to triage patients suspected to have COVID-19 was assessed in a large external validation set, which included 2120 retrospectively collected consecutive cases from three fever clinics inside and outside the epidemic centre of Wuhan (Tianyou Hospital, Xianning Central Hospital, and The Second Xiangya Hospital ) between Jan 22, 2020, and Feb 14, 2020. To validate the sensitivity of the algorithm in a larger sample of patients with COVID-19, we also included 761 chest CT scans from 722 patients with RT-PCR-confirmed COVID-19 treated in a makeshift hospital (Guanggu Fangcang Hospital, Wuhan, China) between Feb 21, 2020, and March 6, 2020. Additionally, the accuracy of AI was compared with a radiologist panel for the identification of lesion burden increase on pairs of CT scans obtained from 100 patients with COVID-19. In the external validation set, using radiological reports as the reference standard, AI-aided triage achieved an AUC of 0·953, with a sensitivity of 0·923, specificity of 0·851, a positive predictive value of 0·790, and a negative predictive value of 0·948. AI took a median of 0·55 min (IQR: 0·43-0·63) to flag a positive case, whereas radiologists took a median of 16·21 min to draft a report and 23·06 min to release a report. With regard to the identification of increases in lesion burden, AI achieved a sensitivity of 0·962 and a specificity of 0·875. The agreement between AI and the radiologist panel was high. A deep learning algorithm for triaging patients with suspected COVID-19 at fever clinics was developed and externally validated. Given its high accuracy across populations with varied COVID-19 prevalence, integration of this system into the standard clinical workflow could expedite identification of chest CT scans with imaging indications of COVID-19. Special Project for Emergency of the Science and Technology Department of Hubei Province, China.",383,COVID-19;Fever,36.0,Lancet Digit Health,Severity of Illness Index;Predictive Value;Polymerase Chain Reaction;Radiologists;Retrospective Studies,6.740333478740571e-06,156.83999999999946,7.989699828031736e-06,429.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
32989379,10.1016/j.asoc.2020.106744,Yes,PMC7510455,32989379.0,2020,2020-09-30,Journal Article,Peer reviewed (PubMed),1,learning distinctive filters for covid-19 detection from chest x-ray using shuffled residual cnn,"COVID-19 is a deadly viral infection that has brought a significant threat to human lives. Automatic diagnosis of COVID-19 from medical imaging enables precise medication, helps to control community outbreak, and reinforces coronavirus testing methods in place. While there exist several challenges in manually inferring traces of this viral infection from X-ray, Convolutional Neural Network (CNN) can mine data patterns that capture subtle distinctions between infected and normal X-rays. To enable automated learning of such latent features, a custom CNN architecture has been proposed in this research. It learns unique convolutional filter patterns for each kind of pneumonia. This is achieved by restricting certain filters in a convolutional layer to maximally respond only to a particular class of pneumonia/COVID-19. The CNN architecture integrates different convolution types to aid better context for learning robust features and strengthen gradient flow between layers. The proposed work also visualizes regions of saliency on the X-ray that have had the most influence on CNN's prediction outcome. To the best of our knowledge, this is the first attempt in deep learning to learn custom filters within a single convolutional layer for identifying specific pneumonia classes. Experimental results demonstrate that the proposed work has significant potential in augmenting current testing methods for COVID-19. It achieves an F1-score of 97.20% and an accuracy of 99.80% on the COVID-19 X-ray set.",222,COVID-19;Pneumonia;Virus Diseases,33.0,Appl Soft Comput,Architecture;Disease Outbreaks,4.415761601572679e-06,62.11200000000001,5.069431942789326e-06,164.0,0.0,External,2. Detection/Diagnosis,X-Ray
32992136,10.1016/j.ijmedinf.2020.104284,Yes,PMC7510591,32992136.0,2020,2020-09-30,"Journal Article;Research Support, N.I.H., Extramural",Peer reviewed (PubMed),1,improving the performance of cnn to predict the likelihood of covid-19 using chest x-ray images with preprocessing algorithms,"This study aims to develop and test a new computer-aided diagnosis (CAD) scheme of chest X-ray images to detect coronavirus (COVID-19) infected pneumonia. CAD scheme first applies two image preprocessing steps to remove the majority of diaphragm regions, process the original image using a histogram equalization algorithm, and a bilateral low-pass filter. Then, the original image and two filtered images are used to form a pseudo color image. This image is fed into three input channels of a transfer learning-based convolutional neural network (CNN) model to classify chest X-ray images into 3 classes of COVID-19 infected pneumonia, other community-acquired no-COVID-19 infected pneumonia, and normal (non-pneumonia) cases. To build and test the CNN model, a publicly available dataset involving 8474 chest X-ray images is used, which includes 415, 5179 and 2,880 cases in three classes, respectively. Dataset is randomly divided into 3 subsets namely, training, validation, and testing with respect to the same frequency of cases in each class to train and test the CNN model. The CNN-based CAD scheme yields an overall accuracy of 94.5 % with a 95 % confidence interval of in classifying 3 classes. CAD also yields 98.4 % sensitivity and 98.0 % specificity in classifying cases with and without COVID-19 infection. However, without using two preprocessing steps, CAD yields a lower classification accuracy of 88.0 %. This study demonstrates that adding two image preprocessing steps and generating a pseudo color image plays an important role in developing a deep learning CAD scheme of chest X-ray images to improve accuracy in detecting COVID-19 infected pneumonia.",258,COVID-19;Infections;Pneumonia,93.0,Int J Med Inform,Coronavirus Infections;Transfer Learning;Algorithms;Sensitivity and Specificity;Neural Networks;Tomography,1.4738023976902124e-05,409.784000000008,2.48896387057198e-05,961.0,0.0,External,2. Detection/Diagnosis,X-Ray
33001832,10.2196/19878,Yes,PMC7593855,33001832.0,2020,2020-10-02,"Journal Article;Observational Study;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,application of an artificial intelligence trilogy to accelerate processing of suspected patients with sars-cov-2 at a smart quarantine station: observational study,"As the COVID-19 epidemic increases in severity, the burden of quarantine stations outside emergency departments (EDs) at hospitals is increasing daily. To address the high screening workload at quarantine stations, all staff members with medical licenses are required to work shifts in these stations. Therefore, it is necessary to simplify the workflow and decision-making process for physicians and surgeons from all subspecialties. The aim of this paper is to demonstrate how the National Cheng Kung University Hospital artificial intelligence (AI) trilogy of diversion to a smart quarantine station, AI-assisted image interpretation, and a built-in clinical decision-making algorithm improves medical care and reduces quarantine processing times. This observational study on the emerging COVID-19 pandemic included 643 patients. An ""AI trilogy"" of diversion to a smart quarantine station, AI-assisted image interpretation, and a built-in clinical decision-making algorithm on a tablet computer was applied to shorten the quarantine survey process and reduce processing time during the COVID-19 pandemic. The use of the AI trilogy facilitated the processing of suspected cases of COVID-19 with or without symptoms; also, travel, occupation, contact, and clustering histories were obtained with the tablet computer device. A separate AI-mode function that could quickly recognize pulmonary infiltrates on chest x-rays was merged into the smart clinical assisting system (SCAS), and this model was subsequently trained with COVID-19 pneumonia cases from the GitHub open source data set. The detection rates for posteroanterior and anteroposterior chest x-rays were 55/59 and 5/11, respectively. The SCAS algorithm was continuously adjusted based on updates to the Taiwan Centers for Disease Control public safety guidelines for faster clinical decision making. Our ex vivo study demonstrated the efficiency of disinfecting the tablet computer surface by wiping it twice with 75% alcohol sanitizer. To further analyze the impact of the AI application in the quarantine station, we subdivided the station group into groups with or without AI. Compared with the conventional ED (n=281), the survey time at the quarantine station (n=1520) was significantly shortened; the median survey time at the ED was 153 minutes, vs 35 minutes at the quarantine station. Furthermore, the use of the AI application in the quarantine station reduced the survey time in the quarantine station; the median survey time without AI was 101 minutes, vs 34 minutes with AI in the quarantine station (P<.001). The AI trilogy improved our medical care workflow by shortening the quarantine survey process and reducing the processing time, which is especially important during an emerging infectious disease epidemic.",410,"COVID-19;COVID-19 Pandemic;Communicable Diseases, Emerging;Pneumonia",4.0,J Med Internet Res,Other Topics;Cluster Analysis,1.1072837602611729e-05,240.00000000000017,1.1911842019426518e-05,648.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
33004526,10.1183/16000617.0181-2020,Yes,PMC7537944,33004526.0,2020,2020-10-03,Journal Article;Review,Peer reviewed (PubMed),1,artificial intelligence in pulmonary medicine: computer vision predictive model and covid-19,"Artificial intelligence (AI) is transforming healthcare delivery. The digital revolution in medicine and healthcare information is prompting a staggering growth of data intertwined with elements from many digital sources such as genomics, medical imaging and electronic health records. Such massive growth has sparked the development of an increasing number of AI-based applications that can be deployed in clinical practice. Pulmonary specialists who are familiar with the principles of AI and its applications will be empowered and prepared to seize future practice and research opportunities. The goal of this review is to provide pulmonary specialists and other readers with information pertinent to the use of AI in pulmonary medicine. First, we describe the concept of AI and some of the requisites of machine learning and deep learning. Next, we review some of the literature relevant to the use of computer vision in medical imaging, predictive modelling with machine learning, and the use of AI for battling the novel severe acute respiratory syndrome-coronavirus-2 pandemic. We close our review with a discussion of limitations and challenges pertaining to the further incorporation of AI into clinical pulmonary practice.",184,COVID-19;Severe Acute Respiratory Syndrome,17.0,Eur Respir Rev,Coronavirus Infections;Health Care,3.515174972530266e-06,39.83200000000001,3.133043271327712e-06,125.0,0.0,,Review,Multimodal
33014121,10.1155/2020/9756518,Yes,PMC7519983,33014121.0,2020,2020-10-06,Journal Article;Review,Peer reviewed (PubMed),1,review on diagnosis of covid-19 from chest ct images using artificial intelligence,"The COVID-19 diagnostic approach is mainly divided into two broad categories, a laboratory-based and chest radiography approach. The last few months have witnessed a rapid increase in the number of studies use artificial intelligence (AI) techniques to diagnose COVID-19 with chest computed tomography (CT). In this study, we review the diagnosis of COVID-19 by using chest CT toward AI. We searched ArXiv, MedRxiv, and Google Scholar using the terms ""deep learning"", ""neural networks"", ""COVID-19"", and ""chest CT"". At the time of writing (August 24, 2020), there have been nearly 100 studies and 30 studies among them were selected for this review. We categorized the studies based on the classification tasks: COVID-19/normal, COVID-19/non-COVID-19, COVID-19/non-COVID-19 pneumonia, and severity. The sensitivity, specificity, precision, accuracy, AUC, and F1 score results were reported as high as 100%, 100%, 99.62, 99.87%, 100%, and 99.5%, respectively. However, the presented results should be carefully compared due to the different degrees of difficulty of different classification tasks.",158,COVID-19;Pneumonia,74.0,Comput Math Methods Med,Radiography;Coronavirus Infections;COVID-19 Testing;Sensitivity and Specificity;Neural Networks,6.102858389061585e-06,131.50399999999968,6.870007677114367e-06,392.0,0.0,,Review,CT
33014355,10.1007/s13755-020-00116-6,Yes,PMC7522455,33014355.0,2020,2020-10-06,Journal Article,Peer reviewed (PubMed),1,the investigation of multiresolution approaches for chest x-ray image based covid-19 detection,"COVID-19 is a novel virus, which has a fast spreading rate, and now it is seen all around the world. The case and death numbers are increasing day by day. Some tests have been used to determine the COVID-19. Chest X-ray and chest computerized tomography (CT) are two important imaging tools for determination and monitoring of COVID-19. And new methods have been searching for determination of the COVID-19. In this paper, the investigation of various multiresolution approaches in detection of COVID-19 is carried out. Chest X-ray images are used as input to the proposed approach. As recent trend in machine learning shifts toward the deep learning, we would like to show that the traditional methods such as multiresolution approaches are still effective. To this end, the well-known multiresolution approaches namely Wavelet, Shearlet and Contourlet transforms are used to decompose the chest X-ray images and the entropy and the normalized energy approaches are employed for feature extraction from the decomposed chest X-ray images. Entropy and energy features are generally accompanied with the multiresolution approaches in texture recognition applications. The extreme learning machines (ELM) classifier is considered in the classification stage of the proposed study. A dataset containing 361 different COVID-19 chest X-ray images and 200 normal (healthy) chest X-ray images are used in the experimental works. The performance evaluation is carried out by employing various metric namely accuracy, sensitivity, specificity and precision. As deep learning is mentioned, a comparison between proposed multiresolution approaches and deep learning approaches is also carried out. To this end, deep feature extraction and fine-tuning of pretrained convolutional neural networks (CNNs) are considered. For deep feature extraction, pretrained, ResNet50 model is employed. For classification of the deep features, the Support Vector Machines (SVM) classifier is used. The ResNet50 model is also used in the fine-tuning. The experimental works show that multiresolution approaches produced better performance than the deep learning approaches. Especially, Shearlet transform outperformed at all. 99.29% accuracy score is obtained by using Shearlet transform.",328,COVID-19;Death,20.0,Health Inf Sci Syst,Sensitivity;Viruses;Entropy;Support Vector Machine,8.044361091374583e-06,195.10399999999908,1.25412768472858e-05,462.0,0.0,External,2. Detection/Diagnosis,X-Ray
33015100,10.3389/fmed.2020.00550,Yes,PMC7461795,33015100.0,2020,2020-10-06,Journal Article,Peer reviewed (PubMed),1,the performance of deep neural networks in differentiating chest x-rays of covid-19 patients from other bacterial and viral pneumonias,"Chest radiography is a critical tool in the early detection, management planning, and follow-up evaluation of COVID-19 pneumonia; however, in smaller clinics around the world, there is a shortage of radiologists to analyze large number of examinations especially performed during a pandemic. Limited availability of high-resolution computed tomography and real-time polymerase chain reaction in developing countries and regions of high patient turnover also emphasizes the importance of chest radiography as both a screening and diagnostic tool. In this paper, we compare the performance of 17 available deep learning algorithms to help identify imaging features of COVID19 pneumonia. We utilize an existing diagnostic technology (chest radiography) and preexisting neural networks (DarkNet-19) to detect imaging features of COVID-19 pneumonia. Our approach eliminates the extra time and resources needed to develop new technology and associated algorithms, thus aiding the front-line healthcare workers in the race against the COVID-19 pandemic. Our results show that DarkNet-19 is the optimal pre-trained neural network for the detection of radiographic features of COVID-19 pneumonia, scoring an overall accuracy of 94.28% over 5,854 X-ray images. We also present a custom visualization of the results that can be used to highlight important visual biomarkers of the disease and disease progression.",200,"COVID-19;COVID-19 Pandemic;Disease Progression;Pneumonia;Pneumonia, Viral",10.0,Front Med (Lausanne),Transfer Learning;Algorithms;Polymerase Chain Reaction;Tomography;Real-Time Polymerase Chain Reaction,2.857691013561324e-06,35.472,2.6266380177587185e-06,102.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
33025386,10.1007/s13246-020-00934-8,Yes,PMC7537970,33025386.0,2020,2020-10-08,Journal Article,Peer reviewed (PubMed),1,issues associated with deploying cnn transfer learning to detect covid-19 from chest x-rays,"Covid-19 first occurred in Wuhan, China in December 2019. Subsequently, the virus spread throughout the world and as of June 2020 the total number of confirmed cases are above 4.7 million with over 315,000 deaths. Machine learning algorithms built on radiography images can be used as a decision support mechanism to aid radiologists to speed up the diagnostic process. The aim of this work is to conduct a critical analysis to investigate the applicability of convolutional neural networks (CNNs) for the purpose of COVID-19 detection in chest X-ray images and highlight the issues of using CNN directly on the whole image. To accomplish this task, we use 12-off-the-shelf CNN architectures in transfer learning mode on 3 publicly available chest X-ray databases together with proposing a shallow CNN architecture in which we train it from scratch. Chest X-ray images are fed into CNN models without any preprocessing to replicate researches used chest X-rays in this manner. Then a qualitative investigation performed to inspect the decisions made by CNNs using a technique known as class activation maps (CAM). Using CAMs, one can map the activations contributed to the decision of CNNs back to the original image to visualize the most discriminating regions on the input image. We conclude that CNN decisions should not be taken into consideration, despite their high classification accuracy, until clinicians can visually inspect and approve the regions of the input image used by CNNs that lead to its prediction.",241,COVID-19;Death,21.0,Phys Eng Sci Med,Algorithms;Transfer Learning;Architecture;Image Processing;Neural Networks;Map,4.232637354609329e-06,140.59199999999927,1.0154622135676914e-05,300.0,0.0,External,2. Detection/Diagnosis,X-Ray
33029064,10.12788/fp.0045,Yes,PMC7535959,33029064.0,2020,2020-10-09,Journal Article,Peer reviewed (PubMed),1,using artificial intelligence for covid-19 chest x-ray diagnosis,"Coronavirus disease-19 (COVID-19), caused by a novel member of the coronavirus family, is a respiratory disease that rapidly reached pandemic proportions with high morbidity and mortality. In only a few months, it has had a dramatic impact on society and world economies. COVID-19 has presented numerous challenges to all aspects of health care, including reliable methods for diagnosis, treatment, and prevention. Initial efforts to contain the spread of the virus were hampered by the time required to develop reliable diagnostic methods. Artificial intelligence (AI) is a rapidly growing field of computer science with many applications for health care. Machine learning is a subset of AI that uses deep learning with neural network algorithms. It can recognize patterns and achieve complex computational tasks often far quicker and with increased precision than can humans. In this article, we explore the potential for the simple and widely available chest X-ray (CXR) to be used with AI to diagnose COVID-19 reliably. Microsoft CustomVision is an automated image classification and object detection system that is a part of Microsoft Azure Cognitive Services. We utilized publicly available CXR images for patients with COVID-19 pneumonia, pneumonia from other etiologies, and normal CXRs as a dataset to train Microsoft CustomVision. Our trained model overall demonstrated 92.9% sensitivity (recall) and positive predictive value (precision), with results for each label showing sensitivity and positive predictive value at 94.8% and 98.9% for COVID-19 pneumonia, 89% and 91.8% for non-COVID-19 pneumonia, 95% and 88.8% for normal lung. We then validated the program using CXRs of patients from our institution with confirmed COVID-19 diagnoses along with non-COVID-19 pneumonia and normal CXRs. Our model performed with 100% sensitivity, 95% specificity, 97% accuracy, 91% positive predictive value, and 100% negative predictive value. We have used a readily available, commercial platform to demonstrate the potential of AI to assist in the successful diagnosis of COVID-19 pneumonia on CXR images. The findings have implications for screening and triage, initial diagnosis, monitoring disease progression, and identifying patients at increased risk of morbidity and mortality. Based on the data, a website was created to demonstrate how such technologies could be shared and distributed to others to combat entities such as COVID-19 moving forward.",364,COVID-19;Disease Progression;Pneumonia;Respiratory Tract Diseases,32.0,Fed Pract,Health Care;Sensitivity and Specificity,2.611939647469426e-06,51.33600000000003,3.769956747395528e-06,129.0,0.0,External,2. Detection/Diagnosis,X-Ray
33037212,10.1038/s41467-020-18685-1,Yes,PMC7547659,33037212.0,2020,2020-10-11,"Evaluation Study;Journal Article;Multicenter Study;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,development and evaluation of an artificial intelligence system for covid-19 diagnosis,"Early detection of COVID-19 based on chest CT enables timely treatment of patients and helps control the spread of the disease. We proposed an artificial intelligence (AI) system for rapid COVID-19 detection and performed extensive statistical analysis of CTs of COVID-19 based on the AI system. We developed and evaluated our system on a large dataset with more than 10 thousand CT volumes from COVID-19, influenza-A/B, non-viral community acquired pneumonia (CAP) and non-pneumonia subjects. In such a difficult multi-class diagnosis task, our deep convolutional neural network-based system is able to achieve an AUC of 97.81% for multi-way classification on test cohort of 3,199 scans, AUC of 92.99% and 93.25% on two publicly available datasets, CC-CCII and MosMedData respectively. In a reader study involving five radiologists, the AI system outperforms all of radiologists in more challenging tasks at a speed of two orders of magnitude above them. Diagnosis performance of chest x-ray (CXR) is compared to that of CT. Detailed interpretation of deep network is also performed to relate system outputs with CT presentations. The code is available at GitHub .",180,"COVID-19;Influenza, Human;Pneumonia",174.0,Nat Commun,Coronavirus Infections;ROC Curve;Age,5.3076149104609256e-06,120.28799999999949,7.272004880888611e-06,312.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,Multimodal
33038076,10.2196/21604,Yes,PMC7674140,33038076.0,2020,2020-10-11,Journal Article,Peer reviewed (PubMed),1,prediction of covid-19 severity using chest computed tomography and laboratory measurements: evaluation using a machine learning approach,"Most of the mortality resulting from COVID-19 has been associated with severe disease. Effective treatment of severe cases remains a challenge due to the lack of early detection of the infection. This study aimed to develop an effective prediction model for COVID-19 severity by combining radiological outcome with clinical biochemical indexes. A total of 46 patients with COVID-19 (10 severe, 36 nonsevere) were examined. To build the prediction model, a set of 27 severe and 151 nonsevere clinical laboratory records and computerized tomography (CT) records were collected from these patients. We managed to extract specific features from the patients' CT images by using a recently published convolutional neural network. We also trained a machine learning model combining these features with clinical laboratory results. We present a prediction model combining patients' radiological outcomes with their clinical biochemical indexes to identify severe COVID-19 cases. The prediction model yielded a cross-validated AUC (AUROC) score of 0.93 and an F1 score of 0.89, which showed a 6% and 15% improvement, respectively, compared to the models based on laboratory test features only. In addition, we developed a statistical model for forecasting COVID-19 severity based on the results of patients' laboratory tests performed before they were classified as severe cases; this model yielded an AUROC score of 0.81. To our knowledge, this is the first report predicting the clinical progression of COVID-19, as well as forecasting severity, based on a combined analysis using laboratory tests and CT images.",242,COVID-19;Clinical Course;Infections,11.0,JMIR Med Inform,Other Topics,1.4981497609144714e-06,19.824000000000005,1.4202157931081288e-06,52.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33041409,10.1016/j.patrec.2020.10.001,Yes,PMC7532353,33041409.0,2020,2020-10-13,Journal Article,Peer reviewed (PubMed),1,a light cnn for detecting covid-19 from ct scans of the chest,"Computer Tomography (CT) imaging of the chest is a valid diagnosis tool to detect COVID-19 promptly and to control the spread of the disease. In this work we propose a light Convolutional Neural Network (CNN) design, based on the model of the SqueezeNet, for the efficient discrimination of COVID-19 CT images with respect to other community-acquired pneumonia and/or healthy CT images. The architecture allows to an accuracy of 85.03% with an improvement of about 3.2% in the first dataset arrangement and of about 2.1% in the second dataset arrangement. The obtained gain, though of low entity, can be really important in medical diagnosis and, in particular, for Covid-19 scenario. Also the average classification time on a high-end workstation, 1.25 s, is very competitive with respect to that of more complex CNN designs, 13.41 s, witch require pre-processing. The proposed CNN can be executed on medium-end laptop without GPU acceleration in 7.81 s: this is impossible for methods requiring GPU acceleration. The performance of the method can be further improved with efficient pre-processing strategies for witch GPU acceleration is not necessary.",180,COVID-19;Pneumonia,79.0,Pattern Recognit Lett,Other Topics,2.4261228955232064e-06,40.26400000000003,3.206565291540672e-06,93.0,0.0,External,2. Detection/Diagnosis,CT
33041635,10.1007/s11042-020-09894-3,Yes,PMC7537375,33041635.0,2020,2020-10-13,Journal Article,Peer reviewed (PubMed),1,a novel comparative study for detection of covid-19 on ct lung images using texture analysis machine learning and deep learning methods,"The Covid-19 virus outbreak that emerged in China at the end of 2019 caused a huge and devastating effect worldwide. In patients with severe symptoms of the disease, pneumonia develops due to Covid-19 virus. This causes intense involvement and damage in lungs. Although the emergence of the disease occurred a short time ago, many literature studies have been carried out in which these effects of the disease on the lungs were revealed by the help of lung CT imaging. In this study, 1.396 lung CT images in total (386 Covid-19 and 1.010 Non-Covid-19) were subjected to automatic classification. In this study, Convolutional Neural Network (CNN), one of the deep learning methods, was used which suggested automatic classification of CT images of lungs for early diagnosis of Covid-19 disease. In addition, k-Nearest Neighbors (k-NN) and Support Vector Machine (SVM) was used to compare the classification successes of deep learning with machine learning. Within the scope of the study, a 23-layer CNN architecture was designed and used as a classifier. Also, training and testing processes were performed for Alexnet and Mobilenetv2 CNN architectures as well. The classification results were also calculated for the case of increasing the number of images used in training for the first 23-layer CNN architecture by 5, 10, and 20 times using data augmentation methods. To reveal the effect of the change in the number of images in the training and test clusters on the results, two different training and testing processes, 2-fold and 10-fold cross-validation, were performed and the results of the study were calculated. As a result, thanks to these detailed calculations performed within the scope of the study, a comprehensive comparison of the success of the texture analysis method, machine learning, and deep learning methods in Covid-19 classification from CT images was made. The highest mean sensitivity, specificity, accuracy, F-1 score, and AUC values obtained as a result of the study were 0,9197, 0,9891, 0,9473, 0,9058, 0,9888; respectively for 2-fold cross-validation, and they were 0,9404, 0,9901, 0,9599, 0,9284, 0,9903; respectively for 10-fold cross-validation.",338,COVID-19;Pneumonia,28.0,Multimed Tools Appl,Architecture;Disease Outbreaks;Area under Curve;Early Diagnosis,3.3561160198545585e-06,86.32799999999992,6.141881525346292e-06,183.0,0.0,External,2. Detection/Diagnosis,CT
33042210,10.1016/j.bspc.2020.102257,Yes,PMC7538100,33042210.0,2020,2020-10-13,Journal Article,Peer reviewed (PubMed),1,mh-covidnet: diagnosis of covid-19 using deep neural networks and meta-heuristic-based feature selection on x-ray images,"COVID-19 is a disease that causes symptoms in the lungs and causes deaths around the world. Studies are ongoing for the diagnosis and treatment of this disease, which is defined as a pandemic. Early diagnosis of this disease is important for human life. This process is progressing rapidly with diagnostic studies based on deep learning. Therefore, to contribute to this field, a deep learning-based approach that can be used for early diagnosis of the disease is proposed in our study. In this approach, a data set consisting of 3 classes of COVID19, normal and pneumonia lung X-ray images was created, with each class containing 364 images. Pre-processing was performed using the image contrast enhancement algorithm on the prepared data set and a new data set was obtained. Feature extraction was completed from this data set with deep learning models such as AlexNet, VGG19, GoogleNet, and ResNet. For the selection of the best potential features, two metaheuristic algorithms of binary particle swarm optimization and binary gray wolf optimization were used. After combining the features obtained in the feature selection of the enhancement data set, they were classified using SVM. The overall accuracy of the proposed approach was obtained as 99.38%. The results obtained by verification with two different metaheuristic algorithms proved that the approach we propose can help experts during COVID-19 diagnostic studies.",222,COVID-19;Death;Pneumonia,44.0,Biomed Signal Process Control,Other Topics,3.1724334381545105e-06,29.66400000000001,2.798286711703352e-06,84.0,0.0,External,2. Detection/Diagnosis,X-Ray
33044938,10.1109/JBHI.2020.3030224,Yes,,33044938.0,2020,2020-10-13,"Journal Article;Research Support, N.I.H., Extramural",Peer reviewed (PubMed),1,severity and consolidation quantification of covid-19 from ct images using deep learning based on hybrid weak labels,"Early and accurate diagnosis of Coronavirus disease (COVID-19) is essential for patient isolation and contact tracing so that the spread of infection can be limited. Computed tomography (CT) can provide important information in COVID-19, especially for patients with moderate to severe disease as well as those with worsening cardiopulmonary status. As an automatic tool, deep learning methods can be utilized to perform semantic segmentation of affected lung regions, which is important to establish disease severity and prognosis prediction. Both the extent and type of pulmonary opacities help assess disease severity. However, manually pixel-level multi-class labelling is time-consuming, subjective, and non-quantitative. In this article, we proposed a hybrid weak label-based deep learning method that utilize both the manually annotated pulmonary opacities from COVID-19 pneumonia and the patient-level disease-type information available from the clinical report. A UNet was firstly trained with semantic labels to segment the total infected region. It was used to initialize another UNet, which was trained to segment the consolidations with patient-level information using the Expectation-Maximization (EM) algorithm. To demonstrate the performance of the proposed method, multi-institutional CT datasets from Iran, Italy, South Korea, and the United States were utilized. Results show that our proposed method can predict the infected regions as well as the consolidation regions with good correlation to human annotation.",214,COVID-19;Infections;Pneumonia,15.0,IEEE J Biomed Health Inform,Severity of Illness Index;Coronavirus Infections;Algorithms;Iran;Semantics;Report;Retrospective Studies,2.7200357801572614e-06,38.944,2.6512310561270377e-06,114.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
33046116,10.1186/s40001-020-00450-1,Yes,PMC7549080,33046116.0,2020,2020-10-14,Journal Article,Peer reviewed (PubMed),1,development of a quantitative segmentation model to assess the effect of comorbidity on patients with covid-19,"The coronavirus disease 2019 (COVID-19) has brought a global disaster. Quantitative lesions may provide the radiological evidence of the severity of pneumonia and further to assess the effect of comorbidity on patients with COVID-19. 294 patients with COVID-19 were enrolled from February, 24, 2020 to June, 1, 2020 from six centers. Multi-task Unet network was used to segment the whole lung and lesions from chest CT images. This deep learning method was pre-trained in 650 CT images (550 in primary dataset and 100 in test dataset) with COVID-19 or community-acquired pneumonia and Dice coefficients in test dataset were calculated. 50 CT scans of 50 patients (15 with comorbidity and 35 without comorbidity) were random selected to mark lesions manually. The results will be compared with the automatic segmentation model. Eight quantitative parameters were calculated based on the segmentation results to evaluate the effect of comorbidity on patients with COVID-19. Quantitative segmentation model was proved to be effective and accurate with all Dice coefficients more than 0.85 and all accuracies more than 0.95. Of the 294 patients, 52 patients were reported having at least one comorbidity; 14 having more than one comorbidity. Patients with any comorbidity were older (P < 0.001), had longer incubation period (P < 0.001), were more likely to have abnormal laboratory findings (P < 0.05), and be in severity status (P < 0.001). More lesions (including larger volume of lesion, consolidation, and ground-glass opacity) were shown in patients with any comorbidity than patients without comorbidity (all P < 0.001). More lesions were found on CT images in patients with more comorbidities. The median volumes of lesion, consolidation, and ground-glass opacity in diabetes mellitus group were largest among the groups with single comorbidity that had the incidence rate of top three. Multi-task Unet network can make quantitative CT analysis of lesions to assess the effect of comorbidity on patients with COVID-19, further to provide the radiological evidence of the severity of pneumonia. More lesions (including GGO and consolidation) were found in CT images of cases with comorbidity. The more comorbidities patients have, the more lesions CT images show.",350,COVID-19;Diabetes Mellitus;Pneumonia,3.0,Eur J Med Res,Coronavirus Infections;Retrospective Studies,8.24024393572104e-06,171.3279999999994,9.683793537961832e-06,478.0,0.0,Self-recorded/clinical,Segmentation-only,CT
33046370,10.1016/j.acra.2020.09.004,Yes,PMC7505599,33046370.0,2020,2020-10-14,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,ct quantification and machine-learning models for assessment of disease severity and prognosis of covid-19 patients,"This study was to investigate the CT quantification of COVID-19 pneumonia and its impacts on the assessment of disease severity and the prediction of clinical outcomes in the management of COVID-19 patients. Ninety-nine COVID-19 patients who were confirmed by positive nucleic acid test (NAT) of RT-PCR and hospitalized from January 19, 2020 to February 19, 2020 were collected for this retrospective study. All patients underwent arterial blood gas test, routine blood test, chest CT examination, and physical examination on admission. In addition, follow-up clinical data including the disease severity, clinical treatment, and clinical outcomes were collected for each patient. Lung volume, lesion volume, nonlesion lung volume (NLLV) (lung volume - lesion volume), and fraction of nonlesion lung volume (%NLLV) (nonlesion lung volume / lung volume) were quantified in CT images by using two U-Net models trained for segmentation of lung and COVID-19 lesions in CT images. Furthermore, we calculated 20 histogram textures for lesions volume and NLLV, respectively. To investigate the validity of CT quantification in the management of COVID-19, we built random forest (RF) models for the purpose of classification and regression to assess the disease severity (Moderate, Severe, and Critical) and to predict the need and length of ICU stay, the duration of oxygen inhalation, hospitalization, sputum NAT-positive, and patient prognosis. The performance of RF classifiers was evaluated using the AUCs and that of RF regressors using the root-mean-square error. Patients were classified into three groups of disease severity: moderate (n = 25), severe (n = 47) and critical (n = 27), according to the clinical staging. Of which, a total of 32 patients, 1 moderate, 6 severe, and 25 critical, respectively, were admitted to ICU. The median values of ICU stay were 0, 0, and 12 days, the duration of oxygen inhalation 10, 15, and 28 days, the hospitalization 12, 16, and 28 days, and the sputum NAT-positive 8, 9, and 13 days, in three severity groups, respectively. The clinical outcomes were complete recovery (n = 3), partial recovery with residual pulmonary damage (n = 80), prolonged recovery (n = 15), and death (n = 1). The %NLLV in three severity groups were 92.18 %, 82.94 %, and 66.19 % with p value <0.05 among each two groups. The AUCs of RF classifiers using hybrid models were 0.927 and 0.929 in classification of moderate vs (severe + critical), and severe vs critical, respectively, which were significantly higher than either radiomics models or clinical models (p < 0.05). The root-mean-square errors of RF regressors were 0.88 weeks for prediction of duration of hospitalization (mean: 2.60 weeks), 0.92 weeks for duration of oxygen inhalation (mean: 2.44 weeks), 0.90 weeks for duration of sputum NAT-positive (mean: 1.59 weeks), and 0.69 weeks for stay of ICU (mean: 1.32 weeks), respectively. The AUCs for prediction of ICU treatment and prognosis (partial recovery vs prolonged recovery) were 0.945 and 0.960, respectively. CT quantification and machine-learning models show great potentials for assisting decision-making in the management of COVID-19 patients by assessing disease severity and predicting clinical outcomes.",503,COVID-19;Death;Pneumonia,49.0,Acad Radiol,Coronavirus Infections;COVID-19 Testing;Polymerase Chain Reaction;Hematologic Tests;Retrospective Studies;Area under Curve;Nucleic Acids;Receiver Operating Characteristic;Random Forest,1.02459229524593e-05,379.8640000000069,1.8649115159968333e-05,931.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33047295,10.1007/s11547-020-01293-w,Yes,PMC7549421,33047295.0,2020,2020-10-14,Journal Article,Peer reviewed (PubMed),1,clinical and laboratory data radiological structured report findings and quantitative evaluation of lung involvement on baseline chest ct in covid-19 patients to predict prognosis,"To evaluate by means of regression models the relationships between baseline clinical and laboratory data and lung involvement on baseline chest CT and to quantify the thoracic disease using an artificial intelligence tool and a visual scoring system to predict prognosis in patients with COVID-19 pneumonia. This study included 103 (41 women and 62 men; 68.8 years of mean age-range, 29-93 years) with suspicious COVID-19 viral infection evaluated by reverse transcription real-time fluorescence polymerase chain reaction (RT-PCR) test. All patients underwent CT examinations at the time of admission in addition to clinical and laboratory findings recording. All chest CT examinations were reviewed using a structured report. Moreover, using an artificial intelligence tool we performed an automatic segmentation on CT images based on Hounsfield unit to calculate residual healthy lung parenchyma, ground-glass opacities (GGO), consolidations and emphysema volumes for both right and left lungs. Two expert radiologists, in consensus, attributed at the CT pulmonary disease involvement a severity score using a scale of 5 levels; the score was attributed for GGO and consolidation for each lung, and then, an overall radiological severity visual score was obtained summing the single score. Univariate and multivariate regression analysis was performed. Symptoms and comorbidities did not show differences statistically significant in terms of patient outcome. Instead, SpO2 was significantly lower in patients hospitalized in critical conditions or died while age, HS CRP, leukocyte count, neutrophils, LDH, d-dimer, troponin, creatinine and azotemia, ALT, AST and bilirubin values were significantly higher. GGO and consolidations were the main CT patterns (a variable combination of GGO and consolidations was found in 87.8% of patients). CT COVID-19 disease was prevalently bilateral with peripheral distribution and multiple lobes localizations. Consolidation, emphysema and residual healthy lung parenchyma volumes showed statistically significant differences in the three groups of patients based on outcome (patients discharged at home, patients hospitalized in stable conditions and patient hospitalized in critical conditions or died) while GGO volume did not affect the patient's outcome. Moreover, the overall radiological severity visual score (cutoff ≥ 8) was a predictor of patient outcome. The highest value of R-squared (R2 = 0.93) was obtained by the model that combines clinical/laboratory findings at CT volumes. The highest accuracy was obtained by clinical/laboratory and CT findings model with a sensitivity, specificity and accuracy, respectively, of 88%, 78% and 81% to predict discharged/stable patients versus critical/died patients. In conclusion, both CT visual score and computerized software-based quantification of the consolidation, emphysema and residual healthy lung parenchyma on chest CT images were independent predictors of outcome in patients with COVID-19 pneumonia.",424,Azotemia;COVID-19;Emphysema;Lung Diseases;Pneumonia;Thoracic Diseases;Virus Diseases,33.0,Radiol Med,Predictive Value;COVID-19 Testing;Polymerase Chain Reaction;Reverse Transcription,9.118158861080293e-06,399.8800000000069,2.015132616035199e-05,953.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33048773,10.1109/JBHI.2020.3030853,Yes,,33048773.0,2020,2020-10-14,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,m 3lung-sys: a deep learning system for multi-class lung pneumonia screening from ct imaging,"To counter the outbreak of COVID-19, the accurate diagnosis of suspected cases plays a crucial role in timely quarantine, medical treatment, and preventing the spread of the pandemic. Considering the limited training cases and resources (e.g, time and budget), we propose a Multi-task Multi-slice Deep Learning System (M 3Lung-Sys) for multi-class lung pneumonia screening from CT imaging, which only consists of two 2D CNN networks, i.e., slice- and patient-level classification networks. The former aims to seek the feature representations from abundant CT slices instead of limited CT volumes, and for the overall pneumonia screening, the latter one could recover the temporal information by feature refinement and aggregation between different slices. In addition to distinguish COVID-19 from Healthy, H1N1, and CAP cases, our M 3Lung-Sys also be able to locate the areas of relevant lesions, without any pixel-level annotation. To further demonstrate the effectiveness of our model, we conduct extensive experiments on a chest CT imaging dataset with a total of 734 patients (251 healthy people, 245 COVID-19 patients, 105 H1N1 patients, and 133 CAP patients). The quantitative results with plenty of metrics indicate the superiority of our proposed model on both slice- and patient-level classification tasks. More importantly, the generated lesion location maps make our system interpretable and more valuable to clinicians.",212,COVID-19;Pneumonia,21.0,IEEE J Biomed Health Inform,Disease Outbreaks;Other Topics;Lung Diseases;Map;Cone-Beam Computed Tomography,2.103030602900144e-06,22.911999999999995,1.6971692791196443e-06,76.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33061946,10.1155/2020/8889023,Yes,PMC7539085,33061946.0,2020,2020-10-17,Journal Article,Peer reviewed (PubMed),1,artificial intelligence-based classification of chest x-ray images into covid-19 and other infectious diseases,"The ongoing pandemic of coronavirus disease 2019 (COVID-19) has led to global health and healthcare crisis, apart from the tremendous socioeconomic effects. One of the significant challenges in this crisis is to identify and monitor the COVID-19 patients quickly and efficiently to facilitate timely decisions for their treatment, monitoring, and management. Research efforts are on to develop less time-consuming methods to replace or to supplement RT-PCR-based methods. The present study is aimed at creating efficient deep learning models, trained with chest X-ray images, for rapid screening of COVID-19 patients. We used publicly available PA chest X-ray images of adult COVID-19 patients for the development of Artificial Intelligence (AI)-based classification models for COVID-19 and other major infectious diseases. To increase the dataset size and develop generalized models, we performed 25 different types of augmentations on the original images. Furthermore, we utilized the transfer learning approach for the training and testing of the classification models. The combination of two best-performing models (each trained on 286 images, rotated through 120° or 140° angle) displayed the highest prediction accuracy for normal, COVID-19, non-COVID-19, pneumonia, and tuberculosis images. AI-based classification models trained through the transfer learning approach can efficiently classify the chest X-ray images representing studied diseases. Our method is more efficient than previously published methods. It is one step ahead towards the implementation of AI-based methods for classification problems in biomedical imaging related to COVID-19.",231,COVID-19;Communicable Diseases;Pneumonia;Tuberculosis,34.0,Int J Biomed Imaging,Health Care;Transfer Learning;Polymerase Chain Reaction;Communicable Diseases,2.7653953517103854e-06,40.72000000000001,3.0612767180094324e-06,108.0,0.0,External,2. Detection/Diagnosis,X-Ray
33065387,10.1016/j.compbiomed.2020.104037,Yes,PMC7543793,33065387.0,2020,2020-10-17,Journal Article,Peer reviewed (PubMed),1,multi-task deep learning based ct imaging analysis for covid-19 pneumonia: classification and segmentation,"This paper presents an automatic classification segmentation tool for helping screening COVID-19 pneumonia using chest CT imaging. The segmented lesions can help to assess the severity of pneumonia and follow-up the patients. In this work, we propose a new multitask deep learning model to jointly identify COVID-19 patient and segment COVID-19 lesion from chest CT images. Three learning tasks: segmentation, classification and reconstruction are jointly performed with different datasets. Our motivation is on the one hand to leverage useful information contained in multiple related tasks to improve both segmentation and classification performances, and on the other hand to deal with the problems of small data because each task can have a relatively small dataset. Our architecture is composed of a common encoder for disentangled feature representation with three tasks, and two decoders and a multi-layer perceptron for reconstruction, segmentation and classification respectively. The proposed model is evaluated and compared with other image segmentation techniques using a dataset of 1369 patients including 449 patients with COVID-19, 425 normal ones, 98 with lung cancer and 397 of different kinds of pathology. The obtained results show very encouraging performance of our method with a dice coefficient higher than 0.88 for the segmentation and an AUC higher than 97% for the classification.",208,COVID-19;Lung Cancer;Pneumonia,171.0,Comput Biol Med,Coronavirus Infections;Architecture;Neural Networks;ROC Curve,8.224448928527063e-06,171.94399999999928,1.047477588697362e-05,439.0,0.0,External,2. Detection/Diagnosis,CT
33081700,10.1186/s12880-020-00521-z,Yes,PMC7573533,33081700.0,2020,2020-10-22,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,a model based on ct radiomic features for predicting rt-pcr becoming negative in coronavirus disease 2019 (covid-19) patients,"Coronavirus disease 2019 (COVID-19) has emerged as a global pandemic. According to the diagnosis and treatment guidelines of China, negative reverse transcription-polymerase chain reaction (RT-PCR) is the key criterion for discharging COVID-19 patients. However, repeated RT-PCR tests lead to medical waste and prolonged hospital stays for COVID-19 patients during the recovery period. Our purpose is to assess a model based on chest computed tomography (CT) radiomic features and clinical characteristics to predict RT-PCR negativity during clinical treatment. From February 10 to March 10, 2020, 203 mild COVID-19 patients in Fangcang Shelter Hospital were retrospectively included (training: n = 141; testing: n = 62), and clinical characteristics were collected. Lung abnormalities on chest CT images were segmented with a deep learning algorithm. CT quantitative features and radiomic features were automatically extracted. Clinical characteristics and CT quantitative features were compared between RT-PCR-negative and RT-PCR-positive groups. Univariate logistic regression and Spearman correlation analyses identified the strongest features associated with RT-PCR negativity, and a multivariate logistic regression model was established. The diagnostic performance was evaluated for both cohorts. The RT-PCR-negative group had a longer time interval from symptom onset to CT exams than the RT-PCR-positive group (median 23 vs. 16 days, p < 0.001). There was no significant difference in the other clinical characteristics or CT quantitative features. In addition to the time interval from symptom onset to CT exams, nine CT radiomic features were selected for the model. ROC curve analysis revealed AUCs of 0.811 and 0.812 for differentiating the RT-PCR-negative group, with sensitivity/specificity of 0.765/0.625 and 0.784/0.600 in the training and testing datasets, respectively. The model combining CT radiomic features and clinical data helped predict RT-PCR negativity during clinical treatment, indicating the proper time for RT-PCR retesting.",285,COVID-19,15.0,BMC Med Imaging,Coronavirus Infections;Algorithms;Logistic Regression;Polymerase Chain Reaction;ROC Curve;Retrospective Studies;Area under Curve;Real-Time Polymerase Chain Reaction;Age;Reverse Transcription,9.98253392747442e-06,241.44000000000128,1.012986139197934e-05,760.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33091743,10.1016/j.media.2020.101844,Yes,PMC7553063,33091743.0,2020,2020-10-23,"Journal Article;Research Support, N.I.H., Extramural",Peer reviewed (PubMed),1,integrative analysis for covid-19 patient outcome prediction,"While image analysis of chest computed tomography (CT) for COVID-19 diagnosis has been intensively studied, little work has been performed for image-based patient outcome prediction. Management of high-risk patients with early intervention is a key to lower the fatality rate of COVID-19 pneumonia, as a majority of patients recover naturally. Therefore, an accurate prediction of disease progression with baseline imaging at the time of the initial presentation can help in patient management. In lieu of only size and volume information of pulmonary abnormalities and features through deep learning based image segmentation, here we combine radiomics of lung opacities and non-imaging features from demographic data, vital signs, and laboratory findings to predict need for intensive care unit (ICU) admission. To our knowledge, this is the first study that uses holistic information of a patient including both imaging and non-imaging data for outcome prediction. The proposed methods were thoroughly evaluated on datasets separately collected from three hospitals, one in the United States, one in Iran, and another in Italy, with a total 295 patients with reverse transcription polymerase chain reaction (RT-PCR) assay positive COVID-19 pneumonia. Our experimental results demonstrate that adding non-imaging features can significantly improve the performance of prediction to achieve AUC up to 0.884 and sensitivity as high as 96.1%, which can be valuable to provide clinical decision support in managing COVID-19 patients. Our methods may also be applied to other lung diseases including but not limited to community acquired pneumonia. The source code of our work is available at GitHub",251,COVID-19;Disease Progression;Lung Diseases;Pneumonia,38.0,Med Image Anal,Predictive Value;COVID-19 Testing;Polymerase Chain Reaction;Area under Curve;Reverse Transcription,2.923135835171604e-06,41.60799999999998,2.9786539439463944e-06,131.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33094700,10.1152/physiolgenomics.00084.2020,Yes,PMC7774002,33094700.0,2020,2020-10-24,Journal Article,Peer reviewed (PubMed),1,implementation of convolutional neural network approach for covid-19 disease detection,"In this paper, two novel, powerful, and robust convolutional neural network (CNN) architectures are designed and proposed for two different classification tasks using publicly available data sets. The first architecture is able to decide whether a given chest X-ray image of a patient contains COVID-19 or not with 98.92% average accuracy. The second CNN architecture is able to divide a given chest X-ray image of a patient into three classes (COVID-19 versus normal versus pneumonia) with 98.27% average accuracy. The hyperparameters of both CNN models are automatically determined using Grid Search. Experimental results on large clinical data sets show the effectiveness of the proposed architectures and demonstrate that the proposed algorithms can overcome the disadvantages mentioned above. Moreover, the proposed CNN models are fully automatic in terms of not requiring the extraction of diseased tissue, which is a great improvement of available automatic methods in the literature. To the best of the author's knowledge, this study is the first study to detect COVID-19 disease from given chest X-ray images, using CNN, whose hyperparameters are automatically determined by the Grid Search. Another important contribution of this study is that it is the first CNN-based COVID-19 chest X-ray image classification study that uses the largest possible clinical data set. A total of 1,524 COVID-19, 1,527 pneumonia, and 1524 normal X-ray images are collected. It is aimed to collect the largest number of COVID-19 X-ray images that exist in the literature until the writing of this research paper.",245,COVID-19;Pneumonia,12.0,Physiol Genomics,Architecture;Image Processing;Neural Networks,8.186698391284834e-06,175.2639999999991,1.1927254462349932e-05,420.0,0.0,External,2. Detection/Diagnosis,X-Ray
33100403,10.1016/j.patcog.2020.107700,Yes,PMC7568501,33100403.0,2020,2020-10-27,Journal Article,Peer reviewed (PubMed),1,metacovid: a siamese neural network framework with contrastive loss for n-shot diagnosis of covid-19 patients,"Various AI functionalities such as pattern recognition and prediction can effectively be used to diagnose (recognize) and predict coronavirus disease 2019 (COVID-19) infections and propose timely response (remedial action) to minimize the spread and impact of the virus. Motivated by this, an AI system based on deep meta learning has been proposed in this research to accelerate analysis of chest X-ray (CXR) images in automatic detection of COVID-19 cases. We present a synergistic approach to integrate contrastive learning with a fine-tuned pre-trained ConvNet encoder to capture unbiased feature representations and leverage a Siamese network for final classification of COVID-19 cases. We validate the effectiveness of our proposed model using two publicly available datasets comprising images from normal, COVID-19 and other pneumonia infected categories. Our model achieves 95.6% accuracy and AUC of 0.97 in diagnosing COVID-19 from CXR images even with a limited number of training samples.",146,COVID-19;Infections;Pneumonia,57.0,Pattern Recognit,Other Topics,2.9106717727295347e-06,54.80000000000004,4.388953433450939e-06,126.0,0.0,External,2. Detection/Diagnosis,X-Ray
33100482,10.1016/j.ipm.2020.102411,Yes,PMC7569413,33100482.0,2020,2020-10-27,Journal Article,Peer reviewed (PubMed),1,cgnet: a graph-knowledge embedded convolutional neural network for detection of pneumonia,"Pneumonia is a global disease that causes high children mortality. The situation has even been worsening by the outbreak of the new coronavirus named COVID-19, which has killed more than 983,907 so far. People infected by the virus would show symptoms like fever and coughing as well as pneumonia as the infection progresses. Timely detection is a public consensus achieved that would benefit possible treatments and therefore contain the spread of COVID-19. X-ray, an expedient imaging technique, has been widely used for the detection of pneumonia caused by COVID-19 and some other virus. To facilitate the process of diagnosis of pneumonia, we developed a deep learning framework for a binary classification task that classifies chest X-ray images into normal and pneumonia based on our proposed CGNet. In our CGNet, there are three components including feature extraction, graph-based feature reconstruction and classification. We first use the transfer learning technique to train the state-of-the-art convolutional neural networks (CNNs) for binary classification while the trained CNNs are used to produce features for the following two components. Then, by deploying graph-based feature reconstruction, we, therefore, combine features through the graph to reconstruct features. Finally, a shallow neural network named GNet, a one layer graph neural network, which takes the combined features as the input, classifies chest X-ray images into normal and pneumonia. Our model achieved the best accuracy at 0.9872, sensitivity at 1 and specificity at 0.9795 on a public pneumonia dataset that includes 5,856 chest X-ray images. To evaluate the performance of our proposed method on detection of pneumonia caused by COVID-19, we also tested the proposed method on a public COVID-19 CT dataset, where we achieved the highest performance at the accuracy of 0.99, specificity at 1 and sensitivity at 0.98, respectively.",290,COVID-19;Fever;Infections;Pneumonia,21.0,Inf Process Manag,Coronavirus Infections;Art;Transfer Learning;Disease Outbreaks,4.833280637665647e-06,83.42399999999982,6.069608354184672e-06,210.0,0.0,External,2. Detection/Diagnosis,Multimodal
33108303,10.1109/JBHI.2020.3034296,Yes,,33108303.0,2020,2020-10-28,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,a deep learning prognosis model help alert for covid-19 patients at high-risk of death: a multi-center study,"Since its outbreak in December 2019, the persistent coronavirus disease (COVID-19) became a global health emergency. It is imperative to develop a prognostic tool to identify high-risk patients and assist in the formulation of treatment plans. We retrospectively collected 366 severe or critical COVID-19 patients from four centers, including 70 patients who died within 14 days (labeled as high-risk patients) since their initial CT scan and 296 who survived more than 14 days or were cured (labeled as low-risk patients). We developed a 3D densely connected convolutional neural network (termed De-COVID19-Net) to predict the probability of COVID-19 patients belonging to the high-risk or low-risk group, combining CT and clinical information. The AUC and other evaluation techniques were used to assess our model. The De-COVID19-Net yielded an AUC of 0.952 (95% confidence interval, 0.928-0.977) on the training set and 0.943 on the test set. The stratified analyses indicated that our model's performance is independent of age, sex, and with/without chronic diseases. The Kaplan-Meier analysis revealed that our model could significantly categorize patients into high-risk and low-risk groups (p < 0.001). In conclusion, De-COVID19-Net can non-invasively predict whether a patient will die shortly based on the patient's initial CT scan with an impressive performance, which indicated that it could be used as a potential prognosis tool to alert high-risk patients and intervene in advance.",222,COVID-19;Chronic Disease;Death,22.0,IEEE J Biomed Health Inform,Disease Outbreaks;Area under Curve,2.11988203748814e-06,21.888,1.8223902400803568e-06,74.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33125051,10.1093/jamia/ocaa280,Yes,PMC7665533,33125051.0,2020,2020-10-31,Journal Article,Peer reviewed (PubMed),1,flannel: focal loss based neural network ensemble for covid-19 detection,"The study sought to test the possibility of differentiating chest x-ray images of coronavirus disease 2019 (COVID-19) against other pneumonia and healthy patients using deep neural networks. We construct the radiography (x-ray) imaging data from 2 publicly available sources, which include 5508 chest x-ray images across 2874 patients with 4 classes: normal, bacterial pneumonia, non-COVID-19 viral pneumonia, and COVID-19. To identify COVID-19, we propose a FLANNEL (Focal Loss bAsed Neural Network EnsembLe) model, a flexible module to ensemble several convolutional neural network models and fuse with a focal loss for accurate COVID-19 detection on class imbalance data. FLANNEL consistently outperforms baseline models on COVID-19 identification task in all metrics. Compared with the best baseline, FLANNEL shows a higher macro-F1 score, with 6% relative increase on the COVID-19 identification task, in which it achieves precision of 0.7833, recall of 0.8609, and F1 score of 0.8168. Ensemble learning that combines multiple independent basis classifiers can increase the robustness and accuracy. We propose a neural weighing module to learn the importance weight for each base model and combine them via weighted ensemble to get the final classification results. In order to handle the class imbalance challenge, we adapt focal loss to our multiple classification task as the loss function. FLANNEL effectively combines state-of-the-art convolutional neural network classification models and tackles class imbalance with focal loss to achieve better performance on COVID-19 detection from x-rays.",231,"COVID-19;Pneumonia;Pneumonia, Bacterial;Pneumonia, Viral",11.0,J Am Med Inform Assoc,Art;Algorithms;Neural Networks;Other Topics;ROC Curve,4.467106612216179e-06,92.4319999999997,6.198033973792741e-06,234.0,0.0,External,2. Detection/Diagnosis,X-Ray
33129141,10.1016/j.media.2020.101836,Yes,PMC7543739,33129141.0,2020,2020-11-01,"Comparative Study;Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,dual-branch combination network (dcn): towards accurate diagnosis and lesion segmentation of covid-19 using ct images,"The recent global outbreak and spread of coronavirus disease (COVID-19) makes it an imperative to develop accurate and efficient diagnostic tools for the disease as medical resources are getting increasingly constrained. Artificial intelligence (AI)-aided tools have exhibited desirable potential; for example, chest computed tomography (CT) has been demonstrated to play a major role in the diagnosis and evaluation of COVID-19. However, developing a CT-based AI diagnostic system for the disease detection has faced considerable challenges, which is mainly due to the lack of adequate manually-delineated samples for training, as well as the requirement of sufficient sensitivity to subtle lesions in the early infection stages. In this study, we developed a dual-branch combination network (DCN) for COVID-19 diagnosis that can simultaneously achieve individual-level classification and lesion segmentation. To focus the classification branch more intensively on the lesion areas, a novel lesion attention module was developed to integrate the intermediate segmentation results. Furthermore, to manage the potential influence of different imaging parameters from individual facilities, a slice probability mapping method was proposed to learn the transformation from slice-level to individual-level classification. We conducted experiments on a large dataset of 1202 subjects from ten institutes in China. The results demonstrated that 1) the proposed DCN attained a classification accuracy of 96.74% on the internal dataset and 92.87% on the external validation dataset, thereby outperforming other models; 2) DCN obtained comparable performance with fewer samples and exhibited higher sensitivity, especially in subtle lesion detection; and 3) DCN provided good interpretability on the loci of infection compared to other deep models due to its classification guided by high-level semantic information. An online CT-based diagnostic platform for COVID-19 derived from our proposed framework is now available.",280,COVID-19;Infections,62.0,Med Image Anal,Radiography;Coronavirus Infections;Disease Outbreaks;Semantics;Sensitivity and Specificity;Neural Networks,3.271104999275018e-06,63.088000000000015,4.342684345924065e-06,158.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33132536,10.1007/s00521-020-05437-x,Yes,PMC7586204,33132536.0,2020,2020-11-03,Journal Article,Peer reviewed (PubMed),1,a deep transfer learning model with classical data augmentation and cgan to detect covid-19 from chest ct radiography digital images,"The Coronavirus disease 2019 (COVID-19) is the fastest transmittable virus caused by severe acute respiratory syndrome Coronavirus 2 (SARS-CoV-2). The detection of COVID-19 using artificial intelligence techniques and especially deep learning will help to detect this virus in early stages which will reflect in increasing the opportunities of fast recovery of patients worldwide. This will lead to release the pressure off the healthcare system around the world. In this research, classical data augmentation techniques along with Conditional Generative Adversarial Nets (CGAN) based on a deep transfer learning model for COVID-19 detection in chest CT scan images will be presented. The limited benchmark datasets for COVID-19 especially in chest CT images are the main motivation of this research. The main idea is to collect all the possible images for COVID-19 that exists until the very writing of this research and use the classical data augmentations along with CGAN to generate more images to help in the detection of the COVID-19. In this study, five different deep convolutional neural network-based models (AlexNet, VGGNet16, VGGNet19, GoogleNet, and ResNet50) have been selected for the investigation to detect the Coronavirus-infected patient using chest CT radiographs digital images. The classical data augmentations along with CGAN improve the performance of classification in all selected deep transfer models. The outcomes show that ResNet50 is the most appropriate deep learning model to detect the COVID-19 from limited chest CT dataset using the classical data augmentation with testing accuracy of 82.91%, sensitivity 77.66%, and specificity of 87.62%.",247,COVID-19;Severe Acute Respiratory Syndrome,88.0,Neural Comput Appl,Health Care;Transfer Learning;Sensitivity and Specificity;Health Care Systems,5.627846369430451e-06,99.55999999999965,6.722431824975207e-06,249.0,0.0,External,2. Detection/Diagnosis,CT
33134214,10.31661/jbpe.v0i0.2008-1153,Yes,PMC7557468,33134214.0,2020,2020-11-03,Journal Article,Peer reviewed (PubMed),1,transfer learning-based automatic detection of coronavirus disease 2019 (covid-19) from chest x-ray images,"Coronavirus disease 2019 (COVID-19) is an emerging infectious disease and global health crisis. Although real-time reverse transcription polymerase chain reaction (RT-PCR) is known as the most widely laboratory method to detect the COVID-19 from respiratory specimens. It suffers from several main drawbacks such as time-consuming, high false-negative results, and limited availability. Therefore, the automatically detect of COVID-19 will be required. This study aimed to use an automated deep convolution neural network based pre-trained transfer models for detection of COVID-19 infection in chest X-rays. In a retrospective study, we have applied Visual Geometry Group (VGG)-16, VGG-19, MobileNet, and InceptionResNetV2 pre-trained models for detection COVID-19 infection from 348 chest X-ray images. Our proposed models have been trained and tested on a dataset which previously prepared. The all proposed models provide accuracy greater than 90.0%. The pre-trained MobileNet model provides the highest classification performance of automated COVID-19 classification with 99.1% accuracy in comparison with other three proposed models. The plotted AUC of receiver operating characteristics (ROC) of VGG16, VGG19, MobileNet, and InceptionResNetV2 models are 0.92, 0.91, 0.99, and 0.97, respectively. The all proposed models were able to perform binary classification with the accuracy more than 90.0% for COVID-19 diagnosis. Our data indicated that the MobileNet can be considered as a promising model to detect COVID-19 cases. In the future, by increasing the number of samples of COVID-19 chest X-rays to the training dataset, the accuracy and robustness of our proposed models increase further.",240,"COVID-19;Communicable Diseases, Emerging;Infections",23.0,J Biomed Phys Eng,Transfer Learning;Polymerase Chain Reaction;Retrospective Studies;Area under Curve;Communicable Diseases;Reverse Transcription;Receiver Operating Characteristic,2.689928135134382e-06,66.98400000000004,4.870666114426089e-06,153.0,0.0,External,2. Detection/Diagnosis,X-Ray
33144676,10.1038/s41598-020-76141-y,Yes,PMC7641115,33144676.0,2020,2020-11-05,Journal Article,Peer reviewed (PubMed),1,the study of automatic machine learning base on radiomics of non-focus area in the first chest ct of different clinical types of covid-19 pneumonia,"To explore the possibility of predicting the clinical types of Corona-Virus-Disease-2019 (COVID-19) pneumonia by analyzing the non-focus area of the lung in the first chest CT image of patients with COVID-19 by using automatic machine learning (Auto-ML). 136 moderate and 83 severe patients were selected from the patients with COVID-19 pneumonia. The clinical and laboratory data were collected for statistical analysis. The texture features of the Non-focus area of the first chest CT of patients with COVID-19 pneumonia were extracted, and then the classification model of the first chest CT of COVID-19 pneumonia was constructed by using these texture features based on the Auto-ML method of radiomics, The AUC, true positive rate (TPR), true negative rate (TNR), positive predictive value (PPV) and negative predictive value (NPV) of the operating characteristic curve (ROC) were used to evaluate the accuracy of the first chest CT image classification model in patients with COVID-19 pneumonia. The TPR, TNR, PPV, NPV and AUC of the training cohort and test cohort of the moderate group and the control group, the severe group and the control group, the moderate group and the severe group were all greater than 95% and 0.95 respectively. The non-focus area of the first CT image of COVID-19 pneumonia has obvious difference in different clinical types. The AUTO-ML classification model of Radiomics based on this difference can be used to predict the clinical types of COVID-19 pneumonia.",234,COVID-19;Pneumonia;Virus Diseases,14.0,Sci Rep,Coronavirus Infections;ROC Curve;Lung Diseases;Age,2.844136434133276e-06,46.48799999999997,2.4020244515105016e-06,147.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33146796,10.1007/s00330-020-07401-8,Yes,PMC7610169,33146796.0,2020,2020-11-05,Journal Article,Peer reviewed (PubMed),1,ct and clinical assessment in asymptomatic and pre-symptomatic patients with early sars-cov-2 in outbreak settings,"The early infection dynamics of patients with SARS-CoV-2 are not well understood. We aimed to investigate and characterize associations between clinical, laboratory, and imaging features of asymptomatic and pre-symptomatic patients with SARS-CoV-2. Seventy-four patients with RT-PCR-proven SARS-CoV-2 infection were asymptomatic at presentation. All were retrospectively identified from 825 patients with chest CT scans and positive RT-PCR following exposure or travel risks in outbreak settings in Japan and China. CTs were obtained for every patient within a day of admission and were reviewed for infiltrate subtypes and percent with assistance from a deep learning tool. Correlations of clinical, laboratory, and imaging features were analyzed and comparisons were performed using univariate and multivariate logistic regression. Forty-eight of 74 initially asymptomatic patients had CT infiltrates that pre-dated symptom onset by 3.8 days. The most common CT infiltrates were ground glass opacities and consolidation. Patient body temperature (p < 0.01), CRP (p < 0.01), and KL-6 (p = 0.02) were associated with the presence of CT infiltrates. Infiltrate volume (p = 0.01), percent lung involvement (p = 0.01), and consolidation (p = 0.043) were associated with subsequent development of symptoms. COVID-19 CT infiltrates pre-dated symptoms in two-thirds of patients. Body temperature elevation and laboratory evaluations may identify asymptomatic patients with SARS-CoV-2 CT infiltrates at presentation, and the characteristics of CT infiltrates could help identify asymptomatic SARS-CoV-2 patients who subsequently develop symptoms. The role of chest CT in COVID-19 may be illuminated by a better understanding of CT infiltrates in patients with early disease or SARS-CoV-2 exposure. Forty-eight of 74 pre-selected asymptomatic patients with SARS-CoV-2 had abnormal chest CT findings. CT infiltrates pre-dated symptom onset by 3.8 days (range 1-5). KL-6, CRP, and elevated body temperature identified patients with CT infiltrates. Higher infiltrate volume, percent lung involvement, and pulmonary consolidation identified patients who developed symptoms.",300,COVID-19;Infections,13.0,Eur Radiol,Disease Outbreaks;Polymerase Chain Reaction;Other Topics;Retrospective Studies,2.3312133195653915e-06,51.96,2.808373286703554e-06,151.0,0.0,Self-recorded/clinical,1. Risk identification,CT
33161334,10.1016/j.compbiomed.2020.104092,Yes,PMC7591316,33161334.0,2020,2020-11-09,Journal Article,Peer reviewed (PubMed),1,the importance of standardisation - covid-19 ct and radiograph image data stock for deep learning purpose,"With the number of affected individuals still growing world-wide, the research on COVID-19 is continuously expanding. The deep learning community concentrates their efforts on exploring if neural networks can potentially support the diagnosis using CT and radiograph images of patients' lungs. The two most popular publicly available datasets for COVID-19 classification are COVID-CT and COVID-19 Image Data Collection. In this work, we propose a new dataset which we call COVID-19 CT and Radiograph Image Data Stock. It contains both CT and radiograph samples of COVID-19 lung findings and combines them with additional data to ensure a sufficient number of diverse COVID-19-negative samples. Moreover, it is supplemented with a carefully defined split. The aim of COVID-19 CT and Radiograph Image Data Stock is to create a public pool of CT and radiograph images of lungs to increase the efficiency of distinguishing COVID-19 disease from other types of pneumonia and from healthy chest. We hope that the creation of this dataset would allow standardisation of the approach taken for training deep neural networks for COVID-19 classification and eventually for building more reliable models.",181,COVID-19;Pneumonia,5.0,Comput Biol Med,Other Topics,4.0811907454222025e-06,64.95199999999994,3.602398006198329e-06,195.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33162872,10.1016/j.asoc.2020.106859,Yes,PMC7598372,33162872.0,2020,2020-11-10,Journal Article,Peer reviewed (PubMed),1,instacovnet-19: a deep learning classification model for the detection of covid-19 patients using chest x-ray,"Recently, the whole world became infected by the newly discovered coronavirus (COVID-19). SARS-CoV-2, or widely known as COVID-19, has proved to be a hazardous virus severely affecting the health of people. It causes respiratory illness, especially in people who already suffer from other diseases. Limited availability of test kits as well as symptoms similar to other diseases such as pneumonia has made this disease deadly, claiming the lives of millions of people. Artificial intelligence models are found to be very successful in the diagnosis of various diseases in the biomedical field In this paper, an integrated stacked deep convolution network InstaCovNet-19 is proposed. The proposed model makes use of various pre-trained models such as ResNet101, Xception, InceptionV3, MobileNet, and NASNet to compensate for a relatively small amount of training data. The proposed model detects COVID-19 and pneumonia by identifying the abnormalities caused by such diseases in Chest X-ray images of the person infected. The proposed model achieves an accuracy of 99.08% on 3 class (COVID-19, Pneumonia, Normal) classification while achieving an accuracy of 99.53% on 2 class (COVID, NON-COVID) classification. The proposed model achieves an average recall, F1 score, and precision of 99%, 99%, and 99%, respectively on ternary classification, while achieving a 100% precision and a recall of 99% on the binary class., while achieving a 100% precision and a recall of 99% on the COVID class. InstaCovNet-19's ability to detect COVID-19 without any human intervention at an economical cost with high accuracy can benefit humankind greatly in this age of Quarantine.",253,COVID-19;Pneumonia,66.0,Appl Soft Comput,Other Topics,3.827441443176099e-06,64.12800000000001,4.827924556457217e-06,170.0,0.0,External,2. Detection/Diagnosis,X-Ray
33164982,10.3233/XST-200735,Yes,PMC7990455,33164982.0,2020,2020-11-10,"Journal Article;Research Support, N.I.H., Intramural;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,using artificial intelligence to assist radiologists in distinguishing covid-19 from other pulmonary infections,"Accurate and rapid diagnosis of coronavirus disease (COVID-19) is crucial for timely quarantine and treatment. In this study, a deep learning algorithm-based AI model using ResUNet network was developed to evaluate the performance of radiologists with and without AI assistance in distinguishing COVID-19 infected pneumonia patients from other pulmonary infections on CT scans. For model development and validation, a total number of 694 cases with 111,066 CT slides were retrospectively collected as training data and independent test data in the study. Among them, 118 are confirmed COVID-19 infected pneumonia cases and 576 are other pulmonary infection cases (e.g. tuberculosis cases, common pneumonia cases and non-COVID-19 viral pneumonia cases). The cases were divided into training and testing datasets. The independent test was performed by evaluating and comparing the performance of three radiologists with different years of practice experience in distinguishing COVID-19 infected pneumonia cases with and without the AI assistance. Our final model achieved an overall test accuracy of 0.914 with an area of the receiver operating characteristic (ROC) curve of 0.903 in which the sensitivity and specificity are 0.918 and 0.909, respectively. The deep learning-based model then achieved a comparable performance by improving the radiologists' performance in distinguish COVOD-19 from other pulmonary infections, yielding better average accuracy and sensitivity, from 0.941 to 0.951 and from 0.895 to 0.942, respectively, when compared to radiologists without using AI assistance. A deep learning algorithm-based AI model developed in this study successfully improved radiologists' performance in distinguishing COVID-19 from other pulmonary infections using chest CT images.",252,"COVID-19;Infections;Pneumonia;Pneumonia, Viral;Tuberculosis",11.0,J Xray Sci Technol,Coronavirus Infections;Algorithms;ROC Curve;Lung Diseases;Age,4.6367166045056114e-06,198.47999999999905,9.818549762037531e-06,446.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33166256,10.1109/JBHI.2020.3036722,Yes,,33166256.0,2020,2020-11-10,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,classification of severe and critical covid-19 using deep learning and radiomics,"The coronavirus disease 2019 (COVID-19) is rapidly spreading inside China and internationally. We aimed to construct a model integrating information from radiomics and deep learning (DL) features to discriminate critical cases from severe cases of COVID-19 using computed tomography (CT) images. We retrospectively enrolled 217 patients from three centers in China, including 82 patients with severe disease and 135 with critical disease. Patients were randomly divided into a training cohort (n = 174) and a test cohort (n = 43). We extracted 102 3-dimensional radiomic features from automatically segmented lung volume and selected the significant features. We also developed a 3-dimensional DL network based on center-cropped slices. Using multivariable logistic regression, we then created a merged model based on significant radiomic features and DL scores. We employed the AUC to evaluate the model's performance. We then conducted cross validation, stratified analysis, survival analysis, and decision curve analysis to evaluate the robustness of our method. The merged model can distinguish critical patients with AUCs of 0.909 and 0.861 in the training and test cohorts, respectively. Stratified analysis indicated that our model was not affected by sex, age, or chronic disease. Moreover, the results of the merged model showed a strong correlation with patient outcomes. A model combining radiomic and DL features of the lung could help distinguish critical cases from severe cases of COVID-19.",223,COVID-19;Chronic Disease,28.0,IEEE J Biomed Health Inform,Other Topics,2.4870244632424738e-06,21.336,1.6493757501049196e-06,69.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
33169050,10.1007/s00138-020-01128-8,Yes,PMC7609373,33169050.0,2020,2020-11-11,Journal Article,Peer reviewed (PubMed),1,a five-layer deep convolutional neural network with stochastic pooling for chest ct-based covid-19 diagnosis,"Till August 17, 2020, COVID-19 has caused 21.59 million confirmed cases in more than 227 countries and territories, and 26 naval ships. Chest CT is an effective way to detect COVID-19. This study proposed a novel deep learning model that can diagnose COVID-19 on chest CT more accurately and swiftly. Based on traditional deep convolutional neural network (DCNN) model, we proposed three improvements: We introduced stochastic pooling to replace average pooling and max pooling; We combined conv layer with batch normalization layer and obtained the conv block (CB); We combined dropout layer with fully connected layer and obtained the fully connected block (FCB). Our algorithm achieved a sensitivity of 93.28% %, a specificity of 94.00% %, and an accuracy of 93.64% %, in identifying COVID-19 from normal subjects. We proved using stochastic pooling yields better performance than average pooling and max pooling. We compared different structure configurations and proved our 3CB + 2FCB yields the best performance. The proposed model is effective in detecting COVID-19 based on chest CT images.",170,COVID-19,32.0,Mach Vis Appl,Other Topics,2.9195755169298275e-06,31.048000000000023,2.6630478666611587e-06,77.0,0.0,External,2. Detection/Diagnosis,CT
33169099,10.1016/j.scs.2020.102589,Yes,PMC7642729,33169099.0,2020,2020-11-11,Journal Article,Peer reviewed (PubMed),1,deep learning and medical image processing for coronavirus (covid-19) pandemic: a survey,"Since December 2019, the coronavirus disease (COVID-19) outbreak has caused many death cases and affected all sectors of human life. With gradual progression of time, COVID-19 was declared by the world health organization (WHO) as an outbreak, which has imposed a heavy burden on almost all countries, especially ones with weaker health systems and ones with slow responses. In the field of healthcare, deep learning has been implemented in many applications, e.g., diabetic retinopathy detection, lung nodule classification, fetal localization, and thyroid diagnosis. Numerous sources of medical images (e.g., X-ray, CT, and MRI) make deep learning a great technique to combat the COVID-19 outbreak. Motivated by this fact, a large number of research works have been proposed and developed for the initial months of 2020. In this paper, we first focus on summarizing the state-of-the-art research works related to deep learning applications for COVID-19 medical image processing. Then, we provide an overview of deep learning and its applications to healthcare found in the last decade. Next, three use cases in China, Korea, and Canada are also presented to show deep learning applications for COVID-19 medical image processing. Finally, we discuss several challenges and issues related to deep learning implementations for COVID-19 medical image processing, which are expected to drive further studies in controlling the outbreak and controlling the crisis, which results in smart healthy cities.",225,COVID-19;COVID-19 Pandemic;Death;Diabetic Retinopathy,126.0,Sustain Cities Soc,Art;World Health Organization;Health Care;Disease Outbreaks;Image Processing;Tomography;Lung Diseases,8.10796071828728e-06,101.9519999999996,7.440436070907691e-06,266.0,0.0,,Review,Multimodal
33169117,10.1016/j.ibmed.2020.100013,Yes,PMC7641591,33169117.0,2020,2020-11-11,Journal Article,Peer reviewed (PubMed),1,deep learning and its role in covid-19 medical imaging,"COVID-19 is one of the greatest global public health challenges in history. COVID-19 is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and is estimated to have an cumulative global case-fatality rate as high as 7.2% (Onder et al., 2020). As the SARS-CoV-2 spread across the globe it catalyzed new urgency in building systems to allow rapid sharing and dissemination of data between international healthcare infrastructures and governments in a worldwide effort focused on case tracking/tracing, identifying effective therapeutic protocols, securing healthcare resources, and in drug and vaccine research. In addition to the worldwide efforts to share clinical and routine population health data, there are many large-scale efforts to collect and disseminate medical imaging data, owing to the critical role that imaging has played in diagnosis and management around the world. Given reported false negative rates of the reverse transcriptase polymerase chain reaction (RT-PCR) of up to 61% (Centers for Disease Control and Prevention, Division of Viral Diseases, 2020; Kucirka et al., 2020), imaging can be used as an important adjunct or alternative. Furthermore, there has been a shortage of test-kits worldwide and laboratories in many testing sites have struggled to process the available tests within a reasonable time frame. Given these issues surrounding COVID-19, many groups began to explore the benefits of 'big data' processing and algorithms to assist with the diagnosis and therapeutic development of COVID-19.",230,COVID-19;Severe Acute Respiratory Syndrome;Virus Diseases,22.0,Intell Based Med,Public Health;Health Care;Polymerase Chain Reaction;Other Topics;Pharmaceutical Preparations,1.891860561455436e-06,25.056,1.621179788009642e-06,82.0,0.0,,Review,Multimodal
33170789,10.1109/JBHI.2020.3037127,Yes,,33170789.0,2020,2020-11-11,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,covidgr dataset and covid-sdnet methodology for predicting covid-19 based on chest x-ray images,"Currently, Coronavirus disease (COVID-19), one of the most infectious diseases in the 21st century, is diagnosed using RT-PCR testing, CT scans and/or Chest X-Ray (CXR) images. CT (Computed Tomography) scanners and RT-PCR testing are not available in most medical centers and hence in many cases CXR images become the most time/cost effective tool for assisting clinicians in making decisions. Deep learning neural networks have a great potential for building COVID-19 triage systems and detecting COVID-19 patients, especially patients with low severity. Unfortunately, current databases do not allow building such systems as they are highly heterogeneous and biased towards severe cases. This article is three-fold: we demystify the high sensitivities achieved by most recent COVID-19 classification models, under a close collaboration with Hospital Universitario Clínico San Cecilio, Granada, Spain, we built COVIDGR-1.0, a homogeneous and balanced database that includes all levels of severity, from normal with Positive RT-PCR, Mild, Moderate to Severe. COVIDGR-1.0 contains 426 positive and 426 negative PA (PosteroAnterior) CXR views and we propose COVID Smart Data based Network (COVID-SDNet) methodology for improving the generalization capacity of COVID-classification models. Our approach reaches good and stable results with an accuracy of, , in severe, moderate and mild COVID-19 severity levels. Our approach could help in the early detection of COVID-19. COVIDGR-1.0 along with the severity level labels are available to the scientific community through this link /.",227,COVID-19;Communicable Diseases,84.0,IEEE J Biomed Health Inform,Polymerase Chain Reaction;Communicable Diseases,2.6844514412568727e-06,48.952000000000034,3.6599037264718393e-06,125.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,X-Ray
33171345,10.1016/j.media.2020.101860,Yes,PMC7558247,33171345.0,2020,2020-11-11,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,ai-driven quantification staging and outcome prediction of covid-19 pneumonia,"Coronavirus disease 2019 (COVID-19) emerged in 2019 and disseminated around the world rapidly. Computed tomography (CT) imaging has been proven to be an important tool for screening, disease quantification and staging. The latter is of extreme importance for organizational anticipation (availability of intensive care unit beds, patient management planning) as well as to accelerate drug development through rapid, reproducible and quantified assessment of treatment response. Even if currently there are no specific guidelines for the staging of the patients, CT together with some clinical and biological biomarkers are used. In this study, we collected a multi-center cohort and we investigated the use of medical imaging and artificial intelligence for disease quantification, staging and outcome prediction. Our approach relies on automatic deep learning-based disease quantification using an ensemble of architectures, and a data-driven consensus for the staging and outcome prediction of the patients fusing imaging biomarkers with clinical and biological attributes. Highly promising results on multiple external/independent evaluation cohorts as well as comparisons with expert human readers demonstrate the potentials of our approach.",172,COVID-19;Pneumonia,63.0,Med Image Anal,Drug;Architecture;Neural Networks,3.71536604551924e-06,49.52799999999999,3.95825780598728e-06,147.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33171723,10.3390/jpm10040213,Yes,PMC7711996,33171723.0,2020,2020-11-12,Journal Article,Peer reviewed (PubMed),1,evaluation of scalability and degree of fine-tuning of deep convolutional neural networks for covid-19 screening on chest x-ray images using explainable deep-learning algorithm,"According to recent studies, patients with COVID-19 have different feature characteristics on chest X-ray (CXR) than those with other lung diseases. This study aimed at evaluating the layer depths and degree of fine-tuning on transfer learning with a deep convolutional neural network (CNN)-based COVID-19 screening in CXR to identify efficient transfer learning strategies. The CXR images used in this study were collected from publicly available repositories, and the collected images were classified into three classes: COVID-19, pneumonia, and normal. To evaluate the effect of layer depths of the same CNN architecture, CNNs called VGG-16 and VGG-19 were used as backbone networks. Then, each backbone network was trained with different degrees of fine-tuning and comparatively evaluated. The experimental results showed the highest AUC value to be 0.950 concerning COVID-19 classification in the experimental group of a fine-tuned with only 2/5 blocks of the VGG16 backbone network. In conclusion, in the classification of medical images with a limited number of data, a deeper layer depth may not guarantee better results. In addition, even if the same pre-trained CNN architecture is used, an appropriate degree of fine-tuning can help to build an efficient deep learning model.",193,COVID-19;Lung Diseases;Pneumonia,19.0,J Pers Med,Transfer Learning;Algorithms;Architecture;Lung;Area under Curve,6.389679205407247e-06,112.8639999999995,8.409932605027979e-06,278.0,0.0,External,2. Detection/Diagnosis,X-Ray
33171999,10.3390/jcm9113576,Yes,PMC7694629,33171999.0,2020,2020-11-12,Journal Article,Peer reviewed (PubMed),1,accuracy of conventional and machine learning enhanced chest radiography for the assessment of covid-19 pneumonia: intra-individual comparison with ct,"To evaluate diagnostic accuracy of conventional radiography (CXR) and machine learning enhanced CXR (mlCXR) for the detection and quantification of disease-extent in COVID-19 patients compared to chest-CT. Real-time polymerase chain reaction (rt-PCR)-confirmed COVID-19-patients undergoing CXR from March to April 2020 together with COVID-19 negative patients as control group were retrospectively included. Two independent readers assessed CXR and mlCXR images for presence, disease extent and type (consolidation vs. ground-glass opacities (GGOs) of COVID-19-pneumonia. Further, readers had to assign confidence levels to their diagnosis. CT obtained ≤ 36 h from acquisition of CXR served as standard of reference. Inter-reader agreement, sensitivity for detection and disease extent of COVID-19-pneumonia compared to CT was calculated. McNemar test was used to test for significant differences. Sixty patients (21 females; median age 61 years, range 38-81 years) were included. Inter-reader agreement improved from good to excellent when mlCXR instead of CXR was used (k = 0.831 vs. k = 0.742). Sensitivity for pneumonia detection improved from 79.5% to 92.3%, however, on the cost of specificity 100% vs. 71.4% (p = 0.031). Overall, sensitivity for the detection of consolidation was higher than for GGO (37.5% vs. 70.4%; respectively). No differences could be found in disease extent estimation between mlCXR and CXR, even though the detection of GGO could be improved. Diagnostic confidence was better on mlCXR compared to CXR (p = 0.013). In line with the current literature, the sensitivity for detection and quantification of COVID-19-pneumonia was moderate with CXR and could be improved when mlCXR was used for image interpretation.",254,COVID-19;Pneumonia,3.0,J Clin Med,Polymerase Chain Reaction;Real-Time Polymerase Chain Reaction,1.3915886187442268e-06,14.711999999999998,1.0752951199964626e-06,43.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,Multimodal
33177550,10.1038/s41598-020-76550-z,Yes,PMC7658227,33177550.0,2020,2020-11-13,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,covid-net: a tailored deep convolutional neural network design for detection of covid-19 cases from chest x-ray images,"The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors' knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors' knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most.",310,COVID-19;COVID-19 Pandemic,842.0,Sci Rep,Other Topics,1.4472777272442296e-05,363.080000000005,2.28677894256116e-05,869.0,0.0,External,2. Detection/Diagnosis,X-Ray
33180877,10.1371/journal.pone.0242301,Yes,PMC7660555,33180877.0,2020,2020-11-13,"Journal Article;Research Support, N.I.H., Intramural",Peer reviewed (PubMed),1,analyzing inter-reader variability affecting deep ensemble learning for covid-19 detection in chest radiographs,"Data-driven deep learning (DL) methods using convolutional neural networks (CNNs) demonstrate promising performance in natural image computer vision tasks. However, their use in medical computer vision tasks faces several limitations, viz., adapting to visual characteristics that are unlike natural images; modeling random noise during training due to stochastic optimization and backpropagation-based learning strategy; challenges in explaining DL black-box behavior to support clinical decision-making; and inter-reader variability in the ground truth (GT) annotations affecting learning and evaluation. This study proposes a systematic approach to address these limitations through application to the pandemic-caused need for Coronavirus disease 2019 (COVID-19) detection using chest X-rays (CXRs). Specifically, our contribution highlights significant benefits obtained through pretraining specific to CXRs in transferring and fine-tuning the learned knowledge toward improving COVID-19 detection performance; using ensembles of the fine-tuned models to further improve performance over individual constituent models; performing statistical analyses at various learning stages for validating results; interpreting learned individual and ensemble model behavior through class-selective relevance mapping (CRM)-based region of interest (ROI) localization; and, analyzing inter-reader variability and ensemble localization performance using Simultaneous Truth and Performance Level Estimation (STAPLE) methods. We find that ensemble approaches markedly improved classification and localization performance, and that inter-reader variability and performance level assessment helps guide algorithm design and parameter optimization. To the best of our knowledge, this is the first study to construct ensembles, perform ensemble-based disease ROI localization, and analyze inter-reader variability and algorithm performance for COVID-19 detection in CXRs.",241,COVID-19,26.0,PLoS One,Radiography;Coronavirus Infections;Black Americans;Noise;X-Rays;Image Processing;Neural Networks,4.8978843799417045e-06,78.56799999999983,4.991550773438779e-06,231.0,0.0,External,2. Detection/Diagnosis,X-Ray
33190102,10.1016/j.ejrad.2020.109402,Yes,PMC7641539,33190102.0,2020,2020-11-16,Journal Article,Peer reviewed (PubMed),1,deep learning analysis provides accurate covid-19 diagnosis on chest computed tomography,"Computed Tomography is an essential diagnostic tool in the management of COVID-19. Considering the large amount of examinations in high case-load scenarios, an automated tool could facilitate and save critical time in the diagnosis and risk stratification of the disease. A novel deep learning derived machine learning (ML) classifier was developed using a simplified programming approach and an open source dataset consisting of 6868 chest CT images from 418 patients which was split into training and validation subsets. The diagnostic performance was then evaluated and compared to experienced radiologists on an independent testing dataset. Diagnostic performance metrics were calculated using Receiver Operating Characteristics (ROC) analysis. Operating points with high positive and low negative likelihood ratios to stratify the risk of COVID-19 being present were identified and validated. The model achieved an overall accuracy of 0.956 on an independent testing dataset of 90 patients. Both rule-in and rule out thresholds were identified and tested. At the rule-in operating point, sensitivity and specificity were 84.4 % and 93.3 % and did not differ from both radiologists (p > 0.05). At the rule-out threshold, sensitivity and specificity differed significantly from the radiologists (p < 0.05). Likelihood ratios and a Fagan nomogram provide prevalence independent test performance estimates. Accurate diagnosis of COVID-19 using a basic deep learning approach is feasible using open-source CT image data. In addition, the machine learning classifier provided validated rule-in and rule-out criteria could be used to stratify the risk of COVID-19 being present.",244,COVID-19,22.0,Eur J Radiol,Reproducibility of Results;ROC Curve;Lung Diseases;Age,3.3552561688177634e-06,59.99199999999997,3.3410730693079965e-06,173.0,0.0,External,2. Detection/Diagnosis,CT
33191476,10.1007/s11548-020-02286-w,Yes,PMC7667011,33191476.0,2020,2020-11-17,Evaluation Study;Journal Article,Peer reviewed (PubMed),1,automated detection of covid-19 using ensemble of transfer learning with deep convolutional neural network based on ct scans,"COVID-19 has infected millions of people worldwide. One of the most important hurdles in controlling the spread of this disease is the inefficiency and lack of medical tests. Computed tomography (CT) scans are promising in providing accurate and fast detection of COVID-19. However, determining COVID-19 requires highly trained radiologists and suffers from inter-observer variability. To remedy these limitations, this paper introduces an automatic methodology based on an ensemble of deep transfer learning for the detection of COVID-19. A total of 15 pre-trained convolutional neural networks (CNNs) architectures: EfficientNets (B0-B5), NasNetLarge, NasNetMobile, InceptionV3, ResNet-50, SeResnet 50, Xception, DenseNet121, ResNext50 and Inception_resnet_v2 are used and then fine-tuned on the target task. After that, we built an ensemble method based on majority voting of the best combination of deep transfer learning outputs to further improve the recognition performance. We have used a publicly available dataset of CT scans, which consists of 349 CT scans labeled as being positive for COVID-19 and 397 negative COVID-19 CT scans that are normal or contain other types of lung diseases. The experimental results indicate that the majority voting of 5 deep transfer learning architecture with EfficientNetB0, EfficientNetB3, EfficientNetB5, Inception_resnet_v2, and Xception has the higher results than the individual transfer learning structure and among the other models based on precision, recall and accuracy metrics in diagnosing COVID-19 from CT scans. Our study based on an ensemble deep transfer learning system with different pre-trained CNNs architectures can work well on a publicly available dataset of CT images for the diagnosis of COVID-19 based on CT scans.",257,COVID-19;Lung Diseases,51.0,Int J Comput Assist Radiol Surg,Transfer Learning;Architecture;COVID-19 Testing;Sensitivity and Specificity;Lung;Neural Networks;Tomography;Paper;ROC Curve;Lung Diseases,6.944001181958971e-06,229.12799999999865,1.5515048664983243e-05,483.0,0.0,External,2. Detection/Diagnosis,CT
33192159,10.1007/s11042-020-10010-8,Yes,PMC7648898,33192159.0,2020,2020-11-17,Journal Article,Peer reviewed (PubMed),1,ai aiding in diagnosing tracking recovery of covid-19 using deep learning on chest ct scans,"Coronavirus (COVID-19) has spread throughout the world, causing mayhem from January 2020 to this day. Owing to its rapidly spreading existence and high death count, the WHO has classified it as a pandemic. Biomedical engineers, virologists, epidemiologists, and people from other medical fields are working to help contain this epidemic as soon as possible. The virus incubates for five days in the human body and then begins displaying symptoms, in some cases, as late as 27 days. In some instances, CT scan based diagnosis has been found to have better sensitivity than RT-PCR, which is currently the gold standard for COVID-19 diagnosis. Lung conditions relevant to COVID-19 in CT scans are ground-glass opacity (GGO), consolidation, and pleural effusion. In this paper, two segmentation tasks are performed to predict lung spaces (segregated from ribcage and flesh in Chest CT) and COVID-19 anomalies from chest CT scans. A 2D deep learning architecture with U-Net as its backbone is proposed to solve both the segmentation tasks. It is observed that change in hyperparameters such as number of filters in down and up sampling layers, addition of attention gates, addition of spatial pyramid pooling as basic block and maintaining the homogeneity of 32 filters after each down-sampling block resulted in a good performance. The proposed approach is assessed using publically available datasets from GitHub and Kaggle. Model performance is evaluated in terms of F1-Score, Mean intersection over union (Mean IoU). It is noted that the proposed approach results in 97.31% of F1-Score and 84.6% of Mean IoU. The experimental results illustrate that the proposed approach using U-Net architecture as backbone with the changes in hyperparameters shows better results in comparison to existing U-Net architecture and attention U-net architecture. The study also recommends how this methodology can be integrated into the workflow of healthcare systems to help control the spread of COVID-19.",307,COVID-19;Death;Pleural Effusion,12.0,Multimed Tools Appl,Health Care;Pandemics;Semantics;Health;Polymerase Chain Reaction;Other Topics,2.3008582381174934e-06,32.512000000000015,2.376382949959378e-06,90.0,0.0,External,Segmentation-only,CT
33192206,10.1016/j.asoc.2020.106885,Yes,PMC7647900,33192206.0,2020,2020-11-17,Journal Article,Peer reviewed (PubMed),1,the ensemble deep learning model for novel covid-19 on ct images,"The rapid detection of the novel coronavirus disease, COVID-19, has a positive effect on preventing propagation and enhancing therapeutic outcomes. This article focuses on the rapid detection of COVID-19. We propose an ensemble deep learning model for novel COVID-19 detection from CT images. 2933 lung CT images from COVID-19 patients were obtained from previous publications, authoritative media reports, and public databases. The images were preprocessed to obtain 2500 high-quality images. 2500 CT images of lung tumor and 2500 from normal lung were obtained from a hospital. Transfer learning was used to initialize model parameters and pretrain three deep convolutional neural network models: AlexNet, GoogleNet, and ResNet. These models were used for feature extraction on all images. Softmax was used as the classification algorithm of the fully connected layer. The ensemble classifier EDL-COVID was obtained via relative majority voting. Finally, the ensemble classifier was compared with three component classifiers to evaluate accuracy, sensitivity, specificity, F value, and Matthews correlation coefficient. The results showed that the overall classification performance of the ensemble model was better than that of the component classifier. The evaluation indexes were also higher. This algorithm can better meet the rapid detection requirements of the novel coronavirus disease COVID-19.",200,COVID-19;Neoplasms,80.0,Appl Soft Comput,Transfer Learning;Algorithms;Sensitivity and Specificity;Lung;Neural Networks,4.502703917717057e-06,70.45600000000003,5.769250080408065e-06,165.0,0.0,External,2. Detection/Diagnosis,CT
33199977,10.1016/j.asoc.2020.106897,Yes,PMC7654325,33199977.0,2020,2020-11-18,Journal Article,Peer reviewed (PubMed),1,ai-assisted ct imaging analysis for covid-19 screening: building and deploying a medical ai system,"The sudden outbreak of novel coronavirus 2019 (COVID-19) increased the diagnostic burden of radiologists. In the time of an epidemic crisis, we hope artificial intelligence (AI) to reduce physician workload in regions with the outbreak, and improve the diagnosis accuracy for physicians before they could acquire enough experience with the new disease. In this paper, we present our experience in building and deploying an AI system that automatically analyzes CT images and provides the probability of infection to rapidly detect COVID-19 pneumonia. The proposed system which consists of classification and segmentation will save about 30%-40% of the detection time for physicians and promote the performance of COVID-19 detection. Specifically, working in an interdisciplinary team of over 30 people with medical and/or AI background, geographically distributed in Beijing and Wuhan, we are able to overcome a series of challenges (e.g. data discrepancy, testing time-effectiveness of model, data security, etc.) in this particular situation and deploy the system in four weeks. In addition, since the proposed AI system provides the priority of each CT image with probability of infection, the physicians can confirm and segregate the infected patients in time. Using 1,136 training cases (723 positives for COVID-19) from five hospitals, we are able to achieve a sensitivity of 0.974 and specificity of 0.922 on the test dataset, which included a variety of pulmonary diseases.",223,COVID-19;Infections;Lung Diseases;Pneumonia,181.0,Appl Soft Comput,Disease Outbreaks;Radiologists,5.460460182024969e-06,94.71199999999968,6.542698645252798e-06,241.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33201872,10.24875/RIC.20000451,Yes,,33201872.0,2020,2020-11-18,Journal Article,Peer reviewed (PubMed),1,validation of chest computed tomography artificial intelligence to determine the requirement for mechanical ventilation and risk of mortality in hospitalized coronavirus disease-19 patients in a tertiary care center in mexico city,"Artificial intelligence (AI) in radiology has improved diagnostic performance and shortened reading times of coronavirus disease 2019 (COVID-19) patients' studies. The objectives pf the study were to analyze the performance of a chest computed tomography (CT) AI quantitative algorithm for determining the risk of mortality/mechanical ventilation (MV) in hospitalized COVID-19 patients and explore a prognostic multivariate model in a tertiary-care center in Mexico City. Chest CT images of 166 COVID-19 patients hospitalized from April 1 to 20, 2020, were retrospectively analyzed using AI algorithm software. Data were collected from their medical records. We analyzed the diagnostic yield of the relevant CT variables using the AUC (AUC ). Optimal thresholds were obtained using the Youden index. We proposed a predictive logistic model for each outcome based on CT AI measures and predetermined laboratory and clinical characteristics. The highest diagnostic yield of the assessed CT variables for mortality was the percentage of total opacity (threshold >51%; AUC = 0.88, sensitivity = 74%, and specificity = 91%). The AUC of the CT severity score (threshold > 12.5) was 0.88 for MV (sensitivity = 65% and specificity = 92%). The proposed prognostic models include the percentage of opacity and lactate dehydrogenase level for mortality and troponin I and CT severity score for MV requirement. The AI-calculated CT severity score and total opacity percentage showed good diagnostic accuracy for mortality and met MV criteria. The proposed prognostic models using biochemical variables and imaging data measured by AI on chest CT showed good risk classification in our population of hospitalized COVID-19 patients.",256,COVID-19,12.0,Rev Invest Clin,Algorithms;ROC Curve;Ventilation,1.5363123227892488e-06,21.69600000000001,1.5628692008042692e-06,54.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33208927,10.1038/s41551-020-00633-5,Yes,PMC7723858,33208927.0,2020,2020-11-20,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,open resource of clinical data from patients with pneumonia for the prediction of covid-19 outcomes via deep learning,"Data from patients with coronavirus disease 2019 (COVID-19) are essential for guiding clinical decision making, for furthering the understanding of this viral disease, and for diagnostic modelling. Here, we describe an open resource containing data from 1,521 patients with pneumonia (including COVID-19 pneumonia) consisting of chest computed tomography (CT) images, 130 clinical features (from a range of biochemical and cellular analyses of blood and urine samples) and laboratory-confirmed severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) clinical status. We show the utility of the database for prediction of COVID-19 morbidity and mortality outcomes using a deep learning algorithm trained with data from 1,170 patients and 19,685 manually labelled CT slices. In an independent validation cohort of 351 patients, the algorithm discriminated between negative, mild and severe cases with areas under the receiver operating characteristic curve of 0.944, 0.860 and 0.884, respectively. The open database may have further uses in the diagnosis and management of patients with COVID-19.",156,COVID-19;Pneumonia;Severe Acute Respiratory Syndrome;Virus Diseases,64.0,Nat Biomed Eng,Algorithms;ROC Curve,3.200910727856569e-06,45.21599999999999,2.9127663738040687e-06,140.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33209367,10.21037/jtd-20-1584,Yes,PMC7656439,33209367.0,2020,2020-11-20,Journal Article,Peer reviewed (PubMed),1,ct imaging features of different clinical types of covid-19 calculated by ai system: a chinese multicenter study,"The study is designed to explore the chest CT features of different clinical types of coronavirus disease 2019 (COVID-19) pneumonia based on a Chinese multicenter dataset using an artificial intelligence (AI) system. A total of 164 patients confirmed COVID-19 were retrospectively enrolled from 6 hospitals. All patients were divided into the mild type (136 cases) and the severe type (28 cases) according to their clinical manifestations. The total CT severity score and quantitative CT features were calculated by AI pneumonia detection and evaluation system with correction by radiologists. The clinical and CT imaging features of different types were analyzed. It was observed that patients in the severe type group were older than the mild type group. Round lesions, Fan-shaped lesions, crazy-paving pattern, fibrosis, ""white lung"", pleural thickening, pleural indentation, mediastinal lymphadenectasis were more common in the CT images of severe patients than in the mild ones. A higher total lung severity score and scores of each lobe were observed in the severe group, with higher scores in bilateral lower lobes of both groups. Further analysis showed that the volume and number of pneumonia lesions and consolidation lesions in overall lung were higher in the severe group, and showed a wider distribution in the lower lobes of bilateral lung in both groups. Chest CT of patients with severe COVID-19 pneumonia showed more consolidative and progressive lesions. With the assistance of AI, CT could evaluate the clinical severity of COVID-19 pneumonia more precisely and help the early diagnosis and surveillance of the patients.",251,COVID-19;Fibrosis;Pneumonia,3.0,J Thorac Dis,Dataset;Fibrosis;Radiologists,2.0544344340695524e-06,29.30399999999998,1.6854083171549825e-06,103.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
33225476,10.1002/mp.14609,Yes,PMC7753662,33225476.0,2020,2020-11-24,Journal Article,Peer reviewed (PubMed),1,abnormal lung quantification in chest ct images of covid-19 patients with deep learning and its application to severity prediction,"Computed tomography (CT) provides rich diagnosis and severity information of COVID-19 in clinical practice. However, there is no computerized tool to automatically delineate COVID-19 infection regions in chest CT scans for quantitative assessment in advanced applications such as severity prediction. The aim of this study was to develop a deep learning (DL)-based method for automatic segmentation and quantification of infection regions as well as the entire lungs from chest CT scans. The DL-based segmentation method employs the ""VB-Net"" neural network to segment COVID-19 infection regions in CT scans. The developed DL-based segmentation system is trained by CT scans from 249 COVID-19 patients, and further validated by CT scans from other 300 COVID-19 patients. To accelerate the manual delineation of CT scans for training, a human-involved-model-iterations (HIMI) strategy is also adopted to assist radiologists to refine automatic annotation of each training case. To evaluate the performance of the DL-based segmentation system, three metrics, that is, Dice similarity coefficient, the differences of volume, and percentage of infection (POI), are calculated between automatic and manual segmentations on the validation set. Then, a clinical study on severity prediction is reported based on the quantitative infection assessment. The proposed DL-based segmentation system yielded Dice similarity coefficients of 91.6% % between automatic and manual segmentations, and a mean POI estimation error of 0.3% for the whole lung on the validation dataset. Moreover, compared with the cases with fully manual delineation that often takes hours, the proposed HIMI training strategy can dramatically reduce the delineation time to 4 min after three iterations of model updating. Besides, the best accuracy of severity prediction was 73.4% % when the mass of infection (MOI) of multiple lung lobes and bronchopulmonary segments were used as features for severity prediction, indicating the potential clinical application of our quantification technique on severity prediction. A DL-based segmentation system has been developed to automatically segment and quantify infection regions in CT scans of COVID-19 patients. Quantitative evaluation indicated high accuracy in automatic infection delineation and severity prediction.",332,COVID-19;Infections,77.0,Med Phys,Other Topics,3.62604250015742e-06,141.91999999999936,9.513936577883663e-06,276.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,CT
33230395,10.1016/j.asoc.2020.106912,Yes,PMC7673219,33230395.0,2020,2020-11-25,Journal Article,Peer reviewed (PubMed),1,cnn-based transfer learning-bilstm network: a novel approach for covid-19 infection detection,"Coronavirus disease 2019 (COVID-2019), which emerged in Wuhan, China in 2019 and has spread rapidly all over the world since the beginning of 2020, has infected millions of people and caused many deaths. For this pandemic, which is still in effect, mobilization has started all over the world, and various restrictions and precautions have been taken to prevent the spread of this disease. In addition, infected people must be identified in order to control the infection. However, due to the inadequate number of Reverse Transcription Polymerase Chain Reaction (RT-PCR) tests, Chest computed tomography (CT) becomes a popular tool to assist the diagnosis of COVID-19. In this study, two deep learning architectures have been proposed that automatically detect positive COVID-19 cases using Chest CT X-ray images. Lung segmentation (preprocessing) in CT images, which are given as input to these proposed architectures, is performed automatically with Artificial Neural Networks (ANN). Since both architectures contain AlexNet architecture, the recommended method is a transfer learning application. However, the second proposed architecture is a hybrid structure as it contains a Bidirectional Long Short-Term Memories (BiLSTM) layer, which also takes into account the temporal properties. While the COVID-19 classification accuracy of the first architecture is 98.14%, this value is 98.70% in the second hybrid architecture. The results prove that the proposed architecture shows outstanding success in infection detection and, therefore this study contributes to previous studies in terms of both deep architectural design and high classification success.",241,COVID-19;Death;Infections,98.0,Appl Soft Comput,Transfer Learning;Architecture;Lung;Polymerase Chain Reaction;Tomography;Reverse Transcription,3.9192146972455e-06,66.60800000000002,5.009229218183255e-06,170.0,0.0,External,2. Detection/Diagnosis,X-Ray
33230398,10.1016/j.bspc.2020.102365,Yes,PMC7674150,33230398.0,2020,2020-11-25,Journal Article,Peer reviewed (PubMed),1,application of deep learning techniques for detection of covid-19 cases using chest x-ray images: a comprehensive study,"The emergence of Coronavirus Disease 2019 (COVID-19) in early December 2019 has caused immense damage to health and global well-being. Currently, there are approximately five million confirmed cases and the novel virus is still spreading rapidly all over the world. Many hospitals across the globe are not yet equipped with an adequate amount of testing kits and the manual Reverse Transcription-Polymerase Chain Reaction (RT-PCR) test is time-consuming and troublesome. It is hence very important to design an automated and early diagnosis system which can provide fast decision and greatly reduce the diagnosis error. The chest X-ray images along with emerging Artificial Intelligence (AI) methodologies, in particular Deep Learning (DL) algorithms have recently become a worthy choice for early COVID-19 screening. This paper proposes a DL assisted automated method using X-ray images for early diagnosis of COVID-19 infection. We evaluate the effectiveness of eight pre-trained Convolutional Neural Network (CNN) models such as AlexNet, VGG-16, GoogleNet, MobileNet-V2, SqueezeNet, ResNet-34, ResNet-50 and Inception-V3 for classification of COVID-19 from normal cases. Also, comparative analyses have been made among these models by considering several important factors such as batch size, learning rate, number of epochs, and type of optimizers with an aim to find the best suited model. The models have been validated on publicly available chest X-ray images and the best performance is obtained by ResNet-34 with an accuracy of 98.33%. This study will be useful for researchers to think for the design of more effective CNN based models for early COVID-19 detection.",249,COVID-19;Infections,106.0,Biomed Signal Process Control,Research Personnel;Polymerase Chain Reaction;Reverse Transcription,6.615828824000554e-06,142.6959999999993,9.75178229026597e-06,349.0,0.0,External,2. Detection/Diagnosis,X-Ray
33230503,10.1016/j.ibmed.2020.100014,Yes,PMC7674009,33230503.0,2020,2020-11-25,Journal Article,Peer reviewed (PubMed),1,covid-19 pneumonia accurately detected on chest radiographs with artificial intelligence,"To investigate the diagnostic performance of an Artificial Intelligence (AI) system for detection of COVID-19 in chest radiographs (CXR), and compare results to those of physicians working alone, or with AI support. An AI system was fine-tuned to discriminate confirmed COVID-19 pneumonia, from other viral and bacterial pneumonia and non-pneumonia patients and used to review 302 CXR images from adult patients retrospectively sourced from nine different databases. Fifty-four physicians blind to diagnosis, were invited to interpret images under identical conditions in a test set, and randomly assigned either to receive or not receive support from the AI system. Comparisons were then made between diagnostic performance of physicians working with and without AI support. AI system performance was evaluated using the AUC (AUROC), and sensitivity and specificity of physician performance compared to that of the AI system. Discrimination by the AI system of COVID-19 pneumonia showed an AUROC curve of 0.96 in the validation and 0.83 in the external test set, respectively. The AI system outperformed physicians in the AUROC overall (70% increase in sensitivity and 1% increase in specificity, p < 0.0001). When working with AI support, physicians increased their diagnostic sensitivity from 47% to 61% (p < 0.001), although specificity decreased from 79% to 75% (p = 0.007). Our results suggest interpreting chest radiographs (CXR) supported by AI, increases physician diagnostic sensitivity for COVID-19 detection. This approach involving a human-machine partnership may help expedite triaging efforts and improve resource allocation in the current crisis.",245,"COVID-19;Pneumonia;Pneumonia, Bacterial",11.0,Intell Based Med,Polymerase Chain Reaction;Real-Time Polymerase Chain Reaction,2.6326552579442736e-06,46.04000000000004,3.4286849640236568e-06,113.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
33231160,10.2174/1573405616666201123120417,Yes,PMC8653418,33231160.0,2020,2020-11-25,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,deep transfer learning for covid-19 prediction: case study for limited data problems,"Automatic prediction of COVID-19 using deep convolution neural networks based pre-trained transfer models and Chest X-ray images. This research employs the advantages of computer vision and medical image analysis to develop an automated model that has the clinical potential for early detection of the disease. Using Deep Learning models, the research aims at evaluating the effectiveness and accuracy of different convolutional neural networks models in the automatic diagnosis of COVID-19 from X-ray images as compared to diagnosis performed by experts in the medical community. Due to the fact that the dataset available for COVID-19 is still limited, the best model to use is the InceptionNetV3. Performance results show that the InceptionNetV3 model yielded the highest accuracy of 98.63% (with data augmentation) and 98.90% (without data augmentation) among the three models designed. However, as the dataset gets bigger, the Inception ResNetV2 and NASNetlarge will do a better job of classification. All the performed networks tend to over-fit when data augmentation is not used, this is due to the small amount of data used for training and validation. A deep transfer learning is proposed to detecting the COVID-19 automatically from chest X-ray by training it with X-ray images gotten from both COVID-19 patients and people with normal chest X-rays. The study is aimed at helping doctors in making decisions in their clinical practice due its high performance and effectiveness, the study also gives an insight to how transfer learning was used to automatically detect the COVID-19.",244,COVID-19,6.0,Curr Med Imaging,Transfer Learning;Neural Networks;Other Topics,2.504193031223194e-06,109.8799999999996,7.134889953229999e-06,227.0,0.0,External,2. Detection/Diagnosis,X-Ray
33250589,10.1016/j.chaos.2020.110495,Yes,PMC7682527,33250589.0,2020,2020-12-01,Journal Article,Peer reviewed (PubMed),1,corodet: a deep learning based classification for covid-19 detection using chest x-ray images,"The Coronavirus 2019, or shortly COVID-19, is a viral disease that causes serious pneumonia and impacts our different body parts from mild to severe depending on patient's immune system. This infection was first reported in Wuhan city of China in December 2019, and afterward, it became a global pandemic spreading rapidly around the world. As the virus spreads through human to human contact, it has affected our lives in a devastating way, including the vigorous pressure on the public health system, the world economy, education sector, workplaces, and shopping malls. Preventing viral spreading requires early detection of positive cases and to treat infected patients as quickly as possible. The need for COVID-19 testing kits has increased, and many of the developing countries in the world are facing a shortage of testing kits as new cases are increasing day by day. In this situation, the recent research using radiology imaging (such as X-ray and CT scan) techniques can be proven helpful to detect COVID-19 as X-ray and CT scan images provide important information about the disease caused by COVID-19 virus. The latest data mining and machine learning techniques such as Convolutional Neural Network (CNN) can be applied along with X-ray and CT scan images of the lungs for the accurate and rapid detection of the disease, assisting in mitigating the problem of scarcity of testing kits. Hence a novel CNN model called CoroDet for automatic detection of COVID-19 by using raw chest X-ray and CT scan images have been proposed in this study. CoroDet is developed to serve as an accurate diagnostics for 2 class classification (COVID and Normal), 3 class classification (COVID, Normal, and non-COVID pneumonia), and 4 class classification (COVID, Normal, non-COVID viral pneumonia, and non-COVID bacterial pneumonia). The performance of our proposed model was compared with ten existing techniques for COVID detection in terms of accuracy. A classification accuracy of 99.1% for 2 class classification, 94.2% for 3 class classification, and 91.2% for 4 class classification was produced by our proposed model, which is obviously better than the state-of-the-art-methods used for COVID-19 detection to the best of our knowledge. Moreover, the dataset with x-ray images that we prepared for the evaluation of our method is the largest datasets for COVID detection as far as our knowledge goes. The experimental results of our proposed method CoroDet indicate the superiority of CoroDet over the existing state-of-the-art-methods. CoroDet may assist clinicians in making appropriate decisions for COVID-19 detection and may also mitigate the problem of scarcity of testing kits.",418,"COVID-19;Infections;Pneumonia;Pneumonia, Bacterial;Pneumonia, Viral;Virus Diseases",100.0,Chaos Solitons Fractals,Coronavirus Infections;Public Health;Art;COVID-19 Testing;Lung Diseases,6.8459003333776295e-06,274.0399999999984,1.836043172947604e-05,567.0,0.0,External,2. Detection/Diagnosis,Multimodal
33250662,10.1007/s00500-020-05424-3,Yes,PMC7679792,33250662.0,2020,2020-12-01,Journal Article,Peer reviewed (PubMed),1,covid-chexnet: hybrid deep learning framework for identifying covid-19 virus in chest x-rays images,"The outbreaks of Coronavirus (COVID-19) epidemic have increased the pressure on healthcare and medical systems worldwide. The timely diagnosis of infected patients is a critical step to limit the spread of the COVID-19 epidemic. The chest radiography imaging has shown to be an effective screening technique in diagnosing the COVID-19 epidemic. To reduce the pressure on radiologists and control of the epidemic, fast and accurate a hybrid deep learning framework for diagnosing COVID-19 virus in chest X-ray images is developed and termed as the COVID-CheXNet system. First, the contrast of the X-ray image was enhanced and the noise level was reduced using the contrast-limited adaptive histogram equalization and Butterworth bandpass filter, respectively. This was followed by fusing the results obtained from two different pre-trained deep learning models based on the incorporation of a ResNet34 and high-resolution network model trained using a large-scale dataset. Herein, the parallel architecture was considered, which provides radiologists with a high degree of confidence to discriminate between the healthy and COVID-19 infected people. The proposed COVID-CheXNet system has managed to correctly and accurately diagnose the COVID-19 patients with a detection accuracy rate of 99.99%, sensitivity of 99.98%, specificity of 100%, precision of 100%, F1-score of 99.99%, MSE of 0.011%, and RMSE of 0.012% using the weighted sum rule at the score-level. The efficiency and usefulness of the proposed COVID-CheXNet system are established along with the possibility of using it in real clinical centers for fast diagnosis and treatment supplement, with less than 2 s per image to get the prediction result.",255,COVID-19,56.0,Soft comput,Radiography;Health Care;Transfer Learning;Architecture;Disease Outbreaks;Noise;Sensitivity and Specificity;Radiologists,2.936940109767073e-06,68.34400000000001,5.058107531710413e-06,159.0,0.0,External,2. Detection/Diagnosis,X-Ray
33259441,10.1097/RLI.0000000000000748,Yes,,33259441.0,2020,2020-12-02,Journal Article;Multicenter Study;Validation Study,Peer reviewed (PubMed),1,a deep-learning diagnostic support system for the detection of covid-19 using chest radiographs: a multireader validation study,"Five publicly available databases comprising normal CXR, confirmed COVID-19 pneumonia cases, and other pneumonias were used. After the harmonization of the data, the training set included 7966 normal cases, 5451 with other pneumonia, and 258 CXRs with COVID-19 pneumonia, whereas in the testing data set, each category was represented by 100 cases. Eleven blinded radiologists with various levels of expertise independently read the testing data set. The data were analyzed separately with the newly proposed artificial intelligence-based system and by consultant radiologists and residents, with respect to positive predictive value (PPV), sensitivity, and F-score (harmonic mean for PPV and sensitivity). The χ2 test was used to compare the sensitivity, specificity, accuracy, PPV, and F-scores of the readers and the system. The proposed system achieved higher overall diagnostic accuracy than the radiologists. The radiologists reached average sensitivities for normal CXR, other type of pneumonia, and COVID-19 pneumonia of 85.0% %, 60.1% %, and 53.2% %, respectively, which were significantly lower than the results achieved by the algorithm (98.0%, 88.0%, and 97.0%; P < 0.00032). The mean PPVs for all 11 radiologists for the 3 categories were 82.4%, 59.0%, and 59.0% for the healthy, other pneumonia, and COVID-19 pneumonia, respectively, resulting in an F-score of 65.5% %, which was significantly lower than the F-score of the algorithm (94.3% %, P < 0.00001). When other pneumonia and COVID-19 pneumonia cases were pooled, the proposed system reached an accuracy of 95.7% for any pathology and the radiologists, 88.8%. The overall accuracy of consultants did not vary significantly compared with residents (65.0% % vs 67.4% %); however, consultants detected significantly more COVID-19 pneumonia cases (P = 0.008) and less healthy cases (P < 0.00001). The system showed robust accuracy for COVID-19 pneumonia detection on CXR and surpassed radiologists at various training levels.",297,COVID-19;Pneumonia,15.0,Invest Radiol,Predictive Value;COVID-19 Testing;Sensitivity and Specificity;Image Processing;Retrospective Studies,1.2605657247563073e-06,26.720000000000013,1.761197804333606e-06,58.0,0.0,External,2. Detection/Diagnosis,X-Ray
33275187,10.1007/s13246-020-00952-6,Yes,PMC7715648,33275187.0,2020,2020-12-05,Journal Article,Peer reviewed (PubMed),1,stacknet-denvis: a multi-layer perceptron stacked ensembling approach for covid-19 detection using x-ray images,"The highly contagious nature of Coronavirus disease 2019 (Covid-19) resulted in a global pandemic. Due to the relatively slow and taxing nature of conventional testing for Covid-19, a faster method needs to be in place. The current researches have suggested that visible irregularities found in the chest X-ray of Covid-19 positive patients are indicative of the presence of the disease. Hence, Deep Learning and Image Classification techniques can be employed to learn from these irregularities, and classify accordingly with high accuracy. This research presents an approach to create a classifier model named StackNet-DenVIS which is designed to act as a screening process before conducting the existing swab tests. Using a novel approach, which incorporates Transfer Learning and Stacked Generalization, the model aims to lower the False Negative rate of classification compensating for the 30% False Negative rate of the swab tests. A dataset gathered from multiple reliable sources consisting of 9953 Chest X-rays (868 Covid and 9085 Non-Covid) was used. Also, this research demonstrates handling data imbalance using various techniques involving Generative Adversarial Networks and sampling techniques. The accuracy, sensitivity, and specificity obtained on our proposed model were 95.07%, 99.40% and 94.61% respectively. To the best of our knowledge, the combination of accuracy and false negative rate obtained by this paper outperforms the current implementations. We must also highlight that our proposed architecture also considers other types of viral pneumonia. Given the unprecedented sensitivity of our model we are optimistic it contributes to a better Covid-19 detection.",247,"COVID-19;Pneumonia, Viral",12.0,Phys Eng Sci Med,Transfer Learning;Algorithms;Architecture;COVID-19 Testing;Sensitivity and Specificity;Image Processing;Lung;Neural Networks;Paper;ROC Curve;Lung Diseases;Research,2.755298529424129e-06,57.18400000000003,4.385894144031125e-06,138.0,0.0,External,2. Detection/Diagnosis,X-Ray
33275588,10.1109/JBHI.2020.3042523,Yes,PMC8545178,33275588.0,2020,2020-12-05,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,covid-19 ct image synthesis with a conditional generative adversarial network,"Coronavirus disease 2019 (COVID-19) is an ongoing global pandemic that has spread rapidly since December 2019. Real-time reverse transcription polymerase chain reaction (rRT-PCR) and chest computed tomography (CT) imaging both play an important role in COVID-19 diagnosis. Chest CT imaging offers the benefits of quick reporting, a low cost, and high sensitivity for the detection of pulmonary infection. Recently, deep-learning-based computer vision methods have demonstrated great promise for use in medical imaging applications, including X-rays, magnetic resonance imaging, and CT imaging. However, training a deep-learning model requires large volumes of data, and medical staff faces a high risk when collecting COVID-19 CT data due to the high infectivity of the disease. Another issue is the lack of experts available for data labeling. In order to meet the data requirements for COVID-19 CT imaging, we propose a CT image synthesis approach based on a conditional generative adversarial network that can effectively generate high-quality and realistic COVID-19 CT images for use in deep-learning-based medical imaging tasks. Experimental results show that the proposed method outperforms other state-of-the-art image synthesis methods with the generated COVID-19 CT images and indicates promising for various machine learning applications including semantic segmentation and classification.",196,COVID-19;Infections,33.0,IEEE J Biomed Health Inform,Radiography;Magnetic Resonance Imaging;Art;Pandemics;Semantics;Lung;Polymerase Chain Reaction;Classification;Tomography;Lung Diseases;Reverse Transcription,3.1340883587884565e-06,93.67999999999968,4.586684920437908e-06,220.0,0.0,External,5. Post-hoc,CT
33285482,10.1016/j.media.2020.101913,Yes,PMC7689310,33285482.0,2020,2020-12-08,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,covid-al: the diagnosis of covid-19 with deep active learning,"The efficient diagnosis of COVID-19 plays a key role in preventing the spread of this disease. The computer-aided diagnosis with deep learning methods can perform automatic detection of COVID-19 using CT scans. However, large scale annotation of CT scans is impossible because of limited time and heavy burden on the healthcare system. To meet the challenge, we propose a weakly-supervised deep active learning framework called COVID-AL to diagnose COVID-19 with CT scans and patient-level labels. The COVID-AL consists of the lung region segmentation with a 2D U-Net and the diagnosis of COVID-19 with a novel hybrid active learning strategy, which simultaneously considers sample diversity and predicted loss. With a tailor-designed 3D residual network, the proposed COVID-AL can diagnose COVID-19 efficiently and it is validated on a large CT scan dataset collected from the CC-CCII. The experimental results demonstrate that the proposed COVID-AL outperforms the state-of-the-art active learning approaches in the diagnosis of COVID-19. With only 30% of the labeled data, the COVID-AL achieves over 95% accuracy of the deep learning method using the whole dataset. The qualitative and quantitative analysis proves the effectiveness and efficiency of the proposed COVID-AL framework.",190,COVID-19,42.0,Med Image Anal,Art;Health Care;Tomography;Other Topics;Lung Diseases,3.205145987727201e-06,57.40000000000002,4.334852711362302e-06,143.0,0.0,External,2. Detection/Diagnosis,CT
33286289,10.3390/e22050517,Yes,PMC7517011,33286289.0,2020,2020-12-09,Journal Article,Peer reviewed (PubMed),1,classification of covid-19 coronavirus pneumonia and healthy lungs in ct scans using q-deformed entropy and deep learning features,"Many health systems over the world have collapsed due to limited capacity and a dramatic increase of suspected COVID-19 cases. What has emerged is the need for finding an efficient, quick and accurate method to mitigate the overloading of radiologists' efforts to diagnose the suspected cases. This study presents the combination of deep learning of extracted features with the Q-deformed entropy handcrafted features for discriminating between COVID-19 coronavirus, pneumonia and healthy computed tomography (CT) lung scans. In this study, pre-processing is used to reduce the effect of intensity variations between CT slices. Then histogram thresholding is used to isolate the background of the CT lung scan. Each CT lung scan undergoes a feature extraction which involves deep learning and a Q-deformed entropy algorithm. The obtained features are classified using a long short-term memory (LSTM) neural network classifier. Subsequently, combining all extracted features significantly improves the performance of the LSTM network to precisely discriminate between COVID-19, pneumonia and healthy cases. The maximum achieved accuracy for classifying the collected dataset comprising 321 patients is 99.68%.",173,COVID-19;Pneumonia,46.0,Entropy (Basel),Health;Radiologists;Entropy,2.442220144341793e-06,32.96000000000001,2.5133045311851887e-06,86.0,0.0,External,2. Detection/Diagnosis,CT
33301073,10.1007/s13246-020-00957-1,Yes,PMC7726306,33301073.0,2020,2020-12-11,Journal Article,Peer reviewed (PubMed),1,hybrid-covid: a novel hybrid 2d/3d cnn based on cross-domain adaptation approach for covid-19 screening from chest x-ray images,"The novel Coronavirus disease (COVID-19), which first appeared at the end of December 2019, continues to spread rapidly in most countries of the world. Respiratory infections occur primarily in the majority of patients treated with COVID-19. In light of the growing number of COVID-19 cases, the need for diagnostic tools to identify COVID-19 infection at early stages is of vital importance. For decades, chest X-ray (CXR) technologies have proven their ability to accurately detect respiratory diseases. More recently, with the availability of COVID-19 CXR scans, deep learning algorithms have played a critical role in the healthcare arena by allowing radiologists to recognize COVID-19 patients from their CXR images. However, the majority of screening methods for COVID-19 reported in recent studies are based on 2D convolutional neural networks (CNNs). Although 3D CNNs are capable of capturing contextual information compared to their 2D counterparts, their use is limited due to their increased computational cost (i.e. requires much extra memory and much more computing power). In this study, a transfer learning-based hybrid 2D/3D CNN architecture for COVID-19 screening using CXRs has been developed. The proposed architecture consists of the incorporation of a pre-trained deep model (VGG16) and a shallow 3D CNN, combined with a depth-wise separable convolution layer and a spatial pyramid pooling module (SPP). Specifically, the depth-wise separable convolution helps to preserve the useful features while reducing the computational burden of the model. The SPP module is designed to extract multi-level representations from intermediate ones. Experimental results show that the proposed framework can achieve reasonable performances when evaluated on a collected dataset (3 classes to be predicted: COVID-19, Pneumonia, and Normal). Notably, it achieved a sensitivity of 98.33%, a specificity of 98.68% and an overall accuracy of 96.91.",286,COVID-19;Infections;Pneumonia;Respiratory Tract Diseases;Respiratory Tract Infections,12.0,Phys Eng Sci Med,Coronavirus Infections;Health Care;Transfer Learning;Algorithms;Architecture;COVID-19 Testing;Sensitivity and Specificity;Lung;Neural Networks,5.075952636185846e-06,181.55199999999888,1.2781042717611814e-05,382.0,0.0,External,2. Detection/Diagnosis,X-Ray
33320858,10.1371/journal.pone.0242899,Yes,PMC7737907,33320858.0,2020,2020-12-16,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,optimised genetic algorithm-extreme learning machine approach for automatic covid-19 detection,"The coronavirus disease (COVID-19), is an ongoing global pandemic caused by severe acute respiratory syndrome. Chest Computed Tomography (CT) is an effective method for detecting lung illnesses, including COVID-19. However, the CT scan is expensive and time-consuming. Therefore, this work focus on detecting COVID-19 using chest X-ray images because it is widely available, faster, and cheaper than CT scan. Many machine learning approaches such as Deep Learning, Neural Network, and Support Vector Machine; have used X-ray for detecting the COVID-19. Although the performance of those approaches is acceptable in terms of accuracy, however, they require high computational time and more memory space. Therefore, this work employs an Optimised Genetic Algorithm-Extreme Learning Machine (OGA-ELM) with three selection criteria (i.e., random, K-tournament, and roulette wheel) to detect COVID-19 using X-ray images. The most crucial strength factors of the Extreme Learning Machine (ELM) are: high capability of the ELM in avoiding overfitting; its usability on binary and multi-type classifiers; and ELM could work as a kernel-based support vector machine with a structure of a neural network. These advantages make the ELM efficient in achieving an excellent learning performance. ELMs have successfully been applied in many domains, including medical domains such as breast cancer detection, pathological brain detection, and ductal carcinoma in situ detection, but not yet tested on detecting COVID-19. Hence, this work aims to identify the effectiveness of employing OGA-ELM in detecting COVID-19 using chest X-ray images. In order to reduce the dimensionality of a histogram oriented gradient features, we use principal component analysis. The performance of OGA-ELM is evaluated on a benchmark dataset containing 188 chest X-ray images with two classes: a healthy and a COVID-19 infected. The experimental result shows that the OGA-ELM achieves 100.00% accuracy with fast computation time. This demonstrates that OGA-ELM is an efficient method for COVID-19 detecting using chest X-ray images.",305,"Breast Cancer;COVID-19;Carcinoma, Intraductal, Noninfiltrating;Severe Acute Respiratory Syndrome",14.0,PLoS One,Neural Networks;Support Vector Machine,1.2681351983418289e-05,301.3040000000022,1.7169053134973487e-05,729.0,0.0,External,2. Detection/Diagnosis,CT
33324064,10.2147/TCRM.S280726,Yes,PMC7733409,33324064.0,2020,2020-12-17,Journal Article,Peer reviewed (PubMed),1,novel deep learning technique used in management and discharge of hospitalized patients with covid-19 in china,"The low sensitivity and false-negative results of nucleic acid testing greatly affect its performance in diagnosing and discharging patients with coronavirus disease (COVID-19). Chest computed tomography (CT)-based evaluation of pneumonia may indicate a need for isolation. Therefore, this radiologic modality plays an important role in managing patients with suspected COVID-19. Meanwhile, deep learning (DL) technology has been successful in detecting various imaging features of chest CT. This study applied a novel DL technique to standardize the discharge criteria of COVID-19 patients with consecutive negative respiratory pathogen nucleic acid test results at a ""square cabin"" hospital. DL was used to evaluate the chest CT scans of 270 hospitalized COVID-19 patients who had two consecutive negative nucleic acid tests (sampling interval >1 day). The CT scans evaluated were obtained after the patients' second negative test result. The standard criterion determined by DL for patient discharge was a total volume ratio of lesion to lung <50%. The mean number of days between hospitalization and DL was 14.3. The average intersection over union was 0.7894. Two hundred and thirteen patients exhibited pneumonia, of whom 54.0% had mild interstitial fibrosis. Twenty-one, 33, and 4 cases exhibited vascular enlargement, pleural thickening, and mediastinal lymphadenopathy, respectively. Of the latter, 18.8% had a total volume ratio of lesions to lung ≥50% according to our severity scale and were monitored continuously in the hospital. Three cases had a positive follow-up nucleic acid test during hospitalization. None of the 230 discharged cases later tested positive or exhibited pneumonia progression. The novel DL enables the accurate management of hospitalized patients with COVID-19 and can help avoid cluster transmission or exacerbation in patients with false-negative acid test.",275,COVID-19;Fibrosis;Lymphadenopathy;Pneumonia,2.0,Ther Clin Risk Manag,Fibrosis;Nucleic Acids,2.252283109840675e-06,20.375999999999983,1.6269823606057986e-06,81.0,0.0,Self-recorded/clinical,5. Post-hoc,CT
33328512,10.1038/s41598-020-79097-1,Yes,PMC7745019,33328512.0,2020,2020-12-18,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,prediction of disease progression in patients with covid-19 by artificial intelligence assisted lesion quantification,"To investigate the value of artificial intelligence (AI) assisted quantification on initial chest CT for prediction of disease progression and clinical outcome in patients with coronavirus disease 2019 (COVID-19). Patients with confirmed COVID-19 infection and initially of non-severe type were retrospectively included. The initial CT scan on admission was used for imaging analysis. The presence of ground glass opacity (GGO), consolidation and other findings were visually evaluated. CT severity score was calculated according to the extent of lesion involvement. In addition, AI based quantification of GGO and consolidation volume were also performed. 123 patients (mean age: 64.43 ; 62 males) were included. GGO + consolidation was more frequently revealed in progress-to-severe group whereas pure GGO was more likely to be found in non-severe group. Compared to non-severe group, patients in progress-to-severe group had larger GGO volume (167.33 cm3 versus 101.12 cm3, p = 0.013) as well as consolidation volume (40.85 cm3 versus 6.63 cm3, p < 0.001). Among imaging parameters, consolidation volume had the largest AUC in discriminating non-severe from progress-to-severe group (AUC = 0.796, p < 0.001) and patients with or without critical events (AUC = 0.754, p < 0.001). According to multivariate regression, consolidation volume and age were two strongest predictors for disease progression (hazard ratio: 1.053 and 1.071, p: 0.006 and 0.008) whereas age and diabetes were predictors for unfavorable outcome. Consolidation volume quantified on initial chest CT was the strongest predictor for disease severity progression and larger consolidation volume was associated with unfavorable clinical outcome.",249,COVID-19;Disease Progression;Infections,12.0,Sci Rep,Severity of Illness Index;ROC Curve;Retrospective Studies;Lung Diseases;Age,2.672601636968649e-06,64.15199999999996,2.6995179856930623e-06,191.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33330341,10.3389/fpubh.2020.599550,Yes,PMC7714903,33330341.0,2020,2020-12-18,Journal Article,Peer reviewed (PubMed),1,analysis of covid-19 infections on a ct image using deepsense model,"In this paper, a data mining model on a hybrid deep learning framework is designed to diagnose the medical conditions of patients infected with the coronavirus disease 2019 (COVID-19) virus. The hybrid deep learning model is designed as a combination of convolutional neural network (CNN) and recurrent neural network (RNN) and named as DeepSense method. It is designed as a series of layers to extract and classify the related features of COVID-19 infections from the lungs. The computerized tomography image is used as an input data, and hence, the classifier is designed to ease the process of classification on learning the multidimensional input data using the Expert Hidden layers. The validation of the model is conducted against the medical image datasets to predict the infections using deep learning classifiers. The results show that the DeepSense classifier offers accuracy in an improved manner than the conventional deep and machine learning classifiers. The proposed method is validated against three different datasets, where the training data are compared with 70%, 80%, and 90% training data. It specifically provides the quality of the diagnostic method adopted for the prediction of COVID-19 infections in a patient.",191,COVID-19;Infections,6.0,Front Public Health,Sensitivity and Specificity;Neural Networks,6.7010775559982665e-06,135.62399999999946,7.902509992295082e-06,353.0,0.0,External,2. Detection/Diagnosis,CT
33332412,10.1371/journal.pone.0243963,Yes,PMC7745979,33332412.0,2020,2020-12-18,Journal Article,Peer reviewed (PubMed),1,vulnerability of deep neural networks for detecting covid-19 cases from chest x-ray images to universal adversarial attacks,"Owing the epidemic of the novel coronavirus disease 2019 (COVID-19), chest X-ray computed tomography imaging is being used for effectively screening COVID-19 patients. The development of computer-aided systems based on deep neural networks (DNNs) has become an advanced open source to rapidly and accurately detect COVID-19 cases because the need for expert radiologists, who are limited in number, forms a bottleneck for screening. However, thus far, the vulnerability of DNN-based systems has been poorly evaluated, although realistic and high-risk attacks using universal adversarial perturbation (UAP), a single (input image agnostic) perturbation that can induce DNN failure in most classification tasks, are available. Thus, we focus on representative DNN models for detecting COVID-19 cases from chest X-ray images and evaluate their vulnerability to UAPs. We consider non-targeted UAPs, which cause a task failure, resulting in an input being assigned an incorrect label, and targeted UAPs, which cause the DNN to classify an input into a specific class. The results demonstrate that the models are vulnerable to non-targeted and targeted UAPs, even in the case of small UAPs. In particular, the 2% norm of the UAPs to the average norm of an image in the image dataset achieves >85% and >90% success rates for the non-targeted and targeted attacks, respectively. Owing to the non-targeted UAPs, the DNN models judge most chest X-ray images as COVID-19 cases. The targeted UAPs allow the DNN models to classify most chest X-ray images into a specified target class. The results indicate that careful consideration is required in practical applications of DNNs to COVID-19 diagnosis; in particular, they emphasize the need for strategies to address security concerns. As an example, we show that iterative fine-tuning of DNN models using UAPs improves the robustness of DNN models against UAPs.",291,COVID-19,13.0,PLoS One,Neural Networks;Other Topics,3.7037324428642815e-06,55.991999999999976,3.644101956184147e-06,165.0,0.0,External,2. Detection/Diagnosis,X-Ray
33354790,10.1002/mp.14676,Yes,,33354790.0,2020,2020-12-24,Journal Article,Peer reviewed (PubMed),1,toward data-efficient learning: a benchmark for covid-19 ct lung and infection segmentation,"Accurate segmentation of lung and infection in COVID-19 computed tomography (CT) scans plays an important role in the quantitative management of patients. Most of the existing studies are based on large and private annotated datasets that are impractical to obtain from a single institution, especially when radiologists are busy fighting the coronavirus disease. Furthermore, it is hard to compare current COVID-19 CT segmentation methods as they are developed on different datasets, trained in different settings, and evaluated with different metrics. To promote the development of data-efficient deep learning methods, in this paper, we built three benchmarks for lung and infection segmentation based on 70 annotated COVID-19 cases, which contain current active research areas, for example, few-shot learning, domain generalization, and knowledge transfer. For a fair comparison among different segmentation methods, we also provide standard training, validation and testing splits, evaluation metrics and, the corresponding code. Based on the state-of-the-art network, we provide more than 40 pretrained baseline models, which not only serve as out-of-the-box segmentation tools but also save computational time for researchers who are interested in COVID-19 lung and infection segmentation. We achieve average dice similarity coefficient (DSC) scores of 97.3%, 97.7%, and 67.3% and average normalized surface dice (NSD) scores of 90.6%, 91.4%, and 70.0% for left lung, right lung, and infection, respectively. To the best of our knowledge, this work presents the first data-efficient learning benchmark for medical image segmentation, and the largest number of pretrained models up to now. All these resources are publicly available, and our work lays the foundation for promoting the development of deep learning methods for efficient COVID-19 CT segmentation with limited data.",271,COVID-19;Infections,80.0,Med Phys,Coronavirus Infections;Art;Research Personnel;Image Processing;Tomography;Lung Diseases,3.1732346290689672e-06,75.35999999999999,4.761943466061767e-06,160.0,0.0,External,Segmentation-only,CT
33360271,10.1016/j.compbiomed.2020.104181,Yes,PMC7831681,33360271.0,2020,2020-12-29,Journal Article,Peer reviewed (PubMed),1,lightweight deep learning models for detecting covid-19 from chest x-ray images,"Deep learning methods have already enjoyed an unprecedented success in medical imaging problems. Similar success has been evidenced when it comes to the detection of COVID-19 from medical images, therefore deep learning approaches are considered good candidates for detecting this disease, in collaboration with radiologists and/or physicians. In this paper, we propose a new approach to detect COVID-19 via exploiting a conditional generative adversarial network to generate synthetic images for augmenting the limited amount of data available. Additionally, we propose two deep learning models following a lightweight architecture, commensurating with the overall amount of data available. Our experiments focused on both binary classification for COVID-19 vs Normal cases and multi-classification that includes a third class for bacterial pneumonia. Our models achieved a competitive performance compared to other studies in literature and also a ResNet8 model. Our best performing binary model achieved 98.7% accuracy, 100% sensitivity and 98.3% specificity, while our three-class model achieved 98.3% accuracy, 99.3% sensitivity and 98.1% specificity. Moreover, via adopting a testing protocol proposed in literature, our models proved to be more robust and reliable in COVID-19 detection than a baseline ResNet8, making them good candidates for detecting COVID-19 from posteroanterior chest X-ray images.",197,"COVID-19;Pneumonia, Bacterial",43.0,Comput Biol Med,Other Topics,3.0491109304109137e-06,64.41600000000005,5.301092409610601e-06,148.0,0.0,External,2. Detection/Diagnosis,X-Ray
33362346,10.1002/ima.22525,Yes,PMC7753711,33362346.0,2020,2020-12-29,Journal Article,Peer reviewed (PubMed),1,an integrated feature frame work for automated segmentation of covid-19 infection from lung ct images,"The novel coronavirus disease (SARS-CoV-2 or COVID-19) is spreading across the world and is affecting public health and the world economy. Artificial Intelligence (AI) can play a key role in enhancing COVID-19 detection. However, lung infection by COVID-19 is not quantifiable due to a lack of studies and the difficulty involved in the collection of large datasets. Segmentation is a preferred technique to quantify and contour the COVID-19 region on the lungs using computed tomography (CT) scan images. To address the dataset problem, we propose a deep neural network (DNN) model trained on a limited dataset where features are selected using a region-specific approach. Specifically, we apply the Zernike moment (ZM) and gray level co-occurrence matrix (GLCM) to extract the unique shape and texture features. The feature vectors computed from these techniques enable segmentation that illustrates the severity of the COVID-19 infection. The proposed algorithm was compared with other existing state-of-the-art deep neural networks using the Radiopedia and COVID-19 CT Segmentation datasets presented specificity, sensitivity, sensitivity, mean absolute error (MAE), enhance-alignment measure (EMφ), and structure measure (S m) of 0.942, 0.701, 0.082, 0.867, and 0.783, respectively. The metrics demonstrate the performance of the model in quantifying the COVID-19 infection with limited datasets.",202,COVID-19;Infections,14.0,Int J Imaging Syst Technol,Coronavirus Infections;Art;Public Health;Algorithms;Tomography;Lung Diseases,2.095270316642497e-06,44.85600000000004,3.203066959118537e-06,99.0,0.0,External,Segmentation-only,CT
33363252,10.1016/j.imu.2020.100505,Yes,PMC7752710,33363252.0,2020,2020-12-29,Journal Article,Peer reviewed (PubMed),1,emcnet: automated covid-19 diagnosis from x-ray images using convolutional neural network and ensemble of machine learning classifiers,"Recently, coronavirus disease (COVID-19) has caused a serious effect on the healthcare system and the overall global economy. Doctors, researchers, and experts are focusing on alternative ways for the rapid detection of COVID-19, such as the development of automatic COVID-19 detection systems. In this paper, an automated detection scheme named EMCNet was proposed to identify COVID-19 patients by evaluating chest X-ray images. A convolutional neural network was developed focusing on the simplicity of the model to extract deep and high-level features from X-ray images of patients infected with COVID-19. With the extracted features, binary machine learning classifiers (random forest, support vector machine, decision tree, and AdaBoost) were developed for the detection of COVID-19. Finally, these classifiers' outputs were combined to develop an ensemble of classifiers, which ensures better results for the dataset of various sizes and resolutions. In comparison with other recent deep learning-based systems, EMCNet showed better performance with 98.91% accuracy, 100% precision, 97.82% recall, and 98.89% F1-score. The system could maintain its great importance on the automatic detection of COVID-19 through instant detection and low false negative rate.",180,COVID-19,60.0,Inform Med Unlocked,Health Care;Research Personnel;Support Vector Machine;Decision Trees;Random Forest,5.214785310333526e-06,94.63999999999974,7.019562186348848e-06,228.0,0.0,External,2. Detection/Diagnosis,X-Ray
33372243,10.1007/s00330-020-07553-7,Yes,PMC7769567,33372243.0,2020,2020-12-30,Journal Article,Peer reviewed (PubMed),1,the usage of deep neural network improves distinguishing covid-19 from other suspected viral pneumonia by clinicians on chest ct: a real-world study,"Based on the current clinical routine, we aimed to develop a novel deep learning model to distinguish coronavirus disease 2019 (COVID-19) pneumonia from other types of pneumonia and validate it with a real-world dataset (RWD). A total of 563 chest CT scans of 380 patients (227/380 were diagnosed with COVID-19 pneumonia) from 5 hospitals were collected to train our deep learning (DL) model. Lung regions were extracted by U-net, then transformed and fed to pre-trained ResNet-50-based IDANNet (Identification and Analysis of New covid-19 Net) to produce a diagnostic probability. Fivefold cross-validation was employed to validate the application of our model. Another 318 scans of 316 patients (243/316 were diagnosed with COVID-19 pneumonia) from 2 other hospitals were enrolled prospectively as the RWDs to testify our DL model's performance and compared it with that from 3 experienced radiologists. A three-dimensional DL model was successfully established. The diagnostic threshold to differentiate COVID-19 and non-COVID-19 pneumonia was 0.685 with an AUC of 0.906 in the internal validation group. In the RWD cohort, our model achieved an AUC of 0.868 with the sensitivity of 0.811 and the specificity of 0.822, non-inferior to the performance of 3 experienced radiologists, suggesting promising clinical practical usage. The established DL model was able to achieve accurate identification of COVID-19 pneumonia from other suspected ones in the real-world situation, which could become a reliable tool in clinical routine. In an internal validation set, our DL model achieved the best performance to differentiate COVID-19 from non-COVID-19 pneumonia with a sensitivity of 0.836, a specificity of 0.800, and an AUC of 0.906 when the threshold was set at 0.685. In the prospective RWD cohort, our DL diagnostic model achieved a sensitivity of 0.811, a specificity of 0.822, and AUC of 0.868, non-inferior to the performance of 3 experienced radiologists. The attention heatmaps were fully generated by the model without additional manual annotation and the attention regions were highly aligned with the ROIs acquired by human radiologists for diagnosis.",327,"COVID-19;Pneumonia;Pneumonia, Viral",9.0,Eur Radiol,Sensitivity and Specificity;Neural Networks;Area under Curve,3.3688817600012887e-06,66.208,4.544144909091095e-06,176.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33425953,10.3389/fmed.2020.608525,Yes,PMC7786372,33425953.0,2021,2021-01-12,Journal Article,Peer reviewed (PubMed),1,covidnet-ct: a tailored deep convolutional neural network design for detection of covid-19 cases from chest ct images,"The coronavirus disease 2019 (COVID-19) pandemic continues to have a tremendous impact on patients and healthcare systems around the world. In the fight against this novel disease, there is a pressing need for rapid and effective screening tools to identify patients infected with COVID-19, and to this end CT imaging has been proposed as one of the key screening methods which may be used as a complement to RT-PCR testing, particularly in situations where patients undergo routine CT scans for non-COVID-19 related reasons, patients have worsening respiratory status or developing complications that require expedited care, or patients are suspected to be COVID-19-positive but have negative RT-PCR test results. Early studies on CT-based screening have reported abnormalities in chest CT images which are characteristic of COVID-19 infection, but these abnormalities may be difficult to distinguish from abnormalities caused by other lung conditions. Motivated by this, in this study we introduce COVIDNet-CT, a deep convolutional neural network architecture that is tailored for detection of COVID-19 cases from chest CT images via a machine-driven design exploration approach. Additionally, we introduce COVIDx-CT, a benchmark CT image dataset derived from CT imaging data collected by the China National Center for Bioinformation comprising 104,009 images across 1,489 patient cases. Furthermore, in the interest of reliability and transparency, we leverage an explainability-driven performance validation strategy to investigate the decision-making behavior of COVIDNet-CT, and in doing so ensure that COVIDNet-CT makes predictions based on relevant indicators in CT images. Both COVIDNet-CT and the COVIDx-CT dataset are available to the general public in an open-source and open access manner as part of the COVID-Net initiative. While COVIDNet-CT is not yet a production-ready screening solution, we hope that releasing the model and dataset will encourage researchers, clinicians, and citizen data scientists alike to leverage and build upon them.",298,COVID-19;COVID-19 Pandemic;Infections,71.0,Front Med (Lausanne),Health Care;Research Personnel;Polymerase Chain Reaction,4.860507664652778e-06,93.06399999999972,5.866539138735989e-06,251.0,0.0,External,2. Detection/Diagnosis,CT
33440674,10.3390/s21020455,Yes,PMC7828058,33440674.0,2021,2021-01-15,Journal Article,Peer reviewed (PubMed),1,explainable covid-19 detection using chest ct scans and deep learning,"This paper explores how well deep learning models trained on chest CT images can diagnose COVID-19 infected people in a fast and automated process. To this end, we adopted advanced deep network architectures and proposed a transfer learning strategy using custom-sized input tailored for each deep architecture to achieve the best performance. We conducted extensive sets of experiments on two CT image datasets, namely, the SARS-CoV-2 CT-scan and the COVID19-CT. The results show superior performances for our models compared with previous studies. Our best models achieved average accuracy, precision, sensitivity, specificity, and F1-score values of 99.4%, 99.6%, 99.8%, 99.6%, and 99.4% on the SARS-CoV-2 dataset, and 92.9%, 91.3%, 93.7%, 92.2%, and 92.5% on the COVID19-CT dataset, respectively. For better interpretability of the results, we applied visualization techniques to provide visual explanations for the models' predictions. Feature visualizations of the learned features show well-separated clusters representing CT images of COVID-19 and non-COVID-19 cases. Moreover, the visualizations indicate that our models are not only capable of identifying COVID-19 cases but also provide accurate localization of the COVID-19-associated regions, as indicated by well-trained radiologists.",181,COVID-19,63.0,Sensors (Basel),Transfer Learning;Algorithms;Architecture;Sensitivity and Specificity;Neural Networks;Tomography,5.043219248603715e-06,201.5999999999991,9.6408416561156e-06,468.0,0.0,External,2. Detection/Diagnosis,CT
33446781,10.1038/s41598-020-80936-4,Yes,PMC7809065,33446781.0,2021,2021-01-16,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't;Research Support, U.S. Gov't, Non-P.H.S.",Peer reviewed (PubMed),1,ct image segmentation for inflamed and fibrotic lungs using a multi-resolution convolutional neural network,"The purpose of this study was to develop a fully-automated segmentation algorithm, robust to various density enhancing lung abnormalities, to facilitate rapid quantitative analysis of computed tomography images. A polymorphic training approach is proposed, in which both specifically labeled left and right lungs of humans with COPD, and nonspecifically labeled lungs of animals with acute lung injury, were incorporated into training a single neural network. The resulting network is intended for predicting left and right lung regions in humans with or without diffuse opacification and consolidation. Performance of the proposed lung segmentation algorithm was extensively evaluated on CT scans of subjects with COPD, confirmed COVID-19, lung cancer, and IPF, despite no labeled training data of the latter three diseases. Lobar segmentations were obtained using the left and right lung segmentation as input to the LobeNet algorithm. Regional lobar analysis was performed using hierarchical clustering to identify radiographic subtypes of COVID-19. The proposed lung segmentation algorithm was quantitatively evaluated using semi-automated and manually-corrected segmentations in 87 COVID-19 CT images, achieving an average symmetric surface distance of mm and Dice coefficient of. Hierarchical clustering identified four radiographical phenotypes of COVID-19 based on lobar fractions of consolidated and poorly aerated tissue. Lower left and lower right lobes were consistently more afflicted with poor aeration and consolidation. However, the most severe cases demonstrated involvement of all lobes. The polymorphic training approach was able to accurately segment COVID-19 cases with diffuse consolidation without requiring COVID-19 cases for training.",243,"Acute Lung Injury;COVID-19;Lung Cancer;Pulmonary Disease, Chronic Obstructive",22.0,Sci Rep,Fibrosis;Neural Networks;Other Topics;Chronic Disease;Cluster Analysis,1.330231547937184e-06,20.440000000000005,1.591848427219288e-06,45.0,0.0,External,Segmentation-only,CT
33449887,10.1109/JBHI.2021.3051470,Yes,,33449887.0,2021,2021-01-16,Journal Article,Peer reviewed (PubMed),1,distant domain transfer learning for medical imaging,"Medical image processing is one of the most important topics in the Internet of Medical Things (IoMT). Recently, deep learning methods have carried out state-of-the-art performances on medical imaging tasks. In this paper, we propose a novel transfer learning framework for medical image classification. Moreover, we apply our method COVID-19 diagnosis with lung Computed Tomography (CT) images. However, well-labeled training data sets cannot be easily accessed due to the disease's novelty and privacy policies. The proposed method has two components: reduced-size Unet Segmentation model and Distant Feature Fusion (DFF) classification model. This study is related to a not well-investigated but important transfer learning problem, termed Distant Domain Transfer Learning (DDTL). In this study, we develop a DDTL model for COVID-19 diagnosis using unlabeled Office-31, Caltech-256, and chest X-ray image data sets as the source data, and a small set of labeled COVID-19 lung CT as the target data. The main contributions of this study are: 1) the proposed method benefits from unlabeled data in distant domains which can be easily accessed, 2) it can effectively handle the distribution shift between the training data and the testing data, 3) it has achieved 96% classification accuracy, which is 13% higher classification accuracy than ""non-transfer"" algorithms, and 8% higher than existing transfer and distant transfer algorithms.",213,COVID-19,16.0,IEEE J Biomed Health Inform,Art;Transfer Learning;Algorithms;Lung;Image Processing;Tomography;Lung Diseases,1.6470740584398297e-06,22.680000000000003,1.5700020314956613e-06,57.0,0.0,External,Segmentation-only,CT
33518813,10.1016/j.patcog.2021.107826,Yes,PMC7833525,33518813.0,2021,2021-02-02,Journal Article,Peer reviewed (PubMed),1,momentum contrastive learning for few-shot covid-19 diagnosis from chest ct images,"The current pandemic, caused by the outbreak of a novel coronavirus (COVID-19) in December 2019, has led to a global emergency that has significantly impacted economies, healthcare systems and personal wellbeing all around the world. Controlling the rapidly evolving disease requires highly sensitive and specific diagnostics. While RT-PCR is the most commonly used, it can take up to eight hours, and requires significant effort from healthcare professionals. As such, there is a critical need for a quick and automatic diagnostic system. Diagnosis from chest CT images is a promising direction. However, current studies are limited by the lack of sufficient training samples, as acquiring annotated CT images is time-consuming. To this end, we propose a new deep learning algorithm for the automated diagnosis of COVID-19, which only requires a few samples for training. Specifically, we use contrastive learning to train an encoder which can capture expressive feature representations on large and publicly available lung datasets and adopt the prototypical network for classification. We validate the efficacy of the proposed model in comparison with other competing methods on two publicly available and annotated COVID-19 CT datasets. Our results demonstrate the superior performance of our model for the accurate diagnosis of COVID-19 based on chest CT images.",205,COVID-19,42.0,Pattern Recognit,Health Care;Disease Outbreaks;Polymerase Chain Reaction;Other Topics,1.8592899263054064e-06,41.88000000000003,2.9065417682602423e-06,89.0,0.0,External,2. Detection/Diagnosis,CT
33520007,10.1007/s12559-020-09785-7,Yes,PMC7829098,33520007.0,2021,2021-02-02,Journal Article,Peer reviewed (PubMed),1,automatic screening of covid-19 using an optimized generative adversarial network,"The quick spread of coronavirus disease (COVID-19) has resulted in a global pandemic and more than fifteen million confirmed cases. To battle this spread, clinical imaging techniques, for example, computed tomography (CT), can be utilized for diagnosis. Automatic identification software tools are essential for helping to screen COVID-19 using CT images. However, there are few datasets available, making it difficult to train deep learning (DL) networks. To address this issue, a generative adversarial network (GAN) is proposed in this work to generate more CT images. The Whale Optimization Algorithm (WOA) is used to optimize the hyperparameters of GAN's generator. The proposed method is tested and validated with different classification and meta-heuristics algorithms using the SARS-CoV-2 CT-Scan dataset, consisting of COVID-19 and non-COVID-19 images. The performance metrics of the proposed optimized model, including accuracy, sensitivity, specificity, F1-score, positive predictive value, and negative predictive value, as well as its confusion matrix and receiver operating characteristic (ROC) curves, indicate that it performs better than state-of-the-art methods. This proposed model will help in the automatic screening of COVID-19 patients and decrease the burden on medicinal services frameworks.",183,COVID-19;Confusion,27.0,Cognit Comput,Art;Algorithms;Tomography;ROC Curve,1.764332097718932e-06,36.68000000000003,2.584813866818012e-06,79.0,0.0,External,5. Post-hoc,CT
33527788,10.3346/jkms.2021.36.e46,Yes,PMC7850864,33527788.0,2021,2021-02-03,Journal Article,Peer reviewed (PubMed),1,quantitative assessment of chest ct patterns in covid-19 and bacterial pneumonia patients: a deep learning perspective,"It is difficult to distinguish subtle differences shown in computed tomography (CT) images of coronavirus disease 2019 (COVID-19) and bacterial pneumonia patients, which often leads to an inaccurate diagnosis. It is desirable to design and evaluate interpretable feature extraction techniques to describe the patient's condition. This is a retrospective cohort study of 170 confirmed patients with COVID-19 or bacterial pneumonia acquired at Yeungnam University Hospital in Daegu, Korea. The Lung and lesion regions were segmented to crop the lesion into 2D patches to train a classifier model that could differentiate between COVID-19 and bacterial pneumonia. The K-means algorithm was used to cluster deep features extracted by the trained model into 20 groups. Each lesion patch cluster was described by a characteristic imaging term for comparison. For each CT image containing multiple lesions, a histogram of lesion types was constructed using the cluster information. Finally, a Support Vector Machine classifier was trained with the histogram and radiomics features to distinguish diseases and severity. The 20 clusters constructed from 170 patients were reviewed based on common radiographic appearance types. Two clusters showed typical findings of COVID-19, with two other clusters showing typical findings related to bacterial pneumonia. Notably, there is one cluster that showed bilateral diffuse ground-glass opacities (GGOs) in the central and peripheral lungs and was considered to be a key factor for severity classification. The proposed method achieved an accuracy of 91.2% for classifying COVID-19 and bacterial pneumonia patients with 95% reported for severity classification. The CT quantitative parameters represented by the values of cluster 8 were correlated with existing laboratory data and clinical parameters. Deep chest CT analysis with constructed lesion clusters revealed well-known COVID-19 CT manifestations comparable to manual CT analysis. The constructed histogram features improved accuracy for both diseases and severity classification, and showed correlations with laboratory data and clinical parameters. The constructed histogram features can provide guidance for improved analysis and treatment of COVID-19.",318,"COVID-19;Pneumonia, Bacterial",11.0,J Korean Med Sci,Severity of Illness Index;Retrospective Studies;Support Vector Machine;Cluster Analysis,4.5117115974570335e-06,211.7199999999989,1.033014706946199e-05,471.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33560995,10.1109/JBHI.2021.3058293,Yes,PMC8545167,33560995.0,2021,2021-02-10,Journal Article,Peer reviewed (PubMed),1,multiscale attention guided network for covid-19 diagnosis using chest x-ray images,"Coronavirus disease 2019 (COVID-19) is one of the most destructive pandemic after millennium, forcing the world to tackle a health crisis. Automated lung infections classification using chest X-ray (CXR) images could strengthen diagnostic capability when handling COVID-19. However, classifying COVID-19 from pneumonia cases using CXR image is a difficult task because of shared spatial characteristics, high feature variation and contrast diversity between cases. Moreover, massive data collection is impractical for a newly emerged disease, which limited the performance of data thirsty deep learning models. To address these challenges, Multiscale Attention Guided deep network with Soft Distance regularization (MAG-SD) is proposed to automatically classify COVID-19 from pneumonia CXR images. In MAG-SD, MA-Net is used to produce prediction vector and attention from multiscale feature maps. To improve the robustness of trained model and relieve the shortage of training data, attention guided augmentations along with a soft distance regularization are posed, which aims at generating meaningful augmentations and reduce noise. Our multiscale attention model achieves better classification performance on our pneumonia CXR image dataset. Plentiful experiments are proposed for MAG-SD which demonstrates its unique advantage in pneumonia classification over cutting-edge models. The code is available at GitHub",194,COVID-19;Infections;Pneumonia,15.0,IEEE J Biomed Health Inform,Radiography;Health;Noise;Attention;Collection;Lung Diseases;Map,1.3841254008511438e-06,38.36000000000004,2.649629469572155e-06,81.0,0.0,External,2. Detection/Diagnosis,X-Ray
33571095,10.1109/TNNLS.2021.3054306,Yes,,33571095.0,2021,2021-02-12,Journal Article,Peer reviewed (PubMed),1,an uncertainty-aware transfer learning-based framework for covid-19 diagnosis,"The early and reliable detection of COVID-19 infected patients is essential to prevent and limit its outbreak. The PCR tests for COVID-19 detection are not available in many countries, and also, there are genuine concerns about their reliability and performance. Motivated by these shortcomings, this article proposes a deep uncertainty-aware transfer learning framework for COVID-19 detection using medical images. Four popular convolutional neural networks (CNNs), including VGG16, ResNet50, DenseNet121, and InceptionResNetV2, are first applied to extract deep features from chest X-ray and computed tomography (CT) images. Extracted features are then processed by different machine learning and statistical modeling techniques to identify COVID-19 cases. We also calculate and report the epistemic uncertainty of classification results to identify regions where the trained models are not confident about their decisions (out of distribution problem). Comprehensive simulation results for X-ray and CT image data sets indicate that linear support vector machine and neural network models achieve the best results as measured by accuracy, sensitivity, specificity, and AUC (ROC) curve. Also, it is found that predictive uncertainty estimates are much higher for CT images compared to X-ray images.",183,COVID-19,28.0,IEEE Trans Neural Netw Learn Syst,Reproducibility of Results;Transfer Learning;COVID-19 Testing;Neural Networks;Support Vector Machine;Radiography;Algorithms;Disease Outbreaks;Computer Simulation;Sensitivity and Specificity;Polymerase Chain Reaction;Tomography;ROC Curve;Area under Curve;Receiver Operating Characteristic,2.4434078435528613e-06,93.07999999999976,4.96085493585434e-06,205.0,0.0,External,2. Detection/Diagnosis,Multimodal
33603047,10.1038/s41598-021-83424-5,Yes,PMC7892869,33603047.0,2021,2021-02-20,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,assisting scalable diagnosis automatically via ct images in the combat against covid-19,"The pandemic of Coronavirus Disease 2019 (COVID-19) is causing enormous loss of life globally. Prompt case identification is critical. The reference method is the real-time reverse transcription PCR (RT-PCR) assay, whose limitations may curb its prompt large-scale application. COVID-19 manifests with chest computed tomography (CT) abnormalities, some even before the onset of symptoms. We tested the hypothesis that the application of deep learning (DL) to 3D CT images could help identify COVID-19 infections. Using data from 920 COVID-19 and 1,073 non-COVID-19 pneumonia patients, we developed a modified DenseNet-264 model, COVIDNet, to classify CT images to either class. When tested on an independent set of 233 COVID-19 and 289 non-COVID-19 pneumonia patients, COVIDNet achieved an accuracy rate of 94.3% and an AUC of 0.98. As of March 23, 2020, the COVIDNet system had been used 11,966 times with a sensitivity of 91.12% and a specificity of 88.50% in six hospitals with PCR confirmation. Application of DL to CT images may improve both efficiency and capacity of case detection and long-term surveillance.",170,COVID-19;Infections;Pneumonia,13.0,Sci Rep,Polymerase Chain Reaction;Other Topics;Retrospective Studies;Reverse Transcription,1.4295170491817463e-06,37.96000000000001,1.9987775266074703e-06,89.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33643491,10.1007/s13278-021-00731-5,Yes,PMC7903408,33643491.0,2021,2021-03-02,Journal Article,Peer reviewed (PubMed),1,synthesis of covid-19 chest x-rays using unpaired image-to-image translation,"Motivated by the lack of publicly available datasets of chest radiographs of positive patients with coronavirus disease 2019 (COVID-19), we build the first-of-its-kind open dataset of synthetic COVID-19 chest X-ray images of high fidelity using an unsupervised domain adaptation approach by leveraging class conditioning and adversarial training. Our contributions are twofold. First, we show considerable performance improvements on COVID-19 detection using various deep learning architectures when employing synthetic images as additional training set. Second, we show how our image synthesis method can serve as a data anonymization tool by achieving comparable detection performance when trained only on synthetic data. In addition, the proposed data generation framework offers a viable solution to the COVID-19 detection in particular, and to medical image classification tasks in general. Our publicly available benchmark dataset (GitHub) consists of 21,295 synthetic COVID-19 chest X-ray images. The insights gleaned from this dataset can be used for preventive actions in the fight against the COVID-19 pandemic.",157,COVID-19;COVID-19 Pandemic,13.0,Soc Netw Anal Min,X-Rays;Translations,1.3475543887142143e-06,24.600000000000016,1.8407648343556005e-06,55.0,0.0,External,5. Post-hoc,X-Ray
33649695,10.1007/s00521-020-05641-9,Yes,PMC7905772,33649695.0,2021,2021-03-03,Journal Article,Peer reviewed (PubMed),1,triage of potential covid-19 patients from chest x-ray images using hierarchical convolutional networks,"The current COVID-19 pandemic has motivated the researchers to use artificial intelligence techniques for a potential alternative to reverse transcription-polymerase chain reaction due to the limited scale of testing. The chest X-ray (CXR) is one of the alternatives to achieve fast diagnosis, but the unavailability of large-scale annotated data makes the clinical implementation of machine learning-based COVID detection difficult. Another issue is the usage of ImageNet pre-trained networks which does not extract reliable feature representations from medical images. In this paper, we propose the use of hierarchical convolutional network (HCN) architecture to naturally augment the data along with diversified features. The HCN uses the first convolution layer from COVIDNet followed by the convolutional layers from well-known pre-trained networks to extract the features. The use of the convolution layer from COVIDNet ensures the extraction of representations relevant to the CXR modality. We also propose the use of ECOC for encoding multiclass problems to binary classification for improving the recognition performance. Experimental results show that HCN architecture is capable of achieving better results in comparison with the existing studies. The proposed method can accurately triage potential COVID-19 patients through CXR images for sharing the testing load and increasing the testing capacity.",199,COVID-19;COVID-19 Pandemic,11.0,Neural Comput Appl,Research Personnel;Polymerase Chain Reaction;Reverse Transcription,1.592287456545964e-06,28.600000000000023,2.3399480382660626e-06,61.0,0.0,External,2. Detection/Diagnosis,X-Ray
33649704,10.1016/j.inffus.2021.02.013,Yes,PMC7904462,33649704.0,2021,2021-03-03,Journal Article,Peer reviewed (PubMed),1,covid-19 and non-covid-19 classification using multi-layers fusion from lung ultrasound images,"COVID-19 or related viral pandemics should be detected and managed without hesitation, since the virus spreads very rapidly. Often with insufficient human and electronic resources, patients need to be checked from stable patients using vital signs, radiographic photographs, or ultrasound images. Vital signs do not often offer the right outcome, and radiographic photos have a variety of other problems. Lung ultrasound (LUS) images can provide good screening without a lot of complications. This paper suggests a model of a convolutionary neural network (CNN) that has fewer learning parameters but can achieve strong accuracy. The model has five main blocks or layers of convolution connectors. A multi-layer fusion functionality of each block is proposed to improve the efficiency of the COVID-19 screening method utilizing the proposed model. Experiments are conducted using freely accessible LUS photographs and video datasets. The proposed fusion method has 92.5% precision, 91.8% accuracy, and 93.2% retrieval using the data collection. These efficiency metric levels are considerably higher than those used in any of the state-of-the-art CNN versions.",170,COVID-19,28.0,Inf Fusion,Art;Other Topics,1.1526108994332089e-06,9.84,9.59469876304506e-07,24.0,0.0,External,2. Detection/Diagnosis,Ultrasound
33662804,10.1016/j.cmpb.2021.106004,Yes,PMC7899930,33662804.0,2021,2021-03-05,Journal Article,Peer reviewed (PubMed),1,does non-covid-19 lung lesion help? investigating transferability in covid-19 ct image segmentation,"Coronavirus disease 2019 (COVID-19) is a highly contagious virus spreading all around the world. Deep learning has been adopted as an effective technique to aid COVID-19 detection and segmentation from computed tomography (CT) images. The major challenge lies in the inadequate public COVID-19 datasets. Recently, transfer learning has become a widely used technique that leverages the knowledge gained while solving one problem and applying it to a different but related problem. However, it remains unclear whether various non-COVID19 lung lesions could contribute to segmenting COVID-19 infection areas and how to better conduct this transfer procedure. This paper provides a way to understand the transferability of non-COVID19 lung lesions and a better strategy to train a robust deep learning model for COVID-19 infection segmentation. Based on a publicly available COVID-19 CT dataset and three public non-COVID19 datasets, we evaluate four transfer learning methods using 3D U-Net as a standard encoder-decoder method. i) We introduce the multi-task learning method to get a multi-lesion pre-trained model for COVID-19 infection. ii) We propose and compare four transfer learning strategies with various performance gains and training time costs. Our proposed Hybrid-encoder Learning strategy introduces a Dedicated-encoder and an Adapted-encoder to extract COVID-19 infection features and general lung lesion features, respectively. An attention-based Selective Fusion unit is designed for dynamic feature selection and aggregation. Experiments show that trained with limited data, proposed Hybrid-encoder strategy based on multi-lesion pre-trained model achieves a mean DSC, NSD, Sensitivity, F1-score, Accuracy and MCC of 0.704, 0.735, 0.682, 0.707, 0.994 and 0.716, respectively, with better genetalization and lower over-fitting risks for segmenting COVID-19 infection. The results reveal the benefits of transferring knowledge from non-COVID19 lung lesions, and learning from multiple lung lesion datasets can extract more general features, leading to accurate and robust pre-trained models. We further show the capability of the encoder to learn feature representations of lung lesions, which improves segmentation accuracy and facilitates training convergence. In addition, our proposed Hybrid-encoder learning method incorporates transferred lung lesion features from non-COVID19 datasets effectively and achieves significant improvement. These findings promote new insights into transfer learning for COVID-19 CT image segmentation, which can also be further generalized to other medical tasks.",360,COVID-19;Infections,19.0,Comput Methods Programs Biomed,Transfer Learning;Algorithms;Lung;Tomography,2.82315297023639e-06,82.11999999999996,5.302364919036313e-06,167.0,0.0,External,Segmentation-only,CT
33674378,10.1136/bmjopen-2020-045120,Yes,PMC7939003,33674378.0,2021,2021-03-07,Journal Article,Peer reviewed (PubMed),1,development of a convolutional neural network to differentiate among the etiology of similar appearing pathological b lines on lung ultrasound: a deep learning study,"Lung ultrasound (LUS) is a portable, low-cost respiratory imaging tool but is challenged by user dependence and lack of diagnostic specificity. It is unknown whether the advantages of LUS implementation could be paired with deep learning (DL) techniques to match or exceed human-level, diagnostic specificity among similar appearing, pathological LUS images. A convolutional neural network (CNN) was trained on LUS images with B lines of different aetiologies. CNN diagnostic performance, as validated using a 10% data holdback set, was compared with surveyed LUS-competent physicians. Two tertiary Canadian hospitals. 612 LUS videos (121 381 frames) of B lines from 243 distinct patients with either COVID-19 (COVID), non-COVID acute respiratory distress syndrome (NCOVID) or hydrostatic pulmonary edema (HPE). The trained CNN performance on the independent dataset showed an ability to discriminate between COVID (AUC 1.0), NCOVID (AUC 0.934) and HPE (AUC 1.0) pathologies. This was significantly better than physician ability (AUCs of 0.697, 0.704, 0.967 for the COVID, NCOVID and HPE classes, respectively), p<0.01. A DL model can distinguish similar appearing LUS pathology, including COVID-19, that cannot be distinguished by humans. The performance gap between humans and the model suggests that subvisible biomarkers within ultrasound images could exist and multicentre research is merited.",201,"COVID-19;Pulmonary Edema;Respiratory Distress Syndrome, Acute",23.0,BMJ Open,Neural Networks;Area under Curve,1.526627155094838e-06,29.96000000000001,1.767053490862832e-06,69.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
33684688,10.1016/j.compbiomed.2021.104296,Yes,PMC7914375,33684688.0,2021,2021-03-09,Journal Article,Peer reviewed (PubMed),1,an integrated autoencoder-based hybrid cnn-lstm model for covid-19 severity prediction from lung ultrasound,"The COVID-19 pandemic has become one of the biggest threats to the global healthcare system, creating an unprecedented condition worldwide. The necessity of rapid diagnosis calls for alternative methods to predict the condition of the patient, for which disease severity estimation on the basis of Lung Ultrasound (LUS) can be a safe, radiation-free, flexible, and favorable option. In this paper, a frame-based 4-score disease severity prediction architecture is proposed with the integration of deep convolutional and recurrent neural networks to consider both spatial and temporal features of the LUS frames. The proposed convolutional neural network (CNN) architecture implements an autoencoder network and separable convolutional branches fused with a modified DenseNet-201 network to build a vigorous, noise-free classification model. A five-fold cross-validation scheme is performed to affirm the efficacy of the proposed network. In-depth result analysis shows a promising improvement in the classification performance by introducing the Long Short-Term Memory (LSTM) layers after the proposed CNN architecture by an average of 7-12%, which is approximately 17% more than the traditional DenseNet architecture alone. From an extensive analysis, it is found that the proposed end-to-end scheme is very effective in detecting COVID-19 severity scores from LUS images.",195,COVID-19;COVID-19 Pandemic,19.0,Comput Biol Med,Health Care;Architecture;Noise;Radiation;Neural Networks;Health Care Systems;Other Topics,1.6128112184834022e-06,33.40000000000002,2.323223646644613e-06,75.0,0.0,External,3. Monitoring/Severity assessment,Ultrasound
33705321,10.1109/TCBB.2021.3065361,Yes,PMC8851430,33705321.0,2021,2021-03-12,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,deep learning enables accurate diagnosis of novel coronavirus (covid-19) with ct images,"A novel coronavirus (COVID-19) recently emerged as an acute respiratory syndrome, and has caused a pneumonia outbreak world-widely. As the COVID-19 continues to spread rapidly across the world, computed tomography (CT) has become essentially important for fast diagnoses. Thus, it is urgent to develop an accurate computer-aided method to assist clinicians to identify COVID-19-infected patients by CT images. Here, we have collected chest CT scans of 88 patients diagnosed with COVID-19 from hospitals of two provinces in China, 100 patients infected with bacteria pneumonia, and 86 healthy persons for comparison and modeling. Based on the data, a deep learning-based CT diagnosis system was developed to identify patients with COVID-19. The experimental results showed that our model could accurately discriminate the COVID-19 patients from the bacteria pneumonia patients with an AUC of 0.95, recall (sensitivity) of 0.96, and precision of 0.79. When integrating three types of CT images, our model achieved a recall of 0.93 with precision of 0.86 for discriminating COVID-19 patients from others. Moreover, our model could extract main lesion features, especially the ground-glass opacity (GGO), which are visually helpful for assisted diagnoses by doctors. An online server is available for online diagnoses with CT images by our server. Source codes and datasets are available at our GitHub (GitHub).",210,COVID-19;Pneumonia;Syndrome,265.0,IEEE/ACM Trans Comput Biol Bioinform,Disease Outbreaks;Area under Curve,2.996617253583268e-06,131.55999999999938,7.438455613036882e-06,279.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33706149,10.1016/j.ejmp.2021.02.023,Yes,,33706149.0,2021,2021-03-12,Journal Article,Peer reviewed (PubMed),1,automatic deep learning-based pleural effusion classification in lung ultrasound images for respiratory pathology diagnosis,"Lung ultrasound (LUS) imaging as a point-of-care diagnostic tool for lung pathologies has been proven superior to X-ray and comparable to CT, enabling earlier and more accurate diagnosis in real-time at the patient's bedside. The main limitation to widespread use is its dependence on the operator training and experience. COVID-19 lung ultrasound findings predominantly reflect a pneumonitis pattern, with pleural effusion being infrequent. However, pleural effusion is easy to detect and to quantify, therefore it was selected as the subject of this study, which aims to develop an automated system for the interpretation of LUS of pleural effusion. A LUS dataset was collected at the Royal Melbourne Hospital which consisted of 623 videos containing 99,209 2D ultrasound images of 70 patients using a phased array transducer. A standardized protocol was followed that involved scanning six anatomical regions providing complete coverage of the lungs for diagnosis of respiratory pathology. This protocol combined with a deep learning algorithm using a Spatial Transformer Network provides a basis for automatic pathology classification on an image-based level. In this work, the deep learning model was trained using supervised and weakly supervised approaches which used frame- and video-based ground truth labels respectively. The reference was expert clinician image interpretation. Both approaches show comparable accuracy scores on the test set of 92.4% and 91.1%, respectively, not statistically significantly different. However, the video-based labelling approach requires significantly less effort from clinical experts for ground truth labelling.",238,COVID-19;Pleural Effusion;Pneumonitis,12.0,Phys Med,Pleural Effusion;COVID-19 Testing;Ultrasonography;Other Topics,1.6930231154738525e-06,25.36000000000001,1.737269391823974e-06,58.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
33711739,10.1016/j.media.2021.101993,Yes,PMC8032481,33711739.0,2021,2021-03-13,Journal Article,Peer reviewed (PubMed),1,deep metric learning-based image retrieval system for chest radiograph and its clinical applications in covid-19,"In recent years, deep learning-based image analysis methods have been widely applied in computer-aided detection, diagnosis and prognosis, and has shown its value during the public health crisis of the novel coronavirus disease 2019 (COVID-19) pandemic. Chest radiograph (CXR) has been playing a crucial role in COVID-19 patient triaging, diagnosing and monitoring, particularly in the United States. Considering the mixed and unspecific signals in CXR, an image retrieval model of CXR that provides both similar images and associated clinical information can be more clinically meaningful than a direct image diagnostic model. In this work we develop a novel CXR image retrieval model based on deep metric learning. Unlike traditional diagnostic models which aim at learning the direct mapping from images to labels, the proposed model aims at learning the optimized embedding space of images, where images with the same labels and similar contents are pulled together. The proposed model utilizes multi-similarity loss with hard-mining sampling strategy and attention mechanism to learn the optimized embedding space, and provides similar images, the visualizations of disease-related attention maps and useful clinical information to assist clinical decisions. The model is trained and validated on an international multi-site COVID-19 dataset collected from 3 different sources. Experimental results of COVID-19 image retrieval and diagnosis tasks show that the proposed model can serve as a robust solution for CXR analysis and patient management for COVID-19. The model is also tested on its transferability on a different clinical decision support task for COVID-19, where the pre-trained model is applied to extract image features from a new dataset without any further training. The extracted features are then combined with COVID-19 patient's vitals, lab tests and medical histories to predict the possibility of airway intubation in 72 hours, which is strongly associated with patient prognosis, and is crucial for patient care and hospital resource planning. These results demonstrate our deep metric learning based image retrieval model is highly efficient in the CXR retrieval, diagnosis and prognosis, and thus has great clinical value for the treatment and management of COVID-19 patients.",340,COVID-19;COVID-19 Pandemic,11.0,Med Image Anal,Public Health;Health Care;Health;Map,1.5253858911340993e-06,46.00000000000004,3.2007901854661936e-06,94.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
33718884,10.1007/s42979-021-00496-w,Yes,PMC7944725,33718884.0,2021,2021-03-16,Journal Article,Peer reviewed (PubMed),1,identification of images of covid-19 from chest x-rays using deep learning: comparing cognex visionpro deep learning 10 software with open source convolutional neural networks,"The novel Coronavirus, COVID-19, pandemic is being considered the most crucial health calamity of the century. Many organizations have come together during this crisis and created various Deep Learning models for the effective diagnosis of COVID-19 from chest radiography images. For example, The University of Waterloo, along with Darwin AI-a start-up spin-off of this department, has designed the Deep Learning model 'COVID-Net' and created a dataset called 'COVIDx' consisting of 13,975 images across 13,870 patient cases. In this study, COGNEX's Deep Learning Software, VisionPro Deep Learning, is used to classify these Chest X-rays from the COVIDx dataset. The results are compared with the results of COVID-Net and various other state-of-the-art Deep Learning models from the open-source community. Deep Learning tools are often referred to as black boxes because humans cannot interpret how or why a model is classifying an image into a particular class. This problem is addressed by testing VisionPro Deep Learning with two settings, first, by selecting the entire image as the Region of Interest (ROI), and second, by segmenting the lungs in the first step, and then doing the classification step on the segmented lungs only, instead of using the entire image. VisionPro Deep Learning results: on the entire image as the ROI it achieves an overall F score of 94.0%, and on the segmented lungs, it gets an F score of 95.3%, which is better than COVID-Net and other state-of-the-art open-source Deep Learning models.",238,COVID-19;COVID-19 Pandemic,11.0,SN Comput Sci,Black Americans;Art;Health;X-Rays;Dataset;Other Topics,1.4204301942413185e-06,30.360000000000024,2.0937111693834503e-06,69.0,0.0,External,2. Detection/Diagnosis,X-Ray
33729944,10.1109/TCBB.2021.3066331,Yes,PMC9647721,33729944.0,2021,2021-03-18,Journal Article,Peer reviewed (PubMed),1,soda: detecting covid-19 in chest x-rays with semi-supervised open set domain adaptation,"Due to the shortage of COVID-19 viral testing kits, radiology is used to complement the screening process. Deep learning methods are promising in automatically detecting COVID-19 disease in chest x-ray images. Most of these works first train a Convolutional Neural Network (CNN) on an existing large-scale chest x-ray image dataset and then fine-tune the model on the newly collected COVID-19 chest x-ray dataset, often at a much smaller scale. However, simple fine-tuning may lead to poor performance due to two issues, firstly the large domain shift present in chest x-ray datasets and secondly the relatively small scale of the COVID-19 chest x-ray dataset. In an attempt to address these issues, we formulate the problem of COVID-19 chest x-ray image classification in a semi-supervised open set domain adaptation setting and propose a novel domain adaptation method, Semi-supervised Open set Domain Adversarial network (SODA). SODA is designed to align the data distributions across different domains in the general domain space and also in the common subspace of source and target data. In our experiments, SODA achieves a leading classification performance compared with recent state-of-the-art models in separating COVID-19 with common pneumonia. We also present results showing that SODA produces better pathology localizations.",200,COVID-19;Pneumonia,9.0,IEEE/ACM Trans Comput Biol Bioinform,Art;Other Topics,1.3711893754864116e-06,30.520000000000024,2.3512711609144155e-06,65.0,0.0,External,2. Detection/Diagnosis,X-Ray
33732718,10.3389/fmed.2021.629134,Yes,PMC7956964,33732718.0,2021,2021-03-19,Journal Article,Peer reviewed (PubMed),1,the effectiveness of image augmentation in deep learning networks for detecting covid-19: a geometric transformation perspective,"Chest X-ray imaging technology used for the early detection and screening of COVID-19 pneumonia is both accessible worldwide and affordable compared to other non-invasive technologies. Additionally, deep learning methods have recently shown remarkable results in detecting COVID-19 on chest X-rays, making it a promising screening technology for COVID-19. Deep learning relies on a large amount of data to avoid overfitting. While overfitting can result in perfect modeling on the original training dataset, on a new testing dataset it can fail to achieve high accuracy. In the image processing field, an image augmentation step (i.e., adding more training data) is often used to reduce overfitting on the training dataset, and improve prediction accuracy on the testing dataset. In this paper, we examined the impact of geometric augmentations as implemented in several recent publications for detecting COVID-19. We compared the performance of 17 deep learning algorithms with and without different geometric augmentations. We empirically examined the influence of augmentation with respect to detection accuracy, dataset diversity, augmentation methodology, and network size. Contrary to expectation, our results show that the removal of recently used geometrical augmentation steps actually improved the Matthews correlation coefficient (MCC) of 17 models. The MCC without augmentation (MCC = 0.51) outperformed four recent geometrical augmentations (MCC = 0.47 for Data Augmentation 1, MCC = 0.44 for Data Augmentation 2, MCC = 0.48 for Data Augmentation 3, and MCC = 0.49 for Data Augmentation 4). When we retrained a recently published deep learning without augmentation on the same dataset, the detection accuracy significantly increased, with a χ McNema r ' s statistic 2 = 163. 2 and a p-value of 2.23 × 10-37. This is an interesting finding that may improve current deep learning algorithms using geometrical augmentations for detecting COVID-19. We also provide clinical perspectives on geometric augmentation to consider regarding the development of a robust COVID-19 X-ray-based detector.",310,COVID-19;Pneumonia,16.0,Front Med (Lausanne),Public Health;Algorithms;Transfer Learning,2.161455385994238e-06,23.68000000000001,2.085777957791416e-06,52.0,0.0,External,5. Post-hoc,X-Ray
33739635,10.3348/kjr.2020.1104,Yes,PMC8236359,33739635.0,2021,2021-03-20,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,machine learning-based prediction of covid-19 severity and progression to critical illness using ct imaging and clinical data,"To develop a machine learning (ML) pipeline based on radiomics to predict Coronavirus Disease 2019 (COVID-19) severity and the future deterioration to critical illness using CT and clinical variables. Clinical data were collected from 981 patients from a multi-institutional international cohort with real-time polymerase chain reaction-confirmed COVID-19. Radiomics features were extracted from chest CT of the patients. The data of the cohort were randomly divided into training, validation, and test sets using a 7:1:2 ratio. A ML pipeline consisting of a model to predict severity and time-to-event model to predict progression to critical illness were trained on radiomics features and clinical variables. The receiver operating characteristic AUC (ROC-AUC), concordance index (C-index), and time-dependent ROC-AUC were calculated to determine model performance, which was compared with consensus CT severity scores obtained by visual interpretation by radiologists. Among 981 patients with confirmed COVID-19, 274 patients developed critical illness. Radiomics features and clinical variables resulted in the best performance for the prediction of disease severity with a highest test ROC-AUC of 0.76 compared with 0.70 (0.76 vs. 0.70, p = 0.023) for visual CT severity score and clinical variables. The progression prediction model achieved a test C-index of 0.868 when it was based on the combination of CT radiomics and clinical variables compared with 0.767 when based on CT radiomics features alone (p < 0.001), 0.847 when based on clinical variables alone (p = 0.110), and 0.860 when based on the combination of visual CT severity scores and clinical variables (p = 0.549). Furthermore, the model based on the combination of CT radiomics and clinical variables achieved time-dependent ROC-AUCs of 0.897, 0.933, and 0.927 for the prediction of progression risks at 3, 5 and 7 days, respectively. CT radiomics features combined with clinical variables were predictive of COVID-19 severity and progression to critical illness with fairly high accuracy.",304,COVID-19;Critical Illness,14.0,Korean J Radiol,Severity of Illness Index;Polymerase Chain Reaction;Radiologists;Critical Illness;ROC Curve;Retrospective Studies;Area under Curve;Real-Time Polymerase Chain Reaction;Age;Receiver Operating Characteristic,2.566466644594123e-06,91.27999999999976,5.265615379740788e-06,196.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33743707,10.1186/s12938-021-00863-x,Yes,PMC7980736,33743707.0,2021,2021-03-22,Journal Article,Peer reviewed (PubMed),1,evaluation of lung involvement in covid-19 pneumonia based on ultrasound images,"Lung ultrasound (LUS) can be an important imaging tool for the diagnosis and assessment of lung involvement. Ultrasound sonograms have been confirmed to illustrate damage to a person's lungs, which means that the correct classification and scoring of a patient's sonogram can be used to assess lung involvement. The purpose of this study was to establish a lung involvement assessment model based on deep learning. A novel multimodal channel and receptive field attention network combined with ResNeXt (MCRFNet) was proposed to classify sonograms, and the network can automatically fuse shallow features and determine the importance of different channels and respective fields. Finally, sonogram classes were transformed into scores to evaluate lung involvement from the initial diagnosis to rehabilitation. Using multicenter and multimodal ultrasound data from 104 patients, the diagnostic model achieved 94.39% accuracy, 82.28% precision, 76.27% sensitivity, and 96.44% specificity. The lung involvement severity and the trend of COVID-19 pneumonia were evaluated quantitatively.",153,COVID-19;Pneumonia,4.0,Biomed Eng Online,Reproducibility of Results;Sensitivity and Specificity;Image Processing;Ultrasonography;Neural Networks,1.205685846316724e-06,19.24,1.2564762784553246e-06,45.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
33755565,10.1109/TUFFC.2021.3068190,Yes,,33755565.0,2021,2021-03-24,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,mini-covidnet: efficient lightweight deep neural network for ultrasound based point-of-care detection of covid-19,"Lung ultrasound (US) imaging has the potential to be an effective point-of-care test for detection of COVID-19, due to its ease of operation with minimal personal protection equipment along with easy disinfection. The current state-of-the-art deep learning models for detection of COVID-19 are heavy models that may not be easy to deploy in commonly utilized mobile platforms in point-of-care testing. In this work, we develop a lightweight mobile friendly efficient deep learning model for detection of COVID-19 using lung US images. Three different classes including COVID-19, pneumonia, and healthy were included in this task. The developed network, named as Mini-COVIDNet, was bench-marked with other lightweight neural network models along with state-of-the-art heavy model. It was shown that the proposed network can achieve the highest accuracy of 83.2% and requires a training time of only 24 min. The proposed Mini-COVIDNet has 4.39 times less number of parameters in the network compared to its next best performing network and requires a memory of only 51.29 MB, making the point-of-care detection of COVID-19 using lung US imaging plausible on a mobile platform. Deployment of these lightweight networks on embedded platforms shows that the proposed Mini-COVIDNet is highly versatile and provides optimal performance in terms of being accurate as well as having latency in the same order as other lightweight networks. The developed lightweight models are available at GitHub",225,COVID-19;Pneumonia,13.0,IEEE Trans Ultrason Ferroelectr Freq Control,Art;Point-of-Care Systems;COVID-19 Testing;Ultrasonography;Neural Networks;Other Topics,1.3448316215562015e-06,21.120000000000005,1.3570430779788255e-06,52.0,0.0,External,2. Detection/Diagnosis,Ultrasound
33769939,10.1109/JBHI.2021.3069169,Yes,PMC8545163,33769939.0,2021,2021-03-27,Journal Article,Peer reviewed (PubMed),1,covid-19 in cxr: from detection and severity scoring to patient disease monitoring,"This work estimates the severity of pneumonia in COVID-19 patients and reports the findings of a longitudinal study of disease progression. It presents a deep learning model for simultaneous detection and localization of pneumonia in chest Xray (CXR) images, which is shown to generalize to COVID-19 pneumonia. The localization maps are utilized to calculate a ""Pneumonia Ratio"" which indicates disease severity. The assessment of disease severity serves to build a temporal disease extent profile for hospitalized patients. To validate the model's applicability to the patient monitoring task, we developed a validation strategy which involves a synthesis of Digital Reconstructed Radiographs (DRRs - synthetic Xray) from serial CT scans; we then compared the disease progression profiles that were generated from the DRRs to those that were generated from CT volumes.",129,COVID-19;Disease Progression;Pneumonia,23.0,IEEE J Biomed Health Inform,Map;Cone-Beam Computed Tomography,1.162391364443714e-06,20.76,1.2962915229353365e-06,51.0,0.0,External,3. Monitoring/Severity assessment,X-Ray
33790965,10.1155/2021/6616069,Yes,PMC7962877,33790965.0,2021,2021-04-02,Journal Article,Peer reviewed (PubMed),1,different appearance of chest ct images of t2dm and ndm patients with covid-19 pneumonia based on an artificial intelligent quantitative method,"COVID-19 is a kind of pneumonia with new coronavirus infection, and the risk of death in COVID-19 patients with diabetes is four times higher than that in healthy people. It is unclear whether there is a difference in chest CT images between type 2 diabetes mellitus (T2DM) and non-diabetes mellitus (NDM) COVID-19 patients. The aim of this study was to investigate the differences in chest CT images between T2DM and NDM patients with COVID-19 based on a quantitative method of artificial intelligence. A total of 62 patients with COVID-19 pneumonia were retrospectively enrolled and divided into group A (T2DM COVID-19 pneumonia group, n = 15) and group B (NDM COVID-19 pneumonia group, n = 47). The clinical and laboratory examination information of the two groups was collected. Quantitative features (volume of consolidation shadows and ground glass shadows, proportion of consolidation shadow (or ground glass shadow) to lobe volume, total volume, total proportion, and number) of chest spiral CT images were extracted using Dr. Wise @Pneumonia software. The results showed that among the 26 CT image features, the total volume and proportion of bilateral pulmonary consolidation shadow in group A were larger than those in group B (P=0.031 and 0.019, respectively); there was no significant difference in the total volume and proportion of bilateral pulmonary ground glass density shadow between the two groups (P > 0.05). In group A, the blood glucose level was correlated with the volume of consolidation shadow and the proportion of consolidation shadow to right middle lobe volume, and higher than those patients in group B. In conclusion, the inflammatory exudation in the lung of COVID-19 patients with diabetes is more serious than that of patients without diabetes based on the quantitative method of artificial intelligence. Moreover, the blood glucose level is positively correlated with pulmonary inflammatory exudation in COVID-19 patients.",304,"COVID-19;Coronavirus Infections;Death;Diabetes Mellitus;Diabetes Mellitus, Type 2;Pneumonia",0.0,Int J Endocrinol,Other Topics,1.019159271954805e-06,11.64,9.887466863385024e-07,27.0,0.0,Self-recorded/clinical,5. Post-hoc,CT
33798078,10.1109/TUFFC.2021.3070696,Yes,PMC8864919,33798078.0,2021,2021-04-03,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,quantitative analysis and automated lung ultrasound scoring for evaluating covid-19 pneumonia with neural networks,"As being radiation-free, portable, and capable of repetitive use, ultrasonography is playing an important role in diagnosing and evaluating the COVID-19 Pneumonia (PN) in this epidemic. By virtue of lung ultrasound scores (LUSS), lung ultrasound (LUS) was used to estimate the excessive lung fluid that is an important clinical manifestation of COVID-19 PN, with high sensitivity and specificity. However, as a qualitative method, LUSS suffered from large interobserver variations and requirement for experienced clinicians. Considering this limitation, we developed a quantitative and automatic lung ultrasound scoring system for evaluating the COVID-19 PN. A total of 1527 ultrasound images prospectively collected from 31 COVID-19 PN patients with different clinical conditions were evaluated and scored with LUSS by experienced clinicians. All images were processed via a series of computer-aided analysis, including curve-to-linear conversion, pleural line detection, region-of-interest (ROI) selection, and feature extraction. A collection of 28 features extracted from the ROI was specifically defined for mimicking the LUSS. Multilayer fully connected neural networks, support vector machines, and decision trees were developed for scoring LUS images using the fivefold cross validation. The model with 128×256 two fully connected layers gave the best accuracy of 87%. It is concluded that the proposed method could assess the ultrasound images by assigning LUSS automatically with high accuracy, potentially applicable to the clinics.",216,COVID-19;Pneumonia,11.0,IEEE Trans Ultrason Ferroelectr Freq Control,Pneumonia;Sensitivity and Specificity;Ultrasonography;Neural Networks;Decision Trees;Age,1.272399676373475e-06,27.92000000000001,1.6252116458614532e-06,64.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
33799220,10.1016/j.compbiomed.2021.104319,Yes,PMC7946571,33799220.0,2021,2021-04-03,Journal Article,Peer reviewed (PubMed),1,exploring the effect of image enhancement techniques on covid-19 detection using chest x-ray images,"Computer-aided diagnosis for the reliable and fast detection of coronavirus disease (COVID-19) has become a necessity to prevent the spread of the virus during the pandemic to ease the burden on the healthcare system. Chest X-ray (CXR) imaging has several advantages over other imaging and detection techniques. Numerous works have been reported on COVID-19 detection from a smaller set of original X-ray images. However, the effect of image enhancement and lung segmentation of a large dataset in COVID-19 detection was not reported in the literature. We have compiled a large X-ray dataset (COVQU) consisting of 18,479 CXR images with 8851 normal, 6012 non-COVID lung infections, and 3616 COVID-19 CXR images and their corresponding ground truth lung masks. To the best of our knowledge, this is the largest public COVID positive database and the lung masks. Five different image enhancement techniques: histogram equalization (HE), contrast limited adaptive histogram equalization (CLAHE), image complement, gamma correction, and balance contrast enhancement technique (BCET) were used to investigate the effect of image enhancement techniques on COVID-19 detection. A novel U-Net model was proposed and compared with the standard U-Net model for lung segmentation. Six different pre-trained Convolutional Neural Networks (CNNs) (ResNet18, ResNet50, ResNet101, InceptionV3, DenseNet201, and ChexNet) and a shallow CNN model were investigated on the plain and segmented lung CXR images. The novel U-Net model showed an accuracy, Intersection over Union (IoU), and Dice coefficient of 98.63%, 94.3%, and 96.94%, respectively for lung segmentation. The gamma correction-based enhancement technique outperforms other techniques in detecting COVID-19 from the plain and the segmented lung CXR images. Classification performance from plain CXR images is slightly better than the segmented lung CXR images; however, the reliability of network performance is significantly improved for the segmented lung images, which was observed using the visualization technique. The accuracy, precision, sensitivity, F1-score, and specificity were 95.11%, 94.55%, 94.56%, 94.53%, and 95.59% respectively for the segmented lung images. The proposed approach with very reliable and comparable performance will boost the fast and robust COVID-19 detection using chest X-ray images.",337,COVID-19;Infections,143.0,Comput Biol Med,Coronavirus Infections;Health Care;Sensitivity and Specificity,3.351367001455905e-06,154.87999999999926,1.0540711183450708e-05,298.0,0.0,External,2. Detection/Diagnosis,X-Ray
33810066,10.3390/s21062215,Yes,PMC8004971,33810066.0,2021,2021-04-04,Journal Article,Peer reviewed (PubMed),1,a few-shot u-net deep learning model for covid-19 infected area segmentation in ct images,"Recent studies indicate that detecting radiographic patterns on CT chest scans can yield high sensitivity and specificity for COVID-19 identification. In this paper, we scrutinize the effectiveness of deep learning models for semantic segmentation of pneumonia-infected area segmentation in CT images for the detection of COVID-19. Traditional methods for CT scan segmentation exploit a supervised learning paradigm, so they require large volumes of data for their training, and assume fixed (static) network weights once the training procedure has been completed. Recently, to overcome these difficulties, few-shot learning (FSL) has been introduced as a general concept of network model training using a very small amount of samples. In this paper, we explore the efficacy of few-shot learning in U-Net architectures, allowing for a dynamic fine-tuning of the network weights as new few samples are being fed into the U-Net. Experimental results indicate improvement in the segmentation accuracy of identifying COVID-19 infected regions. In particular, using 4-fold cross-validation results of the different classifiers, we observed an improvement of 5.388 % for all test data regarding the IoU metric and a similar increment of 5.394 % for the F1 score. Moreover, the statistical significance of the improvement obtained using our proposed few-shot U-Net architecture compared with the traditional U-Net model was confirmed by applying the Kruskal-Wallis test (p-value = 0.026).",217,COVID-19;Pneumonia,38.0,Sensors (Basel),Semantics;Sensitivity and Specificity,1.9769933991523352e-06,46.28000000000004,3.123178340638242e-06,99.0,0.0,External,Segmentation-only,CT
33814763,10.4103/ijri.IJRI_965_20,Yes,PMC7996689,33814763.0,2021,2021-04-06,Journal Article,Peer reviewed (PubMed),1,the value of ai based ct severity scoring system in triage of patients with covid-19 pneumonia as regards oxygen requirement and place of admission,"CT scan is a quick and effective method to triage patients in the Covid-19 pandemic to prevent the heathcare facilities from getting overwhelmed. To find whether an initial HRCT chest can help triage patient by determining their oxygen requirement, place of treatment, laboratory parameters and risk of mortality and to compare 3 CT scoring systems (0-20, 0-25 and percentage of involved lung models) to find if one is a better predictor of prognosis than the other. This was a prospective observational study conducted at a Tertiary care hospital in Mumbai, Patients undergoing CT scan were included by complete enumeration method. Data collected included demographics, days from swab positivity to CT scan, comorbidities, place of treatment, laboratory parameters, oxygen requirement and mortality. We divided the patients into mild, moderate and severe based on 3 criteria - 20 point CT score (OS1), 25 point CT score (OS2) and opacity percentage (OP). CT scans were analysed using CT pneumonia analysis prototype software (Siemens Healthcare version 2.5.2, Erlangen, Germany). ROC curve and Youden's index were used to determine cut off points. Multinomial logistic regression used to study the relations with oxygen requirement and place of admission. Hosmer-Lemeshow test was done to test the goodness of fit of our models. A total of 740 patients were included in our study. All the 3 scoring systems showed a significant positive correlation with oxygen requirement, place of admission and death. Based on ROC analysis a score of 4 for OS1, 9 for OS2 and 12.7% for OP was determined as the cut off for oxygen requirement. CT severity scoring using an automated deep learning software programme is a boon for determining oxygen requirement and triage. As the score increases, the chances of requirement of higher oxygen and intubation increase. All the three scoring systems are predictive of oxygen requirement.",302,COVID-19;COVID-19 Pandemic;Death;Pneumonia,4.0,Indian J Radiol Imaging,Health Care;Logistic Regression;Other Topics;ROC Curve,1.2165164203689995e-06,18.48,1.248061353608678e-06,46.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
33816954,10.7717/peerj-cs.303,Yes,PMC7924532,33816954.0,2021,2021-04-06,Journal Article,Peer reviewed (PubMed),1,a multi-task pipeline with specialized streams for classification and segmentation of infection manifestations in covid-19 scans,"We are concerned with the challenge of coronavirus disease (COVID-19) detection in chest X-ray and Computed Tomography (CT) scans, and the classification and segmentation of related infection manifestations. Even though it is arguably not an established diagnostic tool, using machine learning-based analysis of COVID-19 medical scans has shown the potential to provide a preliminary digital second opinion. This can help in managing the current pandemic, and thus has been attracting significant research attention. In this research, we propose a multi-task pipeline that takes advantage of the growing advances in deep neural network models. In the first stage, we fine-tuned an Inception-v3 deep model for COVID-19 recognition using multi-modal learning, that is, using X-ray and CT scans. In addition to outperforming other deep models on the same task in the recent literature, with an attained accuracy of 99.4%, we also present comparative analysis for multi-modal learning against learning from X-ray scans alone. The second and the third stages of the proposed pipeline complement one another in dealing with different types of infection manifestations. The former features a convolutional neural network architecture for recognizing three types of manifestations, while the latter transfers learning from another knowledge domain, namely, pulmonary nodule segmentation in CT scans, to produce binary masks for segmenting the regions corresponding to these manifestations. Our proposed pipeline also features specialized streams in which multiple deep models are trained separately to segment specific types of infection manifestations, and we show the significant impact that this framework has on various performance metrics. We evaluate the proposed models on widely adopted datasets, and we demonstrate an increase of approximately 2.5% and 4.5% for dice coefficient and mean intersection-over-union (mIoU), respectively, while achieving 60% reduction in computational time, compared to the recent literature.",289,COVID-19;Infections,12.0,PeerJ Comput Sci,Coronavirus Infections;Transfer Learning;Architecture;Neural Networks;Tomography,2.176757454930048e-06,22.200000000000006,1.8805818078617635e-06,61.0,0.0,External,2. Detection/Diagnosis,Multimodal
33821166,10.1016/j.bspc.2021.102588,Yes,PMC8011666,33821166.0,2021,2021-04-07,Journal Article,Peer reviewed (PubMed),1,a fully automated deep learning-based network for detecting covid-19 from a new and large lung ct scan dataset,"This paper aims to propose a high-speed and accurate fully-automated method to detect COVID-19 from the patient's chest CT scan images. We introduce a new dataset that contains 48,260 CT scan images from 282 normal persons and 15,589 images from 95 patients with COVID-19 infections. At the first stage, this system runs our proposed image processing algorithm that analyzes the view of the lung to discard those CT images that inside the lung is not properly visible in them. This action helps to reduce the processing time and false detections. At the next stage, we introduce a novel architecture for improving the classification accuracy of convolutional networks on images containing small important objects. Our architecture applies a new feature pyramid network designed for classification problems to the ResNet50V2 model so the model becomes able to investigate different resolutions of the image and do not lose the data of small objects. As the infections of COVID-19 exist in various scales, especially many of them are tiny, using our method helps to increase the classification performance remarkably. After running these two phases, the system determines the condition of the patient using a selected threshold. We are the first to evaluate our system in two different ways on Xception, ResNet50V2, and our model. In the single image classification stage, our model achieved 98.49% accuracy on more than 7996 test images. At the patient condition identification phase, the system correctly identified almost 234 of 245 patients with high speed. Our dataset is accessible at GitHub",251,COVID-19;Infections,84.0,Biomed Signal Process Control,Other Topics,2.0069894348318804e-06,68.68000000000005,4.486045464560691e-06,143.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33824721,10.1007/s13755-021-00146-8,Yes,PMC8015934,33824721.0,2021,2021-04-08,Journal Article,Peer reviewed (PubMed),1,covid-19 infection map generation and detection from chest x-ray images,"Computer-aided diagnosis has become a necessity for accurate and immediate coronavirus disease 2019 (COVID-19) detection to aid treatment and prevent the spread of the virus. Numerous studies have proposed to use Deep Learning techniques for COVID-19 diagnosis. However, they have used very limited chest X-ray (CXR) image repositories for evaluation with a small number, a few hundreds, of COVID-19 samples. Moreover, these methods can neither localize nor grade the severity of COVID-19 infection. For this purpose, recent studies proposed to explore the activation maps of deep networks. However, they remain inaccurate for localizing the actual infestation making them unreliable for clinical use. This study proposes a novel method for the joint localization, severity grading, and detection of COVID-19 from CXR images by generating the so-called infection maps. To accomplish this, we have compiled the largest dataset with 119,316 CXR images including 2951 COVID-19 samples, where the annotation of the ground-truth segmentation masks is performed on CXRs by a novel collaborative human-machine approach. Furthermore, we publicly release the first CXR dataset with the ground-truth segmentation masks of the COVID-19 infected regions. A detailed set of experiments show that state-of-the-art segmentation networks can learn to localize COVID-19 infection with an F1-score of 83.20%, which is significantly superior to the activation maps created by the previous methods. Finally, the proposed approach achieved a COVID-19 detection performance with 94.96% sensitivity and 99.88% specificity.",229,COVID-19;Infections,29.0,Health Inf Sci Syst,Art;Specificity;Masks;Map,1.4106699491864074e-06,30.400000000000023,2.215110402436631e-06,66.0,0.0,External,2. Detection/Diagnosis,X-Ray
33842563,10.3389/fcvm.2021.638011,Yes,PMC8027078,33842563.0,2021,2021-04-13,Systematic Review,Peer reviewed (PubMed),1,application of machine learning in diagnosis of covid-19 through x-ray and ct images: a scoping review,"Coronavirus disease, first detected in late 2019 (COVID-19), has spread fast throughout the world, leading to high mortality. This condition can be diagnosed using RT-PCR technique on nasopharyngeal and throat swabs with sensitivity values ranging from 30 to 70%. However, chest CT scans and X-ray images have been reported to have sensitivity values of 98 and 69%, respectively. The application of machine learning methods on CT and X-ray images has facilitated the accurate diagnosis of COVID-19. In this study, we reviewed studies which used machine and deep learning methods on chest X-ray images and CT scans for COVID-19 diagnosis and compared their performance. The accuracy of these methods ranged from 76% to more than 99%, indicating the applicability of machine and deep learning methods in the clinical diagnosis of COVID-19.",130,COVID-19,31.0,Front Cardiovasc Med,Polymerase Chain Reaction;Other Topics,1.319274190536263e-06,24.36000000000001,1.938313730142031e-06,47.0,0.0,,Review,Multimodal
33872157,10.1109/TNNLS.2021.3070467,Yes,PMC8544941,33872157.0,2021,2021-04-20,Journal Article,Peer reviewed (PubMed),1,convolutional sparse support estimator-based covid-19 recognition from x-ray images,"Coronavirus disease (COVID-19) has been the main agenda of the whole world ever since it came into sight. X-ray imaging is a common and easily accessible tool that has great potential for COVID-19 diagnosis and prognosis. Deep learning techniques can generally provide state-of-the-art performance in many classification tasks when trained properly over large data sets. However, data scarcity can be a crucial obstacle when using them for COVID-19 detection. Alternative approaches such as representation-based classification might provide satisfactory performance with limited size data sets, but they generally fall short in performance or speed compared to the neural network (NN)-based methods. To address this deficiency, convolution support estimation network (CSEN) has recently been proposed as a bridge between representation-based and NN approaches by providing a noniterative real-time mapping from query sample to ideally SR coefficient support, which is critical information for class decision in representation-based techniques. The main premises of this study can be summarized as follows: 1) A benchmark X-ray data set, namely QaTa-Cov19, containing over 6200 X-ray images is created. The data set covering 462 X-ray images from COVID-19 patients along with three other classes; bacterial pneumonia, viral pneumonia, and normal. 2) The proposed CSEN-based classification scheme equipped with feature extraction from state-of-the-art deep NN solution for X-ray images, CheXNet, achieves over 98% sensitivity and over 95% specificity for COVID-19 recognition directly from raw X-ray images when the average performance of 5-fold cross validation over QaTa-Cov19 data set is calculated. 3) Having such an elegant COVID-19 assistive diagnosis performance, this study further provides evidence that COVID-19 induces a unique pattern in X-rays that can be discriminated with high accuracy.",270,"COVID-19;Pneumonia, Bacterial;Pneumonia, Viral",28.0,IEEE Trans Neural Netw Learn Syst,Art;Sensitivity and Specificity;Neural Networks;Tomography,1.5388879853579129e-06,54.360000000000056,3.741865505550872e-06,111.0,0.0,External,2. Detection/Diagnosis,X-Ray
33883609,10.1038/s41598-021-87994-2,Yes,PMC8060427,33883609.0,2021,2021-04-23,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,randgan: randomized generative adversarial network for detection of covid-19 in chest x-ray,"COVID-19 spread across the globe at an immense rate and has left healthcare systems incapacitated to diagnose and test patients at the needed rate. Studies have shown promising results for detection of COVID-19 from viral bacterial pneumonia in chest X-rays. Automation of COVID-19 testing using medical images can speed up the testing process of patients where health care systems lack sufficient numbers of the reverse-transcription polymerase chain reaction tests. Supervised deep learning models such as convolutional neural networks need enough labeled data for all classes to correctly learn the task of detection. Gathering labeled data is a cumbersome task and requires time and resources which could further strain health care systems and radiologists at the early stages of a pandemic such as COVID-19. In this study, we propose a randomized generative adversarial network (RANDGAN) that detects images of an unknown class (COVID-19) from known and labelled classes (Normal and Viral Pneumonia) without the need for labels and training data from the unknown class of images (COVID-19). We used the largest publicly available COVID-19 chest X-ray dataset, COVIDx, which is comprised of Normal, Pneumonia, and COVID-19 images from multiple public databases. In this work, we use transfer learning to segment the lungs in the COVIDx dataset. Next, we show why segmentation of the region of interest (lungs) is vital to correctly learn the task of classification, specifically in datasets that contain images from different resources as it is the case for the COVIDx dataset. Finally, we show improved results in detection of COVID-19 cases using our generative model (RANDGAN) compared to conventional generative adversarial networks for anomaly detection in medical images, improving the AUC from 0.71 to 0.77.",277,"COVID-19;Pneumonia;Pneumonia, Bacterial;Pneumonia, Viral;Strains",18.0,Sci Rep,Radiography;Health Care;Transfer Learning;COVID-19 Testing;Lung;Polymerase Chain Reaction;Health Care Systems;ROC Curve;Reverse Transcription,2.397801370073215e-06,66.08000000000003,3.816217498841827e-06,150.0,0.0,External,2. Detection/Diagnosis,X-Ray
33888856,10.1038/s41746-021-00446-z,Yes,PMC8062628,33888856.0,2021,2021-04-24,Journal Article,Peer reviewed (PubMed),1,ai-based analysis of ct images for rapid triage of covid-19 patients,"The COVID-19 pandemic overwhelms the medical resources in the stressed intensive care unit (ICU) capacity and the shortage of mechanical ventilation (MV). We performed CT-based analysis combined with electronic health records and clinical laboratory results on Cohort 1 (n = 1662 from 17 hospitals) with prognostic estimation for the rapid stratification of PCR confirmed COVID-19 patients. These models, validated on Cohort 2 (n = 700) and Cohort 3 (n = 662) constructed from nine external hospitals, achieved satisfying performance for predicting ICU, MV, and death of COVID-19 patients (AUROC 0.916, 0.919, and 0.853), even on events happened two days later after admission (AUROC 0.919, 0.943, and 0.856). Both clinical and image features showed complementary roles in prediction and provided accurate estimates to the time of progression (p < 0.001). Our findings are valuable for optimizing the use of medical resources in the COVID-19 pandemic. The models are available here: GitHub .",151,COVID-19;COVID-19 Pandemic;Death,11.0,NPJ Digit Med,Health Care;Polymerase Chain Reaction;Other Topics,1.1021066966785068e-06,9.72,9.80812863535829e-07,23.0,0.0,External,4. Prognosis/Treatment,CT
33907522,10.7150/ijbs.58855,Yes,PMC8071762,33907522.0,2021,2021-04-29,"Journal Article;Research Support, Non-U.S. Gov't;Review",Peer reviewed (PubMed),1,artificial intelligence in the diagnosis of covid-19: challenges and perspectives,"Artificial intelligence (AI) is being used to aid in various aspects of the COVID-19 crisis, including epidemiology, molecular research and drug development, medical diagnosis and treatment, and socioeconomics. The association of AI and COVID-19 can accelerate to rapidly diagnose positive patients. To learn the dynamics of a pandemic with relevance to AI, we search the literature using the different academic databases (PubMed, PubMed Central, Scopus, Google Scholar) and preprint servers (bioRxiv, medRxiv, arXiv). In the present review, we address the clinical applications of machine learning and deep learning, including clinical characteristics, electronic medical records, medical images (CT, X-ray, ultrasound images, etc.) in the COVID-19 diagnosis. The current challenges and future perspectives provided in this review can be used to direct an ideal deployment of AI technology in a pandemic.",129,COVID-19,24.0,Int J Biol Sci,COVID-19 Testing;Other Topics,3.539634048867655e-06,132.19999999999936,6.583126544699655e-06,299.0,0.0,,Review,Multimodal
33913299,10.7507/1001-5515.202008032,Yes,,33913299.0,2021,2021-04-30,Journal Article;Review,Peer reviewed (PubMed),1,research progress in lung parenchyma segmentation based on computed tomography,"Lung diseases such as lung cancer and COVID-19 seriously endanger human health and life safety, so early screening and diagnosis are particularly important. computed tomography (CT) technology is one of the important ways to screen lung diseases, among which lung parenchyma segmentation based on CT images is the key step in screening lung diseases, and high-quality lung parenchyma segmentation can effectively improve the level of early diagnosis and treatment of lung diseases. Automatic, fast and accurate segmentation of lung parenchyma based on CT images can effectively compensate for the shortcomings of low efficiency and strong subjectivity of manual segmentation, and has become one of the research hotspots in this field. In this paper, the research progress in lung parenchyma segmentation is reviewed based on the related literatures published at domestic and abroad in recent years. The traditional machine learning methods and deep learning methods are compared and analyzed, and the research progress of improving the network structure of deep learning model is emphatically introduced. Some unsolved problems in lung parenchyma segmentation were discussed, and the development prospect was prospected, providing reference for researchers in related fields.",186,COVID-19;Lung Cancer;Lung Diseases,1.0,Sheng Wu Yi Xue Gong Cheng Xue Za Zhi,Other Topics,1.1595961395946338e-06,10.8,9.1952548309968e-07,28.0,0.0,,Review,CT
33928256,10.1148/ryai.2020200079,Yes,PMC7392327,33928256.0,2021,2021-05-01,Journal Article,Peer reviewed (PubMed),1,automated assessment and tracking of covid-19 pulmonary disease severity on chest radiographs using convolutional siamese neural networks,"To develop an automated measure of COVID-19 pulmonary disease severity on chest radiographs (CXRs), for longitudinal disease tracking and outcome prediction. A convolutional Siamese neural network-based algorithm was trained to output a measure of pulmonary disease severity on CXRs (pulmonary x-ray severity (PXS) score), using weakly-supervised pretraining on approx. 160,000 anterior-posterior images from CheXpert and transfer learning on 314 frontal CXRs from COVID-19 patients. The algorithm was evaluated on internal and external test sets from different hospitals (154 and 113 CXRs respectively). PXS scores were correlated with radiographic severity scores independently assigned by two thoracic radiologists and one in-training radiologist (Pearson r). For 92 internal test set patients with follow-up CXRs, PXS score change was compared to radiologist assessments of change (Spearman ρ). The association between PXS score and subsequent intubation or death was assessed. Bootstrap 95% confidence intervals were calculated. PXS scores correlated with radiographic pulmonary disease severity scores assigned to CXRs in the internal and external test sets and r=0.86 respectively). The direction of change in PXS score in follow-up CXRs agreed with radiologist assessment ). In patients not intubated on the admission CXR, the PXS score predicted subsequent intubation or death within three days of hospital admission ). A Siamese neural network-based severity score automatically measures radiographic COVID-19 pulmonary disease severity, which can be used to track disease change and predict subsequent intubation or death.",228,COVID-19;Death;Lung Diseases,67.0,Radiol Artif Intell,Transfer Learning;Algorithms;Lung;Receiver Operating Characteristic,2.699102890583264e-06,35.88000000000002,2.6480519906248247e-06,91.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,X-Ray
33932183,10.1007/s00259-021-05375-3,Yes,PMC8087891,33932183.0,2021,2021-05-02,Journal Article;Review,Peer reviewed (PubMed),1,a comprehensive review of imaging findings in covid-19 - status in early 2021,"Medical imaging methods are assuming a greater role in the workup of patients with COVID-19, mainly in relation to the primary manifestation of pulmonary disease and the tissue distribution of the angiotensin-converting-enzyme 2 (ACE 2) receptor. However, the field is so new that no consensus view has emerged guiding clinical decisions to employ imaging procedures such as radiography, computer tomography (CT), positron emission tomography (PET), and magnetic resonance imaging, and in what measure the risk of exposure of staff to possible infection could be justified by the knowledge gained. The insensitivity of current RT-PCR methods for positive diagnosis is part of the rationale for resorting to imaging procedures. While CT is more sensitive than genetic testing in hospitalized patients, positive findings of ground glass opacities depend on the disease stage. There is sparse reporting on PET/CT with -FDG in COVID-19, but available results are congruent with the earlier literature on viral pneumonias. There is a high incidence of cerebral findings in COVID-19, and likewise evidence of gastrointestinal involvement. Artificial intelligence, notably machine learning is emerging as an effective method for diagnostic image analysis, with performance in the discriminative diagnosis of diagnosis of COVID-19 pneumonia comparable to that of human practitioners.",200,"COVID-19;Infections;Lung Diseases;Pneumonia;Pneumonia, Viral",20.0,Eur J Nucl Med Mol Imaging,Radiography;Angiotensin-Converting Enzyme 2;Magnetic Resonance Imaging;Pneumonia;COVID-19 Testing;Lung;Polymerase Chain Reaction;Other Topics;Review,1.0947672807063448e-06,16.72,1.3242852198801511e-06,36.0,0.0,,Review,Multimodal
33932751,10.1016/j.media.2021.102054,Yes,PMC8015379,33932751.0,2021,2021-05-02,Journal Article,Peer reviewed (PubMed),1,ct-based covid-19 triage: deep multitask learning improves joint identification and severity quantification,"The current COVID-19 pandemic overloads healthcare systems, including radiology departments. Though several deep learning approaches were developed to assist in CT analysis, nobody considered study triage directly as a computer science problem. We describe two basic setups: Identification of COVID-19 to prioritize studies of potentially infected patients to isolate them as early as possible; Severity quantification to highlight patients with severe COVID-19, thus direct them to a hospital or provide emergency medical care. We formalize these tasks as binary classification and estimation of affected lung percentage. Though similar problems were well-studied separately, we show that existing methods could provide reasonable quality only for one of these setups. We employ a multitask approach to consolidate both triage approaches and propose a convolutional neural network to leverage all available labels within a single model. In contrast with the related multitask approaches, we show the benefit from applying the classification layers to the most spatially detailed feature map at the upper part of U-Net instead of the less detailed latent representation at the bottom. We train our model on approximately 1500 publicly available CT studies and test it on the holdout dataset that consists of 123 chest CT studies of patients drawn from the same healthcare system, specifically 32 COVID-19 and 30 bacterial pneumonia cases, 30 cases with cancerous nodules, and 31 healthy controls. The proposed multitask model outperforms the other approaches and achieves ROC AUC scores of 0.87 vs. bacterial pneumonia, 0.93 vs. cancerous nodules, and 0.97 vs. healthy controls in Identification of COVID-19, and achieves 0.97 Spearman Correlation in Severity quantification. We have released our code and shared the annotated lesions masks for 32 CT images of patients with COVID-19 from the test dataset.",283,"COVID-19;COVID-19 Pandemic;Pneumonia, Bacterial",26.0,Med Image Anal,Health Care;Health;Area under Curve;Map,1.4271136656044156e-06,37.64000000000003,2.555050399346768e-06,81.0,0.0,External,3. Monitoring/Severity assessment,CT
33934177,10.1007/s00330-021-07937-3,Yes,PMC8088310,33934177.0,2021,2021-05-03,Journal Article;Multicenter Study,Peer reviewed (PubMed),1,machine learning automatically detects covid-19 using chest cts in a large multicenter cohort,"To investigate machine learning classifiers and interpretable models using chest CT for detection of COVID-19 and differentiation from other pneumonias, interstitial lung disease (ILD) and normal CTs. Our retrospective multi-institutional study obtained 2446 chest CTs from 16 institutions (including 1161 COVID-19 patients). Training/validation/testing cohorts included 1011/50/100 COVID-19, 388/16/33 ILD, 189/16/33 other pneumonias, and 559/17/34 normal (no pathologies) CTs. A metric-based approach for the classification of COVID-19 used interpretable features, relying on logistic regression and random forests. A deep learning-based classifier differentiated COVID-19 via 3D features extracted directly from CT attenuation and probability distribution of airspace opacities. Most discriminative features of COVID-19 are the percentage of airspace opacity and peripheral and basal predominant opacities, concordant with the typical characterization of COVID-19 in the literature. Unsupervised hierarchical clustering compares feature distribution across COVID-19 and control cohorts. The metrics-based classifier achieved AUC = 0.83, sensitivity = 0.74, and specificity = 0.79 versus respectively 0.93, 0.90, and 0.83 for the DL-based classifier. Most of ambiguity comes from non-COVID-19 pneumonia with manifestations that overlap with COVID-19, as well as mild COVID-19 cases. Non-COVID-19 classification performance is 91% for ILD, 64% for other pneumonias, and 94% for no pathologies, which demonstrates the robustness of our method against different compositions of control groups. Our new method accurately discriminates COVID-19 from other types of pneumonia, ILD, and CTs with no pathologies, using quantitative imaging features derived from chest CT, while balancing interpretability of results and classification performance and, therefore, may be useful to facilitate diagnosis of COVID-19. Unsupervised clustering reveals the key tomographic features including percent airspace opacity and peripheral and basal opacities most typical of COVID-19 relative to control groups. COVID-19-positive CTs were compared with COVID-19-negative chest CTs (including a balanced distribution of non-COVID-19 pneumonia, ILD, and no pathologies). Classification accuracies for COVID-19, pneumonia, ILD, and CT scans with no pathologies are respectively 90%, 64%, 91%, and 94%. Our deep learning (DL)-based classification method demonstrates an AUC of 0.93 (sensitivity 90%, specificity 83%). Machine learning methods applied to quantitative chest CT metrics can therefore improve diagnostic accuracy in suspected COVID-19, particularly in resource-constrained environments.",347,"COVID-19;Lung Diseases;Pneumonia;Pneumonia, Interstitial",14.0,Eur Radiol,Logistic Regression;Retrospective Studies;Area under Curve;Random Forest;Cluster Analysis,1.6341002980582136e-06,50.200000000000045,3.1578868087085243e-06,107.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33961635,10.1371/journal.pone.0250952,Yes,PMC8104381,33961635.0,2021,2021-05-08,Journal Article,Peer reviewed (PubMed),1,ai-corona: radiologist-assistant deep learning framework for covid-19 diagnosis in chest ct scans,"The development of medical assisting tools based on artificial intelligence advances is essential in the global fight against COVID-19 outbreak and the future of medical systems. In this study, we introduce ai-corona, a radiologist-assistant deep learning framework for COVID-19 infection diagnosis using chest CT scans. Our framework incorporates an EfficientNetB3-based feature extractor. We employed three datasets; the CC-CCII set, the MasihDaneshvari Hospital (MDH) cohort, and the MosMedData cohort. Overall, these datasets constitute 7184 scans from 5693 subjects and include the COVID-19, non-COVID abnormal (NCA), common pneumonia (CP), non-pneumonia, and Normal classes. We evaluate ai-corona on test sets from the CC-CCII set, MDH cohort, and the entirety of the MosMedData cohort, for which it gained AUC scores of 0.997, 0.989, and 0.954, respectively. Our results indicates ai-corona outperforms all the alternative models. Lastly, our framework's diagnosis capabilities were evaluated as assistant to several experts. Accordingly, We observed an increase in both speed and accuracy of expert diagnosis when incorporating ai-corona's assistance.",160,COVID-19;Infections;Pneumonia,23.0,PLoS One,Disease Outbreaks;Polymerase Chain Reaction;Radiologists;Other Topics;ROC Curve;Area under Curve,1.4690375186403008e-06,35.680000000000014,2.0941507006577e-06,82.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
33967366,10.1016/j.bbe.2021.04.006,Yes,PMC8084624,33967366.0,2021,2021-05-11,Journal Article,Peer reviewed (PubMed),1,automated detection of covid-19 from ct scans using convolutional neural networks,"Under the prevailing circumstances of the global pandemic of COVID-19, early diagnosis and accurate detection of COVID-19 through tests/screening and, subsequently, isolation of the infected people would be a proactive measure. Artificial intelligence (AI) based solutions, using Convolutional Neural Network (CNN) and exploiting the Deep Learning model's diagnostic capabilities, have been studied in this paper. Transfer Learning approach, based on VGG16 and ResNet50 architectures, has been used to develop an algorithm to detect COVID-19 from CT scan images consisting of Healthy (Normal), COVID-19, and Pneumonia categories. This paper adopts data augmentation and fine-tuning techniques to improve and optimize the VGG16 and ResNet50 model. Further, stratified 5-fold cross-validation has been conducted to test the robustness and effectiveness of the model. The proposed model performs exceptionally well in case of binary classification (COVID-19 vs. Normal) with an average classification accuracy of more than 99% in both VGG16 and ResNet50 based models. In multiclass classification (COVID-19 vs. Normal vs. Pneumonia), the proposed model achieves an average classification accuracy of 86.74% and 88.52% using VGG16 and ResNet50 architectures as baseline, respectively. Experimental results show that the proposed model achieves superior performance and can be used for automated detection of COVID-19 from CT scans.",199,COVID-19;Pneumonia,18.0,Biocybern Biomed Eng,Algorithms;Transfer Learning;Architecture,2.223991656742149e-06,69.92000000000006,4.790677496018487e-06,140.0,0.0,External,2. Detection/Diagnosis,CT
33967406,10.1016/j.eswa.2021.115152,Yes,PMC8095015,33967406.0,2021,2021-05-11,Journal Article,Peer reviewed (PubMed),1,an integrated framework with machine learning and radiomics for accurate and rapid early diagnosis of covid-19 from chest x-ray,"The objective of the research article is to propose and validate a combination of machine learning and radiomics features to detect COVID-19 early and rapidly from chest X-ray (CXR) in presence of other viral/bacterial pneumonia and at different severity levels of diseases. It is vital to assess the performance of any diagnosis method on an independent data set and at very early stage of the disease when the disease severity of is very low. In such cases, most of the diagnosis methods fail. A total of 378 CXR images containing both normal lung and pneumonia (both COVID-19 and others lung conditions) were collected from publically available data set. 71 radiomics features for each lung segment were chosen from 100 extracted features based on Z-score heatmap and one way ANOVA test that can detect COVID-19. Three best performing classical machine learning algorithms during the training phase - 1) fine Gaussian support vector machine (SVM), 2) fine k-nearest neighbor (KNN) and 3) ensemble bagged model (EBM) trees were chosen for further evaluation on an independent test data set. The independent test data set consists of 115 COVID-19 CXR images collected from a local hospital and 100 CXR images collected from publically available data set containing normal lung and viral/bacterial pneumonia. Severity was scored between 0 to 4 by two experienced radiologists for each lung with pneumonia (both COVID-19 and non COVID-19) for the test data set. Ensemble Bagging Model Trees (EBM) with the selected radiomics features is the most suitable to distinguish between COVID-19 and other lung infections with an overall sensitivity of 87.8% and specificity of 97% (95.2% accuracy and 0.9228 AUC) and is robust across severity levels. The method also can detect COVID-19 from CXR when two experienced radiologists were unable to detect any abnormality in the lung CXR (represented by severity score of 0). Once the CXR is acquired and lung is segmented, it takes less than two minutes for extracting radiomics features and providing diagnosis result. Since the proposed method does not require any manual intervention (e.g., sample collection etc.), it can be straightway integrated with standard X-ray reporting system to be used as an efficient, cost-effective and rapid early diagnosis device.",364,"COVID-19;Infections;Pneumonia;Pneumonia, Bacterial",7.0,Expert Syst Appl,Other Topics,1.5547119414321472e-06,35.48000000000003,2.628807126284742e-06,75.0,0.0,External,2. Detection/Diagnosis,X-Ray
33967656,10.1016/j.inffus.2021.04.008,Yes,PMC8086233,33967656.0,2021,2021-05-11,Journal Article,Peer reviewed (PubMed),1,a critic evaluation of methods for covid-19 automatic detection from x-ray images,"In this paper, we compare and evaluate different testing protocols used for automatic COVID-19 diagnosis from X-Ray images in the recent literature. We show that similar results can be obtained using X-Ray images that do not contain most of the lungs. We are able to remove the lungs from the images by turning to black the center of the X-Ray scan and training our classifiers only on the outer part of the images. Hence, we deduce that several testing protocols for the recognition are not fair and that the neural networks are learning patterns in the dataset that are not correlated to the presence of COVID-19. Finally, we show that creating a fair testing protocol is a challenging task, and we provide a method to measure how fair a specific testing protocol is. In the future research we suggest to check the fairness of a testing protocol using our tools and we encourage researchers to look for better techniques than the ones that we propose.",165,COVID-19,63.0,Inf Fusion,Black Americans;Research Personnel;Techniques;X-Rays;Dataset;Paper,1.828427626122264e-06,46.68000000000002,2.9989569570367807e-06,107.0,0.0,External,2. Detection/Diagnosis,X-Ray
33969323,10.1016/j.patter.2021.100269,Yes,PMC8086827,33969323.0,2021,2021-05-11,Journal Article;Review,Peer reviewed (PubMed),1,on the role of artificial intelligence in medical imaging of covid-19,"Although a plethora of research articles on AI methods on COVID-19 medical imaging are published, their clinical value remains unclear. We conducted the largest systematic review of the literature addressing the utility of AI in imaging for COVID-19 patient care. By keyword searches on PubMed and preprint servers throughout 2020, we identified 463 manuscripts and performed a systematic meta-analysis to assess their technical merit and clinical relevance. Our analysis evidences a significant disparity between clinical and AI communities, in the focus on both imaging modalities (AI experts neglected CT and ultrasound, favoring X-ray) and performed tasks (71.9% of AI papers centered on diagnosis). The vast majority of manuscripts were found to be deficient regarding potential use in clinical practice, but 2.7% (n = 12) publications were assigned a high maturity level and are summarized in greater detail. We provide an itemized discussion of the challenges in developing clinically relevant AI solutions with recommendations and remedies.",155,COVID-19,18.0,Patterns (N Y),Public Health;Health Care;Publications;Systematic Review;Lung;Classification,1.3991462137740154e-06,23.92000000000001,1.676900253958886e-06,54.0,0.0,,Review,Multimodal
33972584,10.1038/s41598-021-88807-2,Yes,PMC8110795,33972584.0,2021,2021-05-12,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,covid-classifier: an automated machine learning model to assist in the diagnosis of covid-19 infection in chest x-ray images,"Chest-X ray (CXR) radiography can be used as a first-line triage process for non-COVID-19 patients with pneumonia. However, the similarity between features of CXR images of COVID-19 and pneumonia caused by other infections makes the differential diagnosis by radiologists challenging. We hypothesized that machine learning-based classifiers can reliably distinguish the CXR images of COVID-19 patients from other forms of pneumonia. We used a dimensionality reduction method to generate a set of optimal features of CXR images to build an efficient machine learning classifier that can distinguish COVID-19 cases from non-COVID-19 cases with high accuracy and sensitivity. By using global features of the whole CXR images, we successfully implemented our classifier using a relatively small dataset of CXR images. We propose that our COVID-Classifier can be used in conjunction with other tests for optimal allocation of hospital resources by rapid triage of non-COVID-19 cases.",143,COVID-19;Infections;Pneumonia,56.0,Sci Rep,Reproducibility of Results;ROC Curve,1.730813245697776e-06,49.52000000000002,2.9113755771059693e-06,112.0,0.0,External,2. Detection/Diagnosis,X-Ray
33977119,10.1016/j.imu.2021.100591,Yes,PMC8099790,33977119.0,2021,2021-05-13,Journal Article;Review,Peer reviewed (PubMed),1,the diagnostic accuracy of artificial intelligence-assisted ct imaging in covid-19 disease: a systematic review and meta-analysis,"Artificial intelligence (AI) systems have become critical in support of decision-making. This systematic review summarizes all the data currently available on the AI-assisted CT-Scan prediction accuracy for COVID-19. The ISI Web of Science, Cochrane Library, PubMed, Scopus, CINAHL, Science Direct, PROSPERO, and EMBASE were systematically searched. We used the revised Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) tool to assess all included studies' quality and potential bias. A hierarchical receiver-operating characteristic summary (HSROC) curve and a summary receiver operating characteristic (SROC) curve have been implemented. The AUC was computed to determine the diagnostic accuracy. Finally, 36 studies (a total of 39,246 image data) were selected for inclusion into the final meta-analysis. The pooled sensitivity for AI was 0.90, specificity was 0.91 and the AUC was 0.96. For deep learning (DL) method, the pooled sensitivity was 0.90, specificity was 0.88 and the AUC was 0.96. In case of machine learning (ML), the pooled sensitivity was 0.90, specificity was 0.95 and the AUC was 0.97. AI in COVID-19 patients is useful in identifying symptoms of lung involvement. More prospective real-time trials are required to confirm AI's role for high and quick COVID-19 diagnosis due to the possible selection bias and retrospective existence of currently available studies.",204,COVID-19,7.0,Inform Med Unlocked,Coronavirus Infections;Systematic Review;Lung;Tomography,1.2860554630545305e-06,18.68,1.589622234325813e-06,37.0,0.0,,Review,CT
33980980,10.1038/s41746-021-00453-0,Yes,PMC8115328,33980980.0,2021,2021-05-14,Journal Article,Peer reviewed (PubMed),1,an artificial intelligence system for predicting the deterioration of covid-19 patients in the emergency department,"During the coronavirus disease 2019 (COVID-19) pandemic, rapid and accurate triage of patients at the emergency department is critical to inform decision-making. We propose a data-driven approach for automatic prediction of deterioration risk using a deep neural network that learns from chest X-ray images and a gradient boosting model that learns from routine clinical variables. Our AI prognosis system, trained using data from 3661 patients, achieves an AUC of 0.786 when predicting deterioration within 96 hours. The deep neural network extracts informative areas of chest X-ray images to assist clinicians in interpreting the predictions and performs comparably to two radiologists in a reader study. In order to verify performance in a real clinical setting, we silently deployed a preliminary version of the deep neural network at New York University Langone Health during the first wave of the pandemic, which produced accurate predictions in real-time. In summary, our findings demonstrate the potential of the proposed system for assisting front-line physicians in the triage of COVID-19 patients.",165,COVID-19;COVID-19 Pandemic,41.0,NPJ Digit Med,Other Topics,1.5029096254328797e-06,22.24000000000001,1.7459806605590286e-06,48.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,X-Ray
33997112,10.1109/tbdata.2020.3035935,Yes,PMC8117951,33997112.0,2021,2021-05-18,Journal Article,Peer reviewed (PubMed),1,covid-19-ct-cxr: a freely accessible and weakly labeled chest x-ray and ct image collection on covid-19 from biomedical literature,"The latest threat to global health is the COVID-19 outbreak. Although there exist large datasets of chest X-rays (CXR) and computed tomography (CT) scans, few COVID-19 image collections are currently available due to patient privacy. At the same time, there is a rapid growth of COVID-19-relevant articles in the biomedical literature, including those that report findings on radiographs. Here, we present COVID-19-CT-CXR, a public database of COVID-19 CXR and CT images, which are automatically extracted from COVID-19-relevant articles from the PubMed Central Open Access (PMC-OA) Subset. We extracted figures, associated captions, and relevant figure descriptions in the article and separated compound figures into subfigures. Because a large portion of figures in COVID-19 articles are not CXR or CT, we designed a deep-learning model to distinguish them from other figure types and to classify them accordingly. The final database includes 1,327 CT and 263 CXR images (as of May 9, 2020) with their relevant text. To demonstrate the utility of COVID-19-CT-CXR, we conducted four case studies. We show that COVID-19-CT-CXR, when used as additional training data, is able to contribute to improved deep-learning (DL) performance for the classification of COVID-19 and non-COVID-19 CT. We collected CT images of influenza, another common infectious respiratory illness that may present similarly to COVID-19, and fine-tuned a baseline deep neural network to distinguish a diagnosis of COVID-19, influenza, or normal or other types of diseases on CT. We fine-tuned an unsupervised one-class classifier from non-COVID-19 CXR and performed anomaly detection to detect COVID-19 CXR. From text-mined captions and figure descriptions, we compared 15 clinical symptoms and 20 clinical findings of COVID-19 versus those of influenza to demonstrate the disease differences in the scientific publications. Our database is unique, as the figures are retrieved along with relevant text with fine-grained descriptions, and it can be extended easily in the future. We believe that our work is complementary to existing resources and hope that it will contribute to medical image analysis of the COVID-19 pandemic. The dataset, code, and DL models are publicly available at GitHub",339,"COVID-19;COVID-19 Pandemic;Influenza, Human",18.0,IEEE Trans Big Data,Public Health;Disease Outbreaks,2.420792879922876e-06,46.55200000000004,3.817186604722665e-06,105.0,0.0,External,2. Detection/Diagnosis,CT
34038371,10.1109/TNNLS.2021.3082015,Yes,,34038371.0,2021,2021-05-27,Journal Article,Peer reviewed (PubMed),1,4s-dt: self-supervised super sample decomposition for transfer learning with application to covid-19 detection,"Due to the high availability of large-scale annotated image datasets, knowledge transfer from pretrained models showed outstanding performance in medical image classification. However, building a robust image classification model for datasets with data irregularity or imbalanced classes can be a very challenging task, especially in the medical imaging domain. In this article, we propose a novel deep convolutional neural network, which we called self-supervised super sample decomposition for transfer learning (4S-DT) model. The 4S-DT encourages a coarse-to-fine transfer learning from large-scale image recognition tasks to a specific chest X-ray image classification task using a generic self-supervised sample decomposition approach. Our main contribution is a novel self-supervised learning mechanism guided by a super sample decomposition of unlabeled chest X-ray images. 4S-DT helps in improving the robustness of knowledge transformation via a downstream learning strategy with a class-decomposition (CD) layer to simplify the local structure of the data. The 4S-DT can deal with any irregularities in the image dataset by investigating its class boundaries using a downstream CD mechanism. We used 50000 unlabeled chest X-ray images to achieve our coarse-to-fine transfer learning with an application to COVID-19 detection, as an exemplar. The 4S-DT has achieved a high accuracy of 99.8% on the larger of the two datasets used in the experimental study and an accuracy of 97.54% on the smaller dataset, which was enriched by augmented images, out of which all real COVID-19 cases were detected.",234,COVID-19,14.0,IEEE Trans Neural Netw Learn Syst,Reproducibility of Results;Algorithms;Transfer Learning;Neural Networks;Other Topics;ROC Curve,2.842540161592792e-06,58.840000000000046,4.098239662253239e-06,127.0,0.0,External,2. Detection/Diagnosis,X-Ray
34052882,10.1007/s00330-021-08050-1,Yes,PMC8164481,34052882.0,2021,2021-05-31,Journal Article,Peer reviewed (PubMed),1,covid-19 classification of x-ray images using deep neural networks,"In the midst of the coronavirus disease 2019 (COVID-19) outbreak, chest X-ray (CXR) imaging is playing an important role in diagnosis and monitoring of patients with COVID-19. We propose a deep learning model for detection of COVID-19 from CXRs, as well as a tool for retrieving similar patients according to the model's results on their CXRs. For training and evaluating our model, we collected CXRs from inpatients hospitalized in four different hospitals. In this retrospective study, 1384 frontal CXRs, of COVID-19 confirmed patients imaged between March and August 2020, and 1024 matching CXRs of non-COVID patients imaged before the pandemic, were collected and used to build a deep learning classifier for detecting patients positive for COVID-19. The classifier consists of an ensemble of pre-trained deep neural networks (DNNS), specifically, ReNet34, ReNet50¸ ReNet152, and vgg16, and is enhanced by data augmentation and lung segmentation. We further implemented a nearest-neighbors algorithm that uses DNN-based image embeddings to retrieve the images most similar to a given image. Our model achieved accuracy of 90.3%, specificity of 90%, and sensitivity of 90.5% on a test dataset comprising 15% of the original images. The AUC of the ROC curve is 0.96. We provide deep learning models, trained and evaluated on CXRs that can assist medical efforts and reduce medical staff workload in handling COVID-19. A machine learning model was able to detect chest X-ray (CXR) images of patients tested positive for COVID-19 with accuracy and detection rate above 90%. A tool was created for finding existing CXR images with imaging characteristics most similar to a given CXR, according to the model's image embeddings.",267,COVID-19,23.0,Eur Radiol,Medical Staff;Algorithms;Disease Outbreaks;Sensitivity and Specificity;Neural Networks;ROC Curve;Retrospective Studies;Lung Diseases;Area under Curve,2.5223122860601705e-06,104.43999999999971,7.022168834611531e-06,207.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
34056622,10.1007/s42979-021-00690-w,Yes,PMC8144280,34056622.0,2021,2021-06-01,Journal Article,Peer reviewed (PubMed),1,automated covid-19 detection from chest x-ray images: a high-resolution network (hrnet) approach,"The pandemic, originated by novel coronavirus 2019 (COVID-19), continuing its devastating effect on the health, well-being, and economy of the global population. A critical step to restrain this pandemic is the early detection of COVID-19 in the human body to constraint the exposure and control the spread of the virus. Chest X-Rays are one of the non-invasive tools to detect this disease as the manual PCR diagnosis process is quite tedious and time-consuming. Our intensive background studies show that, the works till now are not efficient to produce an unbiased detection result. In this work, we proposed an automated COVID-19 classification method, utilizing available COVID and non-COVID X-Ray datasets, along with High-Resolution Network (HRNet) for feature extraction embedding with the UNet for segmentation purposes. To evaluate the proposed method, several baseline experiments have been performed employing numerous deep learning architectures. With extensive experiment, we got a significant result of 99.26% accuracy, 98.53% sensitivity, and 98.82% specificity with HRNet which surpasses the performances of the existing models. Finally, we conclude that our proposed methodology ensures unbiased high accuracy, which increases the probability of incorporating X-Ray images into the diagnosis of the disease.",191,COVID-19,7.0,SN Comput Sci,Health Care;Sensitivity and Specificity;Polymerase Chain Reaction;Other Topics,1.0416137159340751e-06,10.2,9.536399377554318e-07,25.0,0.0,External,2. Detection/Diagnosis,X-Ray
34058647,10.1016/j.clinimag.2021.02.003,Yes,PMC7874917,34058647.0,2021,2021-06-01,Journal Article,Peer reviewed (PubMed),1,early prediction of severity in coronavirus disease (covid-19) using quantitative ct imaging,"To evaluate whether the extent of COVID-19 pneumonia on CT scans using quantitative CT imaging obtained early in the illness can predict its future severity. We conducted a retrospective single-center study on confirmed COVID-19 patients between January 18, 2020 and March 5, 2020. A quantitative AI algorithm was used to evaluate each patient's CT scan to determine the proportion of the lungs with pneumonia (VR) and the rate of change (RAR) in VR from scan to scan. Patients were classified as being in the severe or non-severe group based on their final symptoms. Penalized B-splines regression modeling was used to examine the relationship between mean VR and days from onset of symptoms in the two groups, with 95% and 99% confidence intervals. Median VR max was 18.6% (IQR 9.1-32.7%) in 21 patients in the severe group, significantly higher (P < 0.0001) than in the 53 patients in non-severe group (1.8% (IQR 0.4-5.7%)). RAR was increasing with a median RAR of 2.1% (IQR 0.4-5.5%) in severe and 0.4% (IQR 0.1-0.9%) in non-severe group, which was significantly different (P < 0.0001). Penalized B-spline analyses showed positive relationships between VR and days from onset of symptom. The 95% confidence limits of the predicted means for the two groups diverged 5 days after the onset of initial symptoms with a threshold of 11.9%. Five days after the initial onset of symptoms, CT could predict the patients who later developed severe symptoms with 95% confidence.",240,COVID-19;Pneumonia,7.0,Clin Imaging,Other Topics;Retrospective Studies,1.0207817528197957e-06,14.759999999999998,1.221725586346427e-06,33.0,0.0,Self-recorded/clinical,1. Risk identification,CT
34069841,10.3390/diagnostics11050895,Yes,PMC8157360,34069841.0,2021,2021-06-03,Journal Article,Peer reviewed (PubMed),1,generation of synthetic chest x-ray images and detection of covid-19: a deep learning based approach,"COVID-19 is a disease caused by the SARS-CoV-2 virus. The COVID-19 virus spreads when a person comes into contact with an affected individual. This is mainly through drops of saliva or nasal discharge. Most of the affected people have mild symptoms while some people develop acute respiratory distress syndrome (ARDS), which damages organs like the lungs and heart. Chest X-rays (CXRs) have been widely used to identify abnormalities that help in detecting the COVID-19 virus. They have also been used as an initial screening procedure for individuals highly suspected of being infected. However, the availability of radiographic CXRs is still scarce. This can limit the performance of deep learning (DL) based approaches for COVID-19 detection. To overcome these limitations, in this work, we developed an Auxiliary Classifier Generative Adversarial Network (ACGAN), to generate CXRs. Each generated X-ray belongs to one of the two classes COVID-19 positive or normal. To ensure the goodness of the synthetic images, we performed some experimentation on the obtained images using the latest Convolutional Neural Networks (CNNs) to detect COVID-19 in the CXRs. We fine-tuned the models and achieved more than 98% accuracy. After that, we also performed feature selection using the Harmony Search (HS) algorithm, which reduces the number of features while retaining classification accuracy. We further release a GAN-generated dataset consisting of 500 COVID-19 radiographic images.",222,"COVID-19;Respiratory Distress Syndrome, Acute",21.0,Diagnostics (Basel),Other Topics,1.7510794112715933e-06,39.52000000000002,2.631546443528576e-06,88.0,0.0,External,5. Post-hoc,X-Ray
34075355,10.1007/s42979-021-00695-5,Yes,PMC8152712,34075355.0,2021,2021-06-03,Journal Article,Peer reviewed (PubMed),1,chest x-ray classification using deep learning for automated covid-19 screening,"In today's world, we find ourselves struggling to fight one of the worst pandemics in the history of humanity known as COVID-2019 caused by a coronavirus. When the virus reaches the lungs, we observe ground-glass opacity in the chest X-ray due to fibrosis in the lungs. Due to the significant differences between X-ray images of an infected and non-infected person, artificial intelligence techniques can be used to identify the presence and severity of the infection. We propose a classification model that can analyze the chest X-rays and help in the accurate diagnosis of COVID-19. Our methodology classifies the chest X-rays into four classes viz. normal, pneumonia, tuberculosis (TB), and COVID-19. Further, the X-rays indicating COVID-19 are classified on a severity-basis into mild, medium, and severe. The deep learning model used for the classification of pneumonia, TB, and normal is VGG-16 with a test accuracy of 95.9 %. For the segregation of normal pneumonia and COVID-19, the DenseNet-161 was used with a test accuracy of 98.9 %, whereas the ResNet-18 worked best for severity classification achieving a test accuracy up to 76 %. Our approach allows mass screening of the people using X-rays as a primary validation for COVID-19. The online version contains supplementary material available at 10.1007/s42979-021-00695-5.",207,COVID-19;Fibrosis;Infections;Pneumonia;Tuberculosis,25.0,SN Comput Sci,Tuberculosis;Fibrosis,1.3913886982532635e-06,40.36000000000004,2.926299283895486e-06,83.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
34101042,10.1007/s10916-021-01745-4,Yes,PMC8185498,34101042.0,2021,2021-06-09,Journal Article,Peer reviewed (PubMed),1,deep learning on chest x-ray images to detect and evaluate pneumonia cases at the era of covid-19,"Coronavirus disease 2019 (COVID-19) is an infectious disease with first symptoms similar to the flu. COVID-19 appeared first in China and very quickly spreads to the rest of the world, causing then the 2019-20 coronavirus pandemic. In many cases, this disease causes pneumonia. Since pulmonary infections can be observed through radiography images, this paper investigates deep learning methods for automatically analyzing query chest X-ray images with the hope to bring precision tools to health professionals towards screening the COVID-19 and diagnosing confirmed patients. In this context, training datasets, deep learning architectures and analysis strategies have been experimented from publicly open sets of chest X-ray images. Tailored deep learning models are proposed to detect pneumonia infection cases, notably viral cases. It is assumed that viral pneumonia cases detected during an epidemic COVID-19 context have a high probability to presume COVID-19 infections. Moreover, easy-to-apply health indicators are proposed for estimating infection status and predicting patient status from the detected pneumonia cases. Experimental results show possibilities of training deep learning models over publicly open sets of chest X-ray images towards screening viral pneumonia. Chest X-ray test images of COVID-19 infected patients are successfully diagnosed through detection models retained for their performances. The efficiency of proposed health indicators is highlighted through simulated scenarios of patients presenting infections and health problems by combining real and synthetic health data.",223,"COVID-19;Communicable Diseases;Infections;Pneumonia;Pneumonia, Viral",54.0,J Med Syst,Coronavirus Infections;Architecture;Neural Networks;Communicable Diseases,2.941040937008568e-06,165.91999999999908,1.0975269622901334e-05,326.0,0.0,External,2. Detection/Diagnosis,X-Ray
34103587,10.1038/s41598-021-91305-0,Yes,PMC8187631,34103587.0,2021,2021-06-10,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,early assessment of lung function in coronavirus patients using invariant markers from chest x-rays images,"The primary goal of this manuscript is to develop a computer assisted diagnostic (CAD) system to assess pulmonary function and risk of mortality in patients with coronavirus disease 2019 (COVID-19). The CAD system processes chest X-ray data and provides accurate, objective imaging markers to assist in the determination of patients with a higher risk of death and thus are more likely to require mechanical ventilation and/or more intensive clinical care.To obtain an accurate stochastic model that has the ability to detect the severity of lung infection, we develop a second-order Markov-Gibbs random field (MGRF) invariant under rigid transformation (translation or rotation of the image) as well as scale (i.e., pixel size). The parameters of the MGRF model are learned automatically, given a training set of X-ray images with affected lung regions labeled. An X-ray input to the system undergoes pre-processing to correct for non-uniformity of illumination and to delimit the boundary of the lung, using either a fully-automated segmentation routine or manual delineation provided by the radiologist, prior to the diagnosis. The steps of the proposed methodology are: estimate the Gibbs energy at several different radii to describe the inhomogeneity in lung infection; compute the cumulative distribution function (CDF) as a new representation to describe the local inhomogeneity in the infected region of lung; and input the CDFs to a new neural network-based fusion system to determine whether the severity of lung infection is low or high. This approach is tested on 200 clinical X-rays from 200 COVID-19 positive patients, 100 of whom died and 100 who recovered using multiple training/testing processes including leave-one-subject-out (LOSO), tenfold, fourfold, and twofold cross-validation tests. The Gibbs energy for lung pathology was estimated at three concentric rings of increasing radii. The accuracy and Dice similarity coefficient (DSC) of the system steadily improved as the radius increased. The overall CAD system combined the estimated Gibbs energy information from all radii and achieved a sensitivity, specificity, accuracy, and DSC of 100%, 97% %, 98% %, and 98% %, respectively, by twofold cross validation. Alternative classification algorithms, including support vector machine, random forest, naive Bayes classifier, K-nearest neighbors, and decision trees all produced inferior results compared to the proposed neural network used in this CAD system. The experiments demonstrate the feasibility of the proposed system as a novel tool to objectively assess disease severity and predict mortality in COVID-19 patients. The proposed tool can assist physicians to determine which patients might require more intensive clinical care, such a mechanical respiratory support.",414,COVID-19;Death;Infections,6.0,Sci Rep,X-Rays;Image Processing;Decision Trees;Translations;Rotation;Random Forest,1.8958047645396384e-06,46.080000000000034,2.9852905339147726e-06,102.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,X-Ray
34108787,10.1016/j.bbe.2021.05.013,Yes,PMC8179118,34108787.0,2021,2021-06-11,Journal Article,Peer reviewed (PubMed),1,automatic detection of coronavirus disease (covid-19) in x-ray and ct images: a machine learning-based approach,"The newly identified Coronavirus pneumonia, subsequently termed COVID-19, is highly transmittable and pathogenic with no clinically approved antiviral drug or vaccine available for treatment. The most common symptoms of COVID-19 are dry cough, sore throat, and fever. Symptoms can progress to a severe form of pneumonia with critical complications, including septic shock, pulmonary edema, acute respiratory distress syndrome and multi-organ failure. While medical imaging is not currently recommended in Canada for primary diagnosis of COVID-19, computer-aided diagnosis systems could assist in the early detection of COVID-19 abnormalities and help to monitor the progression of the disease, potentially reduce mortality rates. In this study, we compare popular deep learning-based feature extraction frameworks for automatic COVID-19 classification. To obtain the most accurate feature, which is an essential component of learning, MobileNet, DenseNet, Xception, ResNet, InceptionV3, InceptionResNetV2, VGGNet, NASNet were chosen amongst a pool of deep convolutional neural networks. The extracted features were then fed into several machine learning classifiers to classify subjects as either a case of COVID-19 or a control. This approach avoided task-specific data pre-processing methods to support a better generalization ability for unseen data. The performance of the proposed method was validated on a publicly available COVID-19 dataset of chest X-ray and CT images. The DenseNet121 feature extractor with Bagging tree classifier achieved the best performance with 99% classification accuracy. The second-best learner was a hybrid of the a ResNet50 feature extractor trained by LightGBM with an accuracy of 98.",241,"COVID-19;Cough;Fever;Pneumonia;Pulmonary Edema;Respiratory Distress Syndrome, Acute;Shock, Septic;Sore Throat",86.0,Biocybern Biomed Eng,Transfer Learning;Lung;Antiviral Agents;Pharmaceutical Preparations,2.725377729168577e-06,91.4799999999998,5.813174731312035e-06,191.0,0.0,External,2. Detection/Diagnosis,X-Ray
34113843,10.3389/frai.2021.598932,Yes,PMC8186443,34113843.0,2021,2021-06-12,Journal Article,Peer reviewed (PubMed),1,covid-fact: a fully-automated capsule network-based framework for identification of covid-19 cases from chest ct scans,"The newly discovered Coronavirus Disease 2019 (COVID-19) has been globally spreading and causing hundreds of thousands of deaths around the world as of its first emergence in late 2019. The rapid outbreak of this disease has overwhelmed health care infrastructures and arises the need to allocate medical equipment and resources more efficiently. The early diagnosis of this disease will lead to the rapid separation of COVID-19 and non-COVID cases, which will be helpful for health care authorities to optimize resource allocation plans and early prevention of the disease. In this regard, a growing number of studies are investigating the capability of deep learning for early diagnosis of COVID-19. Computed tomography (CT) scans have shown distinctive features and higher sensitivity compared to other diagnostic tests, in particular the current gold standard, i.e., the Reverse Transcription Polymerase Chain Reaction (RT-PCR) test. Current deep learning-based algorithms are mainly developed based on Convolutional Neural Networks (CNNs) to identify COVID-19 pneumonia cases. CNNs, however, require extensive data augmentation and large datasets to identify detailed spatial relations between image instances. Furthermore, existing algorithms utilizing CT scans, either extend slice-level predictions to patient-level ones using a simple thresholding mechanism or rely on a sophisticated infection segmentation to identify the disease. In this paper, we propose a two-stage fully automated CT-based framework for identification of COVID-19 positive cases referred to as the ""COVID-FACT"". COVID-FACT utilizes Capsule Networks, as its main building blocks and is, therefore, capable of capturing spatial information. In particular, to make the proposed COVID-FACT independent from sophisticated segmentations of the area of infection, slices demonstrating infection are detected at the first stage and the second stage is responsible for classifying patients into COVID and non-COVID cases. COVID-FACT detects slices with infection, and identifies positive COVID-19 cases using an in-house CT scan dataset, containing COVID-19, community acquired pneumonia, and normal cases. Based on our experiments, COVID-FACT achieves an accuracy of 90.82 %, a sensitivity of 94.55 %, a specificity of 86.04 %, and an AUC of 0.98, while depending on far less supervision and annotation, in comparison to its counterparts.",344,COVID-19;Death;Infections;Pneumonia,42.0,Front Artif Intell,Health Care;Diagnostic Tests;Disease Outbreaks;COVID-19 Testing;Sensitivity and Specificity;Polymerase Chain Reaction;Paper;Area under Curve;Early Diagnosis;Reverse Transcription,1.6660314287033013e-06,41.40000000000003,2.6010177712718954e-06,89.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
34127870,10.1016/j.patcog.2021.108109,Yes,PMC8189738,34127870.0,2021,2021-06-16,Journal Article,Peer reviewed (PubMed),1,scoat-net: a novel network for segmenting covid-19 lung opacification from ct images,"Automatic segmentation of lung opacification from computed tomography (CT) images shows excellent potential for quickly and accurately quantifying the infection of Coronavirus disease 2019 (COVID-19) and judging the disease development and treatment response. However, some challenges still exist, including the complexity and variability features of the opacity regions, the small difference between the infected and healthy tissues, and the noise of CT images. Due to limited medical resources, it is impractical to obtain a large amount of data in a short time, which further hinders the training of deep learning models. To answer these challenges, we proposed a novel spatial- and channel-wise coarse-to-fine attention network (SCOAT-Net), inspired by the biological vision mechanism, for the segmentation of COVID-19 lung opacification from CT images. With the UNet++ as basic structure, our SCOAT-Net introduces the specially designed spatial-wise and channel-wise attention modules, which serve to collaboratively boost the attention learning of the network and extract the efficient features of the infected opacification regions at the pixel and channel levels. Experiments show that our proposed SCOAT-Net achieves better results compared to several state-of-the-art image segmentation networks and has acceptable generalization ability.",187,COVID-19;Infections,12.0,Pattern Recognit,Art;Noise;Attention;Tomography;Lung Diseases,1.5621340035502375e-06,23.88000000000001,1.989057678183408e-06,49.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
34134940,10.1016/j.acra.2021.05.002,Yes,PMC8139280,34134940.0,2021,2021-06-18,Journal Article,Peer reviewed (PubMed),1,predicting prolonged hospitalization and supplemental oxygenation in patients with covid-19 infection from ambulatory chest radiographs using deep learning,"The clinical prognosis of outpatients with coronavirus disease 2019 (COVID-19) remains difficult to predict, with outcomes including asymptomatic, hospitalization, intubation, and death. Here we determined the prognostic value of an outpatient chest radiograph, together with an ensemble of deep learning algorithms predicting comorbidities and airspace disease to identify patients at a higher risk of hospitalization from COVID-19 infection. This retrospective study included outpatients with COVID-19 confirmed by reverse transcription-polymerase chain reaction testing who received an ambulatory chest radiography between March 17, 2020 and October 24, 2020. In this study, full admission was defined as hospitalization within 14 days of the COVID-19 test for > 2 days with supplemental oxygen. Univariate analysis and machine learning algorithms were used to evaluate the relationship between the deep learning model predictions and hospitalization for > 2 days. The study included 413 patients, 222 men, with a median age of 51 years (interquartile range, 39-62 years). Fifty-one patients required full admission. A boosted decision tree model produced the best prediction. Variables included patient age, frontal chest radiograph predictions of morbid obesity, congestive heart failure and cardiac arrhythmias, and radiographic opacity, with an internally validated AUC of 0.837 on a test cohort. Deep learning analysis of single frontal chest radiographs was used to generate combined comorbidity and pneumonia scores that predict the need for supplemental oxygen and hospitalization for > 2 days in patients with COVID-19 infection with an AUC of 0.837 (95% confidence interval: 0.791-0.883). Comorbidity scoring may prove useful in other clinical scenarios.",249,"Arrhythmias, Cardiac;COVID-19;Congestive Heart Failure;Death;Infections;Obesity, Morbid;Pneumonia",2.0,Acad Radiol,Polymerase Chain Reaction;Other Topics;Retrospective Studies;Area under Curve;Reverse Transcription,1.2709135533109351e-06,28.920000000000027,2.21548161547878e-06,61.0,0.0,Self-recorded/clinical,1. Risk identification,X-Ray
34149305,10.1007/s10796-021-10144-6,Yes,PMC8204125,34149305.0,2021,2021-06-22,Journal Article,Peer reviewed (PubMed),1,feddpgan: federated differentially private generative adversarial networks framework for the detection of covid-19 pneumonia,"Existing deep learning technologies generally learn the features of chest X-ray data generated by Generative Adversarial Networks (GAN) to diagnose COVID-19 pneumonia. However, the above methods have a critical challenge: data privacy. GAN will leak the semantic information of the training data which can be used to reconstruct the training samples by attackers, thereby this method will leak the privacy of the patient. Furthermore, for this reason, that is the limitation of the training data sample, different hospitals jointly train the model through data sharing, which will also cause privacy leakage. To solve this problem, we adopt the Federated Learning (FL) framework, a new technique being used to protect data privacy. Under the FL framework and Differentially Private thinking, we propose a Federated Differentially Private Generative Adversarial Network (FedDPGAN) to detect COVID-19 pneumonia for sustainable smart cities. Specifically, we use DP-GAN to privately generate diverse patient data in which differential privacy technology is introduced to make sure the privacy protection of the semantic information of the training dataset. Furthermore, we leverage FL to allow hospitals to collaboratively train COVID-19 models without sharing the original data. Under Independent and Identically Distributed (IID) and non-IID settings, the evaluation of the proposed model is on three types of chest X-ray (CXR)images dataset (COVID-19, normal, and normal pneumonia). A large number of truthful reports make the verification of our model can effectively diagnose COVID-19 without compromising privacy.",233,COVID-19;Pneumonia,8.0,Inf Syst Front,Report;Semantics,2.3130068543986533e-06,28.440000000000023,2.683206230536124e-06,59.0,0.0,External,5. Post-hoc,X-Ray
34175533,10.1016/j.compbiomed.2021.104605,Yes,PMC8219713,34175533.0,2021,2021-06-28,Journal Article;Review,Peer reviewed (PubMed),1,medical imaging and computational image analysis in covid-19 diagnosis: a review,"Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus. The disease presents with symptoms such as shortness of breath, fever, dry cough, and chronic fatigue, amongst others. The disease may be asymptomatic in some patients in the early stages, which can lead to increased transmission of the disease to others. This study attempts to review papers on the role of imaging and medical image computing in COVID-19 diagnosis. For this purpose, PubMed, Scopus and Google Scholar were searched to find related studies until the middle of 2021. The contribution of this study is four-fold: 1) to use as a tutorial of the field for both clinicians and technologists, 2) to comprehensively review the characteristics of COVID-19 as presented in medical images, 3) to examine automated artificial intelligence-based approaches for COVID-19 diagnosis, 4) to express the research limitations in this field and the methods used to overcome them. Using machine learning-based methods can diagnose the disease with high accuracy from medical images and reduce time, cost and error of diagnostic procedure. It is recommended to collect bulk imaging data from patients in the shortest possible time to improve the performance of COVID-19 automated diagnostic methods.",198,COVID-19;Communicable Diseases;Cough;Dyspnea;Fatigue;Fever,5.0,Comput Biol Med,COVID-19 Testing;Image Processing;Paper,1.3183911649452605e-06,34.36000000000003,2.3033798413214125e-06,75.0,0.0,,Review,Multimodal
34192015,10.1136/bmjinnov-2020-000593,Yes,PMC7931213,34192015.0,2021,2021-07-01,Journal Article,Peer reviewed (PubMed),1,deep learning model to predict the need for mechanical ventilation using chest x-ray images in hospitalised patients with covid-19,"There exists a wide gap in the availability of mechanical ventilator devices and their acute need in the context of the COVID-19 pandemic. An initial triaging method that accurately identifies the need for mechanical ventilation in hospitalised patients with COVID-19 is needed. We aimed to investigate if a potentially deteriorating clinical course in hospitalised patients with COVID-19 can be detected using all X-ray images taken during hospitalisation. We exploited the well-established DenseNet121 deep learning architecture for this purpose on 663 X-ray images acquired from 528 hospitalised patients with COVID-19. Two Pulmonary and Critical Care experts blindly and independently evaluated the same X-ray images for the purpose of validation. We found that our deep learning model predicted the need for mechanical ventilation with a high accuracy, sensitivity and specificity (90.06%, 86.34% and 84.38%, respectively). This prediction was done approximately 3 days ahead of the actual intubation event. Our model also outperformed two Pulmonary and Critical Care experts who evaluated the same X-ray images and provided an incremental accuracy of 7.24%-13.25%. Our deep learning model accurately predicted the need for mechanical ventilation early during hospitalisation of patients with COVID-19. Until effective preventive or treatment measures become widely available for patients with COVID-19, prognostic stratification as provided by our model is likely to be highly valuable.",213,COVID-19;COVID-19 Pandemic;Clinical Course,8.0,BMJ Innov,Other Topics,1.0885626002661756e-06,14.68,1.2687606330040266e-06,33.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,X-Ray
34192100,10.1109/ACCESS.2020.2994762,Yes,PMC8043420,34192100.0,2020,2020-05-14,Journal Article,Peer reviewed (PubMed),1,covidgan: data augmentation using auxiliary classifier gan for improved covid-19 detection,"Coronavirus (COVID-19) is a viral disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The spread of COVID-19 seems to have a detrimental effect on the global economy and health. A positive chest X-ray of infected patients is a crucial step in the battle against COVID-19. Early results suggest that abnormalities exist in chest X-rays of patients suggestive of COVID-19. This has led to the introduction of a variety of deep learning systems and studies have shown that the accuracy of COVID-19 patient detection through the use of chest X-rays is strongly optimistic. Deep learning networks like convolutional neural networks (CNNs) need a substantial amount of training data. Because the outbreak is recent, it is difficult to gather a significant number of radiographic images in such a short time. Therefore, in this research, we present a method to generate synthetic chest X-ray (CXR) images by developing an Auxiliary Classifier Generative Adversarial Network (ACGAN) based model called CovidGAN. In addition, we demonstrate that the synthetic images produced from CovidGAN can be utilized to enhance the performance of CNN for COVID-19 detection. Classification using CNN alone yielded 85% accuracy. By adding synthetic images produced by CovidGAN,the accuracy increased to 95%. We hope this method will speed up COVID-19 detection and lead to more robust systems of radiology.",216,COVID-19;Severe Acute Respiratory Syndrome;Virus Diseases,184.0,IEEE Access,Disease Outbreaks;Other Topics,4.5478021706617664e-06,88.09599999999976,6.416150560209011e-06,218.0,0.0,External,5. Post-hoc,X-Ray
34194484,10.1155/2021/8828404,Yes,PMC8203406,34194484.0,2021,2021-07-02,Journal Article,Peer reviewed (PubMed),1,transfer learning to detect covid-19 automatically from x-ray images using convolutional neural networks,"The novel coronavirus disease 2019 (COVID-19) is a contagious disease that has caused thousands of deaths and infected millions worldwide. Thus, various technologies that allow for the fast detection of COVID-19 infections with high accuracy can offer healthcare professionals much-needed help. This study is aimed at evaluating the effectiveness of the state-of-the-art pretrained Convolutional Neural Networks (CNNs) on the automatic diagnosis of COVID-19 from chest X-rays (CXRs). The dataset used in the experiments consists of 1200 CXR images from individuals with COVID-19, 1345 CXR images from individuals with viral pneumonia, and 1341 CXR images from healthy individuals. In this paper, the effectiveness of artificial intelligence (AI) in the rapid and precise identification of COVID-19 from CXR images has been explored based on different pretrained deep learning algorithms and fine-tuned to maximise detection accuracy to identify the best algorithms. The results showed that deep learning with X-ray imaging is useful in collecting critical biological markers associated with COVID-19 infections. VGG16 and MobileNet obtained the highest accuracy of 98.28%. However, VGG16 outperformed all other models in COVID-19 detection with an accuracy, F1 score, precision, specificity, and sensitivity of 98.72%, 97.59%, 96.43%, 98.70%, and 98.78%, respectively. The outstanding performance of these pretrained models can significantly improve the speed and accuracy of COVID-19 diagnosis. However, a larger dataset of COVID-19 X-ray images is required for a more accurate and reliable identification of COVID-19 infections when using deep transfer learning. This would be extremely beneficial in this pandemic when the disease burden and the need for preventive measures are in conflict with the currently available resources.",261,"COVID-19;Death;Infections;Pneumonia, Viral",30.0,Int J Biomed Imaging,Art;Health Care;Algorithms;Transfer Learning;Sensitivity and Specificity,2.943537336251224e-06,129.59999999999937,7.972375962940175e-06,272.0,0.0,External,2. Detection/Diagnosis,X-Ray
34194535,10.1155/2021/5528144,Yes,PMC8184329,34194535.0,2021,2021-07-02,Journal Article;Review,Peer reviewed (PubMed),1,an overview of deep learning techniques on chest x-ray and ct scan identification of covid-19,"Pneumonia is an infamous life-threatening lung bacterial or viral infection. The latest viral infection endangering the lives of many people worldwide is the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), which causes COVID-19. This paper is aimed at detecting and differentiating viral pneumonia and COVID-19 disease using digital X-ray images. The current practices include tedious conventional processes that solely rely on the radiologist or medical consultant's technical expertise that are limited, time-consuming, inefficient, and outdated. The implementation is easily prone to human errors of being misdiagnosed. The development of deep learning and technology improvement allows medical scientists and researchers to venture into various neural networks and algorithms to develop applications, tools, and instruments that can further support medical radiologists. This paper presents an overview of deep learning techniques made in the chest radiography on COVID-19 and pneumonia cases.",138,"COVID-19;Pneumonia;Pneumonia, Viral;Severe Acute Respiratory Syndrome;Virus Diseases",11.0,Comput Math Methods Med,Radiography;Research Personnel;COVID-19 Testing;Neural Networks;Paper,2.0706195499174385e-06,67.44,3.6994960503805056e-06,154.0,0.0,,Review,Multimodal
34205176,10.3390/diagnostics11061029,Yes,PMC8228774,34205176.0,2021,2021-07-03,Journal Article,Peer reviewed (PubMed),1,risk stratification for ecmo requirement in covid-19 icu patients using quantitative imaging features in ct scans on admission,"Extracorporeal membrane oxygenation (ECMO) therapy in intensive care units (ICUs) remains the last treatment option for Coronavirus disease 2019 (COVID-19) patients with severely affected lungs but is highly resource demanding. Early risk stratification for the need of ECMO therapy upon admission to the hospital using artificial intelligence (AI)-based computed tomography (CT) assessment and clinical scores is beneficial for patient assessment and resource management; Retrospective single-center study with 95 confirmed COVID-19 patients admitted to the participating ICUs. Patients requiring ECMO therapy (n = 14) during ICU stay versus patients without ECMO treatment (n = 81) were evaluated for discriminative clinical prediction parameters and AI-based CT imaging features and their diagnostic potential to predict ECMO therapy. Reported patient data include clinical scores, AI-based CT findings and patient outcomes; Patients subsequently allocated to ECMO therapy had significantly higher sequential organ failure (SOFA) scores (p < 0.001) and significantly lower oxygenation indices on admission (p = 0.009) than patients with standard ICU therapy. The median time from hospital admission to ECMO placement was 1.4 days (IQR 0.2-4.0). The percentage of lung involvement on AI-based CT assessment on admission to the hospital was significantly higher in ECMO patients (p < 0.001). In binary logistic regression analyses for ECMO prediction including age, sex, body mass index (BMI), SOFA score on admission, lactate on admission and percentage of lung involvement on admission CTs, only SOFA score and lung involvement were significantly associated with subsequent ECMO allocation. Receiver operating characteristic (ROC) curves showed an AUC of 0.83 for lung involvement on admission CT and 0.82 for SOFA scores on ICU admission. A combined parameter of SOFA on ICU admission and lung involvement on admission CT yielded an AUC of 0.91 with a sensitivity of 0.93 and a specificity of 0.84 for ECMO prediction; AI-based assessment of lung involvement on CT scans on admission to the hospital and SOFA scoring, especially if combined, can be used as risk stratification tools for subsequent requirement for ECMO therapy in patients with severe COVID-19 disease to improve resource management in ICU settings.",340,COVID-19,6.0,Diagnostics (Basel),Logistic Regression;ROC Curve;Lung Diseases,1.7868808251653006e-06,39.72000000000005,2.9257527336478468e-06,81.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
34223954,10.1007/s00330-021-08049-8,Yes,PMC8256200,34223954.0,2021,2021-07-06,Journal Article;Multicenter Study,Peer reviewed (PubMed),1,artificial intelligence for prediction of covid-19 progression using ct imaging and clinical data,"Early recognition of coronavirus disease 2019 (COVID-19) severity can guide patient management. However, it is challenging to predict when COVID-19 patients will progress to critical illness. This study aimed to develop an artificial intelligence system to predict future deterioration to critical illness in COVID-19 patients. An artificial intelligence (AI) system in a time-to-event analysis framework was developed to integrate chest CT and clinical data for risk prediction of future deterioration to critical illness in patients with COVID-19. A multi-institutional international cohort of 1,051 patients with RT-PCR confirmed COVID-19 and chest CT was included in this study. Of them, 282 patients developed critical illness, which was defined as requiring ICU admission and/or mechanical ventilation and/or reaching death during their hospital stay. The AI system achieved a C-index of 0.80 for predicting individual COVID-19 patients' to critical illness. The AI system successfully stratified the patients into high-risk and low-risk groups with distinct progression risks (p < 0.0001). Using CT imaging and clinical data, the AI system successfully predicted time to critical illness for individual patients and identified patients with high risk. AI has the potential to accurately triage patients and facilitate personalized treatment. AI system can predict time to critical illness for patients with COVID-19 by using CT imaging and clinical data.",210,COVID-19;Critical Illness;Death,20.0,Eur Radiol,Coronavirus Infections;Polymerase Chain Reaction;Retrospective Studies,1.4728179142286223e-06,43.80000000000005,2.9060094383411653e-06,93.0,0.0,External,4. Prognosis/Treatment,CT
34226795,10.1002/ima.22611,Yes,PMC8242523,34226795.0,2021,2021-07-07,Journal Article,Peer reviewed (PubMed),1,covseg-net: a deep convolution neural network for covid-19 lung ct image segmentation,"COVID-19 is a new type of respiratory infectious disease that poses a serious threat to the survival of human beings all over the world. Using artificial intelligence technology to analyze lung images of COVID-19 patients can achieve rapid and effective detection. This study proposes a COVSeg-NET model that can accurately segment ground glass opaque lesions in COVID-19 lung CT images. The COVSeg-NET model is based on the fully convolutional neural network model structure, which mainly includes convolutional layer, nonlinear unit activation function, maximum pooling layer, batch normalization layer, merge layer, flattening layer, sigmoid layer, and so forth. Through experiments and evaluation results, it can be seen that the dice coefficient, sensitivity, and specificity of the COVSeg-NET model are 0.561, 0.447, and 0.996 respectively, which are more advanced than other deep learning methods. The COVSeg-NET model can use a smaller training set and shorter test time to obtain better segmentation results.",150,COVID-19;Communicable Diseases,4.0,Int J Imaging Syst Technol,Sensitivity and Specificity;Neural Networks;Communicable Diseases,1.492228228875355e-06,13.92,1.422874766958752e-06,32.0,0.0,External,Segmentation-only,CT
34257953,10.1007/s13755-021-00154-8,Yes,PMC8269407,34257953.0,2021,2021-07-15,Journal Article,Peer reviewed (PubMed),1,specmen-dl: spectral mask enhancement with deep learning models to predict covid-19 from lung ultrasound videos,"Lung Ultrasound (LUS) images are considered to be effective for detecting Coronavirus Disease (COVID-19) as an alternative to the existing reverse transcription-polymerase chain reaction (RT-PCR)-based detection scheme. However, the recent literature exhibits a shortage of works dealing with LUS image-based COVID-19 detection. In this paper, a spectral mask enhancement (SpecMEn) scheme is introduced along with a histogram equalization pre-processing stage to reduce the noise effect in LUS images prior to utilizing them for feature extraction. In order to detect the COVID-19 cases, we propose to utilize the SpecMEn pre-processed LUS images in the deep learning (DL) models (namely the SpecMEn-DL method), which offers a better representation of some characteristics features in LUS images and results in very satisfactory classification performance. The performance of the proposed SpecMEn-DL technique is appraised by implementing some state-of-the-art DL models and comparing the results with related studies. It is found that the use of the SpecMEn scheme in DL techniques offers an average increase in accuracy and F1 score of 11 % and 11.75 %, respectively, at the video-level. Comprehensive analysis and visualization of the intermediate steps manifest a very satisfactory detection performance creating a flexible and safe alternative option for the clinicians to get assistance while obtaining the immediate evaluation of the patients.",209,COVID-19,2.0,Health Inf Sci Syst,Art;Noise;Polymerase Chain Reaction;Lung Diseases;Masks;Reverse Transcription,1.1769550864356937e-06,13.959999999999996,9.88607582217e-07,35.0,0.0,External,2. Detection/Diagnosis,Ultrasound
34258315,10.1093/ofid/ofab275,Yes,PMC8244656,34258315.0,2021,2021-07-15,Journal Article,Peer reviewed (PubMed),1,visceral adiposity and severe covid-19 disease: application of an artificial intelligence algorithm to improve clinical risk prediction,"Obesity has been linked to severe clinical outcomes among people who are hospitalized with coronavirus disease 2019 (COVID-19). We tested the hypothesis that visceral adipose tissue (VAT) is associated with severe outcomes in patients hospitalized with COVID-19, independent of body mass index (BMI). We analyzed data from the Massachusetts General Hospital COVID-19 Data Registry, which included patients admitted with polymerase chain reaction-confirmed severe acute respiratory syndrome coronavirus 2 infection from March 11 to May 4, 2020. We used a validated, fully automated artificial intelligence (AI) algorithm to quantify VAT from computed tomography (CT) scans during or before the hospital admission. VAT quantification took an average of 2 seconds per patient. We dichotomized VAT as high and low at a threshold of ≥100 cm2 and used Kaplan-Meier curves and Cox proportional hazards regression to assess the relationship between VAT and death or intubation over 28 days, adjusting for age, sex, race, BMI, and diabetes status. A total of 378 participants had CT imaging. Kaplan-Meier curves showed that participants with high VAT had a greater risk of the outcome compared with those with low VAT (P < .005), especially in those with BMI <30 kg/m2 (P < .005). In multivariable models, the adjusted hazard ratio (aHR) for high vs low VAT was unchanged, whereas BMI was no longer significant. High VAT is associated with a greater risk of severe disease or death in COVID-19 and can offer more precise information to risk-stratify individuals beyond BMI. AI offers a promising approach to routinely ascertain VAT and improve clinical risk prediction in COVID-19.",259,COVID-19;Death;Obesity,12.0,Open Forum Infect Dis,Polymerase Chain Reaction;Other Topics,1.153058854100487e-06,6.479999999999998,9.988256645568293e-07,14.0,0.0,Self-recorded/clinical,1. Risk identification,CT
34276263,10.1016/j.asoc.2021.107692,Yes,PMC8276579,34276263.0,2021,2021-07-20,Journal Article,Peer reviewed (PubMed),1,correcting data imbalance for semi-supervised covid-19 detection using x-ray chest images,"A key factor in the fight against viral diseases such as the coronavirus (COVID-19) is the identification of virus carriers as early and quickly as possible, in a cheap and efficient manner. The application of deep learning for image classification of chest X-ray images of COVID-19 patients could become a useful pre-diagnostic detection methodology. However, deep learning architectures require large labelled datasets. This is often a limitation when the subject of research is relatively new as in the case of the virus outbreak, where dealing with small labelled datasets is a challenge. Moreover, in such context, the datasets are also highly imbalanced, with few observations from positive cases of the new disease. In this work we evaluate the performance of the semi-supervised deep learning architecture known as MixMatch with a very limited number of labelled observations and highly imbalanced labelled datasets. We demonstrate the critical impact of data imbalance to the model's accuracy. Therefore, we propose a simple approach for correcting data imbalance, by re-weighting each observation in the loss function, giving a higher weight to the observations corresponding to the under-represented class. For unlabelled observations, we use the pseudo and augmented labels calculated by MixMatch to choose the appropriate weight. The proposed method improved classification accuracy by up to 18%, with respect to the non balanced MixMatch algorithm. We tested our proposed approach with several available datasets using 10, 15 and 20 labelled observations, for binary classification (COVID-19 positive and normal cases). For multi-class classification (COVID-19 positive, pneumonia and normal cases), we tested 30, 50, 70 and 90 labelled observations. Additionally, a new dataset is included among the tested datasets, composed of chest X-ray images of Costa Rican adult patients.",281,COVID-19;Pneumonia;Virus Diseases,10.0,Appl Soft Comput,Architecture;Disease Outbreaks,1.4423326360138193e-06,34.96000000000003,2.546968646856068e-06,76.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
34365278,10.1016/j.compbiomed.2021.104729,Yes,PMC8330146,34365278.0,2021,2021-08-09,Journal Article,Peer reviewed (PubMed),1,fully automated unified prognosis of covid-19 chest x-ray/ct scan images using deep covix-net model,"SARS-COV2 (Covid-19) prevails in the form of multiple mutant variants causing pandemic situations around the world. Thus, medical diagnosis is not accurate. Although several clinical diagnostic methodologies have been introduced hitherto, chest X-ray and computed tomography (CT) imaging techniques complement the analytical methods (for instance, RT-PCR) to a certain extent. In this context, we demonstrate a novel framework by employing various image segmentation models to leverage the available image databases (9000 chest X-ray images and 6000 CT scan images). The proposed methodology is expected to assist in the prognosis of Covid-19-infected individuals through examination of chest X-rays and CT scans of images using the Deep Covix-Net model for identifying novel coronavirus-infected patients effectively and efficiently. The slice of the precision score is analysed in terms of performance metrics such as accuracy, the confusion matrix, and the receiver operating characteristic curve. The result leans on the database obtainable in the GitHub and Kaggle repository, conforming to their endorsed chest X-ray and CT images. The classification performances of various algorithms were examined for a test set with 1800 images. The proposed model achieved a 96.8% multiple-classification accuracy among Covid-19, normal, and pneumonia chest X-ray databases. Moreover, it attained a 97% accuracy among Covid-19 and normal CT scan images. Thus, the proposed mechanism achieves the rigorousness associated with the machine learning technique, providing rapid outcomes for both training and testing datasets.",228,COVID-19;Confusion;Pneumonia,9.0,Comput Biol Med,Polymerase Chain Reaction;Other Topics,2.4221293201123218e-06,106.07999999999969,6.550946320786989e-06,218.0,0.0,External,4. Prognosis/Treatment,Multimodal
34368420,10.1016/j.imu.2021.100687,Yes,PMC8332742,34368420.0,2021,2021-08-10,Journal Article,Peer reviewed (PubMed),1,automated detection of pneumonia in lung ultrasound using deep video classification for covid-19,"There is a crucial need for quick testing and diagnosis of patients during the COVID-19 pandemic. Lung ultrasound is an imaging modality that is cost-effective, widely accessible, and can be used to diagnose acute respiratory distress syndrome in patients with COVID-19. It can be used to find important characteristics in the images, including A-lines, B-lines, consolidation, and pleural effusion, which all inform the clinician in monitoring and diagnosing the disease. With the use of portable ultrasound transducers, lung ultrasound images can be easily acquired, however, the images are often of poor quality. They often require an expert clinician interpretation, which may be time-consuming and is highly subjective. We propose a method for fast and reliable interpretation of lung ultrasound images by use of deep learning, based on the Kinetics-I3D network. Our learned model can classify an entire lung ultrasound scan obtained at point-of-care, without requiring the use of preprocessing or a frame-by-frame analysis. We compare our video classifier against ground truth classification annotations provided by a set of expert radiologists and clinicians, which include A-lines, B-lines, consolidation, and pleural effusion. Our classification method achieves an accuracy of 90% and an average precision score of 95% with the use of 5-fold cross-validation. The results indicate the potential use of automated analysis of portable lung ultrasound images to assist clinicians in screening and diagnosing patients.",223,"COVID-19;COVID-19 Pandemic;Pleural Effusion;Pneumonia;Respiratory Distress Syndrome, Acute",5.0,Inform Med Unlocked,Other Topics,1.168587226468884e-06,13.56,1.077937292461589e-06,33.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,Ultrasound
34373554,10.1038/s41598-021-95680-6,Yes,PMC8352869,34373554.0,2021,2021-08-11,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,explainable dcnn based chest x-ray image analysis and classification for covid-19 pneumonia detection,"To speed up the discovery of COVID-19 disease mechanisms by X-ray images, this research developed a new diagnosis platform using a deep convolutional neural network (DCNN) that is able to assist radiologists with diagnosis by distinguishing COVID-19 pneumonia from non-COVID-19 pneumonia in patients based on chest X-ray classification and analysis. Such a tool can save time in interpreting chest X-rays and increase the accuracy and thereby enhance our medical capacity for the detection and diagnosis of COVID-19. The explainable method is also used in the DCNN to select instances of the X-ray dataset images to explain the behavior of training-learning models to achieve higher prediction accuracy. The average accuracy of our method is above 96%, which can replace manual reading and has the potential to be applied to large-scale rapid screening of COVID-9 for widely use cases.",137,COVID-19;Pneumonia,9.0,Sci Rep,Sensitivity and Specificity;Neural Networks,2.386903800811074e-06,93.79999999999971,5.530055606085117e-06,205.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
34388462,10.1016/j.compbiomed.2021.104742,Yes,PMC8349313,34388462.0,2021,2021-08-14,Journal Article,Peer reviewed (PubMed),1,deep learning and lung ultrasound for covid-19 pneumonia detection and severity classification,"The Covid-19 European outbreak in February 2020 has challenged the world's health systems, eliciting an urgent need for effective and highly reliable diagnostic instruments to help medical personnel. Deep learning (DL) has been demonstrated to be useful for diagnosis using both computed tomography (CT) scans and chest X-rays (CXR), whereby the former typically yields more accurate results. However, the pivoting function of a CT scan during the pandemic presents several drawbacks, including high cost and cross-contamination problems. Radiation-free lung ultrasound (LUS) imaging, which requires high expertise and is thus being underutilised, has demonstrated a strong correlation with CT scan results and a high reliability in pneumonia detection even in the early stages. In this study, we developed a system based on modern DL methodologies in close collaboration with Fondazione IRCCS Policlinico San Matteo's Emergency Department (ED) of Pavia. Using a reliable dataset comprising ultrasound clips originating from linear and convex probes in 2908 frames from 450 hospitalised patients, we conducted an investigation into detecting Covid-19 patterns and ranking them considering two severity scales. This study differs from other research projects by its novel approach involving four and seven classes. Patients admitted to the ED underwent 12 LUS examinations in different chest parts, each evaluated according to standardised severity scales. We adopted residual convolutional neural networks (CNNs), transfer learning, and data augmentation techniques. Hence, employing methodological hyperparameter tuning, we produced state-of-the-art results meeting F1 score levels, averaged over the number of classes considered, exceeding 98%, and thereby manifesting stable measurements over precision and recall.",253,COVID-19;Pneumonia,16.0,Comput Biol Med,Occupational Groups;Art;Transfer Learning;Disease Outbreaks;Lung;Tomography;Lung Diseases,1.3531742345800022e-06,35.120000000000026,2.381473321301956e-06,76.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
34393275,10.1016/j.ijleo.2021.167780,Yes,PMC8349421,34393275.0,2021,2021-08-17,Journal Article,Peer reviewed (PubMed),1,multi-label segmentation and detection of covid-19 abnormalities from chest radiographs using deep learning,"Due to COVID-19, demand for Chest Radiographs (CXRs) have increased exponentially. Therefore, we present a novel fully automatic modified Attention U-Net (CXAU-Net) multi-class segmentation deep model that can detect common findings of COVID-19 in CXR images. The architectural design of this model includes three novelties: first, an Attention U-net model with channel and spatial attention blocks is designed that precisely localize multiple pathologies; second, dilated convolution applied improves the sensitivity of the model to foreground pixels with additional receptive fields valuation, and third a newly proposed hybrid loss function combines both area and size information for optimizing model. The proposed model achieves average accuracy, DSC, and Jaccard index scores of 0.951, 0.993, 0.984, and 0.921, 0.985, 0.973 for image-based and patch-based approaches respectively for multi-class segmentation on Chest X-ray 14 dataset. Also, average DSC and Jaccard index scores of 0.998, 0.989 are achieved for binary-class segmentation on the Japanese Society of Radiological Technology (JSRT) CXR dataset. These results illustrate that the proposed model outperformed the state-of-the-art segmentation methods.",168,COVID-19,4.0,Optik (Stuttg),Art;Semantics;Other Topics;Societies,1.280191159597521e-06,16.959999999999994,1.703411361500962e-06,34.0,0.0,External,Segmentation-only,X-Ray
34405153,10.1007/s42979-021-00795-2,Yes,PMC8361825,34405153.0,2021,2021-08-19,Journal Article,Peer reviewed (PubMed),1,neural style transfer as data augmentation for improving covid-19 diagnosis classification,"Coronavirus disease 2019 (COVID-19) has accounted for millions of causalities. While it affects not only individuals but also our collective healthcare and economic systems, testing is insufficient and costly hampering efforts to deal with the pandemic. Chest X-rays are routine radiographic imaging tests that are used for the diagnosis of respiratory conditions such as pneumonia and COVID-19. Convolutional neural networks have shown promise to be effective at classifying X-rays for assisting diagnosis of conditions; however, achieving robust performance demanded in most modern medical applications typically requires a large number of samples. While there exist datasets containing thousands of X-ray images of patients with healthy and pneumonia diagnoses, because COVID-19 is such a recent phenomenon, there are relatively few confirmed COVID-19 positive chest X-rays openly available to the research community. In this paper, we demonstrate the effectiveness of cycle-generative adversarial network, commonly used for neural style transfer, as a way to augment COVID-19 negative X-ray images to look like COVID-19 positive images for increasing the number of COVID-19 positive training samples. The statistical results show an increase in the mean macro f1-score over 21% on a one-tailed t score = 2.68 and p value = 0.01 to accept our alternative hypothesis for an α = 0.05. We conclude that this approach, when used in conjunction with standard transfer learning techniques, is effective at improving the performance of COVID-19 classifiers for a variety of common convolutional neural networks.",236,COVID-19;Pneumonia,2.0,SN Comput Sci,Health Care;Transfer Learning;Other Topics,1.190652186949256e-06,11.76,1.0153705560010605e-06,30.0,0.0,External,5. Post-hoc,X-Ray
34450928,10.3390/s21165486,Yes,PMC8401701,34450928.0,2021,2021-08-29,Journal Article,Peer reviewed (PubMed),1,pulmonary covid-19: learning spatiotemporal features combining cnn and lstm networks for lung ultrasound video classification,"Deep Learning is a very active and important area for building Computer-Aided Diagnosis (CAD) applications. This work aims to present a hybrid model to classify lung ultrasound (LUS) videos captured by convex transducers to diagnose COVID-19. A Convolutional Neural Network (CNN) performed the extraction of spatial features, and the temporal dependence was learned using a Long Short-Term Memory (LSTM). Different types of convolutional architectures were used for feature extraction. The hybrid model (CNN-LSTM) hyperparameters were optimized using the Optuna framework. The best hybrid model was composed of an Xception pre-trained on ImageNet and an LSTM containing 512 units, configured with a dropout rate of 0.4, two fully connected layers containing 1024 neurons each, and a sequence of 20 frames in the input layer. The model presented an average accuracy of 93% and sensitivity of 97% for COVID-19, outperforming models based purely on spatial approaches. Furthermore, feature extraction using transfer learning with models pre-trained on ImageNet provided comparable results to models pre-trained on LUS images. The results corroborate with other studies showing that this model for LUS classification can be an important tool in the fight against COVID-19 and other lung diseases.",191,COVID-19;Lung Diseases,6.0,Sensors (Basel),Transfer Learning;Architecture;Lung;Neural Networks,2.523969596060644e-06,52.04000000000004,3.694564868557542e-06,111.0,0.0,,2. Detection/Diagnosis,Ultrasound
34456618,10.1007/s00500-021-06137-x,Yes,PMC8382671,34456618.0,2021,2021-08-31,Journal Article,Peer reviewed (PubMed),1,deep neural networks for covid-19 detection and diagnosis using images and acoustic-based techniques: a recent review,"The new coronavirus disease (COVID-19) has been declared a pandemic since March 2020 by the World Health Organization. It consists of an emerging viral infection with respiratory tropism that could develop atypical pneumonia. Experts emphasize the importance of early detection of those who have the COVID-19 virus. In this way, patients will be isolated from other people and the spread of the virus can be prevented. For this reason, it has become an area of interest to develop early diagnosis and detection methods to ensure a rapid treatment process and prevent the virus from spreading. Since the standard testing system is time-consuming and not available for everyone, alternative early screening techniques have become an urgent need. In this study, the approaches used in the detection of COVID-19 based on deep learning (DL) algorithms, which have been popular in recent years, have been comprehensively discussed. The advantages and disadvantages of different approaches used in literature are examined in detail. We further present the databases and major future challenges of DL-based COVID-19 detection. The computed tomography of the chest and X-ray images gives a rich representation of the patient's lung that is less time-consuming and allows an efficient viral pneumonia detection using the DL algorithms. The first step is the preprocessing of these images to remove noise. Next, deep features are extracted using multiple types of deep models (pretrained models, generative models, generic neural networks, etc.). Finally, the classification is performed using the obtained features to decide whether the patient is infected by coronavirus or it is another lung disease. In this study, we also give a brief review of the latest applications of cough analysis to early screen the COVID-19 and human mobility estimation to limit its spread.",287,"COVID-19;Cough;Lung Diseases;Pneumonia;Pneumonia, Viral;Virus Diseases",7.0,Soft comput,World Health Organization;Noise;Tomography,1.29137885531929e-06,29.280000000000022,2.1990892303839185e-06,64.0,0.0,,Review,Multimodal
34473619,10.2174/1573405617666210902103729,Yes,,34473619.0,2021,2021-09-03,"Journal Article;Review;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,covid-19 imaging-based ai research - a literature review,"The new coronavirus disease 2019 (COVID-19) is spreading rapidly around the world. Artificial Intelligence (AI) assisted identification and detection of diseases is an effective method of medical diagnosis. To present recent advances in AI-assisted diagnosis of COVID-19, we introduce major aspects of AI in the process of diagnosing COVID-19. In this paper, we firstly cover the latest collection and processing methods of datasets of COVID-19. The processing methods mainly include building public datasets, transfer learning, unsupervised learning and weakly supervised learning, semi-supervised learning methods and so on. Secondly, we introduce the algorithm application and evaluation metrics of AI in medical imaging segmentation and automatic screening. Then, we introduce the quantification and severity assessment of infection in COVID-19 patients based on image segmentation and automatic screening. Finally, we analyze and point out the current AI-assisted diagnosis of COVID-19 problems, which may provide useful clues for future work. AI is critical for COVID-19 diagnosis. Combining chest imaging with AI can not only save time and effort, but also provide more accurate and efficient medical diagnosis results.",174,COVID-19;Infections,1.0,Curr Med Imaging,Algorithms;Transfer Learning;Diagnostic Tests;COVID-19 Testing;Paper,1.016055584057576e-06,19.4,2.079564047826489e-06,31.0,0.0,,Review,Multimodal
34492574,10.1016/j.media.2021.102216,Yes,PMC8401374,34492574.0,2021,2021-09-08,Journal Article;Multicenter Study,Peer reviewed (PubMed),1,aiforcovid: predicting the clinical outcomes in patients with covid-19 applying ai to chest-x-rays an italian multicentre study,"Recent epidemiological data report that worldwide more than 53 million people have been infected by SARS-CoV-2, resulting in 1.3 million deaths. The disease has been spreading very rapidly and few months after the identification of the first infected, shortage of hospital resources quickly became a problem. In this work we investigate whether artificial intelligence working with chest X-ray (CXR) scans and clinical data can be used as a possible tool for the early identification of patients at risk of severe outcome, like intensive care or death. Indeed, further to induce lower radiation dose than computed tomography (CT), CXR is a simpler and faster radiological technique, being also more widespread. In this respect, we present three approaches that use features extracted from CXR images, either handcrafted or automatically learnt by convolutional neuronal networks, which are then integrated with the clinical data. As a further contribution, this work introduces a repository that collects data from 820 patients enrolled in six Italian hospitals in spring 2020 during the first COVID-19 emergency. The dataset includes CXR images, several clinical attributes and clinical outcomes. Exhaustive evaluation shows promising performance both in 10-fold and leave-one-centre-out cross-validation, suggesting that clinical data and images have the potential to provide useful information for the management of patients and hospital resources.",211,COVID-19;Death,26.0,Med Image Anal,Other Topics,1.1910395643122325e-06,21.40000000000001,1.4945645261003242e-06,49.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,X-Ray
34516488,10.1097/MD.0000000000026855,Yes,PMC8428739,34516488.0,2021,2021-09-14,Journal Article;Review,Peer reviewed (PubMed),1,application of machine learning in ct images and x-rays of covid-19 pneumonia,"Coronavirus disease (COVID-19) has spread worldwide. X-ray and computed tomography (CT) are 2 technologies widely used in image acquisition, segmentation, diagnosis, and evaluation. Artificial intelligence can accurately segment infected parts in X-ray and CT images, assist doctors in improving diagnosis efficiency, and facilitate the subsequent assessment of the severity of the patient infection. The medical assistant platform based on machine learning can help radiologists make clinical decisions and helper in screening, diagnosis, and treatment. By providing scientific methods for image recognition, segmentation, and evaluation, we summarized the latest developments in the application of artificial intelligence in COVID-19 lung imaging, and provided guidance and inspiration to researchers and doctors who are fighting the COVID-19 virus.",114,COVID-19;Infections;Pneumonia,9.0,Medicine (Baltimore),Other Topics,1.4284361369131703e-06,18.96,1.4346366042775172e-06,46.0,0.0,,Review,Multimodal
34518740,10.1002/ima.22644,Yes,PMC8426801,34518740.0,2021,2021-09-15,Journal Article,Peer reviewed (PubMed),1,genetic-based adaptive momentum estimation for predicting mortality risk factors for covid-19 patients using deep learning,"The mortality risk factors for coronavirus disease (COVID-19) must be early predicted, especially for severe cases, to provide intensive care before they develop to critically ill immediately. This paper aims to develop an optimized convolution neural network (CNN) for predicting mortality risk factors for COVID-19 patients. The proposed model supports two types of input data clinical variables and the computed tomography (CT) scans. The features are extracted from the optimized CNN phase and then applied to the classification phase. The CNN model's hyperparameters were optimized using a proposed genetic-based adaptive momentum estimation (GB-ADAM) algorithm. The GB-ADAM algorithm employs the genetic algorithm (GA) to optimize Adam optimizer's configuration parameters, consequently improving the classification accuracy. The model is validated using three recent cohorts from New York, Mexico, and Wuhan, consisting of 3055, 7497,504 patients, respectively. The results indicated that the most significant mortality risk factors are: CD8+T Lymphocyte (Count), D-dimer greater than 1 Ug/ml, high values of lactate dehydrogenase (LDH), C-reactive protein (CRP), hypertension, and diabetes. Early identification of these factors would help the clinicians in providing immediate care. The results also show that the most frequent COVID-19 signs in CT scans included ground-glass opacity (GGO), followed by crazy-paving pattern, consolidations, and the number of lobes. Moreover, the experimental results show encouraging performance for the proposed model compared with different predicting models.",220,COVID-19;Cardiovascular Diseases;Confusion;Cough;Critical Illness;Death;Diarrhea;Dyspnea;Fever;Hypertension;Infections;Myalgia;Sore Throat;Syndrome,1.0,Int J Imaging Syst Technol,Coronavirus Infections;World Health Organization;Logistic Regression;Architecture;Health;Noise;Risk Factors;Radiologists;Critical Illness;Support Vector Machine;Proteins;Specificity;Health Care;Algorithms;Disease Outbreaks;Sensitivity and Specificity;Analysis;Polymerase Chain Reaction;ROC Curve;Area under Curve;Map,1.2444464832030387e-06,18.12,1.4472885886891712e-06,43.0,0.0,External,1. Risk identification,CT
34526699,10.1038/s41591-021-01506-3,Yes,PMC9157510,34526699.0,2021,2021-09-17,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,federated learning for predicting clinical outcomes in patients with covid-19,"Federated learning (FL) is a method used for training artificial intelligence models with data from multiple sources while maintaining data anonymity, thus removing many barriers to data sharing. Here we used data from 20 institutes across the globe to train a FL model, called EXAM (electronic medical record (EMR) chest X-ray AI model), that predicts the future oxygen requirements of symptomatic patients with COVID-19 using inputs of vital signs, laboratory data and chest X-rays. EXAM achieved an average AUC >0.92 for predicting outcomes at 24 and 72 h from the time of initial presentation to the emergency room, and it provided 16% improvement in average AUC measured across all participating sites and an average increase in generalizability of 38% when compared with models trained at a single site using that site's data. For prediction of mechanical ventilation treatment or death at 24 h at the largest independent test site, EXAM achieved a sensitivity of 0.950 and specificity of 0.882. In this study, FL facilitated rapid data science collaboration without data exchange and generated a model that generalized across heterogeneous, unharmonized datasets for prediction of clinical outcomes in patients with COVID-19, setting the stage for the broader use of FL in healthcare.",201,COVID-19;Death,80.0,Nat Med,Specificity;Oxygen;Health Care;Vital Signs;Health;Other Topics;Data Sharing;Area under Curve;Electronic Health Records,1.7778295379599283e-06,39.36000000000004,2.9112286224309467e-06,84.0,0.0,External,4. Prognosis/Treatment,X-Ray
34539221,10.1007/s11042-021-11299-9,Yes,PMC8436200,34539221.0,2021,2021-09-21,Journal Article,Peer reviewed (PubMed),1,automatic deep learning system for covid-19 infection quantification in chest ct,"The paper proposes an automatic deep learning system for COVID-19 infection areas segmentation in chest CT scans. CT imaging proved its ability to detect the COVID-19 disease even for asymptotic patients, which make it a trustworthy alternative for PCR. Coronavirus disease spread globally and PCR screening is the adopted diagnostic testing method for COVID-19 detection. However, PCR is criticized due its low sensitivity ratios, also, it is time-consuming and manual complicated process. The proposed framework includes different steps; it starts to prepare the region of interest by segmenting the lung organ, which then undergoes edge enhancing diffusion filtering (EED) to improve the infection areas contrast and intensity homogeneity. The proposed FCN is implemented using U-net architecture with modified residual block to include concatenation skip connection. The block improves the learning of gradient values by forwarding the infection area features through the network. The proposed system is evaluated using different measures and achieved dice overlapping score of 0.961 and 0.780 for lung and infection areas segmentation, respectively. The proposed system is trained and tested using many 2D CT slices extracted from diverse datasets from different sources, which demonstrate the system generalization and effectiveness. The use of more datasets from different sources helps to enhance the system accuracy and generalization, which can be accomplished based on the data availability in in the future.",221,COVID-19;Infections;Postoperative Residual Curarization,2.0,Multimed Tools Appl,Coronavirus Infections;Polymerase Chain Reaction,1.4428728634999232e-06,21.24000000000001,1.691390207077252e-06,49.0,0.0,External,Segmentation-only,CT
34606447,10.1109/TMI.2021.3117246,Yes,PMC9014480,34606447.0,2021,2021-10-05,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,integrating domain knowledge into deep networks for lung ultrasound with applications to covid-19,"Lung ultrasound (LUS) is a cheap, safe and non-invasive imaging modality that can be performed at patient bed-side. However, to date LUS is not widely adopted due to lack of trained personnel required for interpreting the acquired LUS frames. In this work we propose a framework for training deep artificial neural networks for interpreting LUS, which may promote broader use of LUS. When using LUS to evaluate a patient's condition, both anatomical phenomena (e.g., the pleural line, presence of consolidations), as well as sonographic artifacts (such as A- and B-lines) are of importance. In our framework, we integrate domain knowledge into deep neural networks by inputting anatomical features and LUS artifacts in the form of additional channels containing pleural and vertical artifacts masks along with the raw LUS frames. By explicitly supplying this domain knowledge, standard off-the-shelf neural networks can be rapidly and efficiently finetuned to accomplish various tasks on LUS data, such as frame classification or semantic segmentation. Our framework allows for a unified treatment of LUS frames captured by either convex or linear probes. We evaluated our proposed framework on the task of COVID-19 severity assessment using the ICLUS dataset. In particular, we finetuned simple image classification models to predict per-frame COVID-19 severity score. We also trained a semantic segmentation model to predict per-pixel COVID-19 severity annotations. Using the combined raw LUS frames and the detected lines for both tasks, our off-the-shelf models performed better than complicated models specifically designed for these tasks, exemplifying the efficacy of our framework.",251,COVID-19,7.0,IEEE Trans Med Imaging,Occupational Groups;Semantics;Ultrasonography;Neural Networks;Other Topics;Masks,1.2899834907309695e-06,27.68000000000001,1.6084140635919236e-06,64.0,0.0,External,3. Monitoring/Severity assessment,Ultrasound
34650825,,Yes,PMC8513790,34650825.0,2021,2021-10-16,Journal Article,Peer reviewed (PubMed),1,context matters: graph-based self-supervised representation learning for medical images,"Supervised learning method requires a large volume of annotated datasets. Collecting such datasets is time-consuming and expensive. Until now, very few annotated COVID-19 imaging datasets are available. Although self-supervised learning enables us to bootstrap the training by exploiting unlabeled data, the generic self-supervised methods for natural images do not sufficiently incorporate the context. For medical images, a desirable method should be sensitive enough to detect deviation from normal-appearing tissue of each anatomical region; here, anatomy is the context. We introduce a novel approach with two levels of self-supervised representation learning objectives: one on the regional anatomical level and another on the patient-level. We use graph neural networks to incorporate the relationship between different anatomical regions. The structure of the graph is informed by anatomical correspondences between each patient and an anatomical atlas. In addition, the graph representation has the advantage of handling any arbitrarily sized image in full resolution. Experiments on large-scale Computer Tomography (CT) datasets of lung images show that our approach compares favorably to baseline methods that do not account for the context. We use the learnt embedding to quantify the clinical progression of COVID-19 and show that our method generalizes well to COVID-19 patients from different hospitals. Qualitative results suggest that our model can identify clinically relevant regions in the images.",214,COVID-19;Clinical Course,2.0,Proc Conf AAAI Artif Intell,Other Topics,1.1147967710239024e-06,4.2,8.706987463484142e-07,9.0,0.0,External,3. Monitoring/Severity assessment,CT
34723206,10.1007/s42979-021-00874-4,Yes,PMC8543772,34723206.0,2021,2021-11-02,Journal Article,Peer reviewed (PubMed),1,an encoder-decoder-based method for segmentation of covid-19 lung infection in ct images,"The novelty of the COVID-19 Disease and the speed of spread, created colossal chaotic, impulse all the worldwide researchers to exploit all resources and capabilities to understand and analyze characteristics of the coronavirus in terms of spread ways and virus incubation time. For that, the existing medical features such as CT-scan and X-ray images are used. For example, CT-scan images can be used for the detection of lung infection. However, the quality of these images and infection characteristics limit the effectiveness of these features. Using artificial intelligence (AI) tools and computer vision algorithms, the accuracy of detection can be more accurate and can help to overcome these issues. In this paper, we propose a multi-task deep-learning-based method for lung infection segmentation on CT-scan images. Our proposed method starts by segmenting the lung regions that may be infected. Then, segmenting the infections in these regions. In addition, to perform a multi-class segmentation the proposed model is trained using the two-stream inputs. The multi-task learning used in this paper allows us to overcome the shortage of labeled data. In addition, the multi-input stream allows the model to learn from many features that can improve the results. To evaluate the proposed method, many metrics have been used including Sorensen-Dice similarity, Sensitivity, Specificity, Precision, and MAE metrics. As a result of experiments, the proposed method can segment lung infections with high performance even with the shortage of data and labeled images. In addition, comparing with the state-of-the-art method our method achieves good performance results. For example, the proposed method reached 78..6% for Dice, 71.1% for Sensitivity metric, 99.3% for Specificity 85.6% for Precision, and 0.062 for Mean Average Error metric, which demonstrates the effectiveness of the proposed method for lung infection segmentation.",288,COVID-19;Infections,23.0,SN Comput Sci,Coronavirus Infections;Art;Algorithms;Research Personnel;Lung Diseases,2.1175509621051287e-06,35.08000000000003,2.518002191681295e-06,75.0,0.0,External,Segmentation-only,CT
34735458,10.1371/journal.pone.0258760,Yes,PMC8568139,34735458.0,2021,2021-11-05,Journal Article,Peer reviewed (PubMed),1,accuracy of deep learning-based computed tomography diagnostic system for covid-19: a consecutive sampling external validation cohort study,"Ali-M3, an artificial intelligence program, analyzes chest computed tomography (CT) and detects the likelihood of coronavirus disease (COVID-19) based on scores ranging from 0 to 1. However, Ali-M3 has not been externally validated. Our aim was to evaluate the accuracy of Ali-M3 for detecting COVID-19 and discuss its clinical value. We evaluated the external validity of Ali-M3 using sequential Japanese sampling data. In this retrospective cohort study, COVID-19 infection probabilities for 617 symptomatic patients were determined using Ali-M3. In 11 Japanese tertiary care facilities, these patients underwent reverse transcription-polymerase chain reaction (RT-PCR) testing. They also underwent chest CT to confirm a diagnosis of COVID-19. Of the 617 patients, 289 were RT-PCR-positive. The AUC of Ali-M3 for predicting a COVID-19 diagnosis was 0.797 (95% confidence interval: 0.762‒0.833) and the goodness-of-fit was P = 0.156. With a cut-off probability of a diagnosis of COVID-19 by Ali-M3 set at 0.5, the sensitivity and specificity were 80.6% and 68.3%, respectively. A cut-off of 0.2 yielded a sensitivity and specificity of 89.2% and 43.2%, respectively. Among the 223 patients who required oxygen, the AUC was 0.825. Sensitivity at a cut-off of 0.5% and 0.2% was 88.7% and 97.9%, respectively. Although the sensitivity was lower when the days from symptom onset were fewer, the sensitivity increased for both cut-off values after 5 days. We evaluated Ali-M3 using external validation with symptomatic patient data from Japanese tertiary care facilities. As Ali-M3 showed sufficient sensitivity performance, despite a lower specificity performance, Ali-M3 could be useful in excluding a diagnosis of COVID-19.",253,COVID-19;Infections,2.0,PLoS One,Coronavirus Infections;Reproducibility of Results;COVID-19 Testing;Reverse Transcription;Health Care;Image Processing;Sensitivity and Specificity;Polymerase Chain Reaction;ROC Curve;Retrospective Studies;Area under Curve;Age;Cohort Studies,1.3805942463492017e-06,33.88000000000002,1.9981137627008754e-06,77.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
34764548,10.1007/s10489-020-01829-7,Yes,PMC7474514,34764548.0,2020,2020-09-05,Journal Article,Peer reviewed (PubMed),1,classification of covid-19 in chest x-ray images using detrac deep convolutional neural network,"Chest X-ray is the first imaging technique that plays an important role in the diagnosis of COVID-19 disease. Due to the high availability of large-scale annotated image datasets, great success has been achieved using convolutional neural networks (CNN s) for image recognition and classification. However, due to the limited availability of annotated medical images, the classification of medical images remains the biggest challenge in medical diagnosis. Thanks to transfer learning, an effective mechanism that can provide a promising solution by transferring knowledge from generic object recognition tasks to domain-specific tasks. In this paper, we validate and a deep CNN, called Decompose, Transfer, and Compose (DeTraC), for the classification of COVID-19 chest X-ray images. DeTraC can deal with any irregularities in the image dataset by investigating its class boundaries using a class decomposition mechanism. The experimental results showed the capability of DeTraC in the detection of COVID-19 cases from a comprehensive image dataset collected from several hospitals around the world. High accuracy of 93.1% (with a sensitivity of 100%) was achieved by DeTraC in the detection of COVID-19 X-ray images from normal, and severe acute respiratory syndrome cases.",187,COVID-19;Severe Acute Respiratory Syndrome,250.0,Appl Intell (Dordr),Transfer Learning;Other Topics,4.874475135720051e-06,129.23199999999937,8.985047722213701e-06,290.0,0.0,External,2. Detection/Diagnosis,X-Ray
34764554,10.1007/s10489-020-01900-3,Yes,PMC7568031,34764554.0,2021,2021-11-13,Journal Article,Peer reviewed (PubMed),1,automated diagnosis of covid-19 with limited posteroanterior chest x-ray images using fine-tuned deep neural networks,"The novel coronavirus 2019 (COVID-19) is a respiratory syndrome that resembles pneumonia. The current diagnostic procedure of COVID-19 follows reverse-transcriptase polymerase chain reaction (RT-PCR) based approach which however is less sensitive to identify the virus at the initial stage. Hence, a more robust and alternate diagnosis technique is desirable. Recently, with the release of publicly available datasets of corona positive patients comprising of computed tomography (CT) and chest X-ray (CXR) imaging; scientists, researchers and healthcare experts are contributing for faster and automated diagnosis of COVID-19 by identifying pulmonary infections using deep learning approaches to achieve better cure and treatment. These datasets have limited samples concerned with the positive COVID-19 cases, which raise the challenge for unbiased learning. Following from this context, this article presents the random oversampling and weighted class loss function approach for unbiased fine-tuned learning (transfer learning) in various state-of-the-art deep learning approaches such as baseline ResNet, Inception-v3, Inception ResNet-v2, DenseNet169, and NASNetLarge to perform binary classification (as normal and COVID-19 cases) and also multi-class classification (as COVID-19, pneumonia, and normal case) of posteroanterior CXR images. Accuracy, precision, recall, loss, and AUC are utilized to evaluate the performance of the models. Considering the experimental results, the performance of each model is scenario dependent; however, NASNetLarge displayed better scores in contrast to other architectures, which is further compared with other recently proposed approaches. This article also added the visual explanation to illustrate the basis of model classification and perception of COVID-19 in CXR images.",245,COVID-19;Infections;Pneumonia;Syndrome,55.0,Appl Intell (Dordr),Art;Health Care;Transfer Learning;Research Personnel;Architecture;Polymerase Chain Reaction;Tomography;Area under Curve,3.409674468293032e-06,89.33599999999981,6.774536408469156e-06,199.0,0.0,External,2. Detection/Diagnosis,X-Ray
34764623,10.1007/s10489-021-02945-8,Yes,PMC8556802,34764623.0,2021,2021-11-13,Journal Article,Peer reviewed (PubMed),1,decision and feature level fusion of deep features extracted from public covid-19 data-sets,"The Coronavirus disease (COVID-19), which is an infectious pulmonary disorder, has affected millions of people and has been declared as a global pandemic by the WHO. Due to highly contagious nature of COVID-19 and its high possibility of causing severe conditions in the patients, the development of rapid and accurate diagnostic tools have gained importance. The real-time reverse transcription-polymerize chain reaction (RT-PCR) is used to detect the presence of Coronavirus RNA by using the mucus and saliva mixture samples taken by the nasopharyngeal swab technique. But, RT-PCR suffers from having low-sensitivity especially in the early stage. Therefore, the usage of chest radiography has been increasing in the early diagnosis of COVID-19 due to its fast imaging speed, significantly low cost and low dosage exposure of radiation. In our study, a computer-aided diagnosis system for X-ray images based on convolutional neural networks (CNNs) and ensemble learning idea, which can be used by radiologists as a supporting tool in COVID-19 detection, has been proposed. Deep feature sets extracted by using seven CNN architectures were concatenated for feature level fusion and fed to multiple classifiers in terms of decision level fusion idea with the aim of discriminating COVID-19, pneumonia and no-finding classes. In the decision level fusion idea, a majority voting scheme was applied to the resultant decisions of classifiers. The obtained accuracy values and confusion matrix based evaluation criteria were presented for three progressively created data-sets. The aspects of the proposed method that are superior to existing COVID-19 detection studies have been discussed and the fusion performance of proposed approach was validated visually by using Class Activation Mapping technique. The experimental results show that the proposed approach has attained high COVID-19 detection performance that was proven by its comparable accuracy and superior precision/recall values with the existing studies.",296,COVID-19;Confusion;Pneumonia,5.0,Appl Intell (Dordr),Transfer Learning;Architecture;Polymerase Chain Reaction;Reverse Transcription,1.3816246813778678e-06,29.96000000000002,2.100444514837195e-06,67.0,0.0,External,2. Detection/Diagnosis,X-Ray
34770423,10.3390/s21217116,Yes,PMC8587284,34770423.0,2021,2021-11-14,Journal Article,Peer reviewed (PubMed),1,impact of lung segmentation on the diagnosis and explanation of covid-19 in chest x-ray images,"COVID-19 frequently provokes pneumonia, which can be diagnosed using imaging exams. Chest X-ray (CXR) is often useful because it is cheap, fast, widespread, and uses less radiation. Here, we demonstrate the impact of lung segmentation in COVID-19 identification using CXR images and evaluate which contents of the image influenced the most. Semantic segmentation was performed using a U-Net CNN architecture, and the classification using three CNN architectures (VGG, ResNet, and Inception). Explainable Artificial Intelligence techniques were employed to estimate the impact of segmentation. A three-classes database was composed: lung opacity (pneumonia), COVID-19, and normal. We assessed the impact of creating a CXR image database from different sources, and the COVID-19 generalization from one source to another. The segmentation achieved a Jaccard distance of 0.034 and a Dice coefficient of 0.982. The classification using segmented images achieved an F1-Score of 0.88 for the multi-class setup, and 0.83 for COVID-19 identification. In the cross-dataset scenario, we obtained an F1-Score of 0.74 and an AUC of 0.9 for COVID-19 identification using segmented images. Experiments support the conclusion that even after segmentation, there is a strong bias introduced by underlying factors from different sources.",190,COVID-19;Pneumonia,32.0,Sensors (Basel),Semantics;Bias;Other Topics;ROC Curve,2.0289081958726785e-06,70.4,4.603536147403732e-06,148.0,0.0,External,2. Detection/Diagnosis,X-Ray
34786295,10.1109/ACCESS.2020.3033762,Yes,PMC8545263,34786295.0,2021,2021-11-18,Journal Article,Peer reviewed (PubMed),1,deep convolutional approaches for the analysis of covid-19 using chest x-ray images from portable devices,"The recent human coronavirus disease (COVID-19) is a respiratory infection caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Given the effects of COVID-19 in pulmonary tissues, chest radiography imaging plays an important role in the screening, early detection, and monitoring of the suspected individuals. Hence, as the pandemic of COVID-19 progresses, there will be a greater reliance on the use of portable equipment for the acquisition of chest X-ray images due to its accessibility, widespread availability, and benefits regarding to infection control issues, minimizing the risk of cross-contamination. This work presents novel fully automatic approaches specifically tailored for the classification of chest X-ray images acquired by portable equipment into 3 different clinical categories: normal, pathological, and COVID-19. For this purpose, 3 complementary deep learning approaches based on a densely convolutional network architecture are herein presented. The joint response of all the approaches allows to enhance the differentiation between patients infected with COVID-19, patients with other diseases that manifest characteristics similar to COVID-19 and normal cases. The proposed approaches were validated over a dataset specifically retrieved for this research. Despite the poor quality of the chest X-ray images that is inherent to the nature of the portable equipment, the proposed approaches provided global accuracy values of 79.62%, 90.27% and 79.86%, respectively, allowing a reliable analysis of portable radiographs to facilitate the clinical decision-making process.",224,COVID-19;Infections;Respiratory Tract Infections;Severe Acute Respiratory Syndrome,24.0,IEEE Access,Other Topics,2.620294881851516e-06,34.40000000000001,3.0229601512243228e-06,92.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
34786299,10.1109/ACCESS.2020.3044858,Yes,PMC8545248,34786299.0,2021,2021-11-18,Journal Article,Peer reviewed (PubMed),1,artificial intelligence applied to chest x-ray images for the automatic detection of covid-19 a thoughtful evaluation approach,"Current standard protocols used in the clinic for diagnosing COVID-19 include molecular or antigen tests, generally complemented by a plain chest X-Ray. The combined analysis aims to reduce the significant number of false negatives of these tests and provide complementary evidence about the presence and severity of the disease. However, the procedure is not free of errors, and the interpretation of the chest X-Ray is only restricted to radiologists due to its complexity. With the long term goal to provide new evidence for the diagnosis, this paper presents an evaluation of different methods based on a deep neural network. These are the first steps to develop an automatic COVID-19 diagnosis tool using chest X-Ray images to differentiate between controls, pneumonia, or COVID-19 groups. The paper describes the process followed to train a Convolutional Neural Network with a dataset of more than 79, 500 X-Ray images compiled from different sources, including more than 8, 500 COVID-19 examples. Three different experiments following three preprocessing schemes are carried out to evaluate and compare the developed models. The aim is to evaluate how preprocessing the data affects the results and improves its explainability. Likewise, a critical analysis of different variability issues that might compromise the system and its effects is performed. With the employed methodology, a 91.5% classification accuracy is obtained, with an 87.4% average recall for the worst but most explainable experiment, which requires a previous automatic segmentation of the lung region.",239,COVID-19;Pneumonia,26.0,IEEE Access,Other Topics,2.26745637740306e-06,29.51200000000001,2.6154485758284043e-06,79.0,0.0,External,2. Detection/Diagnosis,X-Ray
34812365,10.1109/ACCESS.2020.3034032,Yes,PMC8545262,34812365.0,2021,2021-11-24,Journal Article,Peer reviewed (PubMed),1,explainable machine learning for early assessment of covid-19 risk prediction in emergency departments,"Between January and October of 2020, the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) virus has infected more than 34 million persons in a worldwide pandemic leading to over one million deaths worldwide (data from the Johns Hopkins University). Since the virus begun to spread, emergency departments were busy with COVID-19 patients for whom a quick decision regarding in- or outpatient care was required. The virus can cause characteristic abnormalities in chest radiographs (CXR), but, due to the low sensitivity of CXR, additional variables and criteria are needed to accurately predict risk. Here, we describe a computerized system primarily aimed at extracting the most relevant radiological, clinical, and laboratory variables for improving patient risk prediction, and secondarily at presenting an explainable machine learning system, which may provide simple decision criteria to be used by clinicians as a support for assessing patient risk. To achieve robust and reliable variable selection, Boruta and Random Forest (RF) are combined in a 10-fold cross-validation scheme to produce a variable importance estimate not biased by the presence of surrogates. The most important variables are then selected to train a RF classifier, whose rules may be extracted, simplified, and pruned to finally build an associative tree, particularly appealing for its simplicity. Results show that the radiological score automatically computed through a neural network is highly correlated with the score computed by radiologists, and that laboratory variables, together with the number of comorbidities, aid risk prediction. The prediction performance of our approach was compared to that that of generalized linear models and shown to be effective and robust. The proposed machine learning-based computational system can be easily deployed and used in emergency departments for rapid and accurate risk prediction in COVID-19 patients.",285,COVID-19;Death;Severe Acute Respiratory Syndrome,22.0,IEEE Access,Other Topics,1.714399629201226e-06,21.888000000000005,1.5827003398398168e-06,62.0,0.0,Self-recorded/clinical,1. Risk identification,X-Ray
34841040,10.1016/j.imu.2021.100779,Yes,PMC8607740,34841040.0,2021,2021-11-30,Journal Article,Peer reviewed (PubMed),1,data augmentation using generative adversarial networks (gans) for gan-based detection of pneumonia and covid-19 in chest x-ray images,"Successful training of convolutional neural networks (CNNs) requires a substantial amount of data. With small datasets, networks generalize poorly. Data Augmentation techniques improve the generalizability of neural networks by using existing training data more effectively. Standard data augmentation methods, however, produce limited plausible alternative data. Generative Adversarial Networks (GANs) have been utilized to generate new data and improve the performance of CNNs. Nevertheless, data augmentation techniques for training GANs are underexplored compared to CNNs. In this work, we propose a new GAN architecture for augmentation of chest X-rays for semi-supervised detection of pneumonia and COVID-19 using generative models. We show that the proposed GAN can be used to effectively augment data and improve classification accuracy of disease in chest X-rays for pneumonia and COVID-19. We compare our augmentation GAN model with Deep Convolutional GAN and traditional augmentation methods (rotate, zoom, etc.) on two different X-ray datasets and show our GAN-based augmentation method surpasses other augmentation methods for training a GAN in detecting anomalies in X-ray images.",166,COVID-19;Pneumonia,10.0,Inform Med Unlocked,Other Topics,2.788381850334848e-06,37.08000000000004,3.2713084165300685e-06,77.0,0.0,External,5. Post-hoc,X-Ray
34842822,10.3390/tomography7040058,Yes,PMC8628928,34842822.0,2021,2021-11-30,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,the predictive role of artificial intelligence-based chest ct quantification in patients with covid-19 pneumonia,"We sought to analyze the prognostic value of laboratory and clinical data, and an artificial intelligence (AI)-based algorithm for Coronavirus disease 2019 (COVID-19) severity scoring, on CT-scans of patients hospitalized with COVID-19. Moreover, we aimed to determine personalized probabilities of clinical deterioration. Data of symptomatic patients with COVID-19 who underwent chest-CT-examination at the time of hospital admission between April and November 2020 were analyzed. COVID-19 severity score was automatically quantified for each pulmonary lobe as the percentage of affected lung parenchyma with the AI-based algorithm. Clinical deterioration was defined as a composite of admission to the intensive care unit, need for invasive mechanical ventilation, use of vasopressors or in-hospital mortality. In total 326 consecutive patients were included in the analysis (mean age 66.7 years, 52.1% male) of whom 85 experienced clinical deterioration. In the multivariable regression analysis prior myocardial infarction, immunodeficiency, C-reactive protein and AI-based COVID-19 severity score appeared to be independent predictors of clinical deterioration. Personalized probability values were determined. AI-based COVID-19 severity score assessed at hospital admission can provide additional information about the prognosis of COVID-19, possibly serving as a useful tool for individualized risk-stratification.",187,COVID-19;Clinical Deterioration;Myocardial Infarction;Pneumonia,4.0,Tomography,Other Topics,1.2491044985472695e-06,29.680000000000025,1.988216098932854e-06,64.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
34853342,10.1038/s41598-021-02003-w,Yes,PMC8636645,34853342.0,2021,2021-12-03,"Journal Article;Research Support, Non-U.S. Gov't;Validation Study",Peer reviewed (PubMed),1,validation of expert system enhanced deep learning algorithm for automated screening for covid-pneumonia on chest x-rays,"SARS-CoV2 pandemic exposed the limitations of artificial intelligence based medical imaging systems. Earlier in the pandemic, the absence of sufficient training data prevented effective deep learning (DL) solutions for the diagnosis of COVID-19 based on X-Ray data. Here, addressing the lacunae in existing literature and algorithms with the paucity of initial training data; we describe CovBaseAI, an explainable tool using an ensemble of three DL models and an expert decision system (EDS) for COVID-Pneumonia diagnosis, trained entirely on pre-COVID-19 datasets. The performance and explainability of CovBaseAI was primarily validated on two independent datasets. Firstly, 1401 randomly selected CxR from an Indian quarantine center to assess effectiveness in excluding radiological COVID-Pneumonia requiring higher care. Second, curated dataset; 434 RT-PCR positive cases and 471 non-COVID/Normal historical scans, to assess performance in advanced medical settings. CovBaseAI had an accuracy of 87% with a negative predictive value of 98% in the quarantine-center data. However, sensitivity was 0.66-0.90 taking RT-PCR/radiologist opinion as ground truth. This work provides new insights on the usage of EDS with DL methods and the ability of algorithms to confidently predict COVID-Pneumonia while reinforcing the established learning; that benchmarking based on RT-PCR may not serve as reliable ground truth in radiological diagnosis. Such tools can pave the path for multi-modal high throughput detection of COVID-Pneumonia in screening and referral.",218,COVID-19;Pneumonia,3.0,Sci Rep,Predictive Value;Image Processing;Polymerase Chain Reaction;Neural Networks;Radiologists;Retrospective Studies,1.985597469056349e-06,77.83999999999993,4.697749693507525e-06,166.0,0.0,Self-recorded/clinical,2. Detection/Diagnosis,X-Ray
34859905,10.1002/jum.15902,Yes,PMC9015439,34859905.0,2021,2021-12-04,Journal Article,Peer reviewed (PubMed),1,lung ultrasound in covid-19 and post-covid-19 patients an evidence-based approach,"Worldwide, lung ultrasound (LUS) was utilized to assess coronavirus disease 2019 (COVID-19) patients. Often, imaging protocols were however defined arbitrarily and not following an evidence-based approach. Moreover, extensive studies on LUS in post-COVID-19 patients are currently lacking. This study analyses the impact of different LUS imaging protocols on the evaluation of COVID-19 and post-COVID-19 LUS data. LUS data from 220 patients were collected, 100 COVID-19 positive and 120 post-COVID-19. A validated and standardized imaging protocol based on 14 scanning areas and a 4-level scoring system was implemented. We utilized this dataset to compare the capability of 5 imaging protocols, respectively based on 4, 8, 10, 12, and 14 scanning areas, to intercept the most important LUS findings. This to evaluate the optimal trade-off between a time-efficient imaging protocol and an accurate LUS examination. We also performed a longitudinal study, aimed at investigating how to eventually simplify the protocol during follow-up. Additionally, we present results on the agreement between AI models and LUS experts with respect to LUS data evaluation. A 12-areas protocol emerges as the optimal trade-off, for both COVID-19 and post-COVID-19 patients. For what concerns follow-up studies, it appears not to be possible to reduce the number of scanning areas. Finally, COVID-19 and post-COVID-19 LUS data seem to show differences capable to confuse AI models that were not trained on post-COVID-19 data, supporting the hypothesis of the existence of LUS patterns specific to post-COVID-19 patients. A 12-areas acquisition protocol is recommended for both COVID-19 and post-COVID-19 patients, also during follow-up.",251,COVID-19,11.0,J Ultrasound Med,Ultrasonography;Other Topics,1.3917103248836817e-06,32.760000000000026,2.133374350123672e-06,73.0,0.0,Self-recorded/clinical,5. Post-hoc,Ultrasound
34884045,10.3390/s21238045,Yes,PMC8659534,34884045.0,2021,2021-12-11,Journal Article;Review;Systematic Review,Peer reviewed (PubMed),1,role of artificial intelligence in covid-19 detection,"The global pandemic of coronavirus disease (COVID-19) has caused millions of deaths and affected the livelihood of many more people. Early and rapid detection of COVID-19 is a challenging task for the medical community, but it is also crucial in stopping the spread of the SARS-CoV-2 virus. Prior substantiation of artificial intelligence (AI) in various fields of science has encouraged researchers to further address this problem. Various medical imaging modalities including X-ray, computed tomography (CT) and ultrasound (US) using AI techniques have greatly helped to curb the COVID-19 outbreak by assisting with early diagnosis. We carried out a systematic review on state-of-the-art AI techniques applied with X-ray, CT, and US images to detect COVID-19. In this paper, we discuss approaches used by various authors and the significance of these research efforts, the potential challenges, and future trends related to the implementation of an AI system for disease detection during the COVID-19 pandemic.",152,COVID-19;COVID-19 Pandemic;Death,11.0,Sensors (Basel),Art;Research Personnel;Disease Outbreaks;Systematic Review;Tomography;Early Diagnosis,2.8558580372001376e-06,134.11999999999932,7.866745626826584e-06,279.0,0.0,,Review,Multimodal
34891687,10.1109/EMBC46164.2021.9630945,Yes,,34891687.0,2021,2021-12-12,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,interpreting uncertainty in model predictions for covid-19 diagnosis,"COVID-19, due to its accelerated spread has brought in the need to use assistive tools for faster diagnosis in addition to typical lab swab testing. Chest X-Rays for COVID cases tend to show changes in the lungs such as ground glass opacities and peripheral consolidations which can be detected by deep neural networks. However, traditional convolutional networks use point estimate for predictions, lacking in capture of uncertainty, which makes them less reliable for adoption. There have been several works so far in predicting COVID positive cases with chest X-Rays. However, not much has been explored on quantifying the uncertainty of these predictions, interpreting uncertainty, and decomposing this to model or data uncertainty. To address these needs, we develop a visualization framework to address interpretability of uncertainty and its components, with uncertainty in predictions computed with a Bayesian Convolutional Neural Network. This framework aims to understand the contribution of individual features in the Chest-X-Ray images to predictive uncertainty. Providing this as an assistive tool can help the radiologist understand why the model came up with a prediction and whether the regions of interest captured by the model for the specific prediction are of significance in diagnosis. We demonstrate the usefulness of the tool in chest x-ray interpretation through several test cases from a benchmark dataset.",214,COVID-19,0.0,Annu Int Conf IEEE Eng Med Biol Soc,COVID-19 Testing;Other Topics,1.1317416826665073e-06,14.199999999999996,9.57269921139537e-07,37.0,0.0,External,2. Detection/Diagnosis,X-Ray
34891790,10.1109/EMBC46164.2021.9631069,Yes,,34891790.0,2021,2021-12-12,Journal Article,Peer reviewed (PubMed),1,multi-feature multi-scale cnn-derived covid-19 classification from lung ultrasound data,"The global pandemic of the novel coronavirus disease 2019 (COVID-19) has put tremendous pressure on the medical system. Imaging plays a complementary role in the management of patients with COVID-19. Computed tomography (CT) and chest X-ray (CXR) are the two dominant screening tools. However, difficulty in eliminating the risk of disease transmission, radiation exposure and not being cost-effective are some of the challenges for CT and CXR imaging. This fact induces the implementation of lung ultrasound (LUS) for evaluating COVID-19 due to its practical advantages of noninvasiveness, repeatability, and sensitive bedside property. In this paper, we utilize a deep learning model to perform the classification of COVID-19 from LUS data, which could produce objective diagnostic information for clinicians. Specifically, all LUS images are processed to obtain their corresponding local phase filtered images and radial symmetry transformed images before fed into the multi-scale residual convolutional neural network (CNN). Secondly, image combination as the input of the network is used to explore rich and reliable features. Feature fusion strategy at different levels is adopted to investigate the relationship between the depth of feature aggregation and the classification accuracy. Our proposed method is evaluated on the point-of-care US (POCUS) dataset together with the Italian COVID-19 Lung US database (ICLUS-DB) and shows promising performance for COVID-19 prediction.",213,COVID-19,3.0,Annu Int Conf IEEE Eng Med Biol Soc,Neural Networks;Other Topics,1.4056208884819955e-06,29.240000000000016,1.982746128346114e-06,65.0,0.0,External,2. Detection/Diagnosis,Ultrasound
34898799,10.1111/exsy.12823,Yes,PMC8646497,34898799.0,2021,2021-12-14,Journal Article,Peer reviewed (PubMed),1,dc-gan-based synthetic x-ray images augmentation for increasing the performance of efficientnet for covid-19 detection,"Currently, many deep learning models are being used to classify COVID-19 and normal cases from chest X-rays. However, the available data (X-rays) for COVID-19 is limited to train a robust deep-learning model. Researchers have used data augmentation techniques to tackle this issue by increasing the numbers of samples through flipping, translation, and rotation. However, by adopting this strategy, the model compromises for the learning of high-dimensional features for a given problem. Hence, there are high chances of overfitting. In this paper, we used deep-convolutional generative adversarial networks algorithm to address this issue, which generates synthetic images for all the classes (Normal, Pneumonia, and COVID-19). To validate whether the generated images are accurate, we used the k-mean clustering technique with three clusters (Normal, Pneumonia, and COVID-19). We only selected the X-ray images classified in the correct clusters for training. In this way, we formed a synthetic dataset with three classes. The generated dataset was then fed to The EfficientNetB4 for training. The experiments achieved promising results of 95% in terms of AUC. To validate that our network has learned discriminated features associated with lung in the X-rays, we used the Grad-CAM technique to visualize the underlying pattern, which leads the network to its final decision.",204,COVID-19;Pneumonia,7.0,Expert Syst,Research Personnel;Address;X-Rays;Area under Curve;Translations;Rotation;Cluster Analysis,1.342879596014068e-06,24.720000000000017,1.9901431170201147e-06,54.0,0.0,External,5. Post-hoc,X-Ray
34898850,10.1002/ima.22672,Yes,PMC8652855,34898850.0,2021,2021-12-14,Journal Article,Peer reviewed (PubMed),1,coli-net: deep learning-assisted fully automated covid-19 lung and infection pneumonia lesion detection and segmentation from chest computed tomography images,"We present a deep learning (DL)-based automated whole lung and COVID-19 pneumonia infectious lesions (COLI-Net) detection and segmentation from chest computed tomography (CT) images. This multicenter/multiscanner study involved 2368 (347'259 2D slices) and 190 (17 341 2D slices) volumetric CT exams along with their corresponding manual segmentation of lungs and lesions, respectively. All images were cropped, resized, and the intensity values clipped and normalized. A residual network with non-square Dice loss function built upon TensorFlow was employed. The accuracy of lung and COVID-19 lesions segmentation was evaluated on an external reverse transcription-polymerase chain reaction positive COVID-19 dataset (7'333 2D slices) collected at five different centers. To evaluate the segmentation performance, we calculated different quantitative metrics, including radiomic features. The mean Dice coefficients were 0.98 and 0.91 for lung and lesions segmentation, respectively. The mean relative Hounsfield unit differences were 0.03 % and -0.18 % for the lung and lesions, respectively. The relative volume difference for lung and lesions were 0.38 % and 0.81 %, respectively. Most radiomic features had a mean relative error less than 5% with the highest mean relative error achieved for the lung for the range first-order feature and least axis length shape feature for lesions. We developed an automated DL-guided three-dimensional whole lung and infected regions segmentation in COVID-19 patients to provide fast, consistent, robust, and human error immune framework for lung and pneumonia lesion detection and quantification.",232,COVID-19;Infections;Pneumonia,10.0,Int J Imaging Syst Technol,Polymerase Chain Reaction;Reverse Transcription,1.6185333433315698e-06,34.96000000000003,2.6018463402337224e-06,74.0,0.0,External,Segmentation-only,CT
34902668,10.1016/j.ejrad.2021.110066,Yes,PMC8609670,34902668.0,2021,2021-12-14,Journal Article,Peer reviewed (PubMed),1,performance of a computer aided diagnosis system for sars-cov-2 pneumonia based on ultrasound images,"In this study we aimed to leverage deep learning to develop a computer aided diagnosis (CAD) system toward helping radiologists in the diagnosis of SARS-CoV-2 virus syndrome on Lung ultrasonography (LUS). A CAD system is developed based on a transfer learning of a residual network (ResNet) to extract features on LUS and help radiologists to distinguish SARS-CoV-2 virus syndrome from healthy and non-SARS-CoV-2 pneumonia. A publicly available LUS dataset for SARS-CoV-2 virus syndrome consisting of 3909 images has been employed. Six radiologists with different experiences participated in the experiment. A comprehensive LUS data set was constructed and employed to train and verify the proposed method. Several metrics such as accuracy, recall, precision, and F1-score, are used to evaluate the performance of the proposed CAD approach. The performances of the radiologists with and without the help of CAD are also evaluated quantitively. The p-values of the t-test shows that with the help of the CAD system, both junior and senior radiologists significantly improve their diagnosis performance on both balanced and unbalanced datasets. Experimental results indicate the proposed CAD approach and the machine features from it can significantly improve the radiologists' performance in the SARS-CoV-2 virus syndrome diagnosis. With the help of the proposed CAD system, the junior and senior radiologists achieved F1-score values of 91.33% and 95.79% on balanced dataset and 94.20% and 96.43% on unbalanced dataset. The proposed approach is verified on an independent test dataset and reports promising performance. The proposed CAD system reports promising performance in facilitating radiologists' diagnosis SARS-CoV-2 virus syndrome and might assist the development of a fast, accessible screening method for pulmonary diseases.",268,Lung Diseases;Pneumonia;Syndrome,0.0,Eur J Radiol,Transfer Learning;Lung;Ultrasonography;Other Topics,1.1886357848339513e-06,16.799999999999997,1.3041034356304828e-06,40.0,0.0,External,2. Detection/Diagnosis,Ultrasound
34923448,10.1016/j.ijmedinf.2021.104662,Yes,PMC8656148,34923448.0,2021,2021-12-20,Journal Article,Peer reviewed (PubMed),1,image and structured data analysis for prognostication of health outcomes in patients presenting to the ed during the covid-19 pandemic,"Patients admitted to the emergency department (ED) with COVID-19 symptoms are routinely required to have chest radiographs and computed tomography (CT) scans. COVID-19 infection has been directly related to the development of acute respiratory distress syndrome (ARDS) and severe infections could lead to admission to intensive care and increased risk of death. The use of clinical data in machine learning models available at time of admission to ED can be used to assess possible risk of ARDS, the need for intensive care (admission to the Intensive Care Unit; ICU) as well as risk of mortality. In addition, chest radiographs can be inputted into a deep learning model to further assess these risks. This research aimed to develop machine and deep learning models using both structured clinical data and image data from the electronic health record (EHR) to predict adverse outcomes following ED admission. Light Gradient Boosting Machine (LightGBM) was used as the main machine learning algorithm using all clinical data including 42 variables. Compact models were also developed using the 15 most important variables to increase applicability of the models in clinical settings. To predict risk (or early stratified risk) of the aforementioned health outcome events, transfer learning from the CheXNet model was also implemented on the available data. This research utilized clinical data and chest radiographs of 3,571 patients, 18 years and older, admitted to the emergency department between 9th March 2020 and 29th October 2020 at Loyola University Medical Center. The research results show that we can detect COVID-19 infection (AUC = 0.790, predict the risk of developing ARDS (AUC = 0.781, risk stratification of the need for ICU admission (AUC = 0.675 and mortality (AUC = 0.759 at moderate accuracy from both chest X-ray images and clinical data. The results can help in clinical decision making, especially when addressing ARDS and mortality, during the assessment of patients admitted to the ED with or without COVID-19 symptoms.",319,"COVID-19;COVID-19 Pandemic;Death;Infections;Respiratory Distress Syndrome, Acute",1.0,Int J Med Inform,Health Care;Transfer Learning;Algorithms;Tomography;Area under Curve,1.5165647054363613e-06,27.040000000000017,2.0746538104892443e-06,60.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,X-Ray
34972274,10.1121/10.0007272,Yes,PMC8684042,34972274.0,2022,2022-01-02,"Journal Article;Research Support, N.I.H., Extramural",Peer reviewed (PubMed),1,investigating training-test data splitting strategies for automated segmentation and scoring of covid-19 lung ultrasound images,"Ultrasound in point-of-care lung assessment is becoming increasingly relevant. This is further reinforced in the context of the COVID-19 pandemic, where rapid decisions on the lung state must be made for staging and monitoring purposes. The lung structural changes due to severe COVID-19 modify the way ultrasound propagates in the parenchyma. This is reflected by changes in the appearance of the lung ultrasound images. In abnormal lungs, vertical artifacts known as B-lines appear and can evolve into white lung patterns in the more severe cases. Currently, these artifacts are assessed by trained physicians, and the diagnosis is qualitative and operator dependent. In this article, an automatic segmentation method using a convolutional neural network is proposed to automatically stage the progression of the disease. 1863 B-mode images from 203 videos obtained from 14 asymptomatic individual,14 confirmed COVID-19 cases, and 4 suspected COVID-19 cases were used. Signs of lung damage, such as the presence and extent of B-lines and white lung areas, are manually segmented and scored from zero to three (most severe). These manually scored images are considered as ground truth. Different test-training strategies are evaluated in this study. The results shed light on the efficient approaches and common challenges associated with automatic segmentation methods.",204,COVID-19;COVID-19 Pandemic,6.0,J Acoust Soc Am,Other Topics,1.276569753546136e-06,16.559999999999995,1.3002492262829995e-06,40.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
34976571,10.1109/ACCESS.2021.3058537,Yes,PMC8675557,34976571.0,2022,2022-01-04,Journal Article,Peer reviewed (PubMed),1,a review on deep learning techniques for the diagnosis of novel coronavirus (covid-19),"Novel coronavirus (COVID-19) outbreak, has raised a calamitous situation all over the world and has become one of the most acute and severe ailments in the past hundred years. The prevalence rate of COVID-19 is rapidly rising every day throughout the globe. Although no vaccines for this pandemic have been discovered yet, deep learning techniques proved themselves to be a powerful tool in the arsenal used by clinicians for the automatic diagnosis of COVID-19. This paper aims to overview the recently developed systems based on deep learning techniques using different medical imaging modalities like Computer Tomography (CT) and X-ray. This review specifically discusses the systems developed for COVID-19 diagnosis using deep learning techniques and provides insights on well-known data sets used to train these networks. It also highlights the data partitioning techniques and various performance measures developed by researchers in this field. A taxonomy is drawn to categorize the recent works for proper insight. Finally, we conclude by addressing the challenges associated with the use of deep learning methods for COVID-19 detection and probable future trends in this research area. The aim of this paper is to facilitate experts (medical or otherwise) and technicians in understanding the ways deep learning techniques are used in this regard and how they can be potentially further utilized to combat the outbreak of COVID-19.",220,COVID-19,93.0,IEEE Access,Transfer Learning;Research Personnel;Disease Outbreaks;Tomography,1.8113521854507785e-06,48.20000000000006,3.4563814609337e-06,97.0,0.0,,Review,Multimodal
35039620,10.1038/s41598-022-05052-x,Yes,PMC8763911,35039620.0,2022,2022-01-19,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,objective evaluation of deep uncertainty predictions for covid-19 detection,"Deep neural networks (DNNs) have been widely applied for detecting COVID-19 in medical images. Existing studies mainly apply transfer learning and other data representation strategies to generate accurate point estimates. The generalization power of these networks is always questionable due to being developed using small datasets and failing to report their predictive confidence. Quantifying uncertainties associated with DNN predictions is a prerequisite for their trusted deployment in medical settings. Here we apply and evaluate three uncertainty quantification techniques for COVID-19 detection using chest X-Ray (CXR) images. The novel concept of uncertainty confusion matrix is proposed and new performance metrics for the objective evaluation of uncertainty estimates are introduced. Through comprehensive experiments, it is shown that networks pertained on CXR images outperform networks pretrained on natural image datasets such as ImageNet. Qualitatively and quantitatively evaluations also reveal that the predictive uncertainty estimates are statistically higher for erroneous predictions than correct predictions. Accordingly, uncertainty quantification methods are capable of flagging risky predictions with high uncertainty estimates. We also observe that ensemble methods more reliably capture uncertainties during the inference. DNN-based solutions for COVID-19 detection have been mainly proposed without any principled mechanism for risk mitigation. Previous studies have mainly focused on on generating single-valued predictions using pretrained DNNs. In this paper, we comprehensively apply and comparatively evaluate three uncertainty quantification techniques for COVID-19 detection using chest X-Ray images. The novel concept of uncertainty confusion matrix is proposed and new performance metrics for the objective evaluation of uncertainty estimates are introduced for the first time. Using these new uncertainty performance metrics, we quantitatively demonstrate when we could trust DNN predictions for COVID-19 detection from chest X-rays. It is important to note the proposed novel uncertainty evaluation metrics are generic and could be applied for evaluation of probabilistic forecasts in all classification problems.",299,COVID-19;Confusion,16.0,Sci Rep,Transfer Learning;Other Topics,1.0778556262218115e-06,11.199999999999998,1.5474974809219123e-06,18.0,0.0,External,2. Detection/Diagnosis,X-Ray
35054267,10.3390/diagnostics12010101,Yes,PMC8774807,35054267.0,2022,2022-01-22,Journal Article,Peer reviewed (PubMed),1,deep learning-based four-region lung segmentation in chest radiography for covid-19 diagnosis,"Imaging plays an important role in assessing the severity of COVID-19 pneumonia. Recent COVID-19 research indicates that the disease progress propagates from the bottom of the lungs to the top. However, chest radiography (CXR) cannot directly provide a quantitative metric of radiographic opacities, and existing AI-assisted CXR analysis methods do not quantify the regional severity. In this paper, to assist the regional analysis, we developed a fully automated framework using deep learning-based four-region segmentation and detection models to assist the quantification of COVID-19 pneumonia. Specifically, a segmentation model is first applied to separate left and right lungs, and then a detection network of the carina and left hilum is used to separate upper and lower lungs. To improve the segmentation performance, an ensemble strategy with five models is exploited. We evaluated the clinical relevance of the proposed method compared with the radiographic assessment of the quality of lung edema (RALE) annotated by physicians. Mean intensities of segmented four regions indicate a positive correlation to the regional extent and density scores of pulmonary opacities based on the RALE. Therefore, the proposed method can accurately assist the quantification of regional pulmonary opacities of COVID-19 pneumonia patients.",194,COVID-19;Edema;Pneumonia;Rales,5.0,Diagnostics (Basel),Other Topics,9.03080757043512e-07,4.2,9.99235006617322e-07,7.0,0.0,External,Segmentation-only,X-Ray
35110593,10.1038/s41598-022-05532-0,Yes,PMC8810911,35110593.0,2022,2022-02-04,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,effective deep learning approaches for predicting covid-19 outcomes from chest computed tomography volumes,"The rapid evolution of the novel coronavirus disease (COVID-19) pandemic has resulted in an urgent need for effective clinical tools to reduce transmission and manage severe illness. Numerous teams are quickly developing artificial intelligence approaches to these problems, including using deep learning to predict COVID-19 diagnosis and prognosis from chest computed tomography (CT) imaging data. In this work, we assess the value of aggregated chest CT data for COVID-19 prognosis compared to clinical metadata alone. We develop a novel patient-level algorithm to aggregate the chest CT volume into a 2D representation that can be easily integrated with clinical metadata to distinguish COVID-19 pneumonia from chest CT volumes from healthy participants and participants with other viral pneumonia. Furthermore, we present a multitask model for joint segmentation of different classes of pulmonary lesions present in COVID-19 infected lungs that can outperform individual segmentation models for each task. We directly compare this multitask segmentation approach to combining feature-agnostic volumetric CT classification feature maps with clinical metadata for predicting mortality. We show that the combination of features derived from the chest CT volumes improve the AUC performance to 0.80 from the 0.52 obtained by using patients' clinical data alone. These approaches enable the automated extraction of clinically relevant features from chest CT volumes for risk stratification of COVID-19 patients.",215,"COVID-19;COVID-19 Pandemic;Pneumonia;Pneumonia, Viral",6.0,Sci Rep,Image Processing;Lung Diseases;Area under Curve;Map;Cone-Beam Computed Tomography,1.050123951436436e-06,22.60000000000001,2.343267743255214e-06,37.0,0.0,External,4. Prognosis/Treatment,CT
35123135,10.1016/j.compbiomed.2022.105274,Yes,,35123135.0,2022,2022-02-06,Journal Article,Peer reviewed (PubMed),1,dense dilated deep multiscale supervised u-network for biomedical image segmentation,"Biomedical image segmentation is essential for computerized medical image analysis. Deep learning algorithms allow us to design state-of-the-art models for solving segmentation problems. The U-Net and its variants have provided positive results across various datasets. However, the existing networks have the same receptive field at each level and the models are supervised only at the shallow level. Considering these two ideas, we have proposed the D3MSU-Net where the field of view in each level is varied depending upon the depth of the resolution layer and the model is supervised at each resolution level. We have evaluated our network in eight benchmark datasets such as Electron Microscopy, Lung segmentation, Montgomery Chest X-ray, Covid-Radiopaedia, Wound, Medetec, Brain MRI, and Covid-19 lung CT dataset. Additionally, we have provided the performance for various ablations. The experimental results show the superiority of the proposed network. The proposed D3MSU-Net and ablation models are available at GitHub",150,COVID-19;Wounds,3.0,Comput Biol Med,Art;Algorithms,9.45518123180328e-07,2.8,8.831770598710012e-07,4.0,0.0,External,Segmentation-only,Multimodal
35154355,10.1016/j.bspc.2022.103561,Yes,PMC8818345,35154355.0,2022,2022-02-15,Journal Article,Peer reviewed (PubMed),1,automated lung ultrasound scoring for evaluation of coronavirus disease 2019 pneumonia using two-stage cascaded deep learning model,"Coronavirus disease 2019 (COVID-19) pneumonia has erupted worldwide, causing massive population deaths and huge economic losses. In clinic, lung ultrasound (LUS) plays an important role in the auxiliary diagnosis of COVID-19 pneumonia. However, the lack of medical resources leads to the low using efficiency of the LUS, to address this problem, a novel automated LUS scoring system for evaluating COVID-19 pneumonia based on the two-stage cascaded deep learning model was proposed in this paper. 18,330 LUS images collected from 26 COVID-19 pneumonia patients were successfully assigned scores by two experienced doctors according to the designed four-level scoring standard for training the model. At the first stage, we made a secondary selection of these scored images through five ResNet-50 models and five-fold cross validation to obtain the available 12,949 LUS images which were highly relevant to the initial scoring results. At the second stage, three deep learning models including ResNet-50, Vgg-19, and GoogLeNet were formed the cascaded scored model and trained using the new dataset, whose predictive result was obtained by the voting mechanism. In addition, 1000 LUS images collected another 5 COVID-19 pneumonia patients were employed to test the model. Experiments results showed that the automated LUS scoring model was evaluated in terms of accuracy, sensitivity, specificity, and F1-score, being 96.1%, 96.3%, 98.8%, and 96.1%, respectively. They proved the proposed two-stage cascaded deep learning model could automatically score an LUS image, which has great potential for application to the clinics on various occasions.",243,COVID-19;Death;Pneumonia,4.0,Biomed Signal Process Control,Other Topics,9.613819862135928e-07,12.999999999999996,1.6418877261909674e-06,21.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
35167608,10.1371/journal.pone.0263922,Yes,PMC8846502,35167608.0,2022,2022-02-16,"Journal Article;Research Support, N.I.H., Extramural;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,augmenting existing deterioration indices with chest radiographs to predict clinical deterioration,"When hospitals are at capacity, accurate deterioration indices could help identify low-risk patients as potential candidates for home care programs and alleviate hospital strain. To date, many existing deterioration indices are based entirely on structured data from the electronic health record (EHR) and ignore potentially useful information from other sources. To improve the accuracy of existing deterioration indices by incorporating unstructured imaging data from chest radiographs. Machine learning models were trained to predict deterioration of patients hospitalized with acute dyspnea using existing deterioration index scores and chest radiographs. Models were trained on hospitalized patients without coronavirus disease 2019 (COVID-19) and then subsequently tested on patients with COVID-19 between January 2020 and December 2020 at a single tertiary care center who had at least one radiograph taken within 48 hours of hospital admission. Patient deterioration was defined as the need for invasive or non-invasive mechanical ventilation, heated high flow nasal cannula, IV vasopressor administration or in-hospital mortality at any time following admission. The EPIC deterioration index was augmented with unstructured data from chest radiographs to predict risk of deterioration. We compared discriminative performance of the models with and without incorporating chest radiographs using AUC (AUROC), focusing on comparing the fraction and total patients identified as low risk at different negative predictive values (NPV). Data from 6278 hospitalizations were analyzed, including 5562 hospitalizations without COVID-19 (training cohort) and 716 with COVID-19 (216 in validation, 500 in held-out test cohort). At a NPV of 0.95, the best-performing image-augmented deterioration index identified 49 more individuals as low-risk compared to the deterioration index based on clinical data alone in the first 48 hours of admission. At a NPV of 0.9, the EPIC image-augmented deterioration index identified 26 more individuals as low-risk compared to the deterioration index based on clinical data alone in the first 48 hours of admission. Augmenting existing deterioration indices with chest radiographs results in better identification of low-risk patients. The model augmentation strategy could be used in the future to incorporate other forms of unstructured data into existing disease models.",338,COVID-19;Clinical Deterioration;Dyspnea;Strains,3.0,PLoS One,Health Care;Predictive Value;Risk Factors;ROC Curve;Ventilation;Retrospective Studies;Age,9.621134860695946e-07,11.999999999999996,1.60251199802372e-06,20.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,X-Ray
35180499,10.1016/j.compbiomed.2022.105233,Yes,PMC8798789,35180499.0,2022,2022-02-19,Journal Article;Review,Peer reviewed (PubMed),1,a review of deep learning-based detection methods for covid-19,"COVID-19 is a fast-spreading pandemic, and early detection is crucial for stopping the spread of infection. Lung images are used in the detection of coronavirus infection. Chest X-ray (CXR) and computed tomography (CT) images are available for the detection of COVID-19. Deep learning methods have been proven efficient and better performing in many computer vision and medical imaging applications. In the rise of the COVID pandemic, researchers are using deep learning methods to detect coronavirus infection in lung images. In this paper, the currently available deep learning methods that are used to detect coronavirus infection in lung images are surveyed. The available methodologies, public datasets, datasets that are used by each method and evaluation metrics are summarized in this paper to help future researchers. The evaluation metrics that are used by the methods are comprehensively compared.",136,COVID-19;Coronavirus Infections;Infections,24.0,Comput Biol Med,Other Topics,1.0333748210394552e-06,26.400000000000013,2.6337278699917427e-06,42.0,0.0,,Review,Multimodal
35233327,10.7759/cureus.21656,Yes,PMC8881892,35233327.0,2022,2022-03-03,Journal Article,Peer reviewed (PubMed),1,evaluating the association between comorbidities and covid-19 severity scoring on chest ct examinations between the two waves of covid-19: an imaging study using artificial intelligence,"Background Coronavirus disease 2019 (COVID-19) has accounted for over 352 million cases and five million deaths globally. Although it affects populations across all nations, developing or transitional, of all genders and ages, the extent of the specific involvement is not very well known. This study aimed to analyze and determine how different were the first and second waves of the COVID-19 pandemic by assessing computed tomography severity scores (CT-SS). Methodology This was a retrospective, cross-sectional, observational study performed at a tertiary care Institution. We included 301 patients who underwent CT of the chest between June and October 2020 and 1,001 patients who underwent CT of the chest between February and April 2021. All included patients were symptomatic and were confirmed to be COVID-19 positive. We compared the CT-SS between the two datasets. In addition, we analyzed the distribution of CT-SS concerning age, comorbidities, and gender, as well as their differences between the two waves of COVID-19. Analysis was performed using the SPSS version 22 (IBM Corp., Armonk, NY, USA). The artificial intelligence platform U-net architecture with Xception encoder was used in the analysis. Results The study data revealed that while the mean CT-SS did not differ statistically between the two waves of COVID-19, the age group most affected in the second wave was almost a decade younger. While overall the disease had a predilection toward affecting males, our findings showed that females were more afflicted in the second wave of COVID-19 compared to the first wave. In particular, the disease had an increased severity in cases with comorbidities such as hypertension, diabetes mellitus, bronchial asthma, and tuberculosis. Conclusions This assessment demonstrated no significant difference in radiological severity score between the two waves of COVID-19. The secondary objective revealed that the two waves showed demographical differences. Hence, we iterate that no demographical subset of the population should be considered low risk as the disease manifestation was heterogeneous.",316,Asthma;COVID-19;COVID-19 Pandemic;Death;Diabetes Mellitus;Hypertension;Tuberculosis,1.0,Cureus,Health Care;Other Topics,9.029557231843552e-07,4.8,1.034088549183546e-06,8.0,0.0,Self-recorded/clinical,1. Risk identification,CT
35257012,10.1155/2022/8925930,Yes,PMC8898107,35257012.0,2022,2022-03-09,Journal Article,Peer reviewed (PubMed),1,an improved covid-19 detection using gan-based data augmentation and novel qunet-based classification,"COVID-19 is a fatal disease caused by the SARS-CoV-2 virus that has caused around 5.3 Million deaths globally as of December 2021. The detection of this disease is a time taking process that have worsen the situation around the globe, and the disease has been identified as a world pandemic by the WHO. Deep learning-based approaches are being widely used to diagnose the COVID-19 cases, but the limitation of immensity in the publicly available dataset causes the problem of model over-fitting. Modern artificial intelligence-based techniques can be used to increase the dataset to avoid from the over-fitting problem. This research work presents the use of various deep learning models along with the state-of-the-art augmentation methods, namely, classical and generative adversarial network- (GAN-) based data augmentation. Furthermore, four existing deep convolutional networks, namely, DenseNet-121, InceptionV3, Xception, and ResNet101 have been used for the detection of the virus in X-ray images after training on augmented dataset. Additionally, we have also proposed a novel convolutional neural network (QuNet) to improve the COVID-19 detection. The comparative analysis of achieved results reflects that both QuNet and Xception achieved high accuracy with classical augmented dataset, whereas QuNet has also outperformed and delivered 90% detection accuracy with GAN-based augmented dataset.",203,COVID-19;Death,7.0,Biomed Res Int,Art;Image Processing;Neural Networks,1.0275656287195513e-06,14.999999999999996,1.868181974078262e-06,25.0,0.0,External,2. Detection/Diagnosis,X-Ray
35277285,10.1016/j.ultrasmedbio.2022.01.023,Yes,PMC8818339,35277285.0,2022,2022-03-13,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,evaluation of pulmonary edema using ultrasound imaging in patients with covid-19 pneumonia based on a non-local channel attention resnet,"Recent research has revealed that COVID-19 pneumonia is often accompanied by pulmonary edema. Pulmonary edema is a manifestation of acute lung injury (ALI), and may progress to hypoxemia and potentially acute respiratory distress syndrome (ARDS), which have higher mortality. Precise classification of the degree of pulmonary edema in patients is of great significance in choosing a treatment plan and improving the chance of survival. Here we propose a deep learning neural network named Non-local Channel Attention ResNet to analyze the lung ultrasound images and automatically score the degree of pulmonary edema of patients with COVID-19 pneumonia. The proposed method was designed by combining the ResNet with the non-local module and the channel attention mechanism. The non-local module was used to extract the information on characteristics of A-lines and B-lines, on the basis of which the degree of pulmonary edema could be defined. The channel attention mechanism was used to assign weights to decisive channels. The data set contains 2220 lung ultrasound images provided by Huoshenshan Hospital, Wuhan, China, of which 2062 effective images with accurate scores assigned by two experienced clinicians were used in the experiment. The experimental results indicated that our method achieved high accuracy in classifying the degree of pulmonary edema in patients with COVID-19 pneumonia by comparison with previous deep learning methods, indicating its potential to monitor patients with COVID-19 pneumonia.",224,"Acute Lung Injury;COVID-19;Hypoxemia;Pneumonia;Pulmonary Edema;Respiratory Distress Syndrome, Acute",3.0,Ultrasound Med Biol,Respiratory Distress Syndrome;Ultrasonography,9.115410805034936e-07,4.2,1.0009240881177132e-06,7.0,0.0,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
35281724,10.1016/j.cmpbup.2022.100054,Yes,PMC8898857,35281724.0,2022,2022-03-15,Journal Article;Review,Peer reviewed (PubMed),1,a comparative study of x-ray and ct images in covid-19 detection using image processing and deep learning techniques,"The deadly coronavirus has not just devastated the lives of millions but has put the entire healthcare system under tremendous pressure. Early diagnosis of COVID-19 plays a significant role in isolating the positive cases and preventing the further spread of the disease. The medical images along with deep learning models provided faster and more accurate results in the detection of COVID-19. This article extensively reviews the recent deep learning techniques for COVID-19 diagnosis. The research articles discussed reveal that Convolutional Neural Network (CNN) is the most popular deep learning algorithm in detecting COVID-19 from medical images. An overview of the necessity of pre-processing the medical images, transfer learning and data augmentation techniques to deal with data scarcity problems, use of pre-trained models to save time and the role of medical images in the automatic detection of COVID-19 are summarized. This article also provides a sensible outlook for the young researchers to develop highly effective CNN models coupled with medical images in the early detection of the disease.",167,COVID-19,4.0,Comput Methods Programs Biomed Update,Health Care;Transfer Learning;Algorithms;Research Personnel;Tomography;Health Care Systems;Early Diagnosis,9.97388755582209e-07,22.0,2.256293679067161e-06,34.0,0.0,,Review,Multimodal
35282403,10.1007/s11042-022-12214-6,Yes,PMC8901869,35282403.0,2022,2022-03-15,Journal Article,Peer reviewed (PubMed),1,quantifying prognosis severity of covid-19 patients from deep learning based analysis of ct chest images,"The COVID-19 pandemic has affected all the countries in the world with its droplet spread mode. The colossal amount of cases has strained all the healthcare systems due to the serious nature of infections especially for people with comorbidities. A very high specificity Reverse Transcriptase-Polymerase Chain Reaction (RT-PCR) test is the principal technique in use for diagnosing the COVID-19 patients. Also, CT scans have helped medical professionals in patient severity estimation and progression tracking of COVID-19 virus. In study we present our own extensible COVID-19 viral infection tracking prognosis technique. It uses annotated dataset of CT chest scan slice images created with the help of medical professionals. The annotated dataset contains bounding box coordinates of different features for COVID-19 detection like ground glass opacities, crazy paving pattern, consolidations, lesions etc. We qualitatively identify the severity of the patient for later prognosis stages in our study to assist medical staff for patient prioritization. First we detected COVID-19 positive patients with pre-trained Siamese Neural Network (SNN) which obtained 87.6% accuracy, 87.1% F1-Score and 95.1% AUC scores. These metrics were achieved after removal of 40% quantitatively highly similar images from the COVID-CT dataset. This reduced dataset was further medically annotated with COVID-19 features for bounding box detection. After this we assigned severity scores to detected COVID-19 features and calculated the cumulative severity score for COVID-19 patients. For qualitative patient prioritization with prognosis clinical assistance information, we finally converted this score into a multi-classification problem which obtained 47% weighted-average F1-score.",246,COVID-19;COVID-19 Pandemic;Infections;Virus Diseases,2.0,Multimed Tools Appl,Health Care;Polymerase Chain Reaction;Area under Curve,9.283596153597562e-07,8.999999999999998,1.3673642924939198e-06,15.0,0.0,External,4. Prognosis/Treatment,CT
35305501,10.1016/j.compbiomed.2022.105350,Yes,PMC8890789,35305501.0,2022,2022-03-20,Journal Article;Review,Peer reviewed (PubMed),1,covid-19 image classification using deep learning: advances challenges and opportunities,"Corona Virus Disease-2019 (COVID-19), caused by Severe Acute Respiratory Syndrome-Corona Virus-2 (SARS-CoV-2), is a highly contagious disease that has affected the lives of millions around the world. Chest X-Ray (CXR) and Computed Tomography (CT) imaging modalities are widely used to obtain a fast and accurate diagnosis of COVID-19. However, manual identification of the infection through radio images is extremely challenging because it is time-consuming and highly prone to human errors. Artificial Intelligence (AI)-techniques have shown potential and are being exploited further in the development of automated and accurate solutions for COVID-19 detection. Among AI methodologies, Deep Learning (DL) algorithms, particularly Convolutional Neural Networks (CNN), have gained significant popularity for the classification of COVID-19. This paper summarizes and reviews a number of significant research publications on the DL-based classification of COVID-19 through CXR and CT images. We also present an outline of the current state-of-the-art advances and a critical discussion of open challenges. We conclude our study by enumerating some future directions of research in COVID-19 imaging classification.",167,COVID-19;Infections;Severe Acute Respiratory Syndrome;Virus Diseases,10.0,Comput Biol Med,Art;Algorithms;Neural Networks;Tomography;Other Topics,1.1453616571251995e-06,42.80000000000005,3.860216046101669e-06,68.0,0.0,,Review,Multimodal
35310011,10.1007/s11063-022-10785-x,Yes,PMC8924740,35310011.0,2022,2022-03-22,Journal Article,Peer reviewed (PubMed),1,chs-net: a deep learning approach for hierarchical segmentation of covid-19 via ct images,"The pandemic of novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) also known as COVID-19 has been spreading worldwide, causing rampant loss of lives. Medical imaging such as computed tomography (CT), X-ray, etc., plays a significant role in diagnosing the patients by presenting the visual representation of the functioning of the organs. However, for any radiologist analyzing such scans is a tedious and time-consuming task. The emerging deep learning technologies have displayed its strength in analyzing such scans to aid in the faster diagnosis of the diseases and viruses such as COVID-19. In the present article, an automated deep learning based model, COVID-19 hierarchical segmentation network (CHS-Net) is proposed that functions as a semantic hierarchical segmenter to identify the COVID-19 infected regions from lungs contour via CT medical imaging using two cascaded residual attention inception U-Net (RAIU-Net) models. RAIU-Net comprises of a residual inception U-Net model with spectral spatial and depth attention network (SSD) that is developed with the contraction and expansion phases of depthwise separable convolutions and hybrid pooling (max and spectral pooling) to efficiently encode and decode the semantic and varying resolution information. The CHS-Net is trained with the segmentation loss function that is the defined as the average of binary cross entropy loss and dice loss to penalize false negative and false positive predictions. The approach is compared with the recently proposed approaches and evaluated using the standard metrics like accuracy, precision, specificity, recall, dice coefficient and Jaccard similarity along with the visualized interpretation of the model prediction with GradCam++ and uncertainty maps. With extensive trials, it is observed that the proposed approach outperformed the recently proposed approaches and effectively segments the COVID-19 infected regions in the lungs.",281,COVID-19;Severe Acute Respiratory Syndrome,7.0,Neural Process Lett,Specificity;Hybrids;Pandemics;Semantics;Radiologists;Viruses;Entropy;Lung Diseases;Map,1.041346855773588e-06,14.999999999999996,1.7822544089956833e-06,23.0,0.0,External,Segmentation-only,X-Ray
35316609,10.1146/annurev-bioeng-110220-012203,Yes,,35316609.0,2022,2022-03-23,"Journal Article;Review;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,deep learning and medical image analysis for covid-19 diagnosis and prediction,"The coronavirus disease 2019 (COVID-19) pandemic has imposed dramatic challenges to health-care organizations worldwide. To combat the global crisis, the use of thoracic imaging has played a major role in the diagnosis, prediction, and management of COVID-19 patients with moderate to severe symptoms or with evidence of worsening respiratory status. In response, the medical image analysis community acted quickly to develop and disseminate deep learning models and tools to meet the urgent need of managing and interpreting large amounts of COVID-19 imaging data. This review aims to not only summarize existing deep learning and medical image analysis methods but also offer in-depth discussions and recommendations for future investigations. We believe that the wide availability of high-quality, curated, and benchmarked COVID-19 imaging data sets offers the great promise of a transformative test bed to develop, validate, and disseminate novel deep learning methods in the frontiers of data science and artificial intelligence.",150,COVID-19;COVID-19 Pandemic,9.0,Annu Rev Biomed Eng,Health Care;COVID-19 Testing;Other Topics,9.500958393280848e-07,10.799999999999995,1.5035453975018752e-06,18.0,0.0,,Review,Multimodal
35320098,10.1109/TUFFC.2022.3161716,Yes,,35320098.0,2022,2022-03-24,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,deep learning-based classification of reduced lung ultrasound data from covid-19 patients,"The application of lung ultrasound (LUS) imaging for the diagnosis of lung diseases has recently captured significant interest within the research community. With the ongoing COVID-19 pandemic, many efforts have been made to evaluate LUS data. A four-level scoring system has been introduced to semiquantitatively assess the state of the lung, classifying the patients. Various deep learning (DL) algorithms supported with clinical validations have been proposed to automate the stratification process. However, no work has been done to evaluate the impact on the automated decision by varying pixel resolution and bit depth, leading to the reduction in size of overall data. This article evaluates the performance of DL algorithm over LUS data with varying pixel and gray-level resolution. The algorithm is evaluated over a dataset of 448 LUS videos captured from 34 examinations of 20 patients. All videos are resampled by a factor of 2, 3, and 4 of original resolution, and quantized to 128, 64, and 32 levels, followed by score prediction. The results indicate that the automated scoring shows negligible variation in accuracy when it comes to the quantization of intensity levels only. Combined effect of intensity quantization with spatial down-sampling resulted in a prognostic agreement ranging from 73.5% to 82.3%.These results also suggest that such level of prognostic agreement can be achieved over evaluation of data reduced to 32 times of its original size. Thus, laying foundation to efficient processing of data in resource constrained environments.",239,COVID-19;COVID-19 Pandemic;Lung Diseases,4.0,IEEE Trans Ultrason Ferroelectr Freq Control,Ultrasonography;Other Topics,9.911753513400325e-07,6.999999999999999,1.2096529053619696e-06,11.0,0.0,Self-recorded/clinical,4. Prognosis/Treatment,Ultrasound
35359591,10.3389/fmolb.2022.836862,Yes,PMC8961806,35359591.0,2022,2022-04-02,Journal Article,Peer reviewed (PubMed),1,exploring new characteristics: using deep learning and 3d reconstruction to compare the original covid-19 and its delta variant based on chest ct,"Computer-aided diagnostic methods were used to compare the characteristics of the Original COVID-19 and its Delta Variant. This was a retrospective study. A deep learning segmentation model was applied to segment lungs and infections in CT. Three-dimensional (3D) reconstruction was used to create 3D models of the patient's lungs and infections. A stereoscopic segmentation method was proposed, which can subdivide the 3D lung into five lobes and 18 segments. An expert-based CT scoring system was improved and artificial intelligence was used to automatically score instead of visual score. Non-linear regression and quantitative analysis were used to analyze the dynamic changes in the percentages of infection (POI). The POI in the five lung lobes of all patients were calculated and converted into CT scores. The CT scores of Original COVID-19 patients and Delta Variant patients since the onset of initial symptoms were fitted over time, respectively. The peak was found to occur on day 11 in Original COVID-19 patients and on day 15 in Delta Variant patients. The time course of lung changes in CT of Delta Variant patients was redetermined as early stage (0-3 days), progressive and peak stage (4-16 days), and absorption stage (17-42 days). The first RT-PCR negative time in Original COVID-19 patients appeared earlier than in Delta Variant patients (22 vs. 39, p < 0.001). Delta Variant patients had more re-detectable positive RT-PCR test results than Original COVID-19 patients after the first negative RT-PCR time (30.5% vs. 17.1%). In the early stage, CT scores in the right lower lobe were significantly different (Delta Variant vs. Original COVID-19, 0.8 vs. 1.3, p = 0.039). In the absorption stage, CT scores of the right middle lobes were significantly different (Delta Variant vs. Original COVID-19, 0.6 vs. 0.3, p = 0.012). The left and the right lower lobes contributed most to lung involvement at any given time. Compared with the Original COVID-19, the Delta Variant has a longer lung change duration, more re-detectable positive RT-PCR test results, different locations of pneumonia, and more lesions in the early stage, and the peak of infection occurred later.",345,COVID-19;Infections;Pneumonia,1.0,Front Mol Biosci,Linear Regression;Polymerase Chain Reaction;Other Topics;Retrospective Studies,1.0000244519682116e-06,8.399999999999999,1.3545588375281257e-06,14.0,0.0,External,5. Post-hoc,CT
35415768,10.1007/s10439-022-02958-5,Yes,PMC9005164,35415768.0,2022,2022-04-14,Journal Article;Review,Peer reviewed (PubMed),1,detection of covid-19 from ct and chest x-ray images using deep learning models,"Coronavirus 2019 (COVID-19) is a highly transmissible and pathogenic virus caused by severe respiratory syndrome coronavirus 2 (SARS-CoV-2), which first appeared in Wuhan, China, and has since spread in the whole world. This pathology has caused a major health crisis in the world. However, the early detection of this anomaly is a key task to minimize their spread. Artificial intelligence is one of the approaches commonly used by researchers to discover the problems it causes and provide solutions. These estimates would help enable health systems to take the necessary steps to diagnose and track cases of COVID. In this review, we intend to offer a novel method of automatic detection of COVID-19 using tomographic images (CT) and radiographic images (Chest X-ray). In order to improve the performance of the detection system for this outbreak, we used two deep learning models: the VGG and ResNet. The results of the experiments show that our proposed models achieved the best accuracy of 99.35 and 96.77% respectively for VGG19 and ResNet50 with all the chest X-ray images.",173,COVID-19;Syndrome,4.0,Ann Biomed Eng,Research Personnel;Disease Outbreaks,1.4237608515820057e-06,76.40000000000003,6.4349211054209294e-06,124.0,0.0,,Review,Multimodal
35418698,10.1038/s41598-022-10136-9,Yes,PMC9007057,35418698.0,2022,2022-04-15,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,deep learning of chest x-rays can predict mechanical ventilation outcome in icu-admitted covid-19 patients,"The COVID-19 pandemic repeatedly overwhelms healthcare systems capacity and forced the development and implementation of triage guidelines in ICU for scarce resources (e.g. mechanical ventilation). These guidelines were often based on known risk factors for COVID-19. It is proposed that image data, specifically bedside computed X-ray (CXR), provide additional predictive information on mortality following mechanical ventilation that can be incorporated in the guidelines. Deep transfer learning was used to extract convolutional features from a systematically collected, multi-institutional dataset of COVID-19 ICU patients. A model predicting outcome of mechanical ventilation (remission or mortality) was trained on the extracted features and compared to a model based on known, aggregated risk factors. The model reached a 0.702 AUC at predicting mechanical ventilation outcome from pre-intubation CXRs, higher than the risk factor model. Combining imaging data and risk factors increased model performance to 0.743 AUC. Additionally, a post-hoc analysis showed an increase performance on high-quality than low-quality CXRs, suggesting that using only high-quality images would result in an even stronger model.",167,COVID-19;COVID-19 Pandemic,2.0,Sci Rep,Health Care;Transfer Learning;Risk Factors;Health Care Systems;Area under Curve,9.389525709997152e-07,10.199999999999998,1.4699794011907078e-06,17.0,0.0,External,4. Prognosis/Treatment,X-Ray
35431606,10.1007/s11042-022-12640-6,Yes,PMC8993038,35431606.0,2022,2022-04-19,Journal Article,Peer reviewed (PubMed),1,dgcnn: deep convolutional generative adversarial network based convolutional neural network for diagnosis of covid-19,"The latest threat to global health is the coronavirus disease 2019 (COVID-19) pandemic. To prevent COVID-19, recognizing and isolating the infected patients is an essential step. The primary diagnosis method is Reverse Transcription Polymerase Chain Reaction (RT-PCR) test. However, the sensitivity of this test is not satisfactory to successfully control the COVID-19 outbreak. Although there exist many datasets of chest X-rays (CXR) images, but few COVID-19 CXRs are presently accessible owing to privacy of patients. Thus, many researchers have utilized data augmentation techniques to augment the datasets. But, it may cause over-fitting issues, as the existing data augmentation techniques include small modifications to CXRs. Therefore, in this paper, an efficient deep convolutional generative adversarial network and convolutional neural network (DGCNN) is designed to diagnose COVID-19 suspected subjects. Deep convolutional generative adversarial network (DGAN) consists of two networks trained adversarially such that one generates fake images and the other differentiates between them. Thereafter, convolutional neural network (CNN) is utilized for classification purpose. Extensive experiments are conducted to evaluate the performance of the proposed DGCNN. Performance analysis demonstrates that DGCNN can highly improves the diagnosis performance.",184,COVID-19;COVID-19 Pandemic,0.0,Multimed Tools Appl,Research Personnel;Disease Outbreaks;Polymerase Chain Reaction;Reverse Transcription,1.0657868164705165e-06,19.200000000000003,2.20079869927614e-06,32.0,0.0,External,5. Post-hoc,X-Ray
35431611,10.1007/s11042-022-12156-z,Yes,PMC8989406,35431611.0,2022,2022-04-19,Journal Article,Peer reviewed (PubMed),1,covid-cxnet: detecting covid-19 in frontal chest x-ray images using deep learning,"One of the primary clinical observations for screening the novel coronavirus is capturing a chest x-ray image. In most patients, a chest x-ray contains abnormalities, such as consolidation, resulting from COVID-19 viral pneumonia. In this study, research is conducted on efficiently detecting imaging features of this type of pneumonia using deep convolutional neural networks in a large dataset. It is demonstrated that simple models, alongside the majority of pretrained networks in the literature, focus on irrelevant features for decision-making. In this paper, numerous chest x-ray images from several sources are collected, and one of the largest publicly accessible datasets is prepared. Finally, using the transfer learning paradigm, the well-known CheXNet model is utilized to develop COVID-CXNet. This powerful model is capable of detecting the novel coronavirus pneumonia based on relevant and meaningful features with precise localization. COVID-CXNet is a step towards a fully automated and robust COVID-19 detection system.",149,"COVID-19;Pneumonia;Pneumonia, Viral",42.0,Multimed Tools Appl,Transfer Learning;Other Topics,1.0681140360763133e-06,22.6,2.324794728944484e-06,35.0,0.0,External,2. Detection/Diagnosis,X-Ray
35453917,10.3390/diagnostics12040869,Yes,PMC9025113,35453917.0,2022,2022-04-24,Journal Article;Review,Peer reviewed (PubMed),1,a literature review on the use of artificial intelligence for the diagnosis of covid-19 on ct and chest x-ray,"A COVID-19 diagnosis is primarily determined by RT-PCR or rapid lateral-flow testing, although chest imaging has been shown to detect manifestations of the virus. This article reviews the role of imaging (CT and X-ray), in the diagnosis of COVID-19, focusing on the published studies that have applied artificial intelligence with the purpose of detecting COVID-19 or reaching a differential diagnosis between various respiratory infections. In this study, ArXiv, MedRxiv, PubMed, and Google Scholar were searched for studies using the criteria terms 'deep learning', 'artificial intelligence', 'medical imaging', 'COVID-19' and 'SARS-CoV-2'. The identified studies were assessed using a modified version of the Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD). Twenty studies fulfilled the inclusion criteria for this review. Out of those selected, 11 papers evaluated the use of artificial intelligence (AI) for chest X-ray and 12 for CT. The size of datasets ranged from 239 to 19,250 images, with sensitivities, specificities and AUCs ranging from 0.789-1.00, 0.843-1.00 and 0.850-1.00. While AI demonstrates excellent diagnostic potential, broader application of this method is hindered by the lack of relevant comparators in studies, sufficiently sized datasets, and independent testing.",191,COVID-19;Respiratory Tract Infections,5.0,Diagnostics (Basel),Polymerase Chain Reaction;Area under Curve,9.72170304488651e-07,17.199999999999996,1.9357844040571865e-06,28.0,0.0,,Review,Multimodal
35645554,10.1007/s11831-022-09768-x,Yes,PMC9126247,35645554.0,2022,2022-06-02,Journal Article;Review,Peer reviewed (PubMed),1,exploring the deep-learning techniques in detecting the presence of coronavirus in the chest x-ray images: a comprehensive review,"The deadly coronavirus (COVID-19) is one of the dangerous diseases affecting the entire world and is fastly spreading disease. This spread can be reduced by detecting and quarantining the patients at an earlier stage. The most common diagnostic tool for detecting the coronavirus is the Reverse transcription-polymerase chain reaction (RT-PCR) test which is time-consuming and also needs more equipment and manpower. Furthermore, many countries had a deficit of RTPCR kits. This is why it is exceptionally very crucial to develop artificial intelligence (AI) techniques to detect the outbreak of coronavirus. This motivated many researchers to involve deep-learning methods using X-ray images for more decisive analysis. Thus, this paper outlines many papers that used traditional and pre-trained deep learning methods that are newly developed to reduce the spread of COVID-19 disease. Specifically, advanced deep learning methods play a critical role in extracting the features from the chest X-ray images. These features are then used to classify whether the patient is affected with coronavirus or not. Besides, this paper shows that deep learning techniques have probable applications in the medical field.",179,COVID-19,1.0,Arch Comput Methods Eng,Research Personnel;Disease Outbreaks;Polymerase Chain Reaction;Reverse Transcription,9.8005223108865e-07,18.6,2.132411895007014e-06,31.0,0.0,,Review,X-Ray
35692335,10.3389/fpubh.2022.886958,Yes,PMC9174692,35692335.0,2022,2022-06-14,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,automated multi-view multi-modal assessment of covid-19 patients using reciprocal attention and biomedical transform,"Automated severity assessment of coronavirus disease 2019 (COVID-19) patients can help rationally allocate medical resources and improve patients' survival rates. The existing methods conduct severity assessment tasks mainly on a unitary modal and single view, which is appropriate to exclude potential interactive information. To tackle the problem, in this paper, we propose a multi-view multi-modal model to automatically assess the severity of COVID-19 patients based on deep learning. The proposed model receives multi-view ultrasound images and biomedical indices of patients and generates comprehensive features for assessment tasks. Also, we propose a reciprocal attention module to acquire the underlying interactions between multi-view ultrasound data. Moreover, we propose biomedical transform module to integrate biomedical data with ultrasound data to produce multi-modal features. The proposed model is trained and tested on compound datasets, and it yields 92.75% for accuracy and 80.95% for recall, which is the best performance compared to other state-of-the-art methods. Further ablation experiments and discussions conformably indicate the feasibility and advancement of the proposed model.",165,COVID-19,0.0,Front Public Health,Art;Other Topics,9.393111049289876e-07,4.0,9.681414443676878e-07,6.0,0.0,External,3. Monitoring/Severity assessment,Multimodal
35741215,10.3390/diagnostics12061405,Yes,PMC9222177,35741215.0,2022,2022-06-25,Journal Article;Review,Peer reviewed (PubMed),1,lung sonography in critical care medicine,"During the last five decades, lung sonography has developed into a core competency of intensive care medicine. It is a highly accurate bedside tool, with clear diagnostic criteria for most causes of respiratory failure (pneumothorax, pulmonary edema, pneumonia, pulmonary embolism, chronic obstructive pulmonary disease, asthma, and pleural effusion). It helps in distinguishing a hypovolemic from a cardiogenic, obstructive, or distributive shock. In addition to diagnostics, it can also be used to guide ventilator settings, fluid administration, and even antimicrobial therapy, as well as to assess diaphragmatic function. Moreover, it provides risk-reducing guidance during invasive procedures, e.g., intubation, thoracocentesis, or percutaneous dilatational tracheostomy. The recent pandemic has further increased its scope of clinical applications in the management of COVID-19 patients, from their initial presentation at the emergency department, during their hospitalization, and after their discharge into the community. Despite its increasing use, a consensus on education, assessment of competencies, and certification is still missing. Deep learning and artificial intelligence are constantly developing in medical imaging, and contrast-enhanced ultrasound enables new diagnostic perspectives. This review summarizes the clinical aspects of lung sonography in intensive care medicine and provides an overview about current training modalities, diagnostic limitations, and future developments.",197,"Asthma;COVID-19;Hypovolemic;Pleural Effusion;Pneumonia;Pneumothorax;Pulmonary Disease, Chronic Obstructive;Pulmonary Edema;Pulmonary Embolism;Respiratory Failure;Shock",0.0,Diagnostics (Basel),Other Topics,8.639495113515313e-07,0.0,6.679303414150814e-07,0.0,0.0,,Review,Ultrasound
35784006,10.1109/TAI.2021.3062771,Yes,PMC8545030,35784006.0,2021,2021-03-01,Journal Article,Peer reviewed (PubMed),1,a systematic review on the use of ai and ml for fighting the covid-19 pandemic,"Artificial intelligence (AI) and machine learning (ML) have caused a paradigm shift in healthcare that can be used for decision support and forecasting by exploring medical data. Recent studies have shown that AI and ML can be used to fight COVID-19. The objective of this article is to summarize the recent AI- and ML-based studies that have addressed the pandemic. From an initial set of 634 articles, a total of 49 articles were finally selected through an inclusion-exclusion process. In this article, we have explored the objectives of the existing studies (i.e., the role of AI/ML in fighting the COVID-19 pandemic); the context of the studies (i.e., whether it was focused on a specific country-context or with a global perspective; the type and volume of the dataset; and the methodology, algorithms, and techniques adopted in the prediction or diagnosis processes). We have mapped the algorithms and techniques with the data type by highlighting their prediction/classification accuracy. From our analysis, we categorized the objectives of the studies into four groups: disease detection, epidemic forecasting, sustainable development, and disease diagnosis. We observed that most of these studies used deep learning algorithms on image-data, more specifically on chest X-rays and CT scans. We have identified six future research opportunities that we have summarized in this paper. Artificial intelligence (AI) and machine learning (ML) methods have been widely used to assist in the fight against COVID-19 pandemic. A very few in-depth literature reviews have been conducted to synthesize the knowledge and identify future research agenda including a previously published review on data science for COVID-19 in this article. In this article, we synthesized reviewed recent literature that focuses on the usages and applications of AI and ML to fight against COVID-19. We have identified seven future research directions that would guide researchers to conduct future research. The most significant of these are: develop new treatment options, explore the contextual effect and variation in research outcomes, support the health care workforce, and explore the effect and variation in research outcomes based on different types of data.",341,COVID-19;COVID-19 Pandemic,11.0,IEEE Trans Artif Intell,Health Care;Research Personnel;Systematic Review;Classification,2.9491282992876195e-06,75.49599999999997,4.895540047884001e-06,167.0,-1.0,,Review,Multimodal
35788637,10.1038/s41598-022-15327-y,Yes,PMC9252998,35788637.0,2022,2022-07-06,Journal Article,Peer reviewed (PubMed),1,an ml prediction model based on clinical parameters and automated ct scan features for covid-19 patients,"Outcome prediction for individual patient groups is of paramount importance in terms of selection of appropriate therapeutic options, risk communication to patients and families, and allocating resource through optimum triage. This has become even more necessary in the context of the current COVID-19 pandemic. Widening the spectrum of predictor variables by including radiological parameters alongside the usually utilized demographic, clinical and biochemical ones can facilitate building a comprehensive prediction model. Automation has the potential to build such models with applications to time-critical environments so that a clinician will be able to utilize the model outcomes in real-time decision making at bedside. We show that amalgamation of computed tomogram (CT) data with clinical parameters (CP) in generating a Machine Learning model from 302 COVID-19 patients presenting to an acute care hospital in India could prognosticate the need for invasive mechanical ventilation. Models developed from CP alone, CP and radiologist derived CT severity score and CP with automated lesion-to-lung ratio had AUC of 0.87, 0.89, and 0.91, respectively. We show that an operating point on the ROC can be chosen to aid clinicians in risk characterization according to the resource availability and ethical considerations. This approach can be deployed in more general settings, with appropriate calibrations, to predict outcomes of severe COVID-19 patients effectively.",212,COVID-19;COVID-19 Pandemic,3.0,Sci Rep,Other Topics,9.318036782428414e-07,9.599999999999998,1.417851950486706e-06,16.0,-1.0,Self-recorded/clinical,4. Prognosis/Treatment,CT
35789224,10.1109/JSEN.2021.3076767,Yes,PMC8791443,35789224.0,2021,2021-04-30,Journal Article,Peer reviewed (PubMed),1,blockchain-federated-learning and deep learning models for covid-19 detection using ct imaging,"With the increase of COVID-19 cases worldwide, an effective way is required to diagnose COVID-19 patients. The primary problem in diagnosing COVID-19 patients is the shortage and reliability of testing kits, due to the quick spread of the virus, medical practitioners are facing difficulty in identifying the positive cases. The second real-world problem is to share the data among the hospitals globally while keeping in view the privacy concerns of the organizations. Building a collaborative model and preserving privacy are the major concerns for training a global deep learning model. This paper proposes a framework that collects a small amount of data from different sources (various hospitals) and trains a global deep learning model using blockchain-based federated learning. Blockchain technology authenticates the data and federated learning trains the model globally while preserving the privacy of the organization. First, we propose a data normalization technique that deals with the heterogeneity of data as the data is gathered from different hospitals having different kinds of Computed Tomography (CT) scanners. Secondly, we use Capsule Network-based segmentation and classification to detect COVID-19 patients. Thirdly, we design a method that can collaboratively train a global model using blockchain technology with federated learning while preserving privacy. Additionally, we collected real-life COVID-19 patients' data open to the research community. The proposed framework can utilize up-to-date data which improves the recognition of CT images. Finally, we conducted comprehensive experiments to validate the proposed method. Our results demonstrate better performance for detecting COVID-19 patients.",245,COVID-19,40.0,IEEE Sens J,Other Topics,1.8793555080149344e-06,32.24000000000003,2.849285374207295e-06,62.0,-1.0,Self-recorded/clinical,2. Detection/Diagnosis,CT
35808502,10.3390/s22135007,Yes,PMC9269794,35808502.0,2022,2022-07-10,Journal Article;Multicenter Study,Peer reviewed (PubMed),1,development and validation of a multimodal-based prognosis and intervention prediction model for covid-19 patients in a multicenter cohort,"The ability to accurately predict the prognosis and intervention requirements for treating highly infectious diseases, such as COVID-19, can greatly support the effective management of patients, especially in resource-limited settings. The aim of the study is to develop and validate a multimodal artificial intelligence (AI) system using clinical findings, laboratory data and AI-interpreted features of chest X-rays (CXRs), and to predict the prognosis and the required interventions for patients diagnosed with COVID-19, using multi-center data. In total, 2282 real-time reverse transcriptase polymerase chain reaction-confirmed COVID-19 patients’ initial clinical findings, laboratory data and CXRs were retrospectively collected from 13 medical centers in South Korea, between January 2020 and June 2021. The prognostic outcomes collected included intensive care unit (ICU) admission and in-hospital mortality. Intervention outcomes included the use of oxygen (O2) supplementation, mechanical ventilation and extracorporeal membrane oxygenation (ECMO). A deep learning algorithm detecting 10 common CXR abnormalities (DLAD-10) was used to infer the initial CXR taken. A random forest model with a quantile classifier was used to predict the prognostic and intervention outcomes, using multimodal data. The AUC (AUROC) values for the single-modal model, using clinical findings, laboratory data and the outputs from DLAD-10, were 0.742, 0.794 and 0.770, respectively. The AUROC of the combined model, using clinical findings, laboratory data and DLAD-10 outputs, was significantly higher at 0.854 than that of all other models (p < 0.001, using DeLong’s test). In the order of importance, age, dyspnea, consolidation and fever were significant clinical variables for prediction. The most predictive DLAD-10 output was consolidation. We have shown that a multimodal AI model can improve the performance of predicting both the prognosis and intervention in COVID-19 patients, and this could assist in effective treatment and subsequent resource management. Further, image feature extraction using an established AI engine with well-defined clinical outputs, and combining them with different modes of clinical data, could be a useful way of creating an understandable multimodal prediction model.",321,COVID-19;Communicable Diseases;Dyspnea;Fever,0.0,Sensors (Basel),Intensive Care Units;Polymerase Chain Reaction;Retrospective Studies;Communicable Diseases;Random Forest,1.0090107981178396e-06,19.0,2.102076731351094e-06,31.0,-1.0,External,4. Prognosis/Treatment,Multimodal
35866396,10.31083/j.fbl2707198,Yes,,35866396.0,2022,2022-07-23,Journal Article,Peer reviewed (PubMed),1,covidx-us: an open-access benchmark dataset of ultrasound imaging data for ai-driven covid-19 analytics,"The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. Apart from the global health crises, the pandemic has also caused significant economic and financial difficulties and socio-physiological implications. Effective screening, triage, treatment planning, and prognostication of outcome play a key role in controlling the pandemic. Recent studies have highlighted the role of point-of-care ultrasound imaging for COVID-19 screening and prognosis, particularly given that it is non-invasive, globally available, and easy-to-sanitize. COVIDx-US Motivated by these attributes and the promise of artificial intelligence tools to aid clinicians, we introduce COVIDx-US, an open-access benchmark dataset of COVID-19 related ultrasound imaging data. The COVIDx-US dataset was curated from multiple data sources and its current version, i.e., v1.5., consists of 173 ultrasound videos and 21,570 processed images across 147 patients with COVID-19 infection, non-COVID-19 infection, other lung diseases/conditions, as well as normal control cases. The COVIDx-US dataset was released as part of a large open-source initiative, the COVID-Net initiative, and will be continuously growing, as more data sources become available. To the best of the authors' knowledge, COVIDx-US is the first and largest open-access fully-curated benchmark lung ultrasound imaging dataset that contains a standardized and unified lung ultrasound score per video file, providing better interpretation while enabling other research avenues such as severity assessment. In addition, the dataset is reproducible, easy-to-use, and easy-to-scale thanks to the well-documented modular design.",236,COVID-19;COVID-19 Pandemic;Infections;Lung Diseases,5.0,Front Biosci (Landmark Ed),Point-of-Care Systems;Ultrasonography,9.517986548396708e-07,12.999999999999996,1.6398412838853331e-06,21.0,-1.0,External,2. Detection/Diagnosis,Ultrasound
35877363,10.3390/bioengineering9070312,Yes,PMC9311779,35877363.0,2022,2022-07-26,Journal Article,Peer reviewed (PubMed),1,bag of tricks for improving deep learning performance on multimodal image classification,"A comprehensive medical image-based diagnosis is usually performed across various image modalities before passing a final decision; hence, designing a deep learning model that can use any medical image modality to diagnose a particular disease is of great interest. The available methods are multi-staged, with many computational bottlenecks in between. This paper presents an improved end-to-end method of multimodal image classification using deep learning models. We present top research methods developed over the years to improve models trained from scratch and transfer learning approaches. We show that when fully trained, a model can first implicitly discriminate the imaging modality and then diagnose the relevant disease. Our developed models were applied to COVID-19 classification from chest X-ray, CT scan, and lung ultrasound image modalities. The model that achieved the highest accuracy correctly maps all input images to their respective modality, then classifies the disease achieving overall 91.07% accuracy.",147,COVID-19,0.0,Bioengineering (Basel),Transfer Learning;Lung;Tomography;Lung Diseases;Map,9.165351928275704e-07,6.599999999999999,1.203359800316104e-06,11.0,-1.0,External,2. Detection/Diagnosis,Multimodal
35928972,10.1155/2022/9771212,Yes,PMC9344483,35928972.0,2022,2022-08-06,Journal Article,Peer reviewed (PubMed),1,an empirical analysis of an optimized pretrained deep learning model for covid-19 diagnosis,"As a result of the COVID-19 outbreak, which has put the world in an unprecedented predicament, thousands of people have died. Data from structured and unstructured sources are combined to create user-friendly platforms for clinicians and researchers in an integrated bioinformatics approach. The diagnosis and treatment of COVID-19 disease can be accelerated using AI-based platforms. In the battle against the virus, however, researchers and decision-makers must contend with an ever-increasing volume of data, referred to as ""big data."" VGG19 and ResNet152V2 pretrained deep learning architectures were used in this study. With these datasets, we could train and fine-tune our model on lung ultrasound frames from healthy people as well as from patients with COVID-19 and pneumonia. In two separate experiments, we evaluated two different classes of predictive models: one against pneumonia and the other against non-COVID-19. COVID-19 can be detected and diagnosed accurately and efficiently using these models, according to the findings. Therefore, the use of these inexpensive and affordable deep learning methods should be considered as a reliable method for the diagnosis of COVID-19.",175,COVID-19;Pneumonia,5.0,Comput Math Methods Med,Research Personnel;Architecture;Disease Outbreaks;COVID-19 Testing,9.149951717687974e-07,8.999999999999998,1.378320432133149e-06,15.0,-1.0,,2. Detection/Diagnosis,Ultrasound
35966447,10.1109/ius52206.2021.9593662,Yes,PMC9373065,35966447.0,2022,2022-08-16,Journal Article,Peer reviewed (PubMed),1,anatomical feature-based lung ultrasound image quality assessment using deep convolutional neural network,"Lung ultrasound (LUS) has been used for point-of-care diagnosis of respiratory diseases including COVID-19, with advantages such as low cost, safety, absence of radiation, and portability. The scanning procedure and assessment of LUS are highly operator-dependent, and the appearance of LUS images varies with the probe's position, orientation, and contact force. Karamalis et al. introduced the concept of ultrasound confidence maps based on random walks to assess the ultrasound image quality algorithmically by estimating the per-pixel confidence in the image data. However, these confidence maps do not consider the clinical context of an image, such as anatomical feature visibility and diagnosability. This work proposes a deep convolutional network that detects important anatomical features in an LUS image to quantify its clinical context. This work introduces an Anatomical Feature-based Confidence (AFC) Map, quantifying an LUS image's clinical context based on the visible anatomical features. We developed two U-net models, each segmenting one of the two classes crucial for analyzing an LUS image, namely 1) Bright Features: Pleural and Rib Lines and 2) Dark Features: Rib Shadows. Each model takes the LUS image as input and outputs the segmented regions with confidence values for the corresponding class. The evaluation dataset consists of ultrasound images extracted from videos of two sub-regions of the chest above the anterior axial line from three human subjects. The feature segmentation models achieved an average Dice score of 0.72 on the model's output for the testing data. The average of non-zero confidence values in all the pixels was calculated and compared against the image quality scores. The confidence values were different between different image quality scores. The results demonstrated the relevance of using an AFC Map to quantify the clinical context of an LUS image.",287,COVID-19,0.0,IEEE Int Ultrason Symp,Lung Diseases;Map,1.3608589290624138e-06,14.08,1.2594074244740598e-06,32.0,-1.0,Self-recorded/clinical,Segmentation-only,Ultrasound
35968248,10.1007/s00521-022-07653-z,Yes,PMC9362439,35968248.0,2022,2022-08-16,Journal Article,Peer reviewed (PubMed),1,automatic segmentation of covid-19 from computed tomography images using modified u-net model-based majority voting approach,"The coronavirus disease (COVID-19) is an important public health problem that has spread rapidly around the world and has caused the death of millions of people. Therefore, studies to determine the factors affecting the disease, to perform preventive actions and to find an effective treatment are at the forefront. In this study, a deep learning and segmentation-based approach is proposed for the detection of COVID-19 disease from computed tomography images. The proposed model was created by modifying the encoder part of the U-Net segmentation model. In the encoder part, VGG16, ResNet101, DenseNet121, InceptionV3 and EfficientNetB5 deep learning models were used, respectively. Then, the results obtained with each modified U-Net model were combined with the majority vote principle and a final result was reached. As a result of the experimental tests, the proposed model obtained 85.03% Dice score, 89.13% sensitivity and 99.38% specificity on the COVID-19 segmentation test dataset. The results obtained in the study show that the proposed model will especially benefit clinicians in terms of time and cost.",169,COVID-19;Death,1.0,Neural Comput Appl,Other Topics,1.03221595232635e-06,8.399999999999999,1.3894786777824666e-06,14.0,-1.0,External,Segmentation-only,CT
36038496,10.1016/S2589-7500(22)00132-7,Yes,PMC9417284,36038496.0,2022,2022-08-30,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,constructing custom-made radiotranscriptomic signatures of vascular inflammation from routine ct angiograms: a prospective outcomes validation study in covid-19,"Direct evaluation of vascular inflammation in patients with COVID-19 would facilitate more efficient trials of new treatments and identify patients at risk of long-term complications who might respond to treatment. We aimed to develop a novel artificial intelligence (AI)-assisted image analysis platform that quantifies cytokine-driven vascular inflammation from routine CT angiograms, and sought to validate its prognostic value in COVID-19. For this prospective outcomes validation study, we developed a radiotranscriptomic platform that uses RNA sequencing data from human internal mammary artery biopsies to develop novel radiomic signatures of vascular inflammation from CT angiography images. We then used this platform to train a radiotranscriptomic signature (C19-RS), derived from the perivascular space around the aorta and the internal mammary artery, to best describe cytokine-driven vascular inflammation. The prognostic value of C19-RS was validated externally in 435 patients (331 from study arm 3 and 104 from study arm 4) admitted to hospital with or without COVID-19, undergoing clinically indicated pulmonary CT angiography, in three UK National Health Service (NHS) trusts (Oxford, Leicester, and Bath). We evaluated the diagnostic and prognostic value of C19-RS for death in hospital due to COVID-19, did sensitivity analyses based on dexamethasone treatment, and investigated the correlation of C19-RS with systemic transcriptomic changes. Patients with COVID-19 had higher C19-RS than those without, and those infected with the B.1.1.7 (alpha) SARS-CoV-2 variant had higher C19-RS values than those infected with the wild-type SARS-CoV-2 variant. C19-RS had prognostic value for in-hospital mortality in COVID-19 in two testing cohorts, adjusted for clinical factors, biochemical biomarkers of inflammation and myocardial injury, and technical parameters. The adjusted HR for in-hospital mortality was 8·24 in patients who received no dexamethasone treatment, but 2·27 (0·69-7·55, p=0·18) in those who received dexamethasone after the scan, suggesting that vascular inflammation might have been a therapeutic target of dexamethasone in COVID-19. Finally, C19-RS was strongly associated (r=0·61, p=0·00031) with a whole blood transcriptional module representing dysregulation of coagulation and platelet aggregation pathways. Radiotranscriptomic analysis of CT angiography scans introduces a potentially powerful new platform for the development of non-invasive imaging biomarkers. Application of this platform in routine CT pulmonary angiography scans done in patients with COVID-19 produced the radiotranscriptomic signature C19-RS, a marker of cytokine-driven inflammation driving systemic activation of coagulation and responsible for adverse clinical outcomes, which predicts in-hospital mortality and might allow targeted therapy. Engineering and Physical Sciences Research Council, British Heart Foundation, Oxford BHF Centre of Research Excellence, Innovate UK, NIHR Oxford Biomedical Research Centre, Wellcome Trust, Onassis Foundation.",413,COVID-19;Death;Inflammation;Injuries,3.0,Lancet Digit Health,Other Topics,9.468576234548208e-07,12.599999999999996,1.7594798739505507e-06,21.0,-1.0,External,4. Prognosis/Treatment,CT
36085636,10.1109/EMBC48229.2022.9871519,Yes,,36085636.0,2022,2022-09-11,Journal Article,Peer reviewed (PubMed),1,wasserstein gan based chest x-ray dataset augmentation for deep learning models: covid-19 detection use-case,"The novel coronavirus infection (COVID-19) is still continuing to be a concern for the entire globe. Since early detection of COVID-19 is of particular importance, there have been multiple research efforts to supplement the current standard RT-PCR tests. Several deep learning models, with varying effectiveness, using Chest X-Ray images for such diagnosis have also been proposed. While some of the models are quite promising, there still remains a dearth of training data for such deep learning models. The present paper attempts to provide a viable solution to the problem of data deficiency in COVID-19 CXR images. We show that the use of a Wasserstein Generative Adversarial Network (WGAN) could lead to an effective and lightweight solution. It is demonstrated that the WGAN generated images are at par with the original images using inference tests on an already proposed COVID-19 detection model.",141,COVID-19;Coronavirus Infections,1.0,Annu Int Conf IEEE Eng Med Biol Soc,Coronavirus Infections;Polymerase Chain Reaction,1.0273678209101285e-06,25.200000000000017,2.6786689927017994e-06,42.0,-1.0,External,5. Post-hoc,X-Ray
36086665,10.1109/EMBC48229.2022.9871235,Yes,,36086665.0,2022,2022-09-11,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,detection of covid-19 in point of care lung ultrasound,"The coronavirus disease 2019 (COVID-19) evolved into a global pandemic, responsible for a significant number of infections and deaths. In this scenario, point-of-care ultrasound (POCUS) has emerged as a viable and safe imaging modality. Computer vision (CV) solutions have been proposed to aid clinicians in POCUS image interpretation, namely detection/segmentation of structures and image/patient classification but relevant challenges still remain. As such, the aim of this study is to develop CV algorithms, using Deep Learning techniques, to create tools that can aid doctors in the diagnosis of viral and bacterial pneumonia (VP and BP) through POCUS exams. To do so, convolutional neural networks were designed to perform in classification tasks. The architectures chosen to build these models were the VGG16, ResNet50, DenseNet169 e MobileNetV2. Patients images were divided in three classes: healthy (HE), BP and VP (which includes COVID-19). Through a comparative study, which was based on several performance metrics, the model based on the DenseNet169 architecture was designated as the best performing model, achieving 78% average accuracy value of the five iterations of 5- Fold Cross-Validation. Given that the currently available POCUS datasets for COVID-19 are still limited, the training of the models was negatively affected by such and the models were not tested in an independent dataset. Furthermore, it was also not possible to perform lesion detection tasks. Nonetheless, in order to provide explainability and understanding of the models, Gradient-weighted Class Activation Mapping (GradCAM) were used as a tool to highlight the most relevant classification regions. Clinical relevance - Reveals the potential of POCUS to support COVID-19 screening. The results are very promising although the dataset is limite.",270,"COVID-19;Death;Infections;Pneumonia, Bacterial",0.0,Annu Int Conf IEEE Eng Med Biol Soc,Architecture;Point-of-Care Systems;Ultrasonography;Neural Networks,9.115487635885844e-07,6.4,1.152738842289144e-06,10.0,-1.0,External,2. Detection/Diagnosis,Ultrasound
36156419,10.1016/j.media.2022.102605,Yes,PMC9444848,36156419.0,2022,2022-09-27,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,rapid artificial intelligence solutions in a pandemic-the covid-19-20 lung ct lesion segmentation challenge,"Artificial intelligence (AI) methods for the automatic detection and quantification of COVID-19 lesions in chest computed tomography (CT) might play an important role in the monitoring and management of the disease. We organized an international challenge and competition for the development and comparison of AI algorithms for this task, which we supported with public data and state-of-the-art benchmark methods. Board Certified Radiologists annotated 295 public images from two sources (A and B) for algorithms training (n=199, source A), validation (n=50, source A) and testing (n=23, source A; n=23, source B). There were 1,096 registered teams of which 225 and 98 completed the validation and testing phases, respectively. The challenge showed that AI models could be rapidly designed by diverse teams with the potential to measure disease or facilitate timely and patient-specific interventions. This paper provides an overview and the major outcomes of the COVID-19 Lung CT Lesion Segmentation Challenge - 2020.",151,COVID-19,9.0,Med Image Anal,Art;Algorithms;Tomography;Lung Diseases,1.1637796653470489e-06,19.800000000000004,2.2654181874176715e-06,33.0,-1.0,External,Segmentation-only,CT
36158870,10.1016/j.engappai.2022.105398,Yes,PMC9485443,36158870.0,2022,2022-09-27,Journal Article,Peer reviewed (PubMed),1,e-gcs: detection of covid-19 through classification by attention bottleneck residual network,"Recently, the coronavirus disease 2019 (COVID-19) has caused mortality of many people globally. Thus, there existed a need to detect this disease to prevent its further spread. Hence, the study aims to predict COVID-19 infected patients based on deep learning (DL) and image processing. The study intends to classify the normal and abnormal cases of COVID-19 by considering three different medical imaging modalities namely ultrasound imaging, X-ray images and CT scan images through introduced attention bottleneck residual network (AB-ResNet). It also aims to segment the abnormal infected area from normal images for localizing localising the disease infected area through the proposed edge based graph cut segmentation (E-GCS). AB-ResNet is used for classifying images whereas E-GCS segment the abnormal images. The study possess various advantages as it rely on DL and possess capability for accelerating the training speed of deep networks. It also enhance the network depth leading to minimum parameters, minimising the impact of vanishing gradient issue and attaining effective network performance with respect to better accuracy. Performance and comparative analysis is undertaken to evaluate the efficiency of the introduced system and results explores the efficiency of the proposed system in COVID-19 detection with high accuracy .",197,COVID-19,0.0,Eng Appl Artif Intell,Ultrasonography;Other Topics,1.060883044841054e-06,19.0,2.1996323090156945e-06,31.0,-1.0,External,2. Detection/Diagnosis,Multimodal
36159188,10.1007/s00521-022-07709-0,Yes,PMC9483435,36159188.0,2022,2022-09-27,Journal Article;Review,Peer reviewed (PubMed),1,machine learning techniques for ct imaging diagnosis of novel coronavirus pneumonia: a review,"Since 2020, novel coronavirus pneumonia has been spreading rapidly around the world, bringing tremendous pressure on medical diagnosis and treatment for hospitals. Medical imaging methods, such as computed tomography (CT), play a crucial role in diagnosing and treating COVID-19. A large number of CT images (with large volume) are produced during the CT-based medical diagnosis. In such a situation, the diagnostic judgement by human eyes on the thousands of CT images is inefficient and time-consuming. Recently, in order to improve diagnostic efficiency, the machine learning technology is being widely used in computer-aided diagnosis and treatment systems (i.e., CT Imaging) to help doctors perform accurate analysis and provide them with effective diagnostic decision support. In this paper, we comprehensively review these frequently used machine learning methods applied in the CT Imaging Diagnosis for the COVID-19, discuss the machine learning-based applications from the various kinds of aspects including the image acquisition and pre-processing, image segmentation, quantitative analysis and diagnosis, and disease follow-up and prognosis. Moreover, we also discuss the limitations of the up-to-date machine learning technology in the context of CT imaging computer-aided diagnosis.",182,COVID-19;Pneumonia,1.0,Neural Comput Appl,Other Topics,9.56972852033274e-07,9.599999999999998,1.42717139066495e-06,16.0,-1.0,,Review,CT
36193755,10.1259/bjr.20220058,Yes,PMC9733620,36193755.0,2022,2022-10-05,Randomized Controlled Trial;Journal Article,Peer reviewed (PubMed),1,artificial intelligence-based model for covid-19 prognosis incorporating chest radiographs and clinical data; a retrospective model development and validation study,"The purpose of this study was to develop an artificial intelligence-based model to prognosticate COVID-19 patients at admission by combining clinical data and chest radiographs. This retrospective study used the Stony Brook University COVID-19 dataset of 1384 inpatients. After exclusions, 1356 patients were randomly divided into training and test datasets. We implemented three artificial intelligence models, which classified mortality, ICU admission, or ventilation risk. Each model had three submodels with different inputs: clinical data, chest radiographs, and both. We showed the importance of the variables using SHapley Additive exPlanations (SHAP) values. The mortality prediction model was best overall with AUC, sensitivity, specificity, and accuracy of 0.79, and 0.74 for the clinical data-based model; 0.77 for the image-based model, and 0.86 for the mixed model. The mixed model had the best performance (p value < 0.05). The radiographs ranked fourth for prognostication overall, and first of the inpatient tests assessed. These results suggest that prognosis models become more accurate if AI-derived chest radiograph features and clinical data are used together. This AI model evaluates chest radiographs together with clinical data in order to classify patients as having high or low mortality risk. This work shows that chest radiographs taken at admission have significant COVID-19 prognostic information compared to clinical data other than age and sex.",214,COVID-19,0.0,Br J Radiol,Other Topics;Retrospective Studies,1.0285968642752298e-06,17.799999999999997,2.019042903141839e-06,29.0,-1.0,External,4. Prognosis/Treatment,X-Ray
36237723,10.3348/jksr.2020.0138,Yes,PMC9431829,36237723.0,2020,2020-11-01,English Abstract;Journal Article;Review,Peer reviewed (PubMed),1,role of chest radiographs and ct scans and the application of artificial intelligence in coronavirus disease 2019,"Coronavirus disease (COVID-19) has threatened public health as a global pandemic. Chest CT and radiography are crucial in managing COVID-19 in addition to reverse transcription-polymerase chain reaction, which is the gold standard for COVID-19 diagnosis. This is a review of the current status of the use of chest CT and radiography in COVID-19 diagnosis and management and an introduction of early representative studies on the application of artificial intelligence to chest CT and radiography. The authors also share their experiences to provide insights into the future value of artificial intelligence.",90,COVID-19,1.0,Taehan Yongsang Uihakhoe Chi,Polymerase Chain Reaction;Reverse Transcription,1.981181103971354e-06,27.552000000000003,1.8814219125819984e-06,86.0,-1.0,,Review,Multimodal
36266463,10.1038/s41598-022-22196-y,Yes,PMC9584232,36266463.0,2022,2022-10-21,Journal Article,Peer reviewed (PubMed),1,automatic deep learning-based consolidation/collapse classification in lung ultrasound images for covid-19 induced pneumonia,"Our automated deep learning-based approach identifies consolidation/collapse in LUS images to aid in the identification of late stages of COVID-19 induced pneumonia, where consolidation/collapse is one of the possible associated pathologies. A common challenge in training such models is that annotating each frame of an ultrasound video requires high labelling effort. This effort in practice becomes prohibitive for large ultrasound datasets. To understand the impact of various degrees of labelling precision, we compare labelling strategies to train fully supervised models (frame-based method, higher labelling effort) and inaccurately supervised models (video-based methods, lower labelling effort), both of which yield binary predictions for LUS videos on a frame-by-frame level. We moreover introduce a novel sampled quaternary method which randomly samples only 10% of the LUS video frames and subsequently assigns (ordinal) categorical labels to all frames in the video based on the fraction of positively annotated samples. This method outperformed the inaccurately supervised video-based method and more surprisingly, the supervised frame-based approach with respect to metrics such as precision-recall AUC (PR-AUC) and F1 score, despite being a form of inaccurate learning. We argue that our video-based method is more robust with respect to label noise and mitigates overfitting in a manner similar to label smoothing. The algorithm was trained using a ten-fold cross validation, which resulted in a PR-AUC score of 73% and an accuracy of 89%. While the efficacy of our classifier using the sampled quaternary method significantly lowers the labelling effort, it must be verified on a larger consolidation/collapse dataset, our proposed classifier using the sampled quaternary video-based method is clinically comparable with trained experts' performance.",266,COVID-19;Pneumonia,0.0,Sci Rep,Noise;Ultrasonography;Other Topics;Area under Curve,9.886358519627132e-07,11.999999999999996,1.6266101076337684e-06,20.0,-1.0,Self-recorded/clinical,4. Prognosis/Treatment,Ultrasound
36286361,10.3390/jimaging8100267,Yes,PMC9604704,36286361.0,2022,2022-10-27,Journal Article;Review,Peer reviewed (PubMed),1,comprehensive survey of machine learning systems for covid-19 detection,"The last two years are considered the most crucial and critical period of the COVID-19 pandemic affecting most life aspects worldwide. This virus spreads quickly within a short period, increasing the fatality rate associated with the virus. From a clinical perspective, several diagnosis methods are carried out for early detection to avoid virus propagation. However, the capabilities of these methods are limited and have various associated challenges. Consequently, many studies have been performed for COVID-19 automated detection without involving manual intervention and allowing an accurate and fast decision. As is the case with other diseases and medical issues, Artificial Intelligence (AI) provides the medical community with potential technical solutions that help doctors and radiologists diagnose based on chest images. In this paper, a comprehensive review of the mentioned AI-based detection solution proposals is conducted. More than 200 papers are reviewed and analyzed, and 145 articles have been extensively examined to specify the proposed AI mechanisms with chest medical images. A comprehensive examination of the associated advantages and shortcomings is illustrated and summarized. Several findings are concluded as a result of a deep analysis of all the previous works using machine learning for COVID-19 detection, segmentation, and classification.",197,COVID-19;COVID-19 Pandemic,2.0,J Imaging,Other Topics,9.534027465960888e-07,14.599999999999996,1.7190456644214417e-06,23.0,-1.0,,Review,Multimodal
36288236,10.1109/TMI.2022.3217501,Yes,,36288236.0,2022,2022-10-27,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,pseudo-label guided image synthesis for semi-supervised covid-19 pneumonia infection segmentation,"Coronavirus disease 2019 (COVID-19) has become a severe global pandemic. Accurate pneumonia infection segmentation is important for assisting doctors in diagnosing COVID-19. Deep learning-based methods can be developed for automatic segmentation, but the lack of large-scale well-annotated COVID-19 training datasets may hinder their performance. Semi-supervised segmentation is a promising solution which explores large amounts of unlabelled data, while most existing methods focus on pseudo-label refinement. In this paper, we propose a new perspective on semi-supervised learning for COVID-19 pneumonia infection segmentation, namely pseudo-label guided image synthesis. The main idea is to keep the pseudo-labels and synthesize new images to match them. The synthetic image has the same COVID-19 infected regions as indicated in the pseudo-label, and the reference style extracted from the style code pool is added to make it more realistic. We introduce two representative methods by incorporating the synthetic images into model training, including single-stage Synthesis-Assisted Cross Pseudo Supervision (SA-CPS) and multi-stage Synthesis-Assisted Self-Training (SA-ST), which can work individually as well as cooperatively. Synthesis-assisted methods expand the training data with high-quality synthetic data, thus improving the segmentation performance. Extensive experiments on two COVID-19 CT datasets for segmenting the infections demonstrate our method is superior to existing schemes for semi-supervised segmentation, and achieves the state-of-the-art performance on both datasets. Code is available at: GitHub",215,COVID-19;Infections;Pneumonia,0.0,IEEE Trans Med Imaging,Art;Other Topics,1.0262990527315296e-06,9.799999999999995,1.4290310331671457e-06,15.0,-1.0,External,5. Post-hoc,CT
36294846,10.3390/jpm12101707,Yes,PMC9605641,36294846.0,2022,2022-10-28,Journal Article,Peer reviewed (PubMed),1,contrasting efficientnet vit and gmlp for covid-19 detection in ultrasound imagery,"A timely diagnosis of coronavirus is critical in order to control the spread of the virus. To aid in this, we propose in this paper a deep learning-based approach for detecting coronavirus patients using ultrasound imagery. We propose to exploit the transfer learning of a EfficientNet model pre-trained on the ImageNet dataset for the classification of ultrasound images of suspected patients. In particular, we contrast the results of EfficentNet-B2 with the results of ViT and gMLP. Then, we show the results of the three models by learning from scratch, i.e., without transfer learning. We view the detection problem from a multiclass classification perspective by classifying images as COVID-19, pneumonia, and normal. In the experiments, we evaluated the models on a publically available ultrasound dataset. This dataset consists of 261 recordings (202 videos + 59 images) belonging to 216 distinct patients. The best results were obtained using EfficientNet-B2 with transfer learning. In particular, we obtained precision, recall, and F1 scores of 95.84%, 99.88%, and 24 97.41%, respectively, for detecting the COVID-19 class. EfficientNet-B2 with transfer learning presented an overall accuracy of 96.79%, outperforming gMLP and ViT, which achieved accuracies of 93.03% and 92.82%, respectively.",193,COVID-19;Pneumonia,1.0,J Pers Med,Transfer Learning;Other Topics,1.008142276307579e-06,17.799999999999997,2.070306829192237e-06,29.0,-1.0,External,2. Detection/Diagnosis,Ultrasound
36313227,10.7150/ijms.76515,Yes,PMC9608047,36313227.0,2022,2022-11-01,Systematic Review;Journal Article,Peer reviewed (PubMed),1,application of artificial intelligence in diagnosing covid-19 disease symptoms on chest x-rays: a systematic review,"This systematic review focuses on using artificial intelligence (AI) to detect COVID-19 infection with the help of X-ray images. In January 2022, the authors searched PubMed, Embase and Scopus using specific medical subject headings terms and filters. All articles were independently reviewed by two reviewers. All conflicts resulting from a misunderstanding were resolved by a third independent researcher. After assessing abstracts and article usefulness, eliminating repetitions and applying inclusion and exclusion criteria, six studies were found to be qualified for this study. The findings from individual studies differed due to the various approaches of the authors. Sensitivity was 72.59%-100%, specificity was 79%-99.9%, precision was 74.74%-98.7%, accuracy was 76.18%-99.81%, and the AUC was 95.24%-97.7%. AI computational models used to assess chest X-rays in the process of diagnosing COVID-19 should achieve sufficiently high sensitivity and specificity. Their results and performance should be repeatable to make them dependable for clinicians. Moreover, these additional diagnostic tools should be more affordable and faster than the currently available procedures. The performance and calculations of AI-based systems should take clinical data into account.",176,COVID-19;Infections,0.0,Int J Med Sci,Radiography;Research Personnel;Systematic Review,9.492356929955672e-07,11.999999999999996,1.6137147940834795e-06,20.0,-1.0,,Review,X-Ray
36357530,10.1038/s41598-022-23692-x,Yes,PMC9647771,36357530.0,2022,2022-11-11,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,generative adversarial network based data augmentation for cnn based detection of covid-19,"Covid-19 has been a global concern since 2019, crippling the world economy and health. Biological diagnostic tools have since been developed to identify the virus from bodily fluids and since the virus causes pneumonia, which results in lung inflammation, the presence of the virus can also be detected using medical imaging by expert radiologists. The success of each diagnostic method is measured by the hit rate for identifying Covid infections. However, the access for people to each diagnosis tool can be limited, depending on the geographic region and, since Covid treatment denotes a race against time, the diagnosis duration plays an important role. Hospitals with X-ray opportunities are widely distributed all over the world, so a method investigating lung X-ray images for possible Covid-19 infections would offer itself. Promising results have been achieved in the literature in automatically detecting the virus using medical images like CT scans and X-rays using supervised artificial neural network algorithms. One of the major drawbacks of supervised learning models is that they require enormous amounts of data to train, and generalize on new data. In this study, we develop a Swish activated, Instance and Batch normalized Residual U-Net GAN with dense blocks and skip connections to create synthetic and augmented data for training. The proposed GAN architecture, due to the presence of instance normalization and swish activation, can deal with the randomness of luminosity, that arises due to different sources of X-ray images better than the classical architecture and generate realistic-looking synthetic data. Also, the radiology equipment is not generally computationally efficient. They cannot efficiently run state-of-the-art deep neural networks such as DenseNet and ResNet effectively. Hence, we propose a novel CNN architecture that is 40% lighter and more accurate than state-of-the-art CNN networks. Multi-class classification of the three classes of chest X-rays (CXR), ie Covid-19, healthy and Pneumonia, is performed using the proposed model which had an extremely high test accuracy of 99.2% which has not been achieved in any previous studies in the literature. Based on the mentioned criteria for developing Corona infection diagnosis, in the present study, an Artificial Intelligence based method is proposed, resulting in a rapid diagnostic tool for Covid infections based on generative adversarial and convolutional neural networks. The benefit will be a high accuracy of lung infection identification with 99% accuracy. This could lead to a support tool that helps in rapid diagnosis, and an accessible Covid identification method using CXR images.",404,COVID-19;Infections;Pneumonia;Pneumonitis,0.0,Sci Rep,Art;Diagnostic Tests;Algorithms;Architecture;COVID-19 Testing,1.0058233912049686e-06,23.400000000000013,2.5396380140711493e-06,39.0,-1.0,External,5. Post-hoc,X-Ray
36383512,10.1371/journal.pone.0276250,Yes,PMC9668167,36383512.0,2022,2022-11-17,"Journal Article;Research Support, U.S. Gov't, Non-P.H.S.",Peer reviewed (PubMed),1,calibrated bagging deep learning for image semantic segmentation: a case study on covid-19 chest x-ray image,"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) causes coronavirus disease 2019 (COVID-19). Imaging tests such as chest X-ray (CXR) and computed tomography (CT) can provide useful information to clinical staff for facilitating a diagnosis of COVID-19 in a more efficient and comprehensive manner. As a breakthrough of artificial intelligence (AI), deep learning has been applied to perform COVID-19 infection region segmentation and disease classification by analyzing CXR and CT data. However, prediction uncertainty of deep learning models for these tasks, which is very important to safety-critical applications like medical image processing, has not been comprehensively investigated. In this work, we propose a novel ensemble deep learning model through integrating bagging deep learning and model calibration to not only enhance segmentation performance, but also reduce prediction uncertainty. The proposed method has been validated on a large dataset that is associated with CXR image segmentation. Experimental results demonstrate that the proposed method can improve the segmentation performance, as well as decrease prediction uncertainty.",161,COVID-19;Infections;Severe Acute Respiratory Syndrome,0.0,PLoS One,Semantics;Image Processing,1.0927484637224057e-06,30.60000000000003,3.089668498359591e-06,51.0,-1.0,External,Segmentation-only,X-Ray
36420865,10.1080/0954898X.2022.2147231,Yes,,36420865.0,2022,2022-11-25,Systematic Review;Journal Article,Peer reviewed (PubMed),1,a systematic review: chest radiography images (x-ray images) analysis and covid-19 categorization diagnosis using artificial intelligence techniques,"COVID-19 pandemic created a turmoil across nations due to Severe Acute Respiratory Syndrome Corona virus-1(SARS - Co-V-2). The severity of COVID-19 symptoms is starting from cold, breathing problems, issues in respiratory system which may also lead to life threatening situations. This disease is widely contaminating and transmitted from man-to-man. The contamination is spreading when the human organs like eyes, nose, and mouth get in contact with contaminated fluids. This virus can be screened through performing a nasopharyngeal swab test which is time consuming. So the physicians are preferring the fast detection methods like chest radiography images and CT scans. At times some confusion in finding out the accurate disorder from chest radiography images can happen. To overcome this issue this study reviews several deep learning and machine learning procedures to be implemented in X-ray images of chest. This also helps the professionals to find out the other types of malfunctions happening in the chest other than COVID-19 also. This review can act as a guidance to the doctors and radiologists in identifying the COVID-19 and other types of viruses causing illness in the human anatomy and can provide aid soon.",190,COVID-19;COVID-19 Pandemic;Confusion;Severe Acute Respiratory Syndrome,0.0,Network,Radiography;COVID-19 Testing;Systematic Review,9.518810148448176e-07,15.999999999999996,1.8739409136118488e-06,26.0,-1.0,,Review,X-Ray
36439302,10.1007/s00354-022-00195-x,Yes,PMC9676871,36439302.0,2022,2022-11-29,Journal Article,Peer reviewed (PubMed),1,combined cloud-based inference system for the classification of covid-19 in ct-scan and x-ray images,"In the past few years, most of the work has been done around the classification of covid-19 using different images like CT-scan, X-ray, and ultrasound. But none of that is capable enough to deal with each of these image types on a single common platform and can identify the possibility that a person is suffering from COVID or not. Thus, we realized there should be a platform to identify COVID-19 in CT-scan and X-ray images on the fly. So, to fulfill this need, we proposed an AI model to identify CT-scan and X-ray images from each other and then use this inference to classify them of COVID positive or negative. The proposed model uses the inception architecture under the hood and trains on the open-source extended covid-19 dataset. The dataset consists of plenty of images for both image types and is of size 4 GB. We achieved an accuracy of 100%, average macro-Precision of 100%, average macro-Recall of 100%, average macro f1-score of 100%, and AUC score of 99.6%. Furthermore, in this work, cloud-based architecture is proposed to massively scale and load balance as the Number of user requests rises. As a result, it will deliver a service with minimal latency to all users.",204,COVID-19,0.0,New Gener Comput,Transfer Learning;Architecture;Tomography;Area under Curve,1.0535716279986648e-06,14.999999999999996,1.9222720838307e-06,25.0,-1.0,External,2. Detection/Diagnosis,Multimodal
36449642,10.3855/jidc.15022,Yes,,36449642.0,2022,2022-12-01,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,application of deep learning-based diagnostic systems in screening asymptomatic covid-19 patients among oversea returnees,"Our study aimed to investigate the performance of deep learning (DL)-based diagnostic systems in alerting against COVID-19, especially among asymptomatic individuals coming from overseas, and to analyze the features of identified asymptomatic patients in detail. DL diagnostic systems were deployed to assist in the screening of COVID-19, including the pneumonia system and pulmonary nodules system. 1,917 overseas returnees who underwent CT examination and rRT-PCR tests were enrolled. DL pneumonia system promptly alerted clinicians to suspected COVID-19 after CT examinations while the performance was evaluated with rRT-PCR results as the reference. The radiological features of asymptomatic COVID-19 cases were described according to the Nomenclature of the Fleischner Society. Fifty-three cases were confirmed as COVID-19 patients by rRT-PCR tests, including 5 asymptomatic cases. DL pneumonia system correctly alerted 50 cases as suspected COVID-19 with a sensitivity of 0.9434 and specificity of 0.9592 (within 2 minutes per case); while the pulmonary nodules system alerted 2 of the 3 missed asymptomatic cases. Additionally, five asymptomatic patients presented different characteristics such as elevated creatine kinase level and prolonged prothrombin time, as well as atypical radiological features. DL diagnostic systems are promising complementary approaches for prompt screening of imported COVID-19 patients, even the imported asymptomatic cases. Unique clinical and radiological characteristics of asymptomatic cases might be of great value in screening as well. DL-based systems are practical, efficient, and reliable to assist radiologists in screening COVID-19 patients. Differential features of asymptomatic patients might be useful to clinicians in the frontline to differentiate asymptomatic cases.",248,COVID-19;Pneumonia,0.0,J Infect Dev Ctries,Polymerase Chain Reaction;Other Topics,1.0051229246230758e-06,9.599999999999998,1.4443702141395866e-06,16.0,-1.0,Self-recorded/clinical,1. Risk identification,CT
36452055,10.1259/bjro.20220016,Yes,PMC9667478,36452055.0,2022,2022-12-02,Journal Article,Peer reviewed (PubMed),1,radiomorphological signs and clinical severity of sars-cov-2 lineage b117,"We aimed to assess the differences in the severity and chest-CT radiomorphological signs of SARS-CoV-2 B.1.1.7 and non-B.1.1.7 variants. We collected clinical data of consecutive patients with laboratory-confirmed COVID-19 and chest-CT imaging who were admitted to the Emergency Department between September 1- November 13, 2020 (non-B.1.1.7 cases) and March 1-March 18, 2021 (B.1.1.7 cases). We also examined the differences in the severity and radiomorphological features associated with COVID-19 pneumonia. Total pneumonia burden, mean attenuation of ground-glass opacities and consolidation were quantified using deep-learning research software. The final population comprised 500 B.1.1.7 and 500 non-B.1.1.7 cases. Patients with B.1.1.7 infection were younger (58.5 vs 64.8 ; p < .001) and had less comorbidities. Total pneumonia burden was higher in the B.1.1.7 patient group (16.1% vs 6.6% ; p < .001). In the age-specific analysis, in patients <60 years B.1.1.7 pneumonia had increased consolidation burden (0.1% vs 0.1% ; p < .001), and severe COVID-19 was more prevalent (11.5% vs 4.9%; p = .032). Mortality rate was similar in all age groups. Despite B.1.1.7 patients were younger and had fewer comorbidities, they experienced more severe disease than non-B.1.1.7 patients, however, the risk of death was the same between the two groups. Our study provides data on deep-learning based quantitative lung lesion burden and clinical outcomes of patients infected by B.1.1.7 VOC. Our findings might serve as a model for later investigations, as new variants are emerging across the globe.",237,COVID-19;Death;Infections;Pneumonia,1.0,BJR Open,Other Topics,9.055335467890304e-07,6.599999999999999,1.1811493914565774e-06,11.0,-1.0,Self-recorded/clinical,1. Risk identification,CT
36476724,10.1038/s41598-022-24721-5,Yes,PMC9729627,36476724.0,2022,2022-12-09,Journal Article,Peer reviewed (PubMed),1,prediction of oxygen requirement in patients with covid-19 using a pre-trained chest radiograph xai model: efficient development of auditable risk prediction models via a fine-tuning approach,"Risk prediction requires comprehensive integration of clinical information and concurrent radiological findings. We present an upgraded chest radiograph (CXR) explainable artificial intelligence (xAI) model, which was trained on 241,723 well-annotated CXRs obtained prior to the onset of the COVID-19 pandemic. Mean AUC (AUROC) for detection of 20 radiographic features was 0.955 on PA view and 0.909 on AP view. Coexistent and correlated radiographic findings are displayed in an interpretation table, and calibrated classifier confidence is displayed on an AI scoreboard. Retrieval of similar feature patches and comparable CXRs from a Model-Derived Atlas provides justification for model predictions. To demonstrate the feasibility of a fine-tuning approach for efficient and scalable development of xAI risk prediction models, we applied our CXR xAI model, in combination with clinical information, to predict oxygen requirement in COVID-19 patients. Prediction accuracy for high flow oxygen (HFO) and mechanical ventilation (MV) was 0.953 and 0.934 at 24 h and 0.932 and 0.836 at 72 h from the time of emergency department (ED) admission, respectively. Our CXR xAI model is auditable and captures key pathophysiological manifestations of cardiorespiratory diseases and cardiothoracic comorbidities. This model can be efficiently and broadly applied via a fine-tuning approach to provide fully automated risk and outcome predictions in various clinical scenarios in real-world practice.",211,COVID-19;COVID-19 Pandemic,1.0,Sci Rep,Other Topics,1.0238716326535296e-06,15.599999999999994,1.903714523750216e-06,26.0,-1.0,External,4. Prognosis/Treatment,X-Ray
36532127,10.1016/j.asoc.2022.109926,Yes,PMC9746028,36532127.0,2022,2022-12-20,Journal Article,Peer reviewed (PubMed),1,multi-objective automatic analysis of lung ultrasound data from covid-19 patients by means of deep learning and decision trees,"COVID-19 raised the need for automatic medical diagnosis, to increase the physicians' efficiency in managing the pandemic. Among all the techniques for evaluating the status of the lungs of a patient with COVID-19, lung ultrasound (LUS) offers several advantages: portability, cost-effectiveness, safety. Several works approached the automatic detection of LUS imaging patterns related COVID-19 by using deep neural networks (DNNs). However, the decision processes based on DNNs are not fully explainable, which generally results in a lack of trust from physicians. This, in turn, slows down the adoption of such systems. In this work, we use two previously built DNNs as feature extractors at the frame level, and automatically synthesize, by means of an evolutionary algorithm, a decision tree (DT) that aggregates in an interpretable way the predictions made by the DNNs, returning the severity of the patients' conditions according to a LUS score of prognostic value. Our results show that our approach performs comparably or better than previously reported aggregation techniques based on an empiric combination of frame-level predictions made by DNNs. Furthermore, when we analyze the evolved DTs, we discover properties about the DNNs used as feature extractors. We make our data publicly available for further development and reproducibility.",201,COVID-19,0.0,Appl Soft Comput,Other Topics;Decision Trees,8.639495113515313e-07,0.0,8.11681633002991e-07,0.0,-1.0,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
36559994,10.3390/s22249628,Yes,PMC9785652,36559994.0,2022,2022-12-24,Journal Article,Peer reviewed (PubMed),1,image translation by ad cyclegan for covid-19 x-ray images: a new approach for controllable gan,"We propose a new generative model named adaptive cycle-consistent generative adversarial network, or Ad CycleGAN to perform image translation between normal and COVID-19 positive chest X-ray images. An independent pre-trained criterion is added to the conventional Cycle GAN architecture to exert adaptive control on image translation. The performance of Ad CycleGAN is compared with the Cycle GAN without the external criterion. The quality of the synthetic images is evaluated by quantitative metrics including Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Peak Signal-to-Noise Ratio (PSNR), Universal Image Quality Index (UIQI), visual information fidelity (VIF), Frechet Inception Distance (FID), and translation accuracy. The experimental results indicate that the synthetic images generated either by the Cycle GAN or by the Ad CycleGAN have lower MSE and RMSE, and higher scores in PSNR, UIQI, and VIF in homogenous image translation (i.e., Y → Y) compared to the heterogenous image translation process (i.e., X → Y). The synthetic images by Ad CycleGAN through the heterogeneous image translation have significantly higher FID score compared to Cycle GAN (p < 0.01). The image translation accuracy of Ad CycleGAN is higher than that of Cycle GAN when normal images are converted to COVID-19 positive images (p < 0.01). Therefore, we conclude that the Ad CycleGAN with the independent criterion can improve the accuracy of GAN image translation. The new architecture has more control on image synthesis and can help address the common class imbalance issue in machine learning methods and artificial intelligence applications with medical images.",250,COVID-19,0.0,Sensors (Basel),Address;X-Rays;Image Processing;Translations,9.599927376996985e-07,3.0,9.37811931762534e-07,5.0,-1.0,External,5. Post-hoc,X-Ray
36612309,10.3390/cancers15010314,Yes,PMC9818469,36612309.0,2023,2023-01-09,Journal Article,Peer reviewed (PubMed),1,an explainable ai-enabled framework for interpreting pulmonary diseases from chest radiographs,"Explainable Artificial Intelligence is a key component of artificially intelligent systems that aim to explain the classification results. The classification results explanation is essential for automatic disease diagnosis in healthcare. The human respiration system is badly affected by different chest pulmonary diseases. Automatic classification and explanation can be used to detect these lung diseases. In this paper, we introduced a CNN-based transfer learning-based approach for automatically explaining pulmonary diseases, i.e., edema, tuberculosis, nodules, and pneumonia from chest radiographs. Among these pulmonary diseases, pneumonia, which COVID-19 causes, is deadly; therefore, radiographs of COVID-19 are used for the explanation task. We used the ResNet50 neural network and trained the network on extensive training with the COVID-CT dataset and the COVIDNet dataset. The interpretable model LIME is used for the explanation of classification results. Lime highlights the input image's important features for generating the classification result. We evaluated the explanation using radiologists' highlighted images and identified that our model highlights and explains the same regions. We achieved improved classification results with our fine-tuned model with an accuracy of 93% and 97%, respectively. The analysis of our results indicates that this research not only improves the classification results but also provides an explanation of pulmonary diseases with advanced deep-learning methods. This research would assist radiologists with automatic disease detection and explanations, which are used to make clinical decisions and assist in diagnosing and treating pulmonary diseases in the early stage.",236,COVID-19;Edema;Lung Diseases;Pneumonia;Tuberculosis,0.0,Cancers (Basel),Health Care;Transfer Learning;Health;Lung;Polymerase Chain Reaction;Tomography;Lung Diseases;Map;Reverse Transcription,,,,,,External,5. Post-hoc,X-Ray
36714302,10.34133/2022/9780173,Yes,PMC9880989,36714302.0,2023,2023-01-31,Journal Article,Peer reviewed (PubMed),1,a review of deep learning applications in lung ultrasound imaging of covid-19 patients,"The massive and continuous spread of COVID-19 has motivated researchers around the world to intensely explore, understand, and develop new techniques for diagnosis and treatment. Although lung ultrasound imaging is a less established approach when compared to other medical imaging modalities such as X-ray and CT, multiple studies have demonstrated its promise to diagnose COVID-19 patients. At the same time, many deep learning models have been built to improve the diagnostic efficiency of medical imaging. The integration of these initially parallel efforts has led multiple researchers to report deep learning applications in medical imaging of COVID-19 patients, most of which demonstrate the outstanding potential of deep learning to aid in the diagnosis of COVID-19. This invited review is focused on deep learning applications in lung ultrasound imaging of COVID-19 and provides a comprehensive overview of ultrasound systems utilized for data acquisition, associated datasets, deep learning models, and comparative performance.",149,COVID-19,3.0,BME Front,Ultrasonography;Review,,,,,,,Review,Ultrasound
36744156,10.1016/j.rx.2022.11.012,Yes,PMC9886647,36744156.0,2023,2023-02-07,English Abstract;Journal Article,Peer reviewed (PubMed),1,[performance in prognostic capacity and efficiency of the thoracic care suite ge ai tool applied to chest radiography of patients with covid-19 pneumonia],"Rapid progression of COVID-19 pneumonia may put patients at risk of requiring ventilatory support, such as non-invasive mechanical ventilation or endotracheal intubation. Implementing tools that detect COVID-19 pneumonia can improve the patient's healthcare. We aim to evaluate the efficacy and efficiency of the artificial intelligence (AI) tool GE Healthcare's Thoracic Care Suite (featuring Lunit INSIGHT CXR, TCS) to predict the ventilatory support need based on pneumonic progression of COVID-19 on consecutive chest X-rays. Outpatients with confirmed SARS-CoV-2 infection, with chest X-ray (CXR) findings probable or indeterminate for COVID-19 pneumonia, who required a second CXR due to unfavorable clinical course, were collected. The number of affected lung fields for the two CXRs was assessed using the AI tool. One hundred fourteen patients (57.4 years, 65 -57%- men) were retrospectively collected. Fifteen required ventilatory support. Progression of pneumonic extension ≥ 0.5 lung fields per day compared to pneumonia onset, detected using the TCS tool, increased the risk of requiring ventilatory support by 4-fold. Analyzing the AI output required 26 seconds of radiological time. Applying the AI tool, Thoracic Care Suite, to CXR of patients with COVID-19 pneumonia allows us to anticipate ventilatory support requirements requiring less than half a minute.",198,COVID-19;Clinical Course;Pneumonia,0.0,Radiologia,Health Care;Clinical Course;Other Topics;Intubation,,,,,,Self-recorded/clinical,4. Prognosis/Treatment,X-Ray
36812559,10.1371/journal.pdig.0000057,Yes,PMC9931278,36812559.0,2023,2023-02-23,Journal Article,Peer reviewed (PubMed),1,validation of a deep learning value-based care model to predict mortality and comorbidities from chest radiographs in covid-19,"We validate a deep learning model predicting comorbidities from frontal chest radiographs (CXRs) in patients with coronavirus disease 2019 (COVID-19) and compare the model's performance with hierarchical condition category (HCC) and mortality outcomes in COVID-19. The model was trained and tested on 14,121 ambulatory frontal CXRs from 2010 to 2019 at a single institution, modeling select comorbidities using the value-based Medicare Advantage HCC Risk Adjustment Model. Sex, age, HCC codes, and risk adjustment factor (RAF) score were used. The model was validated on frontal CXRs from 413 ambulatory patients with COVID-19 (internal cohort) and on initial frontal CXRs from 487 COVID-19 hospitalized patients (external cohort). The discriminatory ability of the model was assessed using receiver operating characteristic (ROC) curves compared to the HCC data from electronic health records, and predicted age and RAF score were compared using correlation coefficient and absolute mean error. The model predictions were used as covariables in logistic regression models to evaluate the prediction of mortality in the external cohort. Predicted comorbidities from frontal CXRs, including diabetes with chronic complications, obesity, congestive heart failure, arrhythmias, vascular disease, and chronic obstructive pulmonary disease, had a total area under ROC curve of 0.85. The ROC AUC of predicted mortality for the model was 0.84 for the combined cohorts. This model using only frontal CXRs predicted select comorbidities and RAF score in both internal ambulatory and external hospitalized COVID-19 cohorts and was discriminatory of mortality, supporting its potential use in clinical decision making.",244,"Arrhythmias, Cardiac;COVID-19;Congestive Heart Failure;Obesity;Pulmonary Disease, Chronic Obstructive;Vascular Diseases",0.0,PLOS Digit Health,Logistic Regression;Health;Clinical Decision-Making;Sex;ROC Curve;Area under Curve;Receiver Operating Characteristic,,,,,,Self-recorded/clinical,1. Risk identification,X-Ray
36829688,10.3390/bioengineering10020194,Yes,PMC9952300,36829688.0,2023,2023-02-26,Journal Article,Peer reviewed (PubMed),1,the threat of adversarial attack on a covid-19 ct image-based deep learning system,"The coronavirus disease 2019 (COVID-19) rapidly spread around the world, and resulted in a global pandemic. Applying artificial intelligence to COVID-19 research can produce very exciting results. However, most research has focused on applying AI techniques in the study of COVID-19, but has ignored the security and reliability of AI systems. In this paper, we explore adversarial attacks on a deep learning system based on COVID-19 CT images with the aim of helping to address this problem. Firstly, we built a deep learning system that could identify COVID-19 CT images and non-COVID-19 CT images with an average accuracy of 76.27%. Secondly, we attacked the pretrained model with an adversarial attack algorithm, i.e., FGSM, to cause the COVID-19 deep learning system to misclassify the CT images, and the classification accuracy of non-COVID-19 CT images dropped from 80% to 0%. Finally, in response to this attack, we proposed how a more secure and reliable deep learning model based on COVID-19 medical images could be built. This research is based on a COVID-19 CT image recognition system, which studies the security of a COVID-19 CT image-based deep learning system. We hope to draw more researchers' attention to the security and reliability of medical deep learning systems.",203,COVID-19,1.0,Bioengineering (Basel),Other Topics,,,,,,External,5. Post-hoc,CT
36848720,10.1016/j.media.2023.102771,Yes,PMC9933523,36848720.0,2023,2023-02-28,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,dense regression activation maps for lesion segmentation in ct scans of covid-19 patients,"Automatic lesion segmentation on thoracic CT enables rapid quantitative analysis of lung involvement in COVID-19 infections. However, obtaining a large amount of voxel-level annotations for training segmentation networks is prohibitively expensive. Therefore, we propose a weakly-supervised segmentation method based on dense regression activation maps (dRAMs). Most weakly-supervised segmentation approaches exploit class activation maps (CAMs) to localize objects. However, because CAMs were trained for classification, they do not align precisely with the object segmentations. Instead, we produce high-resolution activation maps using dense features from a segmentation network that was trained to estimate a per-lobe lesion percentage. In this way, the network can exploit knowledge regarding the required lesion volume. In addition, we propose an attention neural network module to refine dRAMs, optimized together with the main regression task. We evaluated our algorithm on 90 subjects. Results show our method achieved 70.2% Dice coefficient, substantially outperforming the CAM-based baseline at 48.6%. We published our source code at GitHub",156,COVID-19;Infections,1.0,Med Image Anal,Algorithms;Semantics;Image Processing;Neural Networks;Map,,,,,,Self-recorded/clinical,Segmentation-only,CT
36874529,10.1140/epjp/s13360-023-03744-5,Yes,PMC9969369,36874529.0,2023,2023-03-07,Journal Article,Peer reviewed (PubMed),1,covid-19 therapy optimization by ai-driven biomechanical simulations,"The COVID-19 disease causes pneumonia in many patients that in the most serious cases evolves into the Acute Distress Respiratory Syndrome (ARDS), requiring assisted ventilation and intensive care. In this context, identification of patients at high risk of developing ARDS is a key point for early clinical management, better clinical outcome and optimization in using the limited resources available in the intensive care units. We propose an AI-based prognostic system that makes predictions of oxygen exchange with arterial blood by using as input lung Computed Tomography (CT), the air flux in lungs obtained from biomechanical simulations and Arterial Blood Gas (ABG) analysis. We developed and investigated the feasibility of this system on a small clinical database of proven COVID-19 cases where the initial CT and various ABG reports were available for each patient. We studied the time evolution of the ABG parameters and found correlation with the morphological information extracted from CT scans and disease outcome. Promising results of a preliminary version of the prognostic algorithm are presented. The ability to predict the evolution of patients' respiratory efficiency would be of crucial importance for disease management.",186,COVID-19;Pneumonia;Syndrome,0.0,Eur Phys J Plus,Other Topics,,,,,,External,4. Prognosis/Treatment,CT
36978673,10.3390/bioengineering10030282,Yes,PMC10045773,36978673.0,2023,2023-03-30,Journal Article,Peer reviewed (PubMed),1,perceptive sars-cov-2 end-to-end ultrasound video classification through x3d and key-frames selection,"The SARS-CoV-2 pandemic challenged health systems worldwide, thus advocating for practical, quick and highly trustworthy diagnostic instruments to help medical personnel. It features a long incubation period and a high contagion rate, causing bilateral multi-focal interstitial pneumonia, generally growing into acute respiratory distress syndrome (ARDS), causing hundreds of thousands of casualties worldwide. Guidelines for first-line diagnosis of pneumonia suggest Chest X-rays (CXR) for patients exhibiting symptoms. Potential alternatives include Computed Tomography (CT) scans and Lung UltraSound (LUS). Deep learning (DL) has been helpful in diagnosis using CT scans, LUS, and CXR, whereby the former commonly yields more precise results. CXR and CT scans present several drawbacks, including high costs. Radiation-free LUS imaging requires high expertise, and physicians thus underutilise it. LUS demonstrated a strong correlation with CT scans and reliability in pneumonia detection, even in the early stages. Here, we present an LUS video-classification approach based on contemporary DL strategies in close collaboration with Fondazione IRCCS Policlinico San Matteo's Emergency Department (ED) of Pavia. This research addressed SARS-CoV-2 patterns detection, ranked according to three severity scales by operating a trustworthy dataset comprising ultrasounds from linear and convex probes in 5400 clips from 450 hospitalised subjects. The main contributions of this study are related to the adoption of a standardised severity ranking scale to evaluate pneumonia. This evaluation relies on video summarisation through key-frame selection algorithms. Then, we designed and developed a video-classification architecture which emerged as the most promising. In contrast, the literature primarily concentrates on frame-pattern recognition. By using advanced techniques such as transfer learning and data augmentation, we were able to achieve an F1-Score of over 89% across all classes.",272,"Pneumonia;Pneumonia, Interstitial;Respiratory Distress Syndrome, Acute",0.0,Bioengineering (Basel),Transfer Learning;Algorithms;Architecture;Lung;Tomography,,,,,,Self-recorded/clinical,3. Monitoring/Severity assessment,Ultrasound
37015231,10.1088/1361-6560/acca5c,Yes,PMC10160739,37015231.0,2023,2023-04-05,"Journal Article;Research Support, N.I.H., Extramural",Peer reviewed (PubMed),1,2d medical image synthesis using transformer-based denoising diffusion probabilistic model,"Artificial intelligence (AI) methods have gained popularity in medical imaging research. The size and scope of the training image datasets needed for successful AI model deployment does not always have the desired scale. In this paper, we introduce a medical image synthesis framework aimed at addressing the challenge of limited training datasets for AI models.Approach. The proposed 2D image synthesis framework is based on a diffusion model using a Swin-transformer-based network. This model consists of a forward Gaussian noise process and a reverse process using the transformer-based diffusion model for denoising. Training data includes four image datasets: chest x-rays, heart MRI, pelvic CT, and abdomen CT. We evaluated the authenticity, quality, and diversity of the synthetic images using visual Turing assessments conducted by three medical physicists, and four quantitative evaluations: the Inception score (IS), Fréchet Inception Distance score (FID), feature similarity and diversity score (DS, indicating diversity similarity) between the synthetic and true images. To leverage the framework value for training AI models, we conducted COVID-19 classification tasks using real images, synthetic images, and mixtures of both images.Main results. Visual Turing assessments showed an average accuracy of 0.64 (accuracy converging to50%indicates a better realistic visual appearance of the synthetic images), sensitivity of 0.79, and specificity of 0.50. Average quantitative accuracy obtained from all datasets were IS = 2.28, FID = 37.27, FDS = 0.20, and DS = 0.86. For the COVID-19 classification task, the baseline network obtained an accuracy of 0.88 using a pure real dataset, 0.89 using a pure synthetic dataset, and 0.93 using a dataset mixed of real and synthetic data.Significance. A image synthesis framework was demonstrated for medical image synthesis, which can generate high-quality medical images of different imaging modalities with the purpose of supplementing existing training sets for AI model deployment. This method has potential applications in many data-driven medical imaging research.",306,COVID-19,0.0,Phys Med Biol,Noise;Image Processing;Tomography,,,,,,External,5. Post-hoc,Multimodal
37161130,10.3934/mbe.2023294,Yes,,37161130.0,2023,2023-05-10,"Journal Article;Research Support, Non-U.S. Gov't",Peer reviewed (PubMed),1,data augmentation based semi-supervised method to improve covid-19 ct classification,"The Coronavirus (COVID-19) outbreak of December 2019 has become a serious threat to people around the world, creating a health crisis that infected millions of lives, as well as destroying the global economy. Early detection and diagnosis are essential to prevent further transmission. The detection of COVID-19 computed tomography images is one of the important approaches to rapid diagnosis. Many different branches of deep learning methods have played an important role in this area, including transfer learning, contrastive learning, ensemble strategy, etc. However, these works require a large number of samples of expensive manual labels, so in order to save costs, scholars adopted semi-supervised learning that applies only a few labels to classify COVID-19 CT images. Nevertheless, the existing semi-supervised methods focus primarily on class imbalance and pseudo-label filtering rather than on pseudo-label generation. Accordingly, in this paper, we organized a semi-supervised classification framework based on data augmentation to classify the CT images of COVID-19. We revised the classic teacher-student framework and introduced the popular data augmentation method Mixup, which widened the distribution of high confidence to improve the accuracy of selected pseudo-labels and ultimately obtain a model with better performance. For the COVID-CT dataset, our method makes precision, F1 score, accuracy and specificity 21.04%, 12.95%, 17.13% and 38.29% higher than average values for other methods respectively, For the SARS-COV-2 dataset, these increases were 8.40%, 7.59%, 9.35% and 12.80% respectively. For the Harvard Dataverse dataset, growth was 17.64%, 18.89%, 19.81% and 20.20% respectively. The codes are available at GitHub",249,COVID-19,0.0,Math Biosci Eng,Transfer Learning;Disease Outbreaks;Tomography;Other Topics,,,,,,External,5. Post-hoc,CT
37168039,10.1590/0100-3984.2022.0049,Yes,PMC10165968,37168039.0,2023,2023-05-12,Journal Article,Peer reviewed (PubMed),1,artificial intelligence to predict the need for mechanical ventilation in cases of severe covid-19,"To determinate the accuracy of computed tomography (CT) imaging assessed by deep neural networks for predicting the need for mechanical ventilation (MV) in patients hospitalized with severe acute respiratory syndrome due to coronavirus disease 2019 (COVID-19). This was a retrospective cohort study carried out at two hospitals in Brazil. We included CT scans from patients who were hospitalized due to severe acute respiratory syndrome and had COVID-19 confirmed by reverse transcription-polymerase chain reaction (RT-PCR). The training set consisted of chest CT examinations from 823 patients with COVID-19, of whom 93 required MV during hospitalization. We developed an artificial intelligence (AI) model based on convolutional neural networks. The performance of the AI model was evaluated by calculating its accuracy, sensitivity, specificity, and AUC (ROC) curve. For predicting the need for MV, the AI model had a sensitivity of 0.417 and a specificity of 0.860. The corresponding AUC for the test set was 0.68. The high specificity of our AI model makes it able to reliably predict which patients will and will not need invasive ventilation. That makes this approach ideal for identifying high-risk patients and predicting the minimum number of ventilators and critical care beds that will be required.",198,COVID-19;Severe Acute Respiratory Syndrome,0.0,Radiol Bras,Polymerase Chain Reaction;ROC Curve;Ventilation;Reverse Transcription,,,,,,Self-recorded/clinical,4. Prognosis/Treatment,CT
37189488,10.3390/diagnostics13081387,Yes,PMC10137174,37189488.0,2023,2023-05-16,Journal Article,Peer reviewed (PubMed),1,prognosis prediction in covid-19 patients through deep feature space reasoning,"The COVID-19 pandemic has presented a unique challenge for physicians worldwide, as they grapple with limited data and uncertainty in diagnosing and predicting disease outcomes. In such dire circumstances, the need for innovative methods that can aid in making informed decisions with limited data is more critical than ever before. To allow prediction with limited COVID-19 data as a case study, we present a complete framework for progression and prognosis prediction in chest X-rays (CXR) through reasoning in a COVID-specific deep feature space. The proposed approach relies on a pre-trained deep learning model that has been fine-tuned specifically for COVID-19 CXRs to identify infection-sensitive features from chest radiographs. Using a neuronal attention-based mechanism, the proposed method determines dominant neural activations that lead to a feature subspace where neurons are more sensitive to COVID-related abnormalities. This process allows the input CXRs to be projected into a high-dimensional feature space where age and clinical attributes like comorbidities are associated with each CXR. The proposed method can accurately retrieve relevant cases from electronic health records (EHRs) using visual similarity, age group, and comorbidity similarities. These cases are then analyzed to gather evidence for reasoning, including diagnosis and treatment. By using a two-stage reasoning process based on the Dempster-Shafer theory of evidence, the proposed method can accurately predict the severity, progression, and prognosis of a COVID-19 patient when sufficient evidence is available. Experimental results on two large datasets show that the proposed method achieves 88% precision, 79% recall, and 83.7% F-score on the test sets.",251,COVID-19;COVID-19 Pandemic;Infections,0.0,Diagnostics (Basel),Other Topics,,,,,,External,4. Prognosis/Treatment,X-Ray
37219059,10.1002/jmv.28787,Yes,,37219059.0,2023,2023-05-23,Journal Article,Peer reviewed (PubMed),1,artificial neural network based prediction of the lung tissue involvement as an independent in-hospital mortality and mechanical ventilation risk factor in covid-19,"During COVID-19 pandemic, artificial neural network (ANN) systems have been providing aid for clinical decisions. However, to achieve optimal results, these models should link multiple clinical data points to simple models. This study aimed to model the in-hospital mortality and mechanical ventilation risk using a two step approach combining clinical variables and ANN-analyzed lung inflammation data. A data set of 4317 COVID-19 hospitalized patients, including 266 patients requiring mechanical ventilation, was analyzed. Demographic and clinical data (including the length of hospital stay and mortality) and chest computed tomography (CT) data were collected. Lung involvement was analyzed using a trained ANN. The combined data were then analyzed using unadjusted and multivariate Cox proportional hazards models. Overall in-hospital mortality associated with ANN-assigned percentage of the lung involvement, age category, procalcitonin, glomerular filtration rate (eGFR) and troponin. Furthermore, the risk of mechanical ventilation is also associated with ANN-based percentage of lung inflammation, age, procalcitonin and clinical variables, including diabetes, cardiovascular and cerebrovascular disease and chronic pulmonary disease. ANN-based lung tissue involvement is the strongest predictor of unfavorable outcomes in COVID-19 and represents a valuable support tool for clinical decisions.",186,COVID-19;COVID-19 Pandemic;Cerebrovascular Disorders;Lung Diseases;Pneumonia;Pneumonitis,0.0,J Med Virol,Study;C-Reactive Protein;Neural Networks;Retrospective Studies,,,,,,Self-recorded/clinical,5. Post-hoc,CT
37237626,10.3390/bioengineering10050556,Yes,PMC10215672,37237626.0,2023,2023-05-27,Journal Article,Peer reviewed (PubMed),1,deepcovid-fuse: a multi-modality deep learning model fusing chest x-rays and clinical variables to predict covid-19 risk levels,"The COVID-19 pandemic has posed unprecedented challenges to global healthcare systems, highlighting the need for accurate and timely risk prediction models that can prioritize patient care and allocate resources effectively. This study presents DeepCOVID-Fuse, a deep learning fusion model that predicts risk levels in patients with confirmed COVID-19 by combining chest radiographs (CXRs) and clinical variables. The study collected initial CXRs, clinical variables, and outcomes (i.e., mortality, intubation, hospital length of stay, Intensive care units (ICU) admission) from February to April 2020, with risk levels determined by the outcomes. The fusion model was trained on 1657 patients (Age: 58.30 ; Female: 807) and validated on 428 patients from the local healthcare system and tested on 439 patients from a different holdout hospital. The performance of well-trained fusion models on full or partial modalities was compared using DeLong and McNemar tests. Results show that DeepCOVID-Fuse significantly (p < 0.05) outperformed models trained only on CXRs or clinical variables, with an accuracy of 0.658 and an AUC of 0.842. The fusion model achieves good outcome predictions even when only one of the modalities is used in testing, demonstrating its ability to learn better feature representations across different modalities during training.",198,COVID-19;COVID-19 Pandemic,,Bioengineering (Basel),Intensive Care Units;Health Care;Health;Area under Curve;Receiver Operating Characteristic,,,,,,Self-recorded/clinical,1. Risk identification,Multimodal
rs-114267,10.21203/rs.3.rs-114267/v1,Yes,,,2020,2020-12-11,Preprint,Research Square,0,dabc-net for robust pneumonia segmentation and prediction of covid-19 progression on chest ct scans,"Currently, reliable, robust and ready-to-use CT-based tools for prediction of COVID-19 progression are still lacking. To address this problem, we present DABC-Net, a novel deep learning (DL) tool that combines a 2D U-net for intra-slice spatial information processing, and a recurrent LSTM network to leverage inter-slice context, for automatic volumetric segmentation of lung and pneumonia lesions. We evaluate DABC-Net on more than 10,000 radiologists-labeled CT slices from four different cohorts. Compared to state-of-the-art segmentation tools, DABC-Net is much faster, more robust, and able to estimate segmentation uncertainty. Based only on the first two CT scans within 3 days after admission from 656 longitudinal CT scans, the AUC of our DBAC-Net for disease progression prediction reaches 93%. We release our tool as a GUI for patient-specific prediction of pneumonia progression, to provide clinicians with additional assistance to triage patients at early days after the diagnosis and to optimize the assignment of limited medical resources, which is of particular importance in current critical COVID-19 pandemic.",163,COVID-19;COVID-19 Pandemic;Disease Progression;Pneumonia,,,Art;Lung Diseases;Area under Curve,,,,,,External,4. Prognosis/Treatment,CT
rs-1396136,10.21203/rs.3.rs-1396136/v1,Yes,,,2022,2022-03-11,Preprint,Research Square,0,exploration of interpretability techniques for deep covid-19 classification using chest x-ray images,"The outbreak of COVID-19 has shocked the entire world with its fairly rapid spread and has challenged different sectors. One of the most effective ways to limit its spread is the early and accurate diagnosis of infected patients. Medical imaging such as X-ray and Computed Tomography (CT) combined with the potential of Artificial Intelligence (AI) plays an essential role in supporting the medical staff in the diagnosis process. Thereby, five different deep learning models (ResNet18, ResNet34, InceptionV3, InceptionResNetV2, and DenseNet161) and their Ensemble have been used in this paper, to classify COVID-19, pneumoniae and healthy subjects using Chest X-Ray images. Multi-label classification was performed to predict multiple pathologies for each patient, if present. Foremost, the interpretability of each of the networks was thoroughly studied using techniques like occlusion, saliency, input X gradient, guided backpropagation, integrated gradients, and DeepLIFT. The mean Micro-F1 score of the models for COVID-19 classifications ranges from 0.66 to 0.875, and is 0.89 for the Ensemble of the network models. The qualitative results depicted the ResNets to be the most interpretable models.",175,COVID-19,,,Disease Outbreaks;Other Topics,,,,,,External,2. Detection/Diagnosis,X-Ray
rs-28201,10.21203/rs.3.rs-28201/v1,Yes,,,2020,2020-05-12,Preprint,Research Square,0,role of novel deep-learning-based ct used in management and discharge of covid-19 patients at a “square cabin” hospital in china,"The chest computed tomography (CT) had been used to define the diagnostic and discharge criteria for COVID-19. However, it is difficult to determine the suitability for discharge of a patient with COVID-19 based on CT features in a clinical setting. Deep learning (DL) technology has demonstrated great success in the medical imaging. This study applied the novel deep learning (DL) on chest computed tomography (CT) of COVID-19 patients with consecutive negative respiratory pathogen nucleic acid test results at a “square cabin” hospital in Wuhan, China, with the intent to standardize criteria for discharge. The study included 270 patients (102men, 168 women; mean age, 51.9 years) who had two consecutive negative respiratory pathogen tests (sampling interval: ≥1 day) and underwent low-dose CT 1 day after the first negative test, with strict adherence to epidemic prevention standards. The chest CT of COVID-19 patients with negative nucleic acid tests were evalued by DL, and the standard for discharge was a total volume ratio of lesions to lung of less than 50% determined by DL. The average intersection over union is 0.7894. Fifty-seven and 213 patients exhibited normal lung findings and pneumonia, respectively. 54.0% involved mild interstitial fibrosis. 18.8% had total volume ratio of lesions to lung of more than and equal to 50% according to our severity scale and were monitored continuously in hospital, and three cases of which had a positive follow-up nucleic acid test during hospital observation. None of the 230 discharged cases later tested positive or exhibited pneumonia progression. The novel DL enables the accurate management of COVID-19 patients and can help avoid cluster transmission or exacerbation due to patients with false negitive acid test.",275,COVID-19;Fibrosis;Pneumonia,,,Fibrosis;Nucleic Acids,,,,,,External,5. Post-hoc,CT
rs-52343,10.21203/rs.3.rs-52343/v2,Yes,,,2020,2020-09-16,Preprint,Research Square,0,development a quantitative segmentation model to assess the effect of comorbidity on patients with covid-19,"The coronavirus disease 2019 (COVID-19) has brought a global disaster. Quantitative lesions may provide the radiological evidence of the severity of pneumonia and further to assess the effect of comorbidity on patients with COVID-19. 294 patients with COVID-19 were enrolled from February, 24, 2020 to June, 1, 2020 from six centers. Multi-task Unet network was used to segment the whole lung and lesions from chest CT images. This deep learning method was pre-trained in 650 CT images (550 in primary dataset and 100 in test dataset) with COVID-19 or community acquired pneumonia and Dice coefficients in test dataset were calculated. 50 CT scans of 50 patients (15 with comorbidity and 35 without comorbidity) were random selected to mark lesions manually. The results will be compared with the automatic segmentation model. Eight quantitative parameters were calculated based on the segmentation results to evaluate the effect of comorbidity on patients with COVID-19. Quantitative segmentation model was proved to be effective and accurate with all Dice coefficients more than 0.85 and all accuracies more than 0.95. Of the 294 patients, 52 patients were reported having at least one comorbidity, 14 having more than one comorbidity. Patients with any comorbidity were older (P<0.001), had longer incubation period (P<0.001), were more likely to have abnormal laboratory findings (P<0.05) and be in severity status (P<0.001). More lesions (including larger volume of lesion, consolidation and ground-glass opacity) were shown in patients with any comorbidity than patients without comorbidity (all P<0.001). More lesions were found on CT images in patients with more comorbidities. The median volumes of lesion, consolidation and ground-glass opacity in diabetes mellitus group were largest among the groups with single comorbidity that had the incidence rate of top three. Multi-task Unet network can make quantitative CT analysis of lesions to assess the effect of comorbidity on patients with COVID-19, further to provide the radiological evidence of the severity of pneumonia. More lesions (including GGO and consolidation) were found in CT images of cases with comorbidity. The more comorbidities patients have, the more lesions CT images show.",341,COVID-19;Diabetes Mellitus;Pneumonia,,,Dataset;Eyeglasses,,,,,,Self-recorded/clinical,1. Risk identification,CT
rs-763355,10.21203/rs.3.rs-763355/v1,Yes,,,2021,2021-07-30,Preprint,Research Square,0,how adversarial attacks affect deep neural networks detecting covid-19?,"Considering the global crisis of Coronavirus infection (COVID-19), the essence of utilizing novel approaches to achieve quick and accurate diagnosing methods is required. Deep Neural Networks (DNN) showed outstanding capabilities in classifying various data types, including medical images, in order to build a practical automatic diagnosing system. Therefore, DNNs can help the healthcare system to reduce patients waiting time. However, despite acceptable accuracy and low false-negative rate of DNNs in medical image classification, they have shown vulnerabilities in terms of adversarial attacks. Such input can lead the model to misclassification. This paper investigated the effect of these attacks on five commonly used neural networks, including ResNet-18, ResNet-50, Wide ResNet-16-8 (WRN-16-8), VGG-19, and Inception v3. Four adversarial attacks, including Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), Carlini and Wagner (C and W), and Spatial Transformations Attack (ST), were used to complete this investigation. Average accuracy on test images was 96.7\% and decreased to 41.1%, 25.5%, 50.1%, and 56.3% in FGSM, PGD, C and W, and ST, respectively. Results are indicating that ResNet-50 and WRN-16-8 were generally less affected by attacks. Therefore using defence methods in these two models can enhance their performance encountering adversarial perturbations.",196,COVID-19;Coronavirus Infections,,,Coronavirus Infections;Health Care,,,,,,External,5. Post-hoc,Multimodal
rs-78075,10.21203/rs.3.rs-78075/v1,Yes,,,2020,2020-09-18,Preprint,Research Square,0,association of initial symptoms or comorbidities with pneumonia lesions in covid-19 patients: based on artificial intelligence-enabled ct quantitation,"Coronavirus disease 2019 (COVID-19) patients with a larger ratio of pneumonia lesions are more likely to progress to acute respiratory distress syndrome and death. This study aimed to investigate the relationship of baseline parameters with pneumonia lesions on admission, as quantified by an artificial intelligence (AI) algorithm using computed tomography (CT) images. This retrospective study quantitatively assessed lung lesions on CT using an AI algorithm in 1630 consecutive patients confirmed with COVID-19 on admission and classified the patients into none, mild, intermediate, and severe groups, according to the lesion ratio of the whole lung. A multivariate linear regression model was established to explore the relationship between the lesion ratio and laboratory parameters. The baseline parameters associated with lung lesions, including demographics, initial symptoms, and comorbidities, were determined using a multivariate ordinal regression model. The 1630 patients confirmed with COVID-19 had a median whole lung lesion ratio of 4.1%, and the right lower lung lobe had the most lesions among the five lung lobes based on the evaluation of CT using AI algorithm. The whole lung lesion ratio was associated with the levels of plasma fibrinogen (r=0.280, p<0.001), plasma D-dimer (r=0.248, p<0.001), serum α-hydroxybutyrate dehydrogenase (r=0.363, p<0.001), serum albumin (r=-0.300, p<0.001), and peripheral blood leukocyte count (r=0.194, p<0.001). Among the four patients groups categorised by whole lung lesion ratio, the highest frequency of cough (p<0.001) and shortness of breath (p<0.001) were found in the severe group, and the highest frequency of hypertension (p<0.001), diabetes (p<0.001) and anemia (p=0.039) were observed in the intermediate group. Based on baseline ordinal regression analysis, cough (p=0.009), shortness of breath (p<0.001), hypertension (p=0.002), diabetes (p=0.005), and anemia (p=0.006) were independent risk factors for more severe lung lesions. Based on AI-enabled CT quantitation, patients with initial symptoms of cough/shortness of breath, or with comorbidities of hypertension, diabetes, or anemia, had a higher risk for more severe lung lesions on admission in COVID-19 patients.",316,"Anemia;COVID-19;Cough;Death;Dyspnea;Hypertension;Pneumonia;Respiratory Distress Syndrome, Acute",,,Risk Factors;Retrospective Studies,,,,,,Self-recorded/clinical,1. Risk identification,CT
